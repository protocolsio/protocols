{"access":{"can_view":true,"can_edit":false,"can_remove":false,"can_add":false,"can_publish":false,"can_get_doi":false,"can_share":true,"can_move":true,"can_move_outside":true,"can_transfer":true,"can_download":true,"limited_run":false,"limited_private_links":false,"limited_blind_links":false,"is_locked":false},"authors":[{"name":"Mieke Ronckers","affiliation":"Human-Technology Interaction group, Eindhoven University of Technology;Eindhoven Artificial Intelligence Systems Institute","affiliation_url":null,"username":"","link":null,"image":{"source":"","placeholder":"","webp_source":""},"note":"","is_verified_user":false},{"name":"Rianne Conijn","affiliation":"Human-Technology Interaction group, Eindhoven University of Technology;Eindhoven Artificial Intelligence Systems Institute","affiliation_url":null,"username":"n4wle132w1w4qle1","link":null,"image":{"source":"/img/avatars/010.png","placeholder":"/img/avatars/010.png","webp_source":""},"note":"","is_verified_user":true},{"name":"Chris Snijders","affiliation":"Human-Technology Interaction group, Eindhoven University of Technology","affiliation_url":null,"username":"n4wle132w1w4rle1","link":null,"image":{"source":"/img/avatars/004.png","placeholder":"/img/avatars/004.png","webp_source":""},"note":"","is_verified_user":false}],"before_start":"","book_chapter":null,"can_accept_authorship":false,"can_be_copied":true,"can_claim_authorship":false,"can_manage_keywords":true,"can_remove_fork":false,"can_sign":false,"child_steps":{},"cited_protocols":[],"collection_items":[],"created_on":1714376970,"creator":{"name":"Mieke Ronckers","affiliation":"Human-Technology Interaction group, Eindhoven University of Technology","affiliation_url":"","username":"mieke-ronckers","link":"","image":{"source":"/img/avatars/001.png","placeholder":"/img/avatars/001.png","webp_source":""},"badges":[],"affiliations":[{"affiliation":"Human-Technology Interaction group, Eindhoven University of Technology","url":"","job_title":"","is_default":true},{"affiliation":"Eindhoven Artificial Intelligence Systems Institute","url":"","job_title":"","is_default":false}]},"cross_cloud_origin":null,"description":"{\"blocks\":[{\"key\":\"1rjfc\",\"text\":\"In this protocol, we outline the steps for a systematic review on different implementations of Explainable Artificial Intelligence (XAI) evaluated by end-users. We aim to answer the research question: How do different implementations of XAI influence human-AI interaction? Therefore, we search for studies that compare different implementations of XAI to each other on human-AI interaction outcomes, such as user-perception measures and collaboration performance measures. We aim to create an overview of empirical studies that involve humans in the evaluation of XAI and compare different XAI implementations to each other, to gain more understanding on the factors contributing to a good explanation of AI systems and how this could be potentially different between application domains.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","disclaimer":"{\"blocks\":[{\"key\":\"ded8j\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","document":"","documents":null,"doi":"dx.doi.org/10.17504/protocols.io.n92ld89e8v5b/v1","doi_status":1,"ethics_statement":null,"fork_id":null,"fork_info":null,"forks":[],"funders":[],"groups":[],"guid":"169FB5BFC8734BCEB6E4E57BF075B17F","guidelines":"{\"blocks\":[{\"key\":\"8vuk2\",\"text\":\"In this protocol, we followed the PRISMA guidelines for systematic reviews (Shamseer et al., 2015).\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","has_references":true,"has_step_reagents":false,"has_versions":false,"id":98935,"image":{"source":"https://www.protocols.io/img/default_protocol.png","webp_source":null,"placeholder":"https://www.protocols.io/img/default_protocol.png","webp_placeholder":null},"image_attribution":"","in_trash":false,"is_bookmarked":false,"is_contact_suspended":false,"is_content_confidential":false,"is_content_warning":false,"is_doi_reserved":false,"is_in_pending_publishing":false,"is_in_transfer":false,"is_owner":true,"is_research":true,"is_retracted":false,"is_shared_directly":false,"is_subprotocol":null,"is_unlisted":false,"item_id":1243239,"journal":null,"journals":[],"keywords":"Explainable AI,Systematic review,End-user evaluation","last_modified":1715590867,"link":"","location":null,"manuscript_citation":"","materials":[],"materials_text":"","ownership_history":null,"parent_collections":[],"parent_protocols":[],"peer_reviewed":false,"protocol_references":"{\"blocks\":[{\"key\":\"b9bi8\",\"text\":\"Bussone, A., Stumpf, S., \\u0026 O’Sullivan, D. (2015). The role of explanations on trust and reliance in clinical decision support systems. Proceedings - 2015 IEEE International Conference on Healthcare Informatics, ICHI 2015, 160–169. https://doi.org/10.1109/ICHI.2015.26\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"italic\",\"offset\":135,\"length\":85}],\"entityRanges\":[],\"data\":{}},{\"key\":\"d8krt\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"81r5h\",\"text\":\"Cai, C. J., Winter, S., Steiner, D., Wilcox, L., \\u0026 Terry, M. (2019). “Hello Ai”: Uncovering the onboarding needs of medical practitioners for human–AI collaborative decision-making. In Proceedings of the ACM on Human-Computer Interaction (Vol. 3, Issue CSCW). Association for Computing Machinery. https://doi.org/10.1145/3359206\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"italic\",\"offset\":185,\"length\":52}],\"entityRanges\":[],\"data\":{}},{\"key\":\"9ofhh\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"7tc2f\",\"text\":\"Dodge, J., Vera Liao, Q., Zhang, Y., Bellamy, R. K. E., \\u0026 Dugan, C. (2019). Explaining models: An empirical study of how explanations impact fairness judgment. International Conference on Intelligent User Interfaces, Proceedings IUI, Part F147615, 275–285. https://doi.org/10.1145/3301275.3302310\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"italic\",\"offset\":160,\"length\":72},{\"style\":\"italic\",\"offset\":234,\"length\":12}],\"entityRanges\":[],\"data\":{}},{\"key\":\"298cj\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"5dqtc\",\"text\":\"Farrow, R. (2023). The possibilities and limits of XAI in education: a socio-technical perspective. Learning, Media and Technology, 48(2), 266–279. https://doi.org/10.1080/17439884.2023.2185630\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"italic\",\"offset\":100,\"length\":30},{\"style\":\"italic\",\"offset\":132,\"length\":2}],\"entityRanges\":[],\"data\":{}},{\"key\":\"1p271\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"9guk9\",\"text\":\"Haque, A. B., Islam, A. K. M. N., \\u0026 Mikalef, P. (2023). Explainable Artificial Intelligence (XAI) from a user perspective: A synthesis of prior literature and problematizing avenues for future research. Technological\\nForecasting and Social Change, 186. https://doi.org/10.1016/j.techfore.2022.122120\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"italic\",\"offset\":203,\"length\":43},{\"style\":\"italic\",\"offset\":248,\"length\":3}],\"entityRanges\":[],\"data\":{}},{\"key\":\"io31\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"7rk60\",\"text\":\"Hong, Q. N., Fàbregues, S., Bartlett, G., Boardman, F., Cargo, M., Dagenais, P., Gagnon, M.-P., Griffiths, F., Nicolau, B., O’Cathain, A., Rousseau, M.-C., Vedel, I., \\u0026 Pluye, P. (2018). The Mixed Methods Appraisal\\nTool (MMAT) version 2018 for information professionals and researchers. Education for Information, 34(4), 285–291. https://doi.org/10.3233/EFI-180221\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"italic\",\"offset\":287,\"length\":25},{\"style\":\"italic\",\"offset\":314,\"length\":2}],\"entityRanges\":[],\"data\":{}},{\"key\":\"4fv4\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"fd7rd\",\"text\":\"Laato, S., Tiainen, M., Najmul Islam, A. K. M., \\u0026 Mäntymäki, M. (2021). How to explain AI systems to end users: a systematic literature review and research agenda. Internet Research, 32(7), 1–31. https://doi.org/10.1108/INTR-08-2021-0600\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"italic\",\"offset\":164,\"length\":17},{\"style\":\"italic\",\"offset\":183,\"length\":2}],\"entityRanges\":[],\"data\":{}},{\"key\":\"3kh3j\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"3b404\",\"text\":\"Miller, T. (2019). Explanation in artificial intelligence: Insights from the social sciences. In Artificial Intelligence (Vol. 267, pp. 1–38). Elsevier B.V. https://doi.org/10.1016/j.artint.2018.07.007 \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"italic\",\"offset\":97,\"length\":23}],\"entityRanges\":[],\"data\":{}},{\"key\":\"3fb3r\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"3ro16\",\"text\":\"Nauta, M., Trienes, J., Pathak, S., Nguyen, E., Peters, M., Schmitt, Y., Schlötterer, J., Van Keulen, M., \\u0026 Seifert, C. (2023). From Anecdotal Evidence to Quantitative Evaluation Methods: A Systematic Review on Evaluating Explainable AI. ACM Computing Surveys, 55(13). https://doi.org/10.1145/3583558\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"italic\",\"offset\":238,\"length\":21},{\"style\":\"italic\",\"offset\":261,\"length\":2}],\"entityRanges\":[],\"data\":{}},{\"key\":\"69sa4\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"35g4o\",\"text\":\"Ouzzani, M., Hammady, H., Fedorowicz, Z., \\u0026 Elmagarmid, A. (2016). Rayyan—a web and mobile app for systematic reviews. Systematic Reviews, 5(1), 210. https://doi.org/10.1186/s13643-016-0384-4\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"italic\",\"offset\":119,\"length\":18},{\"style\":\"italic\",\"offset\":139,\"length\":1}],\"entityRanges\":[],\"data\":{}},{\"key\":\"n4vq\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"eokf1\",\"text\":\"Rong, Y., Leemann, T., Nguyen, T. T., Fiedler, L., Qian, P., Unhelkar, V., Seidel, T., Kasneci, G., \\u0026 Kasneci, E.\\n(2024). Towards Human-Centered Explainable AI: A Survey of User Studies for Model Explanations. IEEE Transactions on Pattern Analysis and Machine Intelligence, 46(4), 2104–2122. https://doi.org/10.1109/TPAMI.2023.3331846\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"italic\",\"offset\":210,\"length\":62},{\"style\":\"italic\",\"offset\":274,\"length\":2}],\"entityRanges\":[],\"data\":{}},{\"key\":\"6t4i3\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"bqq4j\",\"text\":\"Shamseer, L., Moher, D., Clarke, M., Ghersi, D., Liberati, A., Petticrew, M., Shekelle, P., Stewart, L. A., Altman, D. G., Booth, A., Chan, A. W., Chang, S., Clifford, T., Dickersin, K., Egger, M., Gøtzsche, P. C.,\\nGrimshaw, J. M., Groves, T., Helfand, M., … Whitlock, E. (2015). Preferred reporting items for systematic review and meta-analysis protocols (prisma-p) 2015: Elaboration and explanation. In BMJ (Online) (Vol. 349). BMJ Publishing Group. https://doi.org/10.1136/bmj.g7647\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"italic\",\"offset\":405,\"length\":12}],\"entityRanges\":[],\"data\":{}},{\"key\":\"3m18h\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"95ilq\",\"text\":\"Wang, D., Yang, Q., Abdul, A., \\u0026 Lim, B. Y. (2019, May 2). Designing theory-driven user-centric explainable AI. Conference on Human Factors in Computing Systems - Proceedings. https://doi.org/10.1145/3290605.3300831\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"italic\",\"offset\":112,\"length\":62}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","public":true,"public_fork_note":"","published_on":1715590867,"references":[],"related_equipments":[],"related_materials":[],"reserved_doi":"","retraction_reason":null,"samples":{},"shared_access_id":265,"show_comparison":false,"sign_info":null,"space_access":{"can_view":false,"can_edit":false,"can_remove":false,"can_add":false,"can_publish":true,"can_get_doi":true,"can_share":false,"can_move":false,"can_move_outside":false,"can_transfer":false,"can_download":false,"limited_run":false,"limited_private_links":false,"limited_blind_links":false,"is_locked":false},"space_id":121637,"state_version_id":568,"stats":{"is_voted":false,"number_of_views":24,"number_of_steps":12,"number_of_bookmarks":0,"number_of_comments":0,"number_of_bookmarked_comments":0,"number_of_steps_comments":0,"number_of_protocol_comments":0,"number_of_exports":0,"number_of_runs":0,"number_of_votes":0,"number_of_reagents":0,"number_of_equipments":0,"number_of_collections":0,"number_of_forks":{"private":0,"public":0},"number_of_accessible_forks":0},"status":{"id":1,"info":""},"steps":[{"id":2034183,"guid":"8D3323AA08ED469FB59A3F9D96B1DCF6","previous_id":2044458,"previous_guid":"5BC5FECCBD9340F2B4A66277B0DE4ABD","section":"\u003cp\u003eIntroduction\u003c/p\u003e","section_color":"#A492FF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"912sp\",\"text\":\"Objectives\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":10}],\"entityRanges\":[],\"data\":{}},{\"key\":\"6o6h6\",\"text\":\"Research question:\\nWith this systematic review, we aim to answer the following research question: How do different implementations of explainable Artificial Intelligence (XAI) influence human-AI interaction, both subjectively (perceptions of humans on AI advice) and objectively (performance of human-AI interaction)?\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"italic\",\"offset\":0,\"length\":18},{\"style\":\"italic\",\"offset\":98,\"length\":219}],\"entityRanges\":[],\"data\":{}},{\"key\":\"1ujc4\",\"text\":\" \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"43qob\",\"text\":\"Objective:\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"italic\",\"offset\":0,\"length\":10}],\"entityRanges\":[],\"data\":{}},{\"key\":\"15ups\",\"text\":\"We aim to create an overview of empirical studies that involve humans in the evaluation of XAI and compare different XAI implementations to each other, to gain more understanding on the factors  contributing to a good explanation of AI systems and how this could be potentially different between\\napplication domains.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":98935,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"2","cases":[],"critical":null},{"id":2034185,"guid":"B9AF9DA223E1480B8CB14521D73BBA89","previous_id":2036311,"previous_guid":"A5B5760902224957B1B4951FB09DCB21","section":"\u003cp\u003eMethods\u003c/p\u003e","section_color":"#94EBFF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"h8v2\",\"text\":\"Information sources\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":19}],\"entityRanges\":[],\"data\":{}},{\"key\":\"844al\",\"text\":\"We will search the electronic databases WebOfScience, Scopus, IEEE explore, and ACM DL. To ensure literature saturation, we will scan the reference lists of included studies or relevant reviews identified through the search. Additionally, we will use the AI-tool “Connected papers” to identify related papers of the included studies, in a similar manner to scanning the reference lists. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":98935,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"4","cases":[],"critical":null},{"id":2034187,"guid":"59ADD76C19424E7EAFC50822703C9A21","previous_id":2034185,"previous_guid":"B9AF9DA223E1480B8CB14521D73BBA89","section":"\u003cp\u003eMethods\u003c/p\u003e","section_color":"#94EBFF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"3d4rq\",\"text\":\"Search strategy\\nWe will search for words related to XAI and user-studies. The general search strategy will be as follows:\\n(   XAI\\n    OR\\n    (   (explanation OR explainable OR explanatory OR interpretable OR intelligible OR explainability OR  interpretability OR intelligibility)\\n        NEAR\\n        (AI OR “Artificial Intelligence” OR “black-box” OR “machine learning” OR “recommender system*”)\\n    )\\n)\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":15}],\"entityRanges\":[],\"data\":{}},{\"key\":\"988c\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"a8cum\",\"text\":\"AND\\n(“user study” OR participant* OR “human subject*” OR “empirical study” OR “lab study” OR “user evaluation” OR “human evaluation” OR “end-user*” OR “user experiment*”)\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"553oj\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"4dfgp\",\"text\":\"NOT\\n( “model calibration” OR “validation data” OR “model performance” OR “cross validation”)\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"h0gb\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"em597\",\"text\":\"Limits\\nThe search will be limited to title, abstract, and keywords. If not possible for one of the databases, we will use a full-text search.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"italic\",\"offset\":0,\"length\":6}],\"entityRanges\":[],\"data\":{}},{\"key\":\"b8al9\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"5fdau\",\"text\":\"Example of search query in Web Of Science:\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"italic\",\"offset\":0,\"length\":42}],\"entityRanges\":[],\"data\":{}},{\"key\":\"bd95h\",\"text\":\"TS=(XAI OR ((explanation OR explainable OR explanatory OR interpretable OR intelligible OR explainability OR  interpretability OR intelligibility) NEAR3 (AI OR “Artificial Intelligence” OR “black-box” OR “machine learning” OR “recommender system*”))) AND TS=(“user study” OR participant* OR “human subject*” OR “empirical study” OR “lab study” OR “user evaluation” OR “human evaluation” OR “end-user*” OR “user experiment*”) NOT TS=( “model calibration” OR “validation data” OR “model performance” OR “cross validation”)\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"u1hd\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"bhj2m\",\"text\":\"The NEAR operator is used to check if these terms appear within a 15 words distance.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":98935,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"5","cases":[],"critical":null},{"id":2034188,"guid":"C4D69A0269E24458A158225690B12189","previous_id":2034187,"previous_guid":"59ADD76C19424E7EAFC50822703C9A21","section":"\u003cp\u003eMethods\u003c/p\u003e","section_color":"#94EBFF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"an23p\",\"text\":\"Study records\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":13}],\"entityRanges\":[],\"data\":{}},{\"key\":\"el7fb\",\"text\":\"Data management\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"italic\",\"offset\":0,\"length\":15}],\"entityRanges\":[],\"data\":{}},{\"key\":\"f8st3\",\"text\":\"The results from the literature search will be downloaded from the databases and uploaded to Rayyan.ai, an online tool for organizing systematic reviews (Ouzzani et al., 2016). We will use the function for automatically resolving duplicates, for duplicates with a similarity of 97% of higher. Other duplicates will be manually screened by MR and removed if necessary. For screening, Rayyan.ai will be used for both the first screening round (title and abstracts), and the second round (full-text), making use of the “blind mode”. Since Rayyan does not offer an automatic full-text search, we will manually search and download the full-text versions and upload it to Rayyan for full-text screening.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"fe9cv\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"825b6\",\"text\":\"Selection process\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"italic\",\"offset\":0,\"length\":17}],\"entityRanges\":[],\"data\":{}},{\"key\":\"1ojac\",\"text\":\"Prior to the formal screening process, we will perform a pilot to refine the screening criteria and to reach consensus among all authors. Then, MR will screen all search results on titles and abstracts, taking a lenient perspective. All studies that are clearly not meeting the criteria will be excluded by MR. Other studies will be presented to RC and CS as well for title-abstract screening. All authors will screen these\\npapers independently and blinded to other’s decisions.  \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"3gjh4\",\"text\":\" \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"9s1kt\",\"text\":\"After the title-abstract screening, we will obtain full reports for studies that are not excluded after the first round. Then, full-text screening will be done with a procedure similar to the title-abstract screening. First, MR will screen all papers and exclude papers clearly not meeting the criteria. Then, all authors will screen the full-text of the remaining papers independently and blinded to other’s decisions. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"6tfoc\",\"text\":\" \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"5k85n\",\"text\":\"For all steps, disagreements will be resolved through discussion between all authors. We will record the reasons for excluding trials. The authors will not be blinded to the journal titles, study authors, or institutions.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"5acj0\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"4e3me\",\"text\":\"Data collection process\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"italic\",\"offset\":0,\"length\":23}],\"entityRanges\":[],\"data\":{}},{\"key\":\"9rvid\",\"text\":\"The data of the included papers will be extracted by MR. To reduce bias or errors in the data extraction, RC and CS will check the extracted data from a random sample of the papers. Disagreements will be resolved through discussion. Extracted data will include research aim, methodology, participant demographics, XAI details, and all reported human-AI interaction outcomes. All extracted data will be collected in a table (through Excel or similar software). If (part of) the information is not presented in the paper and not available through supplementary materials, we will contact authors for additional data, with a maximum of three email attempts.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"6jmfp\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"fvt4i\",\"text\":\"Data items\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"italic\",\"offset\":0,\"length\":10}],\"entityRanges\":[],\"data\":{}},{\"key\":\"3men3\",\"text\":\"We will extract the following information from included papers: \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"dq36t\",\"text\":\"Research question and aim, hypotheses \",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"5qo2r\",\"text\":\"Information about the AI system: type of AI model, accuracy, confidence, etc. \",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"4q0ch\",\"text\":\"Design of XAI implementations, e.g., visuals, text, XAI method/algorithm, exact wording.\",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"8b099\",\"text\":\"Application domain and the presented scenario/script \",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"3prrh\",\"text\":\"Study design, such as number of conditions, procedure, etc. \",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"9hopi\",\"text\":\"Measurements of human-AI interaction (e.g., questionnaires, time measurements, performance measurments, interview questions)\",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"bm6qe\",\"text\":\"Sample sizes and participant characteristics\",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"2j4a6\",\"text\":\"Results of XAI implementations on human-AI interaction outcomes (statistical tests, p-values, effect sizes, themes and codes) \",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"f2v44\",\"text\":\"Results of other factors influencing or mediating the results (e.g., individual characteristics)\",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":98935,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"6","cases":[],"critical":null},{"id":2036311,"guid":"A5B5760902224957B1B4951FB09DCB21","previous_id":2034183,"previous_guid":"8D3323AA08ED469FB59A3F9D96B1DCF6","section":"\u003cp\u003eMethods\u003c/p\u003e","section_color":"#94EBFF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"4l44d\",\"text\":\"Elegibility criteria\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":20}],\"entityRanges\":[],\"data\":{}},{\"key\":\"7l8mj\",\"text\":\"Studies will be selected according to the criteria outlined below.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"e64tv\",\"text\":\" \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"bm53r\",\"text\":\"Study designs\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"italic\",\"offset\":0,\"length\":13}],\"entityRanges\":[],\"data\":{}},{\"key\":\"ad4fv\",\"text\":\"We will include all types of studies that involve human participants: e.g., user studies and experiments. Studies can be both qualitative and quantitative. We will exclude cross-sectional studies, case series, and case reports. Additionally, evaluation frameworks and literature studies will be excluded.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"1tgre\",\"text\":\" \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"e1rb6\",\"text\":\"Participants\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"italic\",\"offset\":0,\"length\":12}],\"entityRanges\":[],\"data\":{}},{\"key\":\"abqpi\",\"text\":\"The population of interest is all types of users of AI systems, in all application domains. We will include empirical studies including human participants.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"8m50l\",\"text\":\" \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"9rnk9\",\"text\":\"Interventions\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"italic\",\"offset\":0,\"length\":13}],\"entityRanges\":[],\"data\":{}},{\"key\":\"4fqji\",\"text\":\"The phenomenon of interest is AI-systems that present an explanation to realize “explainable” or “interpretable” AI, for any application domain. Recommender systems will be included as AI-systems as well. Participants should be aware that they are interacting with an AI system and they should be actively trying to understand the AI system and/or its output. Therefore, we will exclude studies where users are not clearly aware that recommendations are generated by AI or studies where AI provides recommendations without the user or use case specifically requesting it, such as music and series recommendations on streaming platforms.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"69t3n\",\"text\":\" \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"1ljuc\",\"text\":\"Comparators\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"italic\",\"offset\":0,\"length\":11}],\"entityRanges\":[],\"data\":{}},{\"key\":\"drqg1\",\"text\":\"Studies should compare different XAI implementations with each other, which can be a comparison between XAI algorithms or methods (e.g., feature-based, example-based, counterfactuals, etc.) and/or comparison between the explanation and presentation methods (e.g., size, text or visual, tone, level of detail, completeness, etc.). We will exclude comparisons between different black-box AI-models without different XAI implementations or  comparisons between factors that are associated to the original black-box AI-model, such as model accuracy, and timing of the errors. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"1ktan\",\"text\":\" \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"9krre\",\"text\":\"Outcomes\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"italic\",\"offset\":0,\"length\":8}],\"entityRanges\":[],\"data\":{}},{\"key\":\"cifjj\",\"text\":\"Studies will be included if they measure any type of  human-AI interaction outcome. This could be subjective experiences of the users, such as trust, likeability,\\npreference, etc., or objective measures, such as effectiveness, performance of the human-AI collaboration, decision time, anchoring and adjusting decisions,\\netc.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"bsd8r\",\"text\":\" \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"digj5\",\"text\":\"Report characteristics\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"italic\",\"offset\":0,\"length\":22}],\"entityRanges\":[],\"data\":{}},{\"key\":\"7u3ti\",\"text\":\"We will include articles published in English. Other languages will be excluded.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"j04o\",\"text\":\"Articles should be published and peer-reviewed. Other types of articles, such as commentaries, letters, editorials, etc. will not be included. Additionally, papers only published in archive will be excluded. There will be no restriction on the year of publication, papers from all years will be included up until the day of the final search.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":98935,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"3","cases":[],"critical":null},{"id":2036312,"guid":"5B74C4314D144ADFBAA2EBFC1BB1AB81","previous_id":2034188,"previous_guid":"C4D69A0269E24458A158225690B12189","section":"\u003cp\u003eMethods\u003c/p\u003e","section_color":"#94EBFF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"c61j2\",\"text\":\"Outcomes and prioritization\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":27}],\"entityRanges\":[],\"data\":{}},{\"key\":\"e47pm\",\"text\":\"The primary outcome is to create an overview of the XAI implementations that are compared in the included studies, the different factors presented in the explanation, and how these influence human-AI interaction, both subjectively and objectively. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"uj89\",\"text\":\" \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"2gdhn\",\"text\":\"As secondary outcome, we will create an overview of the findings for different domains (health, law, education, etc.) and types of users (experts/laymen, personalities), and how the influence of XAI implementations on human-AI interaction outcomes might be differ. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":98935,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"7","cases":[],"critical":null},{"id":2036313,"guid":"0BB9AB3874F049678A0940E9680D79B5","previous_id":2036312,"previous_guid":"5B74C4314D144ADFBAA2EBFC1BB1AB81","section":"\u003cp\u003eMethods\u003c/p\u003e","section_color":"#94EBFF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"c34aj\",\"text\":\"Risk of bias in individual studies\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":34}],\"entityRanges\":[],\"data\":{}},{\"key\":\"t5vs\",\"text\":\"For risk of bias assessment, we will use the Mixed Methods Appraisal Tool (MMAT; Hong et al., 2018). This tool is most appropriate, since we include all types of user-studies (qualitative and quantitative, with different types of design). We will visually represent and critically discuss the overall scores and the scores per criteria. If a study has an extreme overall score, and can be seen as an outlier (threshold still to be discussed), we can exclude this study from the review.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":98935,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"8","cases":[],"critical":null},{"id":2036314,"guid":"CE8C55B5E0E947BF9A8D3C58E5F00DC2","previous_id":2036313,"previous_guid":"0BB9AB3874F049678A0940E9680D79B5","section":"\u003cp\u003eMethods\u003c/p\u003e","section_color":"#94EBFF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"7pkil\",\"text\":\"Data synthesis\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":14}],\"entityRanges\":[],\"data\":{}},{\"key\":\"55uhi\",\"text\":\"We will not be performing a meta-analysis, because we expect that the included studies will lack the level of similarity needed to perform a meta-analysis. Therefore, we will provide a systematic narrative synthesis with information presented in both text and tables to summarise and explain the characteristics and findings of the included studies. The narrative synthesis will be used to create an overview of all empirical studies that involve humans and compare different XAI implementations to each other, to gain more understanding on the factors contributing to a good explanation of AI systems and how this could be potentially different between application domains.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":98935,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"9","cases":[],"critical":null},{"id":2036315,"guid":"6B4DCF1A2D164036A15F40167A681260","previous_id":2036314,"previous_guid":"CE8C55B5E0E947BF9A8D3C58E5F00DC2","section":"\u003cp\u003eMethods\u003c/p\u003e","section_color":"#94EBFF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"66pes\",\"text\":\"Confidence in cumulative evidence\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":33}],\"entityRanges\":[],\"data\":{}},{\"key\":\"ciilp\",\"text\":\"We do not plan to perform an assessment of the confidence in cumulative evidence, because we are\\nnot performing a meta-analysis. However, we plan to create an overview of the distribution of application domains, AI-methods, user populations, etc. We aim to critically review the state-of-the-art of user-studies in XAI, and to identify potential gaps in the targeted populations or domains and to identify potential differences between different target groups. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":98935,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"10","cases":[],"critical":null},{"id":2036509,"guid":"38DF73507D89447DA0DA9AC9E518D031","previous_id":2036315,"previous_guid":"6B4DCF1A2D164036A15F40167A681260","section":"\u003cp\u003eAcknowledgements\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"1p8eu\",\"text\":\"Contributions\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":13}],\"entityRanges\":[],\"data\":{}},{\"key\":\"e8hv7\",\"text\":\"MR is the guarantor, drafted the manuscript, developed the search strategy, and chose the risk of bias assessment strategy. All authors contributed to the development of the selection criteria and data extraction criteria. Additionally, all authors read, provided feedback and approved the final manuscript.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":98935,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"11","cases":[],"critical":null},{"id":2036512,"guid":"6CDED51BEDEA4DE4B6B5A3EA10BFF69F","previous_id":2036509,"previous_guid":"38DF73507D89447DA0DA9AC9E518D031","section":"\u003cp\u003eAcknowledgements\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"edpos\",\"text\":\"Financial support\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":17}],\"entityRanges\":[],\"data\":{}},{\"key\":\"86qte\",\"text\":\"The PhD position, and therefore this project, has been partly funded by Eindhoven AI Systems Institute (EAISI) and partly by the Human-Technology Interaction Group.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":98935,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"12","cases":[],"critical":null},{"id":2044458,"guid":"5BC5FECCBD9340F2B4A66277B0DE4ABD","previous_id":0,"previous_guid":null,"section":"\u003cp\u003eIntroduction\u003c/p\u003e","section_color":"#A492FF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"10jk6\",\"text\":\"Rationale\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":9}],\"entityRanges\":[],\"data\":{}},{\"key\":\"clt1b\",\"text\":\"The field of Artificial Intelligence (AI) is rapidly expanding, with AI technologies increasingly integrated into everyday life. Concerns about the lack of transparency and interpretability in many opaque AI systems have led to a growing interest in Explainable AI (XAI), aimed at making AI systems and their outcomes understandable to users. Current studies in XAI often focus on algorithm and expert perspectives. In these studies, explanations are often meant to help developers improve the AI system, or the design of the explanation is based on the researcher’s intuition of a ‘good’ explanation (Miller, 2019).\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"4op0\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"25e2s\",\"text\":\"However, AI systems are often applied in non-technical domains, such as healthcare (Bussone et al., 2015; Cai et al., 2019), criminal justice (Dodge et al., 2019), and education (Farrow, 2023). This means that end-users are often laymen with no technical background. They need explanations to understand the underlying principles of AI systems and to make effective decisions supported by the AI. Therefore, XAI solutions should be developed more for end-users and XAI research needs to shift towards human-centered approaches, involving end-users in the evaluation process (Laato et al., 2021; Wang et al., 2019). Currently, only a small proportion (20%) of XAI research involves human participants in evaluating explanations (Nauta et al., 2023).\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"3o3ka\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"5vgda\",\"text\":\"A first step in the direction of more human-centered XAI evaluations is a literature review by (Rong et al., 2024). They give an overview of existing user studies in XAI, that compared various types of AI explanations to AI systems with no explanations. While most findings indicated that explanations improved different human-AI interaction outcomes, such as trust, understanding, usability, and collaboration performance, some did not. The challenge underlying these mixed results lies in the absence of a clear understanding of what elements in explanations contribute to positive human-AI interaction. Research should investigate which elements of the explanations contribute to a good explanation of AI. This requires studies that test the influence of one element in the explanation while keeping all other factors equal across conditions. In this systematic review, we search for studies that compare different implementations of XAI to each other on human-AI collaboration outcomes, not only comparing an explanation to a control condition without an explanation to identify studies that test the specific influence of separate elements in an explanation.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"81o4l\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"1ad4o\",\"text\":\"Additionally, it remains uncertain whether elements of the explanations have the same influence on human-AI interaction across different target groups or application domains. For example, (Haque et al., 2023) mention that XAI solutions are presented in different ways in different domains; in health-care-related systems explanations often need textual and visual(graphical) formats, whereas in law-related systems hybrid explanations are optional. Therefore, in this systematic review, we intend to create an overview of the findings of existing research on different XAI implementations for different target groups and application domains.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":98935,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"1","cases":[],"critical":null}],"template_id":0,"title":"Comparing Implementations of Explainable Artificial Intelligence using End-User Evaluations: Protocol for a Systematic  Review","title_html":"Comparing Implementations of Explainable Artificial Intelligence using End-User Evaluations: Protocol for a Systematic  Review","type_id":1,"units":[{"id":1,"type_id":3,"name":"µL","can_manage":0,"read_only":0},{"id":2,"type_id":3,"name":"mL","can_manage":0,"read_only":0},{"id":3,"type_id":3,"name":"L","can_manage":0,"read_only":0},{"id":4,"type_id":3,"name":"µg","can_manage":0,"read_only":0},{"id":5,"type_id":3,"name":"mg","can_manage":0,"read_only":0},{"id":6,"type_id":3,"name":"g","can_manage":0,"read_only":0},{"id":7,"type_id":3,"name":"kg","can_manage":0,"read_only":0},{"id":8,"type_id":3,"name":"ng","can_manage":0,"read_only":0},{"id":9,"type_id":3,"name":"Hz","can_manage":0,"read_only":0},{"id":10,"type_id":24,"name":"°C","can_manage":0,"read_only":0},{"id":11,"type_id":24,"name":"°К","can_manage":0,"read_only":0},{"id":12,"type_id":24,"name":"°F","can_manage":0,"read_only":0},{"id":13,"type_id":25,"name":"Mass Percent","can_manage":0,"read_only":0},{"id":14,"type_id":25,"name":"% volume","can_manage":0,"read_only":0},{"id":15,"type_id":25,"name":"Mass / % volume","can_manage":0,"read_only":0},{"id":16,"type_id":25,"name":"Parts per Million (PPM)","can_manage":0,"read_only":0},{"id":17,"type_id":25,"name":"Parts per Billion (PPB)","can_manage":0,"read_only":0},{"id":18,"type_id":25,"name":"Parts per Trillion (PPT)","can_manage":0,"read_only":0},{"id":19,"type_id":25,"name":"Mole Fraction","can_manage":0,"read_only":0},{"id":20,"type_id":25,"name":"Mole Percent","can_manage":0,"read_only":0},{"id":21,"type_id":25,"name":"Molarity (M)","can_manage":0,"read_only":1},{"id":22,"type_id":25,"name":"Molarity (M)","can_manage":0,"read_only":0},{"id":23,"type_id":25,"name":"Genome copies per ml","can_manage":0,"read_only":0},{"id":24,"type_id":3,"name":"μV","can_manage":0,"read_only":0},{"id":25,"type_id":3,"name":"ms","can_manage":0,"read_only":0},{"id":26,"type_id":3,"name":"pg","can_manage":0,"read_only":0},{"id":27,"type_id":25,"name":"Molarity dilutions","can_manage":0,"read_only":0},{"id":28,"type_id":25,"name":"millimolar (mM)","can_manage":0,"read_only":0},{"id":29,"type_id":25,"name":"micromolar (µM)","can_manage":0,"read_only":0},{"id":30,"type_id":25,"name":"nanomolar (nM)","can_manage":0,"read_only":0},{"id":31,"type_id":25,"name":"picomolar (pM)","can_manage":0,"read_only":0},{"id":32,"type_id":24,"name":"Room temperature","can_manage":0,"read_only":0},{"id":33,"type_id":30,"name":"rpm","can_manage":0,"read_only":0},{"id":34,"type_id":30,"name":"x g","can_manage":0,"read_only":0},{"id":165,"type_id":24,"name":"On ice","can_manage":0,"read_only":0},{"id":200,"type_id":32,"name":"cm","can_manage":0,"read_only":0},{"id":201,"type_id":32,"name":"mm","can_manage":0,"read_only":0},{"id":202,"type_id":32,"name":"µm","can_manage":0,"read_only":0},{"id":203,"type_id":32,"name":"nm","can_manage":0,"read_only":0},{"id":204,"type_id":25,"name":"mg/mL","can_manage":0,"read_only":0},{"id":205,"type_id":25,"name":"µg/µL","can_manage":0,"read_only":0},{"id":206,"type_id":25,"name":"% (v/v)","can_manage":0,"read_only":0},{"id":207,"type_id":3,"name":"V","can_manage":0,"read_only":0},{"id":1324,"type_id":30,"name":"rcf","can_manage":0,"read_only":0},{"id":1359,"type_id":35,"name":"Bar","can_manage":0,"read_only":0},{"id":1360,"type_id":35,"name":"Pa","can_manage":0,"read_only":0}],"uri":"comparing-implementations-of-explainable-artificia-dcux2wxn","url":"https://www.protocols.io/view/comparing-implementations-of-explainable-artificia-dcux2wxn","version_class":98935,"version_data":{"id":0,"code":"dcux2wxn","version_class":98935,"parent_id":null,"parent_uri":null,"is_same_owner":false,"is_parent_public":false,"has_pending_merge_request":false,"has_approved_merge_request":false,"merge_request":null},"version_id":0,"version_uri":"comparing-implementations-of-explainable-artificia-n92ld89e8v5b/v1","versions":[{"id":98935,"title":"Comparing Implementations of Explainable Artificial Intelligence using End-User Evaluations: Protocol for a Systematic  Review","title_html":"Comparing Implementations of Explainable Artificial Intelligence using End-User Evaluations: Protocol for a Systematic  Review","image":{"source":"https://www.protocols.io/img/default_protocol.png","webp_source":null,"placeholder":"https://www.protocols.io/img/default_protocol.png","webp_placeholder":null},"doi":"dx.doi.org/10.17504/protocols.io.n92ld89e8v5b/v1","uri":"comparing-implementations-of-explainable-artificia-dcux2wxn","published_on":1715590867,"modified_on":1715590867,"version_class":98935,"version_id":0,"version_code":"dcux2wxn","version_uri":"comparing-implementations-of-explainable-artificia-n92ld89e8v5b/v1","created_on":1714376970,"categories":null,"type_id":1,"creator":{"name":"Mieke Ronckers","affiliation":"Human-Technology Interaction group, Eindhoven University of Technology","affiliation_url":"","username":"mieke-ronckers","link":"","image":{"source":"/img/avatars/001.png","placeholder":"/img/avatars/001.png","webp_source":""}},"stats":{"number_of_comments":0,"last_comment_time":0}}],"warning":""}