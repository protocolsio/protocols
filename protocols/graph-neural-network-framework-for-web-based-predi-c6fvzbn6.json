{"access":{"can_view":true,"can_edit":false,"can_remove":false,"can_add":false,"can_publish":false,"can_get_doi":false,"can_share":true,"can_move":true,"can_move_outside":true,"can_transfer":true,"can_download":true,"limited_run":false,"limited_private_links":false,"limited_blind_links":false,"is_locked":false},"authors":[{"name":"Anagha S Setlur","affiliation":"Department of Biotechnology, RV College of Engineering, Bangalore- 560059, affiliated to Visvesvaraya Technological University (VTU), Belagavi- 590018 ","affiliation_url":"","username":"anagha-s-setlur","link":"","image":{"source":"/img/avatars/007.png","placeholder":"/img/avatars/007.png","webp_source":""},"note":"","is_verified_user":true},{"name":"Vidya Niranjan","affiliation":"Department of Biotechnology, RV College of Engineering, Bangalore- 560059, affiliated to Visvesvaraya Technological University (VTU), Belagavi- 590018 ","affiliation_url":null,"username":"vidya-niranjan","link":"","image":{"source":"/img/avatars/005.png","placeholder":"/img/avatars/005.png","webp_source":""},"note":"","is_verified_user":true},{"name":"Arjun Balaji","affiliation":"Department of Electronics \u0026 Telecommunication, RV College of Engineering, Bangalore- 560059, affiliated to Visvesvaraya Technological University (VTU), Belagavi- 590018 ","affiliation_url":null,"username":"n4vle122r105sle1","link":null,"image":{"source":"/img/avatars/004.png","placeholder":"/img/avatars/004.png","webp_source":""},"note":"","is_verified_user":false},{"name":"Chandrashekar K","affiliation":"Department of Biotechnology, RV College of Engineering, Bangalore- 560059, affiliated to Visvesvaraya Technological University (VTU), Belagavi- 590018 ","affiliation_url":null,"username":"chandrashekar--k","link":"","image":{"source":"/img/avatars/004.png","placeholder":"/img/avatars/004.png","webp_source":""},"note":"","is_verified_user":true}],"before_start":"{\"blocks\":[{\"key\":\"cs4lu\",\"text\":\"Check system compatibility to run pre-processing of models and GCN/hybrid GCN models.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","book_chapter":null,"can_accept_authorship":false,"can_be_copied":true,"can_claim_authorship":false,"can_manage_keywords":true,"can_remove_fork":false,"can_sign":false,"child_steps":{},"cited_protocols":[],"collection_items":[],"created_on":1702632112,"creator":{"name":"Vidya Niranjan","affiliation":"","affiliation_url":null,"username":"vidya-niranjan","link":"","image":{"source":"/img/avatars/005.png","placeholder":"/img/avatars/005.png","webp_source":""},"badges":[{"id":4,"name":"Gold power author!","image":{"source":"/img/badges/gold.svg","placeholder":"/img/badges/gold.svg"}}],"affiliations":[]},"cross_cloud_origin":null,"description":"{\"blocks\":[{\"key\":\"7ev3s\",\"text\":\"Estimating the docking score between proteins and drugs is very important in the application of structure-based drug design. This project explores the application of Graph Neural networks (GNN) in the field of molecular property prediction using SMILES representation, the trained models are then deployed on a web-based platform for broader accessibility and use. The primary dataset utilized in this study includes molecular data represented by MolPort IDs and associated docking scores, which are critical in assessing molecular interactions. A significant aspect of this project is data preprocessing, where each molecule, initially represented as a SMILES string, is converted into a graph format. Effective molecular representation learning is pivotal to facilitate molecular property prediction. Models are then evaluated based on various performance metrics and deployed on the web-based platform.\",\"type\":\"align-justify\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"4ohkd\",\"text\":\"\",\"type\":\"align-justify\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"b2uqf\",\"text\":\"Keywords: QSAR, machine and deep learning, graph convolution networks, graph neural networks, data pre-processing, human organs, web-based predictions\",\"type\":\"align-justify\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","disclaimer":"","document":"","documents":null,"doi":"dx.doi.org/10.17504/protocols.io.j8nlkoy9xv5r/v1","doi_status":1,"ethics_statement":"{\"blocks\":[{\"key\":\"a7j83\",\"text\":\"None.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","fork_id":null,"fork_info":null,"forks":[],"funders":[],"groups":[],"guid":"430B16E36FB445A59F9D8F5F27745859","guidelines":"{\"blocks\":[{\"key\":\"d2kr9\",\"text\":\"QSAR modeling should be performed for each protein under each organ first. The ligand IDs and SMILES structures are the preferred columns to be present in the analytical dataset.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","has_references":true,"has_step_reagents":false,"has_versions":false,"id":92373,"image":{"source":"https://content.protocols.io/files/pcsqbjq4f.jpg","webp_source":"https://content.protocols.io/files/pcspbjq4f.webp","placeholder":"","webp_placeholder":""},"image_attribution":"","in_trash":false,"is_bookmarked":false,"is_contact_suspended":false,"is_content_confidential":false,"is_content_warning":false,"is_doi_reserved":false,"is_in_pending_publishing":false,"is_in_transfer":false,"is_owner":true,"is_research":true,"is_retracted":false,"is_shared_directly":false,"is_subprotocol":null,"is_unlisted":false,"item_id":1198281,"journal":null,"journals":[],"keywords":"QSAR, machine learning and deep learning, graph convolution networks, graph neural networks, data pre-processing, human organs, web-based predictions","last_modified":1702974911,"link":"","location":null,"manuscript_citation":"","materials":[],"materials_text":"","ownership_history":null,"parent_collections":[],"parent_protocols":[],"peer_reviewed":false,"protocol_references":"{\"blocks\":[{\"key\":\"2ivtm\",\"text\":\"1. Kaplan Z, Ehrlich S, Leswing K (2021) Benchmark study of DeepAutoQSAR, ChemProp, and DeepPurpose on the ADMET subset of the Therapeutic Data Commons. https://newsite.schrodinger.com/life-science/learn/white-papers/benchmark-study-deepautoqsar-chemprop-and-deeppurpose-admet-subset-therapeutic-data/\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":153,\"length\":148}],\"data\":{}},{\"key\":\"6iege\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"bq3l1\",\"text\":\"2. Gion K, Gattani S, Kaplan Z (2022) DeepAutoQSAR hardware benchmark. https://newsite.schrodinger.com/materials-science/learn/white-papers/deepautoqsar-hardware-benchmark/\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":1,\"offset\":71,\"length\":101}],\"data\":{}},{\"key\":\"3p0mj\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"6r2h8\",\"text\":\"3. Schrödinger Release 2023-4: DeepAutoQSAR, Schrödinger, LLC, New York, NY, 2023.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"aq2ac\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"2e92t\",\"text\":\"4. https://www.molport.com/shop/index\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":2,\"offset\":3,\"length\":34}],\"data\":{}},{\"key\":\"4bkvp\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"7goti\",\"text\":\"5. Wu F, Souza A, Zhang T, Fifty C, Yu T, Weinberger K. Simplifying graph convolutional networks. International conference on machine learning 2019 May 24 (pp. 6861-6871). PMLR.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"dumuv\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"16plj\",\"text\":\"6. Javeed A. A hybrid attention mechanism for multi-target entity relation extraction using graph neural networks. Machine Learning with Applications. 2023 Mar 15;11:100444.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"link\",\"mutability\":\"MUTABLE\",\"data\":{\"guid\":\"978573199E2A11EEBE4A0A58A9FEAC02\",\"url\":\"https://newsite.schrodinger.com/life-science/learn/white-papers/benchmark-study-deepautoqsar-chemprop-and-deeppurpose-admet-subset-therapeutic-data\"}},\"1\":{\"type\":\"link\",\"mutability\":\"MUTABLE\",\"data\":{\"guid\":\"9BEB22459E2A11EEBE4A0A58A9FEAC02\",\"url\":\"https://newsite.schrodinger.com/materials-science/learn/white-papers/deepautoqsar-hardware-benchmark\"}},\"2\":{\"type\":\"link\",\"mutability\":\"MUTABLE\",\"data\":{\"guid\":\"F80667109E2A11EEBE4A0A58A9FEAC02\",\"url\":\"https://www.molport.com/shop/index\"}}}}","public":true,"public_fork_note":"","published_on":1702974911,"references":[],"related_equipments":[],"related_materials":[],"reserved_doi":"","retraction_reason":null,"samples":{},"shared_access_id":265,"show_comparison":false,"sign_info":null,"space_access":{"can_view":false,"can_edit":false,"can_remove":false,"can_add":false,"can_publish":true,"can_get_doi":true,"can_share":false,"can_move":false,"can_move_outside":false,"can_transfer":false,"can_download":false,"limited_run":false,"limited_private_links":false,"limited_blind_links":false,"is_locked":false},"state_version_id":1153,"stats":{"is_voted":false,"number_of_views":22,"number_of_steps":12,"number_of_bookmarks":0,"number_of_comments":0,"number_of_bookmarked_comments":0,"number_of_steps_comments":0,"number_of_protocol_comments":0,"number_of_exports":0,"number_of_runs":0,"number_of_votes":0,"number_of_reagents":0,"number_of_equipments":0,"number_of_collections":0,"number_of_forks":{"private":0,"public":0},"number_of_accessible_forks":0},"status":{"id":1,"info":"We use this protocol and it's working"},"steps":[{"id":1881206,"guid":"759551C3186E4AA2963C165B1C839C85","previous_id":0,"previous_guid":null,"section":"\u003cp\u003e\u003cstrong\u003eIMPORTING LIBRARIES\u003c/strong\u003e\u003c/p\u003e","section_color":"#A492FF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"5aup9\",\"text\":\"Import all necessary libraries\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":30}],\"entityRanges\":[],\"data\":{}},{\"key\":\"9fsrg\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"49uhc\",\"text\":\"Ensure the installation and importation of all the necessary libraries needed for both the data preprocessing and the model training and evaluation. Provided below is a screenshot of the required libraries to be imported.\",\"type\":\"align-justify\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"bevki\",\"text\":\"\",\"type\":\"align-justify\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"b6r3v\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"q2na\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"59df6\",\"text\":\" \",\"type\":\"align-justify\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":1,\"offset\":0,\"length\":1}],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"image\",\"mutability\":\"IMMUTABLE\",\"data\":{\"height\":210,\"id\":428564,\"is_video\":false,\"legend\":\"{\\\"blocks\\\":[{\\\"key\\\":\\\"2hg8a\\\",\\\"text\\\":\\\"Importing required libraries\\\",\\\"type\\\":\\\"unstyled\\\",\\\"depth\\\":0,\\\"inlineStyleRanges\\\":[{\\\"style\\\":\\\"bold\\\",\\\"offset\\\":0,\\\"length\\\":28}],\\\"entityRanges\\\":[],\\\"data\\\":{}}],\\\"entityMap\\\":{}}\",\"mime\":\"image/png\",\"originalFile\":{},\"original_name\":\"image.png\",\"placeholder\":\"https://content.protocols.io/files/pcsybjq4f.jpg\",\"shadow\":true,\"source\":\"https://content.protocols.io/files/pcswbjq4f.jpg\",\"type\":1,\"webp_placeholder\":\"https://content.protocols.io/files/pcsxbjq4f.webp\",\"webp_source\":\"https://content.protocols.io/files/pcsvbjq4f.webp\",\"width\":550}},\"1\":{\"type\":\"image\",\"mutability\":\"MUTABLE\",\"data\":{\"height\":210,\"id\":428560,\"is_video\":false,\"legend\":\"{\\\"blocks\\\":[{\\\"key\\\":\\\"4nu16\\\",\\\"text\\\":\\\"Importing required libraries\\\",\\\"type\\\":\\\"unstyled\\\",\\\"depth\\\":0,\\\"inlineStyleRanges\\\":[{\\\"style\\\":\\\"bold\\\",\\\"offset\\\":0,\\\"length\\\":28}],\\\"entityRanges\\\":[],\\\"data\\\":{}}],\\\"entityMap\\\":{}}\",\"mime\":\"image/png\",\"originalFile\":{},\"original_name\":\"image.png\",\"placeholder\":\"https://content.protocols.io/files/pcsubjq4f.jpg\",\"source\":\"https://content.protocols.io/files/pcssbjq4f.jpg\",\"type\":1,\"webp_placeholder\":\"https://content.protocols.io/files/pcstbjq4f.webp\",\"webp_source\":\"https://content.protocols.io/files/pcsrbjq4f.webp\",\"width\":550}}}}","data":null,"protocol_id":92373,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"1","cases":[],"critical":null},{"id":1881795,"guid":"492D625E4D394D1BB66CA5B6840042D9","previous_id":1881206,"previous_guid":"759551C3186E4AA2963C165B1C839C85","section":"\u003cp\u003e\u003cstrong\u003eDATASET CREATION\u003c/strong\u003e\u003c/p\u003e","section_color":"#94EBFF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"a0p4b\",\"text\":\"In the present scenario, Quantitative Structure Activity Relationship (QSAR) data generated from Schrodinger Maestro was used for dataset creation. QSAR models were first generated for specific proteins and by taking a set of ligands from MolPort.\",\"type\":\"align-justify\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"cpvqn\",\"text\":\"\",\"type\":\"align-justify\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"5gjcr\",\"text\":\"Taking an example for Brain, O14672. Here, Y(Obs) is the docking score. This dataset has the MolPort IDs and the docking scores obtained from QSAR modeling data.\",\"type\":\"align-justify\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"4vqnv\",\"text\":\"\",\"type\":\"align-justify\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"74dq4\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"1cean\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"5n6is\",\"text\":\" \",\"type\":\"align-justify\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":1,\"offset\":0,\"length\":1}],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"image\",\"mutability\":\"IMMUTABLE\",\"data\":{\"height\":568,\"id\":428568,\"is_video\":false,\"legend\":\"\",\"mime\":\"image/png\",\"originalFile\":{},\"original_name\":\"image.png\",\"placeholder\":\"https://content.protocols.io/files/pcs4bjq4f.jpg\",\"shadow\":true,\"source\":\"https://content.protocols.io/files/pcs2bjq4f.jpg\",\"type\":1,\"webp_placeholder\":\"https://content.protocols.io/files/pcs3bjq4f.webp\",\"webp_source\":\"https://content.protocols.io/files/pcszbjq4f.webp\",\"width\":550}},\"1\":{\"type\":\"image\",\"mutability\":\"MUTABLE\",\"data\":{\"height\":568,\"id\":428572,\"is_video\":false,\"legend\":\"{\\\"blocks\\\":[{\\\"key\\\":\\\"74vv2\\\",\\\"text\\\":\\\"QSAR sample data to be used for graph generation\\\",\\\"type\\\":\\\"unstyled\\\",\\\"depth\\\":0,\\\"inlineStyleRanges\\\":[{\\\"style\\\":\\\"bold\\\",\\\"offset\\\":0,\\\"length\\\":48}],\\\"entityRanges\\\":[],\\\"data\\\":{}}],\\\"entityMap\\\":{}}\",\"mime\":\"image/png\",\"originalFile\":{},\"original_name\":\"image.png\",\"placeholder\":\"https://content.protocols.io/files/pcs8bjq4f.jpg\",\"source\":\"https://content.protocols.io/files/pcs6bjq4f.jpg\",\"type\":1,\"webp_placeholder\":\"https://content.protocols.io/files/pcs7bjq4f.webp\",\"webp_source\":\"https://content.protocols.io/files/pcs5bjq4f.webp\",\"width\":550}}}}","data":null,"protocol_id":92373,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"2","cases":[],"critical":null},{"id":1881796,"guid":"AAD44BB6FF534527BD101AB823666204","previous_id":1881795,"previous_guid":"492D625E4D394D1BB66CA5B6840042D9","section":"\u003cp\u003e\u003cstrong\u003eDATASET CREATION\u003c/strong\u003e\u003c/p\u003e","section_color":"#94EBFF","section_duration":0,"is_substep":true,"step":"{\"blocks\":[{\"key\":\"323og\",\"text\":\"Creation of analytical dataset\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":30}],\"entityRanges\":[],\"data\":{}},{\"key\":\"711dv\",\"text\":\" \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":1}],\"entityRanges\":[],\"data\":{}},{\"key\":\"7ed83\",\"text\":\"Using the second dataset containing MolPort IDs and the SMILES string. An analytical dataset was created.\",\"type\":\"align-justify\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"516c9\",\"text\":\"\",\"type\":\"align-justify\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"67i7s\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"bqhnk\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"avo0i\",\"text\":\" \",\"type\":\"align-justify\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":1,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"90gdo\",\"text\":\"The following is performed to prepare an analytical dataset:\",\"type\":\"align-justify\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"c8j5n\",\"text\":\"\",\"type\":\"align-justify\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"9v5b\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":2,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"c1r43\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"c4dgi\",\"text\":\" \",\"type\":\"align-justify\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":3,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"7jkj7\",\"text\":\"The processed dataset looks as follows:\",\"type\":\"align-justify\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"9f9au\",\"text\":\"\",\"type\":\"align-justify\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"f3utq\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":4,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"6ks6h\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"12m78\",\"text\":\" \",\"type\":\"align-justify\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":5,\"offset\":0,\"length\":1}],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"image\",\"mutability\":\"IMMUTABLE\",\"data\":{\"height\":208,\"id\":428588,\"is_video\":false,\"legend\":\"\",\"mime\":\"image/png\",\"originalFile\":{},\"original_name\":\"image.png\",\"placeholder\":\"https://content.protocols.io/files/pctqbjq4f.jpg\",\"shadow\":true,\"source\":\"https://content.protocols.io/files/pctnbjq4f.jpg\",\"type\":1,\"webp_placeholder\":\"https://content.protocols.io/files/pctpbjq4f.webp\",\"webp_source\":\"https://content.protocols.io/files/pctmbjq4f.webp\",\"width\":550}},\"1\":{\"type\":\"image\",\"mutability\":\"MUTABLE\",\"data\":{\"height\":208,\"id\":428592,\"is_video\":false,\"legend\":\"{\\\"blocks\\\":[{\\\"key\\\":\\\"68vum\\\",\\\"text\\\":\\\"Creation of analytical dataset\\\",\\\"type\\\":\\\"unstyled\\\",\\\"depth\\\":0,\\\"inlineStyleRanges\\\":[{\\\"style\\\":\\\"bold\\\",\\\"offset\\\":0,\\\"length\\\":30}],\\\"entityRanges\\\":[],\\\"data\\\":{}}],\\\"entityMap\\\":{}}\",\"mime\":\"image/png\",\"originalFile\":{},\"original_name\":\"image.png\",\"placeholder\":\"https://content.protocols.io/files/pctubjq4f.jpg\",\"source\":\"https://content.protocols.io/files/pctsbjq4f.jpg\",\"type\":1,\"webp_placeholder\":\"https://content.protocols.io/files/pcttbjq4f.webp\",\"webp_source\":\"https://content.protocols.io/files/pctrbjq4f.webp\",\"width\":550}},\"2\":{\"type\":\"image\",\"mutability\":\"IMMUTABLE\",\"data\":{\"height\":132,\"id\":428596,\"is_video\":false,\"legend\":\"\",\"mime\":\"image/png\",\"originalFile\":{},\"original_name\":\"image.png\",\"placeholder\":\"https://content.protocols.io/files/pctybjq4f.jpg\",\"shadow\":true,\"source\":\"https://content.protocols.io/files/pctwbjq4f.jpg\",\"type\":1,\"webp_placeholder\":\"https://content.protocols.io/files/pctxbjq4f.webp\",\"webp_source\":\"https://content.protocols.io/files/pctvbjq4f.webp\",\"width\":550}},\"3\":{\"type\":\"image\",\"mutability\":\"MUTABLE\",\"data\":{\"height\":132,\"id\":428576,\"is_video\":false,\"legend\":\"\",\"mime\":\"image/png\",\"originalFile\":{},\"original_name\":\"image.png\",\"placeholder\":\"https://content.protocols.io/files/pctcbjq4f.jpg\",\"source\":\"https://content.protocols.io/files/pctabjq4f.jpg\",\"type\":1,\"webp_placeholder\":\"https://content.protocols.io/files/pctbbjq4f.webp\",\"webp_source\":\"https://content.protocols.io/files/pcs9bjq4f.webp\",\"width\":550}},\"4\":{\"type\":\"image\",\"mutability\":\"IMMUTABLE\",\"data\":{\"height\":203,\"id\":428580,\"is_video\":false,\"legend\":\"\",\"mime\":\"image/png\",\"originalFile\":{},\"original_name\":\"image.png\",\"placeholder\":\"https://content.protocols.io/files/pctgbjq4f.jpg\",\"shadow\":true,\"source\":\"https://content.protocols.io/files/pctebjq4f.jpg\",\"type\":1,\"webp_placeholder\":\"https://content.protocols.io/files/pctfbjq4f.webp\",\"webp_source\":\"https://content.protocols.io/files/pctdbjq4f.webp\",\"width\":550}},\"5\":{\"type\":\"image\",\"mutability\":\"MUTABLE\",\"data\":{\"height\":203,\"id\":428584,\"is_video\":false,\"legend\":\"\",\"mime\":\"image/png\",\"originalFile\":{},\"original_name\":\"image.png\",\"placeholder\":\"https://content.protocols.io/files/pctkbjq4f.jpg\",\"source\":\"https://content.protocols.io/files/pctibjq4f.jpg\",\"type\":1,\"webp_placeholder\":\"https://content.protocols.io/files/pctjbjq4f.webp\",\"webp_source\":\"https://content.protocols.io/files/pcthbjq4f.webp\",\"width\":550}}}}","data":null,"protocol_id":92373,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"2.1","cases":[],"critical":null},{"id":1881798,"guid":"EC8DC857408A4CE48F30A136FDBBEA22","previous_id":1881796,"previous_guid":"AAD44BB6FF534527BD101AB823666204","section":"\u003cp\u003e\u003cstrong\u003eDATA PRE-PROCESSING\u003c/strong\u003e\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"b2pa6\",\"text\":\"SMILES to graph conversion\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":26}],\"entityRanges\":[],\"data\":{}},{\"key\":\"b5tih\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"8fr0j\",\"text\":\"Data preprocessing is a pivotal step in this model. Each molecule represented by a SMILES string is converted into a graph, with atoms as nodes and chemical bonds as edges. This graph representation is essential for the GNN to accurately interpret molecular structures.\",\"type\":\"align-justify\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"e9si4\",\"text\":\"\",\"type\":\"align-justify\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"7ka9k\",\"text\":\"Feature Representation\",\"type\":\"align-justify\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":22}],\"entityRanges\":[],\"data\":{}},{\"key\":\"ci00h\",\"text\":\"\",\"type\":\"align-justify\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"dqrvr\",\"text\":\"●   Atom Features: Each atom is represented by a one-hot encoded feature vector, indicating the atom type. The model considers four types of atoms (C, O, N, B), leading to a 4-dimensional feature vector for each atom.\",\"type\":\"align-justify\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":4,\"length\":14}],\"entityRanges\":[],\"data\":{}},{\"key\":\"2bl61\",\"text\":\"●  Bond Features: Bonds are characterized by their type (single, double, triple, aromatic) and their inclusion in a ring structure. Each bond is represented by a 5-dimensional feature vector.\",\"type\":\"align-justify\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":3,\"length\":14}],\"entityRanges\":[],\"data\":{}},{\"key\":\"4gohq\",\"text\":\"\",\"type\":\"align-justify\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"5dbu\",\"text\":\" \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"c9fee\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"6q6al\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"tables\",\"mutability\":\"MUTABLE\",\"data\":{\"cellsMeta\":{\"0_0\":\"\",\"0_1\":\"\",\"1_0\":\"\",\"1_1\":\"\",\"2_0\":\"\",\"2_1\":\"\",\"3_0\":\"\",\"3_1\":\"\",\"4_0\":\"\",\"4_1\":\"\",\"5_0\":\"\",\"5_1\":\"\",\"A_1\":{\"className\":\"_dt-h-center\"},\"A_2\":{\"className\":\"_dt-h-center\"},\"A_3\":{\"className\":\"_dt-h-center\"},\"A_4\":{\"className\":\"_dt-h-center\"},\"A_5\":{\"className\":\"_dt-h-center\"},\"A_6\":{\"className\":\"_dt-h-center\"},\"B_1\":{\"className\":\"_dt-h-center\"},\"B_2\":{\"className\":\"_dt-h-center\"},\"B_3\":{\"className\":\"_dt-h-center\"},\"B_4\":{\"className\":\"_dt-h-center\"},\"B_5\":{\"className\":\"_dt-h-center\"},\"B_6\":{\"className\":\"_dt-h-center\"}},\"colTitles\":[\"\",\"\"],\"colWidths\":[200,156],\"data\":[[\"  Feature\\n  \",\"  Dimensions\\n  \"],[\"  One-hot encoding of atom types (C, O, N, B)\\n  \",\"  4\\n  \"],[\"  Edge features for bond types (single, double, triple, aromatic)\\n  \",\"  4\\n  \"],[\"  Edge features for bond presence in a ring structure\\n  \",\"  1\\n  \"],[\"  Atom features for atom presence in a ring structure\\n  \",\"  1\\n  \"],[\"  Bond indices for atom connectivity\\n  \",\"  2 per bond\\n  \"]],\"guid\":\"CF130177DAE744178EB307D83A40FBF2\",\"isJexcelDataFormat\":true,\"legend\":\"\",\"mergeCells\":{},\"printData\":[[\"  Feature\\n  \",\"  Dimensions\\n  \"],[\"  One-hot encoding of atom types (C, O, N, B)\\n  \",\"  4\\n  \"],[\"  Edge features for bond types (single, double, triple, aromatic)\\n  \",\"  4\\n  \"],[\"  Edge features for bond presence in a ring structure\\n  \",\"  1\\n  \"],[\"  Atom features for atom presence in a ring structure\\n  \",\"  1\\n  \"],[\"  Bond indices for atom connectivity\\n  \",\"  2 per bond\\n  \"]],\"rowHeights\":[23,23,23,23,23,23]}}}}","data":null,"protocol_id":92373,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"3","cases":[],"critical":null},{"id":1881799,"guid":"9EF7E499D51442738794DC1BB9ACCDA5","previous_id":1881798,"previous_guid":"EC8DC857408A4CE48F30A136FDBBEA22","section":"\u003cp\u003e\u003cstrong\u003eDATA PRE-PROCESSING\u003c/strong\u003e\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":true,"step":"{\"blocks\":[{\"key\":\"ckhb6\",\"text\":\"Using RDKit library for feature representation\",\"type\":\"align-justify\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":46}],\"entityRanges\":[],\"data\":{}},{\"key\":\"afsi2\",\"text\":\"\",\"type\":\"align-justify\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"74rbe\",\"text\":\"So, to represent all these features, we utilize the functionalities of the RDKit library. The function converts a SMILES string into a molecular graph, encoding atom types using one-hot encoding and representing bonds with their types and ring membership.\",\"type\":\"align-justify\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"69eng\",\"text\":\"\",\"type\":\"align-justify\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"f4l0k\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"1f1iv\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"9uusq\",\"text\":\"\",\"type\":\"align-justify\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"evptu\",\"text\":\" \",\"type\":\"align-justify\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":1,\"offset\":0,\"length\":1}],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"image\",\"mutability\":\"IMMUTABLE\",\"data\":{\"height\":596,\"id\":428600,\"is_video\":false,\"legend\":\"{\\\"blocks\\\":[{\\\"key\\\":\\\"9jfa5\\\",\\\"text\\\":\\\"Using RDKit for feature representation\\\",\\\"type\\\":\\\"unstyled\\\",\\\"depth\\\":0,\\\"inlineStyleRanges\\\":[{\\\"style\\\":\\\"bold\\\",\\\"offset\\\":0,\\\"length\\\":38}],\\\"entityRanges\\\":[],\\\"data\\\":{}}],\\\"entityMap\\\":{}}\",\"mime\":\"image/png\",\"originalFile\":{},\"original_name\":\"image.png\",\"placeholder\":\"https://content.protocols.io/files/pct4bjq4f.jpg\",\"shadow\":true,\"source\":\"https://content.protocols.io/files/pct2bjq4f.jpg\",\"type\":1,\"webp_placeholder\":\"https://content.protocols.io/files/pct3bjq4f.webp\",\"webp_source\":\"https://content.protocols.io/files/pctzbjq4f.webp\",\"width\":550}},\"1\":{\"type\":\"image\",\"mutability\":\"MUTABLE\",\"data\":{\"height\":596,\"id\":428604,\"is_video\":false,\"legend\":\"{\\\"blocks\\\":[{\\\"key\\\":\\\"3ovsa\\\",\\\"text\\\":\\\"Using RDKit for feature representation\\\",\\\"type\\\":\\\"unstyled\\\",\\\"depth\\\":0,\\\"inlineStyleRanges\\\":[{\\\"style\\\":\\\"bold\\\",\\\"offset\\\":0,\\\"length\\\":38}],\\\"entityRanges\\\":[],\\\"data\\\":{}}],\\\"entityMap\\\":{}}\",\"mime\":\"image/png\",\"originalFile\":{},\"original_name\":\"image.png\",\"placeholder\":\"https://content.protocols.io/files/pct8bjq4f.jpg\",\"source\":\"https://content.protocols.io/files/pct6bjq4f.jpg\",\"type\":1,\"webp_placeholder\":\"https://content.protocols.io/files/pct7bjq4f.webp\",\"webp_source\":\"https://content.protocols.io/files/pct5bjq4f.webp\",\"width\":550}}}}","data":null,"protocol_id":92373,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"3.1","cases":[],"critical":null},{"id":1881800,"guid":"1CDBACF375464287B391F1E8B96B9005","previous_id":1881799,"previous_guid":"9EF7E499D51442738794DC1BB9ACCDA5","section":"\u003cp\u003e\u003cstrong\u003eMODEL TRAINING AND EVALUATION\u003c/strong\u003e\u003c/p\u003e","section_color":"#FFED92","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"edm4g\",\"text\":\"Model defining and training\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":27}],\"entityRanges\":[],\"data\":{}},{\"key\":\"8rv1j\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"umfc\",\"text\":\"Define the models and train with early stopping along with appropriate parameters. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":92373,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"4","cases":[],"critical":null},{"id":1881801,"guid":"C86BA2ED0C5442E5B3B8892E05757513","previous_id":1881800,"previous_guid":"1CDBACF375464287B391F1E8B96B9005","section":"\u003cp\u003e\u003cstrong\u003eMODEL TRAINING AND EVALUATION\u003c/strong\u003e\u003c/p\u003e","section_color":"#FFED92","section_duration":0,"is_substep":true,"step":"{\"blocks\":[{\"key\":\"3ird9\",\"text\":\"MODEL 1- GRAPH CONVOLUTION NETWORK (GCN) \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":41}],\"entityRanges\":[],\"data\":{}},{\"key\":\"eebmv\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"fkg7e\",\"text\":\"The first model we explore is a Graph Convolution Network (GCN) with 2 convolution layers. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"53cin\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"c7tir\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"fcvrc\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"1gnsn\",\"text\":\" \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":1,\"offset\":0,\"length\":1}],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"image\",\"mutability\":\"IMMUTABLE\",\"data\":{\"height\":499,\"id\":428608,\"is_video\":false,\"legend\":\"\",\"mime\":\"image/png\",\"originalFile\":{},\"original_name\":\"image.png\",\"placeholder\":\"https://content.protocols.io/files/pcucbjq4f.jpg\",\"shadow\":true,\"source\":\"https://content.protocols.io/files/pcuabjq4f.jpg\",\"type\":1,\"webp_placeholder\":\"https://content.protocols.io/files/pcubbjq4f.webp\",\"webp_source\":\"https://content.protocols.io/files/pct9bjq4f.webp\",\"width\":550}},\"1\":{\"type\":\"image\",\"mutability\":\"MUTABLE\",\"data\":{\"height\":499,\"id\":428612,\"is_video\":false,\"legend\":\"\",\"mime\":\"image/png\",\"originalFile\":{},\"original_name\":\"image.png\",\"placeholder\":\"https://content.protocols.io/files/pcugbjq4f.jpg\",\"source\":\"https://content.protocols.io/files/pcuebjq4f.jpg\",\"type\":1,\"webp_placeholder\":\"https://content.protocols.io/files/pcufbjq4f.webp\",\"webp_source\":\"https://content.protocols.io/files/pcudbjq4f.webp\",\"width\":550}}}}","data":null,"protocol_id":92373,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"4.1","cases":[],"critical":null},{"id":1881802,"guid":"91F80EA2D62D4C7887D60F4581362266","previous_id":1881801,"previous_guid":"C86BA2ED0C5442E5B3B8892E05757513","section":"\u003cp\u003e\u003cstrong\u003eMODEL TRAINING AND EVALUATION\u003c/strong\u003e\u003c/p\u003e","section_color":"#FFED92","section_duration":0,"is_substep":true,"step":"{\"blocks\":[{\"key\":\"9kanv\",\"text\":\"MODEL 2- HYBRID GCN \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":20}],\"entityRanges\":[],\"data\":{}},{\"key\":\"b4bo\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"2aqjq\",\"text\":\"The second model we explore is a hybrid GCN model:\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"66qa1\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"7dv48\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"acacn\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"da45g\",\"text\":\" \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":1,\"offset\":0,\"length\":1}],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"image\",\"mutability\":\"IMMUTABLE\",\"data\":{\"height\":401,\"id\":428616,\"is_video\":false,\"legend\":\"\",\"mime\":\"image/png\",\"originalFile\":{},\"original_name\":\"image.png\",\"placeholder\":\"https://content.protocols.io/files/pcukbjq4f.jpg\",\"shadow\":true,\"source\":\"https://content.protocols.io/files/pcuibjq4f.jpg\",\"type\":1,\"webp_placeholder\":\"https://content.protocols.io/files/pcujbjq4f.webp\",\"webp_source\":\"https://content.protocols.io/files/pcuhbjq4f.webp\",\"width\":550}},\"1\":{\"type\":\"image\",\"mutability\":\"MUTABLE\",\"data\":{\"height\":401,\"id\":428620,\"is_video\":false,\"legend\":\"\",\"mime\":\"image/png\",\"originalFile\":{},\"original_name\":\"image.png\",\"placeholder\":\"https://content.protocols.io/files/pcuqbjq4f.jpg\",\"source\":\"https://content.protocols.io/files/pcunbjq4f.jpg\",\"type\":1,\"webp_placeholder\":\"https://content.protocols.io/files/pcupbjq4f.webp\",\"webp_source\":\"https://content.protocols.io/files/pcumbjq4f.webp\",\"width\":550}}}}","data":null,"protocol_id":92373,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"4.2","cases":[],"critical":null},{"id":1881804,"guid":"4F001863E29542ECBC7680FB478A14B1","previous_id":1881802,"previous_guid":"91F80EA2D62D4C7887D60F4581362266","section":"\u003cp\u003e\u003cstrong\u003eMODEL TRAINING AND EVALUATION\u003c/strong\u003e\u003c/p\u003e","section_color":"#FFED92","section_duration":0,"is_substep":true,"step":"{\"blocks\":[{\"key\":\"c9s8b\",\"text\":\"5-fold cross validation\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":23}],\"entityRanges\":[],\"data\":{}},{\"key\":\"ah3uk\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"edfkk\",\"text\":\"Utilizing 5-Fold cross-validation for training enhancing its robustness and reliability. This method ensured a comprehensive evaluation by systematically partitioning the data into distinct subsets for both training and validation. \",\"type\":\"align-justify\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"7f2gp\",\"text\":\"\",\"type\":\"align-justify\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"a9pvj\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"3ueor\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"fubc6\",\"text\":\" \",\"type\":\"align-justify\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":1,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"16kb4\",\"text\":\"The model's performance was further evaluated using metrics like Root Mean Squared Error (RMSE) and Mean Average Error(MAE), providing insights into its predictive accuracy and overall performance. \",\"type\":\"align-justify\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"4scat\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"image\",\"mutability\":\"IMMUTABLE\",\"data\":{\"height\":197,\"id\":428624,\"is_video\":false,\"legend\":\"\",\"mime\":\"image/png\",\"originalFile\":{},\"original_name\":\"image.png\",\"placeholder\":\"https://content.protocols.io/files/pcuubjq4f.jpg\",\"shadow\":true,\"source\":\"https://content.protocols.io/files/pcusbjq4f.jpg\",\"type\":1,\"webp_placeholder\":\"https://content.protocols.io/files/pcutbjq4f.webp\",\"webp_source\":\"https://content.protocols.io/files/pcurbjq4f.webp\",\"width\":550}},\"1\":{\"type\":\"image\",\"mutability\":\"MUTABLE\",\"data\":{\"height\":197,\"id\":428628,\"is_video\":false,\"legend\":\"\",\"mime\":\"image/png\",\"originalFile\":{},\"original_name\":\"image.png\",\"placeholder\":\"https://content.protocols.io/files/pcuybjq4f.jpg\",\"source\":\"https://content.protocols.io/files/pcuwbjq4f.jpg\",\"type\":1,\"webp_placeholder\":\"https://content.protocols.io/files/pcuxbjq4f.webp\",\"webp_source\":\"https://content.protocols.io/files/pcuvbjq4f.webp\",\"width\":550}}}}","data":null,"protocol_id":92373,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"4.3","cases":[],"critical":null},{"id":1881805,"guid":"5E6243E777624ACD8EF7E73C6515D3F5","previous_id":1881804,"previous_guid":"4F001863E29542ECBC7680FB478A14B1","section":"\u003cp\u003e\u003cstrong\u003ePICKING THE BEST MODEL AND UPLOADING IN REPOSITORY\u003c/strong\u003e\u003c/p\u003e","section_color":"#EA9F6C","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"5mgog\",\"text\":\"The best possible model was picked and the weights were saved. Then, these weights were uploaded onto the Streamlit repository.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"b39ng\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"7b5h5\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"f5jcu\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"2ug3j\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"gdpp\",\"text\":\"These same steps were repeated across different proteins, datasets and models to integrate all models from each human organ into a single platform.\",\"type\":\"align-justify\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"fntee\",\"text\":\" \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":1,\"offset\":0,\"length\":1}],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"image\",\"mutability\":\"IMMUTABLE\",\"data\":{\"height\":150,\"id\":428632,\"is_video\":false,\"legend\":\"\",\"mime\":\"image/png\",\"originalFile\":{},\"original_name\":\"image.png\",\"placeholder\":\"https://content.protocols.io/files/pcu4bjq4f.jpg\",\"shadow\":true,\"source\":\"https://content.protocols.io/files/pcu2bjq4f.jpg\",\"type\":1,\"webp_placeholder\":\"https://content.protocols.io/files/pcu3bjq4f.webp\",\"webp_source\":\"https://content.protocols.io/files/pcuzbjq4f.webp\",\"width\":550}},\"1\":{\"type\":\"image\",\"mutability\":\"MUTABLE\",\"data\":{\"height\":150,\"id\":428636,\"is_video\":false,\"legend\":\"{\\\"blocks\\\":[{\\\"key\\\":\\\"f012d\\\",\\\"text\\\":\\\"Screenshot of the deployed application for graph neural network based docking score prediction\\\",\\\"type\\\":\\\"unstyled\\\",\\\"depth\\\":0,\\\"inlineStyleRanges\\\":[{\\\"style\\\":\\\"bold\\\",\\\"offset\\\":0,\\\"length\\\":94}],\\\"entityRanges\\\":[],\\\"data\\\":{}}],\\\"entityMap\\\":{}}\",\"mime\":\"image/png\",\"originalFile\":{},\"original_name\":\"image.png\",\"placeholder\":\"https://content.protocols.io/files/pcu8bjq4f.jpg\",\"source\":\"https://content.protocols.io/files/pcu6bjq4f.jpg\",\"type\":1,\"webp_placeholder\":\"https://content.protocols.io/files/pcu7bjq4f.webp\",\"webp_source\":\"https://content.protocols.io/files/pcu5bjq4f.webp\",\"width\":550}}}}","data":null,"protocol_id":92373,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"5","cases":[],"critical":null},{"id":1882685,"guid":"BB1B0EE6890843CBB66EDBF2323BC86A","previous_id":1881805,"previous_guid":"5E6243E777624ACD8EF7E73C6515D3F5","section":"\u003cp\u003e\u003cstrong\u003eCONCLUSION\u003c/strong\u003e\u003c/p\u003e","section_color":"#E57785","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"2p9q3\",\"text\":\"This protocol briefs the steps required to integrate all predicted QSAR data from each organ into a single, all-in-one platform for all human organs and proteins associated with them, to enable users to provide a SMILES structure and estimate the predicted docking score after mapping with the integrated models. Data pre-processing is the primary step in this protocol, followed by creation of analytical dataset for conversion into graphs. Advanced machine and deep learning technique called the graph convolution network (GCN) is shown as model 1, where high dimensional data is converted to low dimensional data and the graphs are correlated to the target variables (in this case, docking scores). The hybrid model, shown as model 2, also adds an additional concept of attention mechanism, that employs positional encoding along with traditional GCN. The web-application allows users to choose which model to utilise for their prediction. This protocol allows for the direct binding affinity predictions of small molecules to important proteins in the human organs, thereby, providing an overall safety information on the small molecules.\",\"type\":\"align-justify\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":92373,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"6","cases":[],"critical":null},{"id":1882686,"guid":"9503B989FB8B468690CBC3147AA0C775","previous_id":1882685,"previous_guid":"BB1B0EE6890843CBB66EDBF2323BC86A","section":"\u003cp\u003e\u003cstrong\u003eACKNOWLEDGEMENTS\u003c/strong\u003e\u003c/p\u003e","section_color":"#EA94FF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"3r9bj\",\"text\":\"The authors thank Mr. Akshay Uttarkar for providing inputs throughout.\",\"type\":\"align-justify\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":92373,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"7","cases":[],"critical":null}],"template_id":5,"title":"Graph Neural Network Framework for Web-Based Prediction of Protein-Ligand Docking Scores across multiple organs","title_html":"Graph Neural Network Framework for Web-Based Prediction of Protein-Ligand Docking Scores across multiple organs","type_id":1,"units":[{"id":1,"type_id":3,"name":"µL","can_manage":0,"read_only":0},{"id":2,"type_id":3,"name":"mL","can_manage":0,"read_only":0},{"id":3,"type_id":3,"name":"L","can_manage":0,"read_only":0},{"id":4,"type_id":3,"name":"µg","can_manage":0,"read_only":0},{"id":5,"type_id":3,"name":"mg","can_manage":0,"read_only":0},{"id":6,"type_id":3,"name":"g","can_manage":0,"read_only":0},{"id":7,"type_id":3,"name":"kg","can_manage":0,"read_only":0},{"id":8,"type_id":3,"name":"ng","can_manage":0,"read_only":0},{"id":9,"type_id":3,"name":"Hz","can_manage":0,"read_only":0},{"id":10,"type_id":24,"name":"°C","can_manage":0,"read_only":0},{"id":11,"type_id":24,"name":"°К","can_manage":0,"read_only":0},{"id":12,"type_id":24,"name":"°F","can_manage":0,"read_only":0},{"id":13,"type_id":25,"name":"Mass Percent","can_manage":0,"read_only":0},{"id":14,"type_id":25,"name":"% volume","can_manage":0,"read_only":0},{"id":15,"type_id":25,"name":"Mass / % volume","can_manage":0,"read_only":0},{"id":16,"type_id":25,"name":"Parts per Million (PPM)","can_manage":0,"read_only":0},{"id":17,"type_id":25,"name":"Parts per Billion (PPB)","can_manage":0,"read_only":0},{"id":18,"type_id":25,"name":"Parts per Trillion (PPT)","can_manage":0,"read_only":0},{"id":19,"type_id":25,"name":"Mole Fraction","can_manage":0,"read_only":0},{"id":20,"type_id":25,"name":"Mole Percent","can_manage":0,"read_only":0},{"id":21,"type_id":25,"name":"Molarity (M)","can_manage":0,"read_only":1},{"id":22,"type_id":25,"name":"Molarity (m)","can_manage":0,"read_only":0},{"id":23,"type_id":25,"name":"Genome copies per ml","can_manage":0,"read_only":0},{"id":24,"type_id":3,"name":"μV","can_manage":0,"read_only":0},{"id":25,"type_id":3,"name":"ms","can_manage":0,"read_only":0},{"id":26,"type_id":3,"name":"pg","can_manage":0,"read_only":0},{"id":27,"type_id":25,"name":"Molarity dilutions","can_manage":0,"read_only":0},{"id":28,"type_id":25,"name":"millimolar (mM)","can_manage":0,"read_only":0},{"id":29,"type_id":25,"name":"micromolar (µM)","can_manage":0,"read_only":0},{"id":30,"type_id":25,"name":"nanomolar (nM)","can_manage":0,"read_only":0},{"id":31,"type_id":25,"name":"picomolar (pM)","can_manage":0,"read_only":0},{"id":32,"type_id":24,"name":"Room temperature","can_manage":0,"read_only":0},{"id":33,"type_id":30,"name":"rpm","can_manage":0,"read_only":0},{"id":34,"type_id":30,"name":"x g","can_manage":0,"read_only":0},{"id":165,"type_id":24,"name":"On ice","can_manage":0,"read_only":0},{"id":200,"type_id":32,"name":"cm","can_manage":0,"read_only":0},{"id":201,"type_id":32,"name":"mm","can_manage":0,"read_only":0},{"id":202,"type_id":32,"name":"µm","can_manage":0,"read_only":0},{"id":203,"type_id":32,"name":"nm","can_manage":0,"read_only":0},{"id":204,"type_id":25,"name":"mg/mL","can_manage":0,"read_only":0},{"id":205,"type_id":25,"name":"µg/µL","can_manage":0,"read_only":0},{"id":206,"type_id":25,"name":"% (v/v)","can_manage":0,"read_only":0},{"id":207,"type_id":3,"name":"V","can_manage":0,"read_only":0},{"id":1324,"type_id":30,"name":"rcf","can_manage":0,"read_only":0},{"id":1359,"type_id":35,"name":"Bar","can_manage":0,"read_only":0},{"id":1360,"type_id":35,"name":"Pa","can_manage":0,"read_only":0}],"uri":"graph-neural-network-framework-for-web-based-predi-c6fvzbn6","url":"https://www.protocols.io/view/graph-neural-network-framework-for-web-based-predi-c6fvzbn6","version_class":92373,"version_data":{"id":0,"code":"c6fvzbn6","version_class":92373,"parent_id":null,"parent_uri":null,"is_same_owner":false,"is_parent_public":false,"has_pending_merge_request":false,"has_approved_merge_request":false,"merge_request":null},"version_id":0,"version_uri":"graph-neural-network-framework-for-web-based-predi-j8nlkoy9xv5r/v1","versions":[{"id":92373,"title":"Graph Neural Network Framework for Web-Based Prediction of Protein-Ligand Docking Scores across multiple organs","title_html":"Graph Neural Network Framework for Web-Based Prediction of Protein-Ligand Docking Scores across multiple organs","image":{"source":"https://content.protocols.io/files/pcsqbjq4f.jpg","webp_source":null,"placeholder":"https://content.protocols.io/files/pcsqbjq4f.jpg","webp_placeholder":null},"doi":"dx.doi.org/10.17504/protocols.io.j8nlkoy9xv5r/v1","uri":"graph-neural-network-framework-for-web-based-predi-c6fvzbn6","published_on":1702974911,"modified_on":1702974911,"version_class":92373,"version_id":0,"version_code":"c6fvzbn6","version_uri":"graph-neural-network-framework-for-web-based-predi-j8nlkoy9xv5r/v1","created_on":1702632112,"categories":null,"type_id":1,"creator":{"name":"Vidya Niranjan","affiliation":null,"affiliation_url":null,"username":"vidya-niranjan","link":"","image":{"source":"/img/avatars/005.png","placeholder":"/img/avatars/005.png","webp_source":""}},"stats":{"number_of_comments":0,"last_comment_time":0}}],"warning":"{\"blocks\":[{\"key\":\"fo8d9\",\"text\":\"NA\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}"}