{"id":43142,"title":"Stranded Transcript Count Table Generation from Long Reads","title_html":"Stranded Transcript Count Table Generation from Long Reads","image":{"source":"https:\/\/www.protocols.io\/img\/default_protocol.png","placeholder":"https:\/\/www.protocols.io\/img\/default_protocol.png"},"doi":"dx.doi.org\/10.17504\/protocols.io.bndema3e","doi_status":2,"uri":"stranded-transcript-count-table-generation-from-lo-bndema3e","type_id":1,"template_id":1,"published_on":1602558736,"parent_protocols":[],"parent_collections":[],"cited_protocols":[],"version_id":11,"version_data":{"id":"11","code":"bndema3e","parent_id":29301,"parent_uri":"stranded-transcript-count-table-generation-from-lo-8uvhww6","is_same_owner":true,"has_pending_merge_request":false,"has_approved_merge_request":true},"created_on":1602555249,"modified_on":null,"categories":null,"public":1,"is_unlisted":0,"creator":{"name":"David A. Eccles","affiliation":"Malaghan Institute of Medical Research (NZ)","affiliations":[{"affiliation":"Malaghan Institute of Medical Research (NZ)","url":"http:\/\/www.malaghan.org.nz\/","is_default":1}],"username":"david-eccles","note":null,"link":null,"image":{"source":"https:\/\/s3.amazonaws.com\/pr-journal\/vi7jpt6.jpg","placeholder":"https:\/\/s3.amazonaws.com\/pr-journal\/vi7jpt6.jpg"},"badges":[{"id":4,"image":{"source":"\/img\/badges\/gold.svg","placeholder":"\/img\/badges\/gold.svg"},"name":"Gold power author!"},{"id":6,"image":{"source":"\/img\/badges\/accelerator.svg","placeholder":"\/img\/badges\/accelerator.svg"},"name":"Science accelerator"}],"verified":0,"is_verified_user":false,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},"journal":null,"journal_name":null,"journal_link":null,"article_citation":null,"has_versions":0,"link":null,"total_collections":0,"number_of_steps":7,"authors":[{"name":"David Eccles","affiliation":"Malaghan Institute of Medical Research (NZ)","affiliations":[],"username":"david-eccles","note":null,"link":null,"image":{"source":"https:\/\/s3.amazonaws.com\/pr-journal\/vi7jpt6.jpg","placeholder":"https:\/\/s3.amazonaws.com\/pr-journal\/vi7jpt6.jpg"},"badges":[],"verified":1,"is_verified_user":true,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false}],"versions":[],"groups":[],"is_owner":1,"has_subprotocols":0,"is_subprotocol":0,"is_bookmarked":0,"can_claim_authorship":0,"can_accept_authorship":0,"can_be_copied":1,"can_remove_fork":1,"fork_id":null,"url":"https:\/\/www.protocols.io\/view\/stranded-transcript-count-table-generation-from-lo-bndema3e","forks_count":{"private":0,"public":0},"access":{"can_view":1,"can_remove":0,"can_add":0,"can_edit":0,"can_publish":0,"can_get_doi":0,"can_share":1,"can_move":1,"can_move_outside":1,"can_transfer":1,"can_download":1,"is_locked":0},"guid":"F44C036A6DAE4E44A8D6C6B4BD4C6EA7","state_version_id":32,"steps":[{"id":1050107,"guid":"0E0E520E7ABA403B999788FB2A3F9255","previous_id":null,"previous_guid":null,"modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"A30E67F0CD19421C95403E90026EF847","order_id":1,"type_id":6,"title":"Section","source":{"title":"Demultiplex Reads    "}},{"id":1054724,"guid":"1EB6BF03C1FB44C6AB33A48389F33E12","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Demultiplex and orient reads as per the protocol <\/div><div class = \"text-block\"><a href=\"https:\/\/dx.doi.org\/10.17504\/protocols.io.74vhqw6\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">Preparing Reads for Stranded Mapping<\/span><\/a><\/div><div class = \"text-block\"><span>. It is expected that these demultiplexed reads will be split up in the current directory, and coupled with a '<\/span><span style = \"font-style:italic;\">barcode_counts.txt<\/span><span>' file. If that's the case, the following should work:<\/span><\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">for bc in $(awk '{print $2}' barcode_counts.txt);<\/div><div class = \"text-block\">  do ls oriented\/${bc}_reads_dirAdjusted.fq.gz;<\/div><div class = \"text-block\">done<\/div><\/div><\/code><\/pre><\/div><div class = \"text-block\">Example expected output:<\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">oriented\/BC03_reads_dirAdjusted.fastq.gz<\/div><div class = \"text-block\">oriented\/BC04_reads_dirAdjusted.fastq.gz<\/div><div class = \"text-block\">oriented\/BC05_reads_dirAdjusted.fastq.gz<\/div><div class = \"text-block\">oriented\/BC06_reads_dirAdjusted.fastq.gz<\/div><div class = \"text-block\">oriented\/BC07_reads_dirAdjusted.fastq.gz<\/div><div class = \"text-block\">oriented\/BC08_reads_dirAdjusted.fastq.gz<\/div><\/div><\/code><\/pre><\/div><div class = \"text-block\"><span>If the '<\/span><span style = \"font-style:italic;\">barcode_counts.txt<\/span><span>' file is not present, this error will appear:<\/span><\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">awk: fatal: cannot open file `barcode_counts.txt' for reading (No such file or directory)<\/div><\/div><\/code><\/pre><\/div><div class = \"text-block\">If one or more of the oriented read files is missing, it will look something like this:<\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">oriented\/BC03_reads_dirAdjusted.fastq.gz<\/div><div class = \"text-block\">oriented\/BC04_reads_dirAdjusted.fastq.gz<\/div><div class = \"text-block\">ls: cannot access 'oriented\/BC05_reads_dirAdjusted.fastq.gz':<\/div><div class = \"text-block\">  No such file or directory<\/div><div class = \"text-block\">ls: cannot access 'oriented\/BC06_reads_dirAdjusted.fastq.gz':<\/div><div class = \"text-block\">  No such file or directory<\/div><div class = \"text-block\">oriented\/BC07_reads_dirAdjusted.fastq.gz<\/div><div class = \"text-block\">oriented\/BC08_reads_dirAdjusted.fastq.gz<\/div><\/div><\/code><\/pre><\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#A492FF","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1050108,"guid":"BDAEBE6959B24982A72DF1C86DE8C79C","previous_id":1050107,"previous_guid":"0E0E520E7ABA403B999788FB2A3F9255","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"303C5F48AB3F4904A5AECCC0C4F87FDF","order_id":1,"type_id":6,"title":"Section","source":{"title":"Index Preparation"}},{"id":1054724,"guid":"5F7C06B7BC574793B25205AD661E389C","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Prepare a substitution matrix for barcode mapping. The default substitution matrix is swayed too much by INDELs in the barcode sequences, so here's one that I've developed using a combination of trial & error and last-train:<\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">#last -Q 0<\/div><div class = \"text-block\">#last -a 13<\/div><div class = \"text-block\">#last -A 13<\/div><div class = \"text-block\">#last -b 4<\/div><div class = \"text-block\">#last -B 4<\/div><div class = \"text-block\">#last -S 1<\/div><div class = \"text-block\"># score matrix (query letters = columns, reference letters = rows):<\/div><div class = \"text-block\">       A      C      G      T<\/div><div class = \"text-block\">A      5    -18     -7    -18<\/div><div class = \"text-block\">C    -18      6    -18    -12<\/div><div class = \"text-block\">G     -7    -18      5    -18<\/div><div class = \"text-block\">T    -18    -12    -18      6<\/div><\/div><\/code><\/pre><\/div><div class = \"text-block\"><span> \n\n<\/span><span style = \"font-style:italic;\">[note: this is a <\/span><span style = \"font-style:italic;font-weight:bold;\">different<\/span><span style = \"font-style:italic;\"> matrix from that used for demultiplexing and read orientation]<\/span><\/div><\/div>"}},{"id":1054725,"guid":"64980A2001DC11EAA93F118C05A07E9B","order_id":2,"type_id":23,"title":"file","source":{"source":"https:\/\/s3.amazonaws.com\/protocols-files\/public\/d3caf5d2f980d165712bb8262c51687a45460e9aedd9631ff736620da233c966\/bttkjpt6.mat","placeholder":"\/img\/extensions\/file.png","original_name":"cDNA.mat"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#94EBFF","section_duration":0,"critical":[],"critical_id":null,"duration":0},{"id":1050109,"guid":"532AF7FA45B9422A8C57E8B96B16BD1A","previous_id":1050108,"previous_guid":"BDAEBE6959B24982A72DF1C86DE8C79C","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"8A47466E7D8643FC98D7C7E78B4FD582","order_id":1,"type_id":6,"title":"Section","source":{"title":"Index Preparation"}},{"id":1054724,"guid":"9EBD03F8FDD74A5E9BF4096EC89A9DC5","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Prepare transcript index (see Guidelines for data sources). Following <\/div><div class = \"text-block\"><a href=\"https:\/\/github.com\/mcfrith\/last-rna\/blob\/master\/last-long-reads.md#option-1-prepare-a-genome-without-repeat-masking\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">Martin Frith's recommendation<\/span><\/a><\/div><div class = \"text-block\">, the '-uNEAR' seeding scheme is used to slightly increase sensitivity. This will generate seven additional files of the form <index name>.XXX:<\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">lastdb -uNEAR Mus_musculus.GRCm38.ensembl_v98.mtr.fa Mus_musculus.GRCm38.ensembl_v98.mtr.fa<\/div><\/div><\/code><\/pre><\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#94EBFF","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1050110,"guid":"62A6B19ACDA2492387AB8F37C2225CBD","previous_id":1050109,"previous_guid":"532AF7FA45B9422A8C57E8B96B16BD1A","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"C6238211653740A28F29E2DD4AF0665A","order_id":1,"type_id":6,"title":"Section","source":{"title":"Transcriptome Mapping"}},{"id":1054724,"guid":"9422661F97EA45FC8A85A58D299E20C1","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Reads are mapped to the transcriptome with LAST.<\/div><div class = \"text-block\"><span>The results of that mapping can be piped through <\/span><span style = \"font-style:italic;\">last-split<\/span><span> and <\/span><span style = \"font-style:italic;\">last-postmask<\/span><span> to exclude unlikely hits, then through '<\/span><span style = \"font-style:italic;\">maf-convert -n tab'<\/span><span> to convert to a one-line-per-mapping CSV format. This CSV format is further processed to make sure that there is only one mapping per transcript-read pair.<\/span><\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">mkdir -p mapped<\/div><div class = \"text-block\">for bc in $(awk '{print $2}' barcode_counts.txt);<\/div><div class = \"text-block\">  do echo \"** ${bc} **\";<\/div><div class = \"text-block\">  lastal -P 10 -p cDNA.mat Mus_musculus.GRCm38.ensembl_v98.mtr.fa <(pv oriented\/${bc}_reads_dirAdjusted.fq.gz | zcat) | \\<\/div><div class = \"text-block\">    last-split -n -m0.99 | last-postmask | maf-convert -n tab | \\<\/div><div class = \"text-block\">    cut -f 2,7,10 | sort | \\<\/div><div class = \"text-block\">    uniq | gzip > mapped\/trnMapping_LAST_${bc}_vs_Mmus_transcriptome.txt.gz;<\/div><div class = \"text-block\">done<\/div><\/div><\/code><\/pre><\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#84CE84","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1050111,"guid":"F434A099DA0142BAAA46C8C80F841683","previous_id":1050110,"previous_guid":"62A6B19ACDA2492387AB8F37C2225CBD","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"990C7B0FB6804FFAA94CE20404577DE7","order_id":1,"type_id":6,"title":"Section","source":{"title":"Transcriptome Mapping"}},{"id":1054724,"guid":"D0218609E1CD40A2A95C2A1D929AB17C","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">The result is then aggregated to sum up counts per transcript:<\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">for bc in $(awk '{print $2}' barcode_counts.txt);<\/div><div class = \"text-block\">  do echo \"** ${bc} **\";<\/div><div class = \"text-block\">  zcat mapped\/trnMapping_LAST_${bc}_vs_Mmus_transcriptome.txt.gz | \\<\/div><div class = \"text-block\">    awk -F'\\t' -v \"bc=${bc}\" '{print bc,$1,$3}' | sort | uniq -c | \\<\/div><div class = \"text-block\">    gzip > mapped\/trnCounts_LAST_${bc}_vs_Mmus_transcriptome.txt.gz;<\/div><div class = \"text-block\">done<\/div><\/div><\/code><\/pre><\/div><div class = \"text-block\">Note: I've split this up into two steps (compared to previous versions of this protocol) so that an intermediate count of the total number of mapped transcripts per barcode can be done:<\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">for bc in $(awk '{print $2}' barcode_counts.txt);<\/div><div class = \"text-block\">  do echo -n \"${bc} \";<\/div><div class = \"text-block\">  zcat mapped\/trnMapping_LAST_${bc}_vs_Mmus_transcriptome.txt.gz | \\<\/div><div class = \"text-block\">    awk '{print $2}' | sort | uniq | wc -l;<\/div><div class = \"text-block\">done<\/div><\/div><\/code><\/pre><\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#84CE84","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1050112,"guid":"C5AB23C2DA3748D18BA73B9C8ACDCDB6","previous_id":1050111,"previous_guid":"F434A099DA0142BAAA46C8C80F841683","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"E5B52F0262844923BC6E46BF4751B4CE","order_id":1,"type_id":6,"title":"Section","source":{"title":"Annotation and Result generation"}},{"id":1054724,"guid":"7325F77486C448119330718BD185114B","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Transcript counts are merged with ensembl gene annotation, then converted into wide format (one line per transcript) using an R script.<\/div><div class = \"text-block\">The transcript annotation in this case is from ensembl BioMart (see Guidelines for more details).<\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">#!\/usr\/bin\/env Rscript<\/div><div class = \"text-block\">library(tidyverse);<\/div><div class = \"text-block\">## load used barcode identifiers<\/div><div class = \"text-block\">bcNames <- read.table(\"barcode_counts.txt\", stringsAsFactors=FALSE)[,2];<\/div><div class = \"text-block\">## load count data into \"narrow\" array (one line per count)<\/div><div class = \"text-block\">trn.counts <- tibble();<\/div><div class = \"text-block\">for(bc in bcNames){<\/div><div class = \"text-block\">    trn.counts <-<\/div><div class = \"text-block\">        bind_rows(trn.counts,<\/div><div class = \"text-block\">           sprintf(\"mapped\/trnCounts_LAST_%s_vs_Mmus_transcriptome.txt.gz\", bc) %>%<\/div><div class = \"text-block\">              read_table2(col_names=c(\"count\",\"barcode\",<\/div><div class = \"text-block\">                                      \"transcript\",\"dir\")));<\/div><div class = \"text-block\">}<\/div><div class = \"text-block\">## remove revision number from transcript names (if present)<\/div><div class = \"text-block\">trn.counts$transcript <- sub(\"\\\\.[0-9]+$\",\"\",trn.counts$transcript);<\/div><div class = \"text-block\">## convert to wide format (one line per transcript)<\/div><div class = \"text-block\">trn.counts.wide <- spread(trn.counts, barcode, count) %>%<\/div><div class = \"text-block\">    mutate(dir = c(\"+\"=\"fwd\", \"-\"=\"rev\")[dir]);<\/div><div class = \"text-block\">for(bd in colnames(trn.counts.wide[,-1])){<\/div><div class = \"text-block\">    trn.counts.wide[[bd]] <- replace_na(trn.counts.wide[[bd]],0);<\/div><div class = \"text-block\">}<\/div><div class = \"text-block\">## load ensemble transcript metadata (including gene name)<\/div><div class = \"text-block\">ensembl.df <- read_delim(\"ensembl_mm10_geneFeatureLocations.txt.gz\",<\/div><div class = \"text-block\">                         delim=\"\\t\");<\/div><div class = \"text-block\">colnames(ensembl.df) <-<\/div><div class = \"text-block\">    c(\"Transcript stable ID\" = \"transcript\",<\/div><div class = \"text-block\">      \"Gene description\" = \"Description\",<\/div><div class = \"text-block\">      \"Gene name\" = \"Gene\",<\/div><div class = \"text-block\">      \"Gene start (bp)\" = \"Start\",<\/div><div class = \"text-block\">      \"Gene end (bp)\" = \"End\",<\/div><div class = \"text-block\">      \"Strand\" = \"Strand\",<\/div><div class = \"text-block\">      \"Chromosome\/scaffold name\" = \"Chr\")[colnames(ensembl.df)];<\/div><div class = \"text-block\">ensembl.df$Description <- sub(\" \\\\[.*$\",\"\",ensembl.df$Description);<\/div><div class = \"text-block\">ensembl.df$Description <- sub(\"^(.{50}).+$\",\"\\\\1...\",ensembl.df$Description);<\/div><div class = \"text-block\">options(scipen=15); ## don't show scientific notation for large positions<\/div><div class = \"text-block\">## merge ensembl metadata with transcript counts<\/div><div class = \"text-block\">gene.counts.wide <- inner_join(ensembl.df, trn.counts.wide, by=\"transcript\");<\/div><div class = \"text-block\">gene.counts.wide <- gene.counts.wide[order(-rowSums(gene.counts.wide[,-(1:8)])),];<\/div><div class = \"text-block\">## write result out to a file<\/div><div class = \"text-block\">write.csv(gene.counts.wide, file=\"wide_transcript_counts_LAST.csv\", row.names=FALSE);<\/div><\/div><\/code><\/pre><\/div><\/div>"}},{"id":1054725,"guid":"02C0C1202B2211E9A10E9FC59ECBFD74","order_id":2,"type_id":23,"title":"file","source":{"source":"https:\/\/s3.amazonaws.com\/pr-journal\/bcvaa.r","placeholder":"https:\/\/www.protocols.io\/img\/extensions\/r.png","original_name":"count_analysis.r"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#FFED92","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1050113,"guid":"951F94ED397D463696690D2CD176DC41","previous_id":1050112,"previous_guid":"C5AB23C2DA3748D18BA73B9C8ACDCDB6","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"8C45477D6FAC48DD9B35E4D2F69BDE0E","order_id":1,"type_id":6,"title":"Section","source":{"title":"Downstream Workflows"}},{"id":1054724,"guid":"992CE47152074377BA17B0351638E57A","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Here is a downstream workflow that carries out transcript-level differential expression analysis using <\/div><div class = \"text-block\"><a href=\"https:\/\/bioconductor.org\/packages\/release\/bioc\/html\/DESeq2.html\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">DESeq2<\/span><\/a><\/div><div class = \"text-block\">:<\/div><div class = \"text-block\"><a href=\"https:\/\/dx.doi.org\/10.17504\/protocols.io.799hr96\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">Creating Differential Transcript Expression Results with DESeq2<\/span><\/a><\/div><div class = \"text-block\"><span>I would like to emphasise that batch effects should be considered for nanopore sequencing, given how frequently the technology changes. Make sure that at least the sequencing <\/span><span style = \"font-style:italic;\">library<\/span><span> (i.e. samples prepared in tandem on the same day from the same kit) is added into the statistical model, and try to make sure that sequencing libraries are fairly heterogeneous - replicates from a sample with skewed transcript distributions could influence the outcome of statistical tests.<\/span><\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#EA9F6C","section_duration":0,"critical":null,"critical_id":null,"duration":0}],"document":null,"materials":[],"description":"<div class = \"text-blocks\"><div class = \"text-block\">This protocol is for comparing different samples at the transcript level, using long reads that are mapped to transcripts.<\/div><div class = \"text-block\"><span style = \"font-weight:bold;\">Input(s)<\/span><span>: demultiplexed and oriented fastq files (see protocol <\/span><a href=\"https:\/\/dx.doi.org\/10.17504\/protocols.io.57hg9j6\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">Preparing Reads for Stranded Mapping<\/span><\/a><span>), transcript reference fasta file, annotation file<\/span><\/div><div class = \"text-block\"><span style = \"font-weight:bold;\">Output(s):<\/span><span> transcript table, sorted by differential coverage, annotated with gene name \/ description \/ location<\/span><\/div><\/div>","changed_on":1602558736}