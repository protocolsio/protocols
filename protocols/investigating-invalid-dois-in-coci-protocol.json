{"id":49641,"title":"Investigating Invalid DOIs in COCI - Protocol","title_html":"<p>Investigating Invalid DOIs in COCI - Protocol<\/p>","image":{"source":"https:\/\/s3.amazonaws.com\/protocols-files\/files\/dfw9bjrk7.jpg","placeholder":"https:\/\/s3.amazonaws.com\/protocols-files\/files\/dfw9bjrk7.jpg"},"doi":"dx.doi.org\/10.17504\/protocols.io.buqhnvt6","doi_status":2,"uri":"investigating-invalid-dois-in-coci-protocol-buqhnvt6","type_id":1,"template_id":5,"published_on":1620076740,"parent_protocols":[],"parent_collections":[],"cited_protocols":[],"version_id":2,"version_data":{"id":"2","code":"buqhnvt6","parent_id":49419,"parent_uri":"investigating-invalid-dois-in-coci-buhjnt4n","is_same_owner":true,"has_pending_merge_request":false,"has_approved_merge_request":true},"created_on":1620054530,"modified_on":null,"categories":null,"public":1,"is_unlisted":0,"creator":{"name":"Sara Coppini","affiliation":null,"affiliations":[],"username":"m4vle152y1t4ule1","note":null,"link":null,"image":{"source":"\/img\/avatars\/001.png","placeholder":"\/img\/avatars\/001.png"},"badges":[{"id":2,"image":{"source":"\/img\/badges\/bronze.svg","placeholder":"\/img\/badges\/bronze.svg"},"name":"Author"}],"verified":0,"is_verified_user":false,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},"journal":null,"journal_name":null,"journal_link":null,"article_citation":null,"has_versions":0,"link":null,"total_collections":0,"number_of_steps":18,"authors":[{"name":"Sara Coppini","affiliation":"University of Bologna","affiliations":[],"username":null,"note":"Bachelor's degree in Philosophy, currently studying Digital Humanities and Digital Knowledge (Master Degree) at the University of Bologna.","link":null,"image":{"source":null,"placeholder":null},"badges":[],"verified":0,"is_verified_user":false,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},{"name":"Nooshin Shahidzadeh","affiliation":"University of Bologna","affiliations":[],"username":"m4vle152w1s4wle1","note":"Bachelor's degree in Software Engeneering, currently studying Digital Humanities and Digital Knowledge (Master Degree) at the University of Bologna.","link":null,"image":{"source":"https:\/\/lh3.googleusercontent.com\/-JyXkvY_GkJ8\/AAAAAAAAAAI\/AAAAAAAAQM0\/AMZuuckwTaJ5CYq_-NQHetIJrXUXbEmx9w\/s96-c\/photo.jpg","placeholder":"https:\/\/lh3.googleusercontent.com\/-JyXkvY_GkJ8\/AAAAAAAAAAI\/AAAAAAAAQM0\/AMZuuckwTaJ5CYq_-NQHetIJrXUXbEmx9w\/s96-c\/photo.jpg"},"badges":[],"verified":1,"is_verified_user":true,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},{"name":"Alessia Cioffi","affiliation":"University of Bologna","affiliations":[],"username":null,"note":"Bachelor's degree in Classical Literature, currently studying Digital Humanities and Digital Knowledge (Master Degree) at the University of Bologna.","link":null,"image":{"source":null,"placeholder":null},"badges":[],"verified":0,"is_verified_user":false,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},{"name":"Arianna Moretti","affiliation":"University of Bologna","affiliations":[],"username":null,"note":"Bachelor's degree in Anthropology, Religions, Oriental Civilizations, currently studying Digital Humanities and Digital Knowledge (Master Degree) at the University of Bologna.","link":null,"image":{"source":null,"placeholder":null},"badges":[],"verified":0,"is_verified_user":false,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false}],"versions":[],"groups":[{"id":22817,"uri":"open-science-20202021","title":"Open Science 2020\/2021","image":{"source":"https:\/\/www.protocols.io\/img\/group_placeholder.png","placeholder":"https:\/\/www.protocols.io\/img\/group_placeholder.png"},"tech_support":{"email":null,"phone":null,"hide_contact":0,"use_email":0,"url":null},"is_member":1,"request":{"id":22817,"uri":"open-science-20202021","title":"Open Science 2020\/2021","image":{"source":"https:\/\/www.protocols.io\/img\/group_placeholder.png","placeholder":"https:\/\/www.protocols.io\/img\/group_placeholder.png"},"tech_support":{"email":null,"phone":null,"hide_contact":0,"use_email":0,"url":null},"is_member":1,"description":null,"research_interests":null,"website":null,"location":null,"affiliation":null,"status":{"is_visible":true,"access_level":0},"stats":{"files":[],"total_members":0,"total_followers":0,"total_child_groups":0,"total_parent_groups":0,"has_collaborations":0},"user_status":{"is_member":true,"is_confirmed":true,"is_invited":false,"is_owner":false,"is_admin":false,"is_following":false},"join_link":null,"token":null,"owner":{"name":" ","affiliation":null,"affiliations":[],"username":null,"note":null,"link":null,"image":{"source":null,"placeholder":null},"badges":[],"verified":0,"is_verified_user":false,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},"is_protocol_requested":0,"is_group_requested":0,"is_my":false,"is_request":false,"is_confirmed":1,"is_declined":0,"requester":{"name":" ","affiliation":null,"affiliation_url":null,"username":null,"link":null},"protocol":{"id":0,"title":"Investigating Invalid DOIs in COCI - Protocol","title_html":"Investigating Invalid DOIs in COCI - Protocol","image":{"source":null,"placeholder":null},"doi":null,"doi_status":0,"uri":"investigating-invalid-dois-in-coci-protocol-buqhnvt6","type_id":1,"template_id":0,"published_on":null,"stats":{"number_of_views":0,"number_of_steps":0,"number_of_bookmarks":0,"number_of_comments":0,"number_of_exports":0,"number_of_runs":0,"number_of_votes":0,"is_voted":0},"parent_protocols":[],"parent_collections":[],"cited_protocols":[]},"created_on":1618395700,"resolve_on":0,"resolved_user":{"name":" ","affiliation":null,"affiliations":[],"username":null,"note":null,"link":null,"image":{"source":null,"placeholder":null},"badges":[],"verified":0,"is_verified_user":false,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},"shared":false}}],"is_owner":1,"has_subprotocols":0,"is_subprotocol":0,"is_bookmarked":0,"can_claim_authorship":0,"can_accept_authorship":0,"can_be_copied":1,"can_remove_fork":1,"fork_id":null,"url":"https:\/\/www.protocols.io\/view\/investigating-invalid-dois-in-coci-protocol-buqhnvt6","forks_count":{"private":0,"public":0},"access":{"can_view":1,"can_remove":0,"can_add":0,"can_edit":0,"can_publish":0,"can_get_doi":0,"can_share":1,"can_move":1,"can_move_outside":1,"can_transfer":1,"can_download":1,"is_locked":0},"guid":"3D1445EB6996437E9F862658D0B8CDEA","state_version_id":913,"steps":[{"id":1171761,"guid":"8E4619019AE04C35A6273665425D509A","previous_id":null,"previous_guid":null,"modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"44AA62AAF2964AF88A9EE1D42C51CBF7","order_id":1,"type_id":6,"title":"Section","source":{"title":"Presenting the Input Material"}},{"id":1054724,"guid":"FB98F877B3964AEA955D9E5099B2CC8F","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Given the academic background of the project, we got our input material from Peroni, S. (2021). Citations to invalid DOI-identified entities obtained from processing DOI-to-DOI citations to add in COCI (1.0). Zenodo. <\/div><div class = \"text-block\"><a href=\"https:\/\/doi.org\/10.5281\/ZENODO.4625300\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">https:\/\/doi.org\/10.5281\/ZENODO.4625300<\/span><\/a><\/div><div class = \"text-block\">. As explained in the description of the resource, this dataset contains a two-column CSV file, where the first column (\"Valid_citing_DOI\") contains the DOI of a citing entity retrieved in Crossref, while the second column (\"Invalid_cited_DOI\") contains the invalid DOI of a cited entity identified by looking at the field \"reference\" in the JSON document returned by querying the <\/div><div class = \"text-block\"><a href=\"https:\/\/api.crossref.org\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">Crossref API<\/span><\/a><\/div><div class = \"text-block\"> with the citing DOI.<\/div><div class = \"text-block\">These citations to invalid DOIs have been retrieved while processing Crossref data for adding open citations in COCI, but they have not been added in COCI since they point to a non-resolvable cited document.<\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#A492FF","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1171762,"guid":"E9F70B5905464901916E35AB7121BFEB","previous_id":1171761,"previous_guid":"8E4619019AE04C35A6273665425D509A","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"028BB9E1FCA44B67A8704A89F741D58D","order_id":1,"type_id":6,"title":"Section","source":{"title":"Reading the CSV Data"}},{"id":1054724,"guid":"224E3D183BCA4549835905121952DF39","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">First we read the CSV of the invalid DOIs, containing all the invalid cited DOIs in one column and their valid citing counterparts in another, using xsv_reader.<\/div><\/div>"}},{"id":1054725,"guid":"5693F7409B8711EB8E5115F12A6921AC","order_id":2,"type_id":9,"title":"dataset","source":{"name":"Citations to invalid DOI-identified entities","link":"https:\/\/zenodo.org\/record\/4625300#.YHQ2Si2l1dg"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#94EBFF","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1171764,"guid":"44FA81478AEB4889954619565DC952A8","previous_id":1171803,"previous_guid":"A5DA1640AC2611EBA11869784025321E","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"E579E787B50049E9BAE683758BA6C6BE","order_id":1,"type_id":6,"title":"Section","source":{"title":"Creating the Output JSON File"}},{"id":1054724,"guid":"987B161F82F647AD955CAA74A1595615","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">In this step, we read all the cache files and create a final output file, deleting the caches in the process.<\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#FFED92","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1171767,"guid":"9BE45949962D402DA67ED6C4B82982C5","previous_id":1171786,"previous_guid":"09FFEEE0AC2411EBA11869784025321E","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"476FF4883B9F43649CF5C54685570E69","order_id":1,"type_id":6,"title":"Section","source":{"title":"Processing Each Line in the CSV File and Extracting the Needed Information"}},{"id":1054724,"guid":"AC039FBA19B44346910C2D0F11E4752D","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">In order to verify whether the validity state of the previously invalid cited DOI of a citation has changed over the time, we make an API request to the doi.org service.<\/div><div class = \"text-block\">First of all, we assign to a URL variable a value composed of a base URL for the API request (i.e.: \"<\/div><div class = \"text-block\"><a href=\"https:\/\/doi.org\/api\/handles\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">https:\/\/doi.org\/api\/handles\/<\/span><\/a><\/div><div class = \"text-block\">\") and the Digital Object Identifier of the cited element of the citational data, retrieved by considering the second element of each row of the input file.\u00a0<\/div><div class = \"text-block\">We use the composed url to try to make the effective API request considering the obtained response status code.\u00a0<\/div><div class = \"text-block\">In the case the request fails, a connection error is raised and the running of the application stops. <\/div><\/div>"}}],"cases":[{"guid":"FD63EAA11E164A3F8B86F51DA0083197","step_guid":"9BE45949962D402DA67ED6C4B82982C5","title":"If the invalid cited DOI is now valid","short_title":"Now Valid","description":"{\"blocks\":[{\"key\":\"cqc85\",\"text\":\"In this case we extract the publisher data and add the row to the valid citations cache.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","first_step_id":1171768,"first_step_guid":"A5DA1640AC2611EBA11869784025321E"},{"guid":"28DBBA99EC3746C6B528DDEF601F4DED","step_guid":"9BE45949962D402DA67ED6C4B82982C5","title":"If the invalid cited DOI is still invalid","short_title":"Still Invalid","description":"{\"blocks\":[{\"key\":\"diju3\",\"text\":\"In this case we extract the publisher data and add the row to the invalid citations cache.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"6gk8m\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","first_step_id":1171775,"first_step_guid":"C6821280AC2611EBA11869784025321E"}],"data":null,"html":null,"section":null,"section_color":"#84CE84","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1171775,"guid":"58EE3649CCB34C5ABB94CFEFF9438078","previous_id":1171884,"previous_guid":"C6821280AC2611EBA11869784025321E","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"FFD88FB14CED4EEC9861894A8DD43F0D","order_id":1,"type_id":6,"title":"Section","source":{"title":"Creating the Output File"}},{"id":1054724,"guid":"0F3B55D494964AF3B9571F806FA18417","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">In this step, after having processed every row in the CSV, we collect all the data from our cache files, delete them, and create the output JSON file.<\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#FFED92","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1171777,"guid":"3D9CBDC0AC2211EBA11869784025321E","previous_id":1171762,"previous_guid":"E9F70B5905464901916E35AB7121BFEB","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"ADDFF2D142A74C81930E455ACE9EFF06","order_id":1,"type_id":6,"title":"Section","source":{"title":"Reading the CSV Data"}},{"id":1054724,"guid":"4E796F8B8D7F4E8FBF4DC04999331202","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Then, we create:\u00a0<\/div><div class = \"text-block\"><ol style = \"list-style-type: decimal;\"><li style = \"counter-reset:ol0;\">an empty dictionary (i.e.: publisher_data), which is going to be filled with dictionaries representing each publisher encountered,\u00a0<\/li><li style = \"counter-reset:ol0;\">two empty lists (i.e.: correct_dois_data and incorrect_dois_data), which are going to store citational data in form of lists.<\/li><\/ol><\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#94EBFF","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1171778,"guid":"5D32FBE0AC2211EBA11869784025321E","previous_id":1171777,"previous_guid":"3D9CBDC0AC2211EBA11869784025321E","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"5529670A13344A1E8BC55667CDED04A4","order_id":1,"type_id":6,"title":"Section","source":{"title":"Reading the CSV Data"}},{"id":1054724,"guid":"99CAC9A7238546CD89F6A819860F23D0","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">After that, in order to retrieve data gathered in the previous runs of the code, we run the function extract_row_number(publisher_data), which reads the cache files we create in the following steps and fills the aforementioned publisher_data dictionary and also returns:<\/div><div class = \"text-block\"><ol style = \"list-style-type: decimal;\"><li style = \"counter-reset:ol0;\">start_index, an integer which shows from which row in the CSV we should restart the process,<\/li><li style = \"counter-reset:ol0;\">prefix_to_name_dict, a dictionary which keeps known prefix to publisher name matchings, in order to avoid making extraneous API calls when encountering an already seen prefix.<\/li><\/ol><\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#94EBFF","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1171780,"guid":"1D93F240AC2311EBA11869784025321E","previous_id":1171778,"previous_guid":"5D32FBE0AC2211EBA11869784025321E","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"6D50768603D84602A161F5B664C52B64","order_id":1,"type_id":6,"title":"Section","source":{"title":"Processing Each Line in the CSV File and Extracting the Needed Information"}},{"id":1054724,"guid":"74B93F8E31E349CB940C6A72DEE78213","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">In this step, we check if we have processed 100 rows since the last write to cache. If we have, we write to the cache files once again.<\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#84CE84","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1171783,"guid":"6482F930AC2311EBA11869784025321E","previous_id":1171780,"previous_guid":"1D93F240AC2311EBA11869784025321E","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"D283296961C142278DC1FAD1B5AC0D42","order_id":1,"type_id":6,"title":"Section","source":{"title":"Processing Each Line in the CSV File and Extracting the Needed Information"}},{"id":1054724,"guid":"A5338EC066B3464C93CD5EF5730C9407","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">We initialize a counter\u2019s value to 0 (i.e.: i = 0), so to keep the count of the already processed rows.\u00a0\u00a0<\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#84CE84","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1171785,"guid":"D4B4BEA0AC2311EBA11869784025321E","previous_id":1171783,"previous_guid":"6482F930AC2311EBA11869784025321E","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"2068E4FB960A48AE8731ED80BAE6610F","order_id":1,"type_id":6,"title":"Section","source":{"title":"Processing Each Line in the CSV File and Extracting the Needed Information"}},{"id":1054724,"guid":"1CB44CD41C08443F99AFA55DA0A5CD01","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">If the counter is lesser than 100, we skip to the API request step. In the opposite case, when the counter reaches 100 (a sample value that can be changed if wanted), we call the write_to_csv(publisher_data, prefix_to_name_dict, correct_dois_data, incorrect_dois_data) function, whose aim is that of writing everything we have processed so far to cache files in order to avoid loss of data in case the running of the code is for some reason interrupted. The cache files are:<\/div><div class = \"text-block\"><ol style = \"list-style-type: decimal;\"><li style = \"counter-reset:ol0;\">correct_dois.csv, which includes every citation row with a cited DOI we found to have been validated since the creation of our source, the invalid_dois.csv file, <\/li><li style = \"counter-reset:ol0;\"><a href=\"#\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\"> <\/span><\/a><\/li><li style = \"counter-reset:ol0;\"><\/li><li style = \"counter-reset:ol0;\">incorrect dois.csv, which includes every citation row with a cited DOI we found to still be invalid, <\/li><li style = \"counter-reset:ol0;\"><a href=\"#\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\"> <\/span><\/a><\/li><li style = \"counter-reset:ol0;\"><\/li><li style = \"counter-reset:ol0;\">publiser_data.csv, which includes a row for each publisher, containing information on:<\/li><li style = \"counter-reset:ol0;\">its name,<\/li><li style = \"counter-reset:ol0;\">the number of still invalid citations it is responsible for,<\/li><li style = \"counter-reset:ol0;\">the number of now valid citations it is responsible for,<\/li><li style = \"counter-reset:ol0;\">the number of still invalid citations its publications have received,<\/li><li style = \"counter-reset:ol0;\">the number of now valid citations its publications have received.<\/li><\/ol><\/div><table border><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.1007\/s11771-020-4410-2<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.13745\/j.esf.2016.02.011<\/td><\/tr><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.1007\/s40617-018-00299-1<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.1901\/jaba.2012.45-657<\/td><\/tr><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.1145\/3190617<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.1145\/2838344.2856460<\/td><\/tr><\/table><div class = \"text-block\"><ol style = \"list-style-type: decimal;\"><li style = \"counter-reset:ol0;\">incorrect dois.csv, which includes every citation row with a cited DOI we found to still be invalid, <\/li><li style = \"counter-reset:ol0;\"><a href=\"#\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\"> <\/span><\/a><\/li><li style = \"counter-reset:ol0;\"><\/li><li style = \"counter-reset:ol0;\">publiser_data.csv, which includes a row for each publisher, containing information on:<\/li><li style = \"counter-reset:ol0;\">its name,<\/li><li style = \"counter-reset:ol0;\">the number of still invalid citations it is responsible for,<\/li><li style = \"counter-reset:ol0;\">the number of now valid citations it is responsible for,<\/li><li style = \"counter-reset:ol0;\">the number of still invalid citations its publications have received,<\/li><li style = \"counter-reset:ol0;\">the number of now valid citations its publications have received.<\/li><\/ol><\/div><table border><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.14778\/1920841.1920954<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.5555\/646836.708343<\/td><\/tr><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.5406\/ethnomusicology.59.2.0202<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.2307\/20184517<\/td><\/tr><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.1161\/01.cir.63.6.1391<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.1161\/01.cir.63.6.1391<\/td><\/tr><\/table><div class = \"text-block\"><ul style = \"list-style-type:disc;\"><li style = \"counter-reset:ol0;list-style-type:disc;\">publiser_data.csv, which includes a row for each publisher, containing information on:<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">its name,<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">the number of still invalid citations it is responsible for,<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">the number of now valid citations it is responsible for,<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">the number of still invalid citations its publications have received,<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">the number of now valid citations its publications have received.<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\"><a href=\"#\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\"> <\/span><\/a><\/li><li style = \"counter-reset:ol0;list-style-type:disc;\"><\/li><li style = \"counter-reset:ol0;list-style-type:disc;\"><\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">prefix_name.json, which includes the aforementioned prefix to publisher name matchings. <\/li><\/ul><\/div><div class = \"text-block\"><ol style = \"list-style-type: decimal;\"><li style = \"counter-reset:ol0;\">its name,<\/li><li style = \"counter-reset:ol0;\">the number of still invalid citations it is responsible for,<\/li><li style = \"counter-reset:ol0;\">the number of now valid citations it is responsible for,<\/li><li style = \"counter-reset:ol0;\">the number of still invalid citations its publications have received,<\/li><li style = \"counter-reset:ol0;\">the number of now valid citations its publications have received.<\/li><\/ol><\/div><table border><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">VLDB Endowment<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">15<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">377<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">120<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">0<\/td><\/tr><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">Test accounts<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">0<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">0<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">0<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">17267<\/td><\/tr><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">University of Illinois Press<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">0<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">187<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">0<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">6<\/td><\/tr><\/table><div class = \"text-block\"><ul style = \"list-style-type:disc;\"><\/ul><\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">{<\/div><div class = \"text-block\">    \"10.14778\": \"VLDB Endowment\",<\/div><div class = \"text-block\">    \"10.5555\": \"Test accounts\",<\/div><div class = \"text-block\">    \"10.5406\": \"University of Illinois Press\",<\/div><div class = \"text-block\">    ...<\/div><div class = \"text-block\">}<\/div><\/div><\/code><\/pre><\/div><\/div>"}},{"id":1054725,"guid":"8C09F44489CC43A2AAB6E9674F289E8D","order_id":2,"type_id":1,"title":"description","source":{"description":"<table border><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.1007\/s11771-020-4410-2<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.13745\/j.esf.2016.02.011<\/td><\/tr><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.1007\/s40617-018-00299-1<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.1901\/jaba.2012.45-657<\/td><\/tr><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.1145\/3190617<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.1145\/2838344.2856460<\/td><\/tr><\/table>"}},{"id":1054726,"guid":"D57E7428942E4DB694D97AF804A94233","order_id":3,"type_id":1,"title":"description","source":{"description":"<table border><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.14778\/1920841.1920954<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.5555\/646836.708343<\/td><\/tr><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.5406\/ethnomusicology.59.2.0202<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.2307\/20184517<\/td><\/tr><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.1161\/01.cir.63.6.1391<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.1161\/01.cir.63.6.1391<\/td><\/tr><\/table>"}},{"id":1054727,"guid":"B8E8B2FF87E04A5F9B2BBB2C80887DEB","order_id":4,"type_id":1,"title":"description","source":{"description":"<table border><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">VLDB Endowment<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">15<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">377<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">120<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">0<\/td><\/tr><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">Test accounts<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">0<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">0<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">0<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">17267<\/td><\/tr><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">University of Illinois Press<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">0<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">187<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">0<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">6<\/td><\/tr><\/table>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#84CE84","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1171786,"guid":"09FFEEE0AC2411EBA11869784025321E","previous_id":1171785,"previous_guid":"D4B4BEA0AC2311EBA11869784025321E","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"2EB9D3EA552D4245B0D30F0825B03318","order_id":1,"type_id":6,"title":"Section","source":{"title":"Processing Each Line in the CSV File and Extracting the Needed Information"}},{"id":1054724,"guid":"223C6BE30B3D490092EFC92C010C23A7","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">We empty both correct_dois_data and incorrect_dois_data by assigning to them two empty lists.<\/div><div class = \"text-block\">We then increment the value of the variable start_index by i (i.e.: the value of the counter), and we re-initialize the value of the counter i to 0.\u00a0<\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#84CE84","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1171803,"guid":"A5DA1640AC2611EBA11869784025321E","previous_id":1171767,"previous_guid":"9BE45949962D402DA67ED6C4B82982C5","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"7A08A9975F01409CBB90DE6FDB1C5EB8","order_id":1,"type_id":6,"title":"Section","source":{"title":"Processing Each Line in the CSV File and Extracting the Needed Information"}},{"id":1054724,"guid":"E8A71EF116BD4417A05B4AC991B58AEA","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">In the case the response is positive (i.e.: we get a status code 200), we append the list representing the citational data to correct_dois_data list, and we call the function extract_publisher_valid(row, publisher_data, prefix_to_name_dict) in order to manage the identification of both the publishers of the citing and the cited DOIs. With this function, we first check whether the prefix of the cited DOI exists in our prefix to publisher name matching dictionary. If it does not, we call the extract_publishers(prefix, prefix_to_name_dict) function to find the name of the publisher by sending an API request to the Crossref REST API for prefixes, <\/div><div class = \"text-block\"><a href=\"https:\/\/api.crossref.org\/prefixes\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">https:\/\/api.crossref.org\/prefixes\/<\/span><\/a><\/div><div class = \"text-block\">, (putting the publisher\u2019s name as \"unidentified\" in case Crossref does not recognize the prefix) and then, if the publisher name is not already a key in the publisher_data dictionary, we create a new item in the publisher_data dictionary with key set to the name we found and the respective field based on the publisher (i.e. \u201cresponsible_for_v\u201d or \u201creceiving_v\u201d) set to 1. otherwise , based on the function, we add 1 to the respective field of the publisher item with that name as key in the publisher_data dictionary\u00a0 (i.e. \u201cresponsible_for_v\u201d or \u201creceiving_v\u201d).<\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#84CE84","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1171884,"guid":"C6821280AC2611EBA11869784025321E","previous_id":1171767,"previous_guid":"9BE45949962D402DA67ED6C4B82982C5","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"6E5AED702F98418CB8F22D39A5954322","order_id":1,"type_id":6,"title":"Section","source":{"title":"Processing Each Line in the CSV File and Extracting the Needed Information"}},{"id":1054724,"guid":"516258D7FF4741A6B60D64D4A62711BE","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\"><span>In the opposite case, we append the list representing the citational data to incorrect_dois_data list, and we call the function extract_publisher_invalid(row, publisher_data, prefix_to_name_dict) in order to manage the identification of both the publishers of the citing and the cited DOIs. The functionality of this function is very much like that of the aforementioned extract_publisher_valid(row, publisher_data, prefix_to_name_dict), with the only diffe<\/span><span style = \":UNDERLINE;\">re<\/span><span>nce that it intervenes on the field devoted to the storage of the data about citational data that couldn\u2019t be validated (i.e.: \u201cresponsible_for_i\u201d and \u201creceiving_i\u201d).\u00a0<\/span><\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#84CE84","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1171885,"guid":"A52BB860AC2711EBA11869784025321E","previous_id":1171775,"previous_guid":"58EE3649CCB34C5ABB94CFEFF9438078","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"8ACF22E495DF40F8A7F9797837319D1B","order_id":1,"type_id":6,"title":"Section","source":{"title":"Creating the Output File"}},{"id":1054724,"guid":"CB63E4E519F4482687C3D7F7D6324B98","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">In order to store the data retrieved after the last cache files update (i.e.: the data related to the csv lines processed after the last re-initialization of the i counter to 0), the write_to_csv(publisher_data, prefix_to_name_dict, correct_dois_data, incorrect_dois_data) function is called once again, and the two lists correct_dois_data and incorrect_dois_data are newly emptied.<\/div><div class = \"text-block\">At this point, the retrieved data has to be used to compile the output JSON file.<\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#FFED92","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1171886,"guid":"B04F2150AC2711EBA11869784025321E","previous_id":1171885,"previous_guid":"A52BB860AC2711EBA11869784025321E","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"1F62BCF28293468D833ADAA19797E2D2","order_id":1,"type_id":6,"title":"Section","source":{"title":"Creating the Output File"}},{"id":1054724,"guid":"AC6EAB6E6312486889818EAA7AB9CA33","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\"><span>We read all cache files and put them together in the following way: <\/span><span style = \"font-weight:bold;\">[INSERT EXAMPLE DICT]<\/span><\/div><div class = \"text-block\">The output file is a json file which includes the following fields:<\/div><div class = \"text-block\"><ul style = \"list-style-type:disc;\"><li style = \"counter-reset:ol0;list-style-type:disc;\">citations, a dictionary with the two fields \"valid\" and \"invalid\", each of which includes a list of dictionaries for all the citation data in correct_dois.csv and incorrect_dois.csv respectively,<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">publishers, a list of dictionaries, each of which contains all information gathered about a publisher extracted from publisher_data.csv and prefix_name.json,<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">total_num_of_valid_citations, an integer showing the number of processed citation data that we found to have been validated after the initial source file creation.<\/li><\/ul><\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#FFED92","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1171889,"guid":"E2F9D190AC3111EBA11869784025321E","previous_id":1171764,"previous_guid":"44FA81478AEB4889954619565DC952A8","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"7BEF8642E30D41E99625ACD06114A002","order_id":1,"type_id":6,"title":"Section","source":{"title":"Creating the Output JSON File"}},{"id":1054724,"guid":"E2BA4B8561204AEEADFC0AC547368D96","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">In order to store the data retrieved after the last cache files update (i.e.: the data related to the csv lines processed after the last re-initialization of the i counter to 0), the write_to_csv(publisher_data, prefix_to_name_dict, correct_dois_data, incorrect_dois_data) function is called once again, and the two lists correct_dois_data and incorrect_dois_data are newly emptied.<\/div><div class = \"text-block\">At this point, the retrieved data has to be used to compile the output JSON file.<\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#FFED92","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1171890,"guid":"F0471F60AC3111EBA11869784025321E","previous_id":1171889,"previous_guid":"E2F9D190AC3111EBA11869784025321E","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"A22BDF933ED94134AA508A3951908E44","order_id":1,"type_id":6,"title":"Section","source":{"title":"Creating the Output JSON File"}},{"id":1054724,"guid":"DCD48C1EF7D44F73999DCFD0BC9C78A7","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">We read all cache files and put them together in the following way: <\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">{<\/div><div class = \"text-block\">    \"citations\": {<\/div><div class = \"text-block\">        \"valid\": [<\/div><div class = \"text-block\">            {<\/div><div class = \"text-block\">                \"Valid_citing_doi\": \"10.1007\/s11771-020-4410-2\",<\/div><div class = \"text-block\">                \"Valid_cited_doi\": \"10.13745\/j.esf.2016.02.011\"<\/div><div class = \"text-block\">            },<\/div><div class = \"text-block\">            ...<\/div><div class = \"text-block\">         ]<\/div><div class = \"text-block\">        \"invalid\": [<\/div><div class = \"text-block\">            {<\/div><div class = \"text-block\">                \"Valid_citing_doi\": \"10.14778\/1920841.1920954\",<\/div><div class = \"text-block\">                \"Invalid_cited_doi\": \"10.5555\/646836.708343\"<\/div><div class = \"text-block\">            },<\/div><div class = \"text-block\">            ...<\/div><div class = \"text-block\">        ]<\/div><div class = \"text-block\">    },<\/div><div class = \"text-block\">    \"publishers\": [<\/div><div class = \"text-block\">        {<\/div><div class = \"text-block\">            \"name\": \"VLDB Endowment\",<\/div><div class = \"text-block\">            \"responsible_for_v\": 15,<\/div><div class = \"text-block\">            \"responsible_for_i\": 377,<\/div><div class = \"text-block\">            \"receiving_v\": 120,<\/div><div class = \"text-block\">            \"receiving_i\": 0,<\/div><div class = \"text-block\">            \"prefix_list\": [<\/div><div class = \"text-block\">                \"10.14778\"<\/div><div class = \"text-block\">            ]<\/div><div class = \"text-block\">        },<\/div><div class = \"text-block\">        ...<\/div><div class = \"text-block\">    ],<\/div><div class = \"text-block\">    \"total_num_of_valid_citations\": 12219<\/div><div class = \"text-block\">}<\/div><\/div><\/code><\/pre><\/div><div class = \"text-block\">The output file is a json file which includes the following fields:<\/div><div class = \"text-block\"><ul style = \"list-style-type:disc;\"><li style = \"counter-reset:ol0;list-style-type:disc;\">citations, a dictionary with the two fields \"valid\" and \"invalid\", each of which includes a list of dictionaries for all the citation data in correct_dois.csv and incorrect_dois.csv respectively,<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">publishers, a list of dictionaries, each of which contains all information gathered about a publisher extracted from publisher_data.csv and prefix_name.json,<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">total_num_of_valid_citations, an integer showing the number of processed citation data that we found to have been validated after the initial source file creation.<\/li><\/ul><\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#FFED92","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1172038,"guid":"7256E6E0AC4911EBB59AB3A90F7830B6","previous_id":1171890,"previous_guid":"F0471F60AC3111EBA11869784025321E","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"9CC3EE8DB0C14074B19AA399A61B488D","order_id":1,"type_id":6,"title":"Section","source":{"title":"Creating Visualizations"}},{"id":1054724,"guid":"8550C69FF73C423B92ACFF939F26B9A9","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">As an extra step, from the collected data we have extrapolated and restructured the relevant information for each research question. We have chosen to represent the data concerning the first two questions with stacked bar charts and tables, and those concerning research question number three with a donut chart. We used Javascript, JQuery, d3.js and ChartJS.<\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#EA9F6C","section_duration":0,"critical":null,"critical_id":null,"duration":0}],"document":"","materials":[],"description":"<div class = \"text-blocks\"><div class = \"text-block\"><span style = \"font-weight:bold;\">A preliminary note<\/span><\/div><div class = \"text-block\"><span>This protocol illustrates the workflow adopted within a scholarly research that operates within the OpenCitations environment, which is an independent infrastructure organization for open scholarship dedicated to the publication of open bibliographic and citation data by the use of <\/span><a href=\"https:\/\/en.wikipedia.org\/wiki\/Semantic_Web\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">Semantic Web<\/span><\/a><span> (<\/span><a href=\"https:\/\/en.wikipedia.org\/wiki\/Linked_data\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">Linked Data<\/span><\/a><span>) technologies. COCI is the OpenCitations Index of Crossref open DOI-to-DOI citations.<\/span><\/div><div class = \"text-block\"><span style = \"font-weight:bold;\">Purpose<\/span><\/div><div class = \"text-block\">The primary purpose of this research is to find the publishers responsible for the missing citations in COCI (the OpenCitations Index of Crossref open DOI-to-DOI citations) by sending incorrect metadata to Crossref, the publishers to whom such invalid citations point to, and the number of previously invalid citations which are currently valid. Further, the additional aim of the present research is to provide material for future and deeper research on the same subject matter. In particular, we focus on keeping track of the main trends of evolution on the validity of citational data and on providing data to facilitate publishers' identification.<\/div><div class = \"text-block\"><span style = \"font-weight:bold;\">Study design\/methodology<\/span><\/div><div class = \"text-block\">In order to study the invalid citations, we use an already generated CSV file which is available online, containing - for each citation - the valid citing DOI and the invalid cited DOI. First of all, through a DOI API request we check whether the validity state of the cited DOI has changed, and then we use DOI's prefix for a CROSSREF API request, in order to identify the responsible and referenced publishers.<\/div><div class = \"text-block\"><span style = \"font-weight:bold;\">Findings<\/span><\/div><div class = \"text-block\">For each individual publisher, we retrieve the number of incorrect given citations metadata sent, and the number of invalid citations received, to which we decided to add the information about the number of addressed and received citations validated with the software we developed, and its list of prefixes. We also extract the total number of invalid citations that have since been corrected. Any further material provided as result of this research, such as the lists of validated and still invalid citations, is meant to incentivize future improvements of the studies on this field.<\/div><div class = \"text-block\"><span style = \"font-weight:bold;\">Originality\/value<\/span><\/div><div class = \"text-block\">The results of this research may point us to publishers who generally send out incorrect citation metadata and, inversely, those who generally receive invalid citations. These findings can first of all raise awareness of the accuracy of certain publishing houses in managing their metadata (or lack thereof). Moreover, finding these trends and showcasing the labor of the corrections may lead to increasingly valid citations if the proper measures are taken.<\/div><div class = \"text-block\"><span style = \"font-weight:bold;\">Research limitations\/implications<\/span><\/div><div class = \"text-block\">Based on the available data for COCI, there may be a slight bias in our sample, causing some publishers to be incorrectly represented.<\/div><div class = \"text-block\"><span style = \"font-weight:bold;\">Minimal bibliography on related projects<\/span><\/div><div class = \"text-block\"><ul style = \"list-style-type:disc;\"><li style = \"counter-reset:ol0;list-style-type:disc;\"><span>Heibi, I., Peroni, S. & Shotton, D. Software review: COCI, the OpenCitations Index of Crossref open DOI-to-DOI citations.Scientometrics 121, 1213\u20131228 (2019). <\/span><a href=\"https:\/\/doi.org\/10.1007\/s11192-019-03217-6\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">https:\/\/doi.org\/10.1007\/s11192-019-03217-6<\/span><\/a><span>.<\/span><\/li><li style = \"counter-reset:ol0;list-style-type:disc;\"><span>Silvio Peroni, David Shotton (2020). OpenCitations, an infrastructure organization for open scholarship. Quantitative Science Studies, 1(1): 428-444. <\/span><a href=\"https:\/\/doi.org\/10.1162\/qss_a_00023\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">https:\/\/doi.org\/10.1162\/qss_a_00023<\/span><\/a><span style = \":;\">.<\/span><\/li><li style = \"counter-reset:ol0;list-style-type:disc;\"><span>Peroni, S. (2021). Citations to invalid DOI-identified entities obtained from processing DOI-to-DOI citations to add in COCI (1.0). Zenodo. <\/span><a href=\"https:\/\/doi.org\/10.5281\/ZENODO.4625300\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">https:\/\/doi.org\/10.5281\/ZENODO.4625300<\/span><\/a><span style = \":;\">.<\/span><\/li><\/ul><\/div><div class = \"text-block\"><span style = \"font-weight:bold;\">Related Diagrams<\/span><\/div><div class = \"text-block\">In order to improve readability and reusability of our protocol, we provide here both the reduced and the extended version of the flow diagram representing the steps of the procedure. <\/div><\/div>","changed_on":1620076740}