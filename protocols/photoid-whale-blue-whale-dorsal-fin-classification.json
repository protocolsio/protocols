{"id":35633,"title":"PhotoId-Whale: blue whale dorsal fin classification for mobile devices","title_html":"<p>PhotoId-Whale: blue whale dorsal fin classification for mobile devices<\/p>","image":{"source":"https:\/\/s3.amazonaws.com\/protocols-files\/public\/a83c8da8a362624cca1144a775f190cc12cd44f2e5b4fc540ca28ee2d82d9dcf\/b5jxbct6x.png","placeholder":"https:\/\/s3.amazonaws.com\/protocols-files\/public\/a83c8da8a362624cca1144a775f190cc12cd44f2e5b4fc540ca28ee2d82d9dcf\/b5jxbct6x.png"},"doi":"dx.doi.org\/10.17504\/protocols.io.be2rjgd6","doi_status":2,"uri":"photoid-whale-blue-whale-dorsal-fin-classification-be2rjgd6","type_id":1,"template_id":1,"published_on":1602605162,"parent_protocols":[],"parent_collections":[],"cited_protocols":[],"version_id":0,"version_data":{"id":"0","code":"be2rjgd6","parent_id":0,"parent_uri":null,"is_same_owner":false,"has_pending_merge_request":false,"has_approved_merge_request":false},"created_on":1586831873,"modified_on":null,"categories":null,"public":1,"is_unlisted":0,"creator":{"name":"Rosa I Ramos-Arredondo","affiliation":"Instituto Polit\u00e9cnico Nacional - ESIME Culhuacan ","affiliations":[{"affiliation":"Instituto Polit\u00e9cnico Nacional - ESIME Culhuacan ","url":"https:\/\/posgrados.esimecu.ipn.mx\/","is_default":1}],"username":"rosa-i-ramosarredondo","note":null,"link":"https:\/\/doi.org\/10.1371\/journal.pone.0237570","image":{"source":"https:\/\/s3.amazonaws.com\/protocols-files\/public\/a83c8da8a362624cca1144a775f190cc12cd44f2e5b4fc540ca28ee2d82d9dcf\/b5nzbct6x.jpg","placeholder":"https:\/\/s3.amazonaws.com\/protocols-files\/public\/a83c8da8a362624cca1144a775f190cc12cd44f2e5b4fc540ca28ee2d82d9dcf\/b5nzbct6x.jpg"},"badges":[{"id":2,"image":{"source":"\/img\/badges\/bronze.svg","placeholder":"\/img\/badges\/bronze.svg"},"name":"Author"}],"verified":0,"is_verified_user":false,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},"journal":"PLOS One","journal_name":"PLOS One","journal_link":"https:\/\/doi.org\/10.1371\/journal.pone.0237570","article_citation":"Ramos-Arredondo RI,  Carvajal-G\u00e1mez BE,  Gendron D,  Gallegos-Funes FJ,  M\u00fajica-Vargas D,  Rosas-Fern\u00e1ndez JB (2020) PhotoId-Whale: Blue whale dorsal fin classification for mobile devices. PLoS ONE  15(10): e0237570. doi: <a target=\"_blank\" href=\"https:\/\/dx.doi.org\/10.1371\/journal.pone.0237570\">10.1371\/journal.pone.0237570<\/a> ","has_versions":0,"link":"https:\/\/doi.org\/10.1371\/journal.pone.0237570","total_collections":0,"number_of_steps":7,"authors":[{"name":"Rosa I Ramos-Arredondo","affiliation":"Instituto Polit\u00e9cnico Nacional - ESIME Culhuacan ","affiliations":[],"username":"rosa-i-ramosarredondo","note":null,"link":null,"image":{"source":"https:\/\/s3.amazonaws.com\/protocols-files\/public\/a83c8da8a362624cca1144a775f190cc12cd44f2e5b4fc540ca28ee2d82d9dcf\/b5nzbct6x.jpg","placeholder":"https:\/\/s3.amazonaws.com\/protocols-files\/public\/a83c8da8a362624cca1144a775f190cc12cd44f2e5b4fc540ca28ee2d82d9dcf\/b5nzbct6x.jpg"},"badges":[],"verified":1,"is_verified_user":true,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},{"name":"Blanca E","affiliation":"Blanca E. Carvajal-G\u00e1mez(SEPI-ESCOM, Instituto Polit\u00e9cnico Nacional)","affiliations":[],"username":"blanca-e","note":null,"link":null,"image":{"source":"\/img\/avatars\/011.png","placeholder":"\/img\/avatars\/011.png"},"badges":[],"verified":1,"is_verified_user":true,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},{"name":"Diane Gendron","affiliation":"(CICIMAR, Instituto Polit\u00e9cnico Nacional)","affiliations":[],"username":null,"note":null,"link":null,"image":{"source":null,"placeholder":null},"badges":[],"verified":0,"is_verified_user":false,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},{"name":"J. Francisco Gallegos-Funes","affiliation":"(SEPI-Zacatenco, Instituto Polit\u00e9cnico Nacional)","affiliations":[],"username":null,"note":null,"link":null,"image":{"source":null,"placeholder":null},"badges":[],"verified":0,"is_verified_user":false,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},{"name":"Dante M\u00fajica-Vargas","affiliation":"(Departamento de Ciencias Computacionales, Tecnol\u00f3gico Nacional de M\u00e9xico)","affiliations":[],"username":null,"note":null,"link":null,"image":{"source":null,"placeholder":null},"badges":[],"verified":0,"is_verified_user":false,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},{"name":"J.B. Rosas-Fern\u00e1ndez","affiliation":"(Secretar\u00eda de Educaci\u00f3n, Ciencia, Tecnolog\u00eda e Innovaci\u00f3n)","affiliations":[],"username":null,"note":null,"link":null,"image":{"source":null,"placeholder":null},"badges":[],"verified":0,"is_verified_user":false,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false}],"versions":[],"groups":[],"is_owner":1,"has_subprotocols":0,"is_subprotocol":0,"is_bookmarked":0,"can_claim_authorship":0,"can_accept_authorship":0,"can_be_copied":1,"can_remove_fork":1,"fork_id":null,"url":"https:\/\/www.protocols.io\/view\/photoid-whale-blue-whale-dorsal-fin-classification-be2rjgd6","forks_count":{"private":0,"public":0},"access":{"can_view":1,"can_remove":0,"can_add":0,"can_edit":0,"can_publish":0,"can_get_doi":0,"can_share":1,"can_move":1,"can_move_outside":1,"can_transfer":1,"can_download":1,"is_locked":0},"guid":"F8B157207DF611EAA64E8908EBF0F563","state_version_id":251,"steps":[{"id":916128,"guid":"12DF43407E7011EAB21B9F1FBCD9747E","previous_id":null,"previous_guid":null,"modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"85E4A5BBD62A43A185B862D049E352FD","order_id":1,"type_id":6,"title":"Section","source":{"title":"Image to be classified"}},{"id":1054724,"guid":"81C7F346AAA04D16B9B562F4CC4868DF","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Obtain the image to be classified. The image is obtained from the database or acquired in the field. <\/div><div class = \"text-block\"><a href=\"https:\/\/www.cicimar.ipn.mx\/.\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">CICIMAR-IPN researchers<\/span><\/a><\/div><div class = \"text-block\">.<\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#A492FF","section_duration":0,"critical":[],"critical_id":null,"duration":0},{"id":916131,"guid":"3ED589007E7011EAB21B9F1FBCD9747E","previous_id":916128,"previous_guid":"12DF43407E7011EAB21B9F1FBCD9747E","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"F4A3B64EF21548C782EA1570F28C93B0","order_id":1,"type_id":6,"title":"Section","source":{"title":"Image Pre-Processing"}},{"id":1054724,"guid":"888FBA72CEA5446F8E0B7D8DE8000E78","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">This stage is divided into two substages, which are described below<\/div><div class = \"text-block\">i)\tROI selection: by means of a graphical interface, the initial point is indicated, mainly in the area of the dorsal fin according to the criteria proposed in reference.<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/a83c8da8a362624cca1144a775f190cc12cd44f2e5b4fc540ca28ee2d82d9dcf\/b5j2bct6x.png\" \/><\/div><div class = \"text-block\">ii) Extraction of the dorsal fin from the image background<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/a83c8da8a362624cca1144a775f190cc12cd44f2e5b4fc540ca28ee2d82d9dcf\/b5j3bct6x.png\" \/><\/div><\/div>"}},{"id":1054725,"guid":"64331675E4CA4A9C9B12FE21B7F27ED6","order_id":2,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/a83c8da8a362624cca1144a775f190cc12cd44f2e5b4fc540ca28ee2d82d9dcf\/b5j2bct6x.png\" \/><\/div>"}},{"id":1054726,"guid":"C1F7EA168B94458DB7C1473F14BED35E","order_id":3,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/a83c8da8a362624cca1144a775f190cc12cd44f2e5b4fc540ca28ee2d82d9dcf\/b5j3bct6x.png\" \/><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#94EBFF","section_duration":0,"critical":[],"critical_id":null,"duration":0},{"id":916133,"guid":"519C0DC07E7011EAB21B9F1FBCD9747E","previous_id":916131,"previous_guid":"3ED589007E7011EAB21B9F1FBCD9747E","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"0CC05FC11F954B8F8D25D43DCE9A0D25","order_id":1,"type_id":6,"title":"Section","source":{"title":"Extraction of main characteristics"}},{"id":1054724,"guid":"E577BCDC75374EF693A819DA10A2C6BE","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Extraction of main characteristics: From the result obtained in step 2, SIFT is implemented on the contour of the dorsal fin. Figure shows a block diagram of the considerations made in the extraction of the main characteristics of the processed images obtained in step 2.<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/a83c8da8a362624cca1144a775f190cc12cd44f2e5b4fc540ca28ee2d82d9dcf\/b5j4bct6x.png\" \/><\/div><\/div>"}},{"id":1054725,"guid":"D9563C4FBC4C4D44B5698C1B4C555063","order_id":2,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/a83c8da8a362624cca1144a775f190cc12cd44f2e5b4fc540ca28ee2d82d9dcf\/b5j4bct6x.png\" \/><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#84CE84","section_duration":0,"critical":[],"critical_id":null,"duration":0},{"id":916134,"guid":"608AFDA07E7011EAB21B9F1FBCD9747E","previous_id":916133,"previous_guid":"519C0DC07E7011EAB21B9F1FBCD9747E","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"95F3D6146DBD4BEC9BCB296B59C45E8B","order_id":1,"type_id":6,"title":"Section","source":{"title":"Classification"}},{"id":1054724,"guid":"0504FB26AA71489BB9C0F83BF3430A72","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">We divide this stage into different subsets of steps to improve the analysis performance of all the images that are contained in the dorsal fin image database.<\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#FFED92","section_duration":0,"critical":[],"critical_id":null,"duration":0},{"id":916149,"guid":"E7415D107E7711EA8A7111D15EDCCBC6","previous_id":916134,"previous_guid":"608AFDA07E7011EAB21B9F1FBCD9747E","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"B97E3FD4715E45F4833BB25B169E77D8","order_id":1,"type_id":6,"title":"Section","source":{"title":"Classification"}},{"id":1054724,"guid":"BE98CA17A2824B58A67C7C917FAA77D3","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">A group of images is randomly selected from each class for the proposed training according to the classification made by the <\/div><div class = \"text-block\"><a href=\"https:\/\/www.cicimar.ipn.mx\/.\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">CICIMAR-IPN researchers<\/span><\/a><\/div><div class = \"text-block\">. We worked according to these classes, which are right falcate, left falcate, right hook, left hook, right triangular and left triangular, and selected 20 images from each class for training.<\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#FFED92","section_duration":0,"critical":[],"critical_id":null,"duration":0},{"id":916150,"guid":"5B8B1BC07E7811EA8A7111D15EDCCBC6","previous_id":916149,"previous_guid":"E7415D107E7711EA8A7111D15EDCCBC6","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"8A796C75481B48D885F05E9C5B0A7433","order_id":1,"type_id":6,"title":"Section","source":{"title":"Classification"}},{"id":1054724,"guid":"0FF0D5BD022C43F3A658AF16C0EB4305","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">For the training system, the weights are added to the descriptors of each class in the training samples as shown.<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/a83c8da8a362624cca1144a775f190cc12cd44f2e5b4fc540ca28ee2d82d9dcf\/b5j5bct6x.png\" \/><\/div><div class = \"text-block\">where z is the value of the contrast change of the dorsal fin contour image, N is the number of samples taken by each class, and j corresponds to each of the classes used for classification.<\/div><\/div>"}},{"id":1054725,"guid":"519C05F72E9C483E9ADBA07728AA2B07","order_id":2,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/a83c8da8a362624cca1144a775f190cc12cd44f2e5b4fc540ca28ee2d82d9dcf\/b5j5bct6x.png\" \/><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#FFED92","section_duration":0,"critical":[],"critical_id":null,"duration":0},{"id":916151,"guid":"34AF12207E7A11EA8A7111D15EDCCBC6","previous_id":916150,"previous_guid":"5B8B1BC07E7811EA8A7111D15EDCCBC6","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"5DDD09C8CD0D499A91A68D3385D15FE5","order_id":1,"type_id":6,"title":"Section","source":{"title":"Classification"}},{"id":1054724,"guid":"5003E7F9FB3048DE87942F3F88E59DD2","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\"><div class = \"justify\" style = \"text-align:justify\">For each class, the number of matching points between the sample image (original sample after ROI selection) and the samples used in the training must be obtained.<\/div><style>\n\t\t\t\t\t\t\t  .justify:after {\n\t\t\t\t\t\t\t    content: \"\";\n\t\t\t\t\t\t\t    display:inline-block;\n\t\t\t\t\t\t\t    width: 100%;\n\t\t\t\t\t\t\t  }\n\t\t\t\t\t\t\t<\/style><\/div><div class = \"text-block\"><div class = \"justify\" style = \"text-align:justify\">The number of intersections is calculated with the norm of the Euclidean distance between two samples and the ordinate with the minimum distance between them.<\/div><style>\n\t\t\t\t\t\t\t  .justify:after {\n\t\t\t\t\t\t\t    content: \"\";\n\t\t\t\t\t\t\t    display:inline-block;\n\t\t\t\t\t\t\t    width: 100%;\n\t\t\t\t\t\t\t  }\n\t\t\t\t\t\t\t<\/style><\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/a83c8da8a362624cca1144a775f190cc12cd44f2e5b4fc540ca28ee2d82d9dcf\/b5j6bct6x.png\" \/><\/div><div class = \"text-block\"><span>where class number is the number of total classes to classify, N is the number of training samples, x and y are the coordinates of the vector at the current training position, <\/span><span style = \"font-style:italic;\">L (j, x, y, \u03c3)<\/span><span>is the position of the value in the vector of the image in different scales, | |<\/span><span style = \"vertical-align:sub;\">L2<\/span><span> and is the norm of the vector L2. <\/span><\/div><div class = \"text-block\">A graphical interpretation of the method :<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/a83c8da8a362624cca1144a775f190cc12cd44f2e5b4fc540ca28ee2d82d9dcf\/b5j8bct6x.png\" \/><\/div><div class = \"text-block\"><div class = \"justify\" style = \"text-align:justify\"> <\/div><style>\n\t\t\t\t\t\t\t  .justify:after {\n\t\t\t\t\t\t\t    content: \"\";\n\t\t\t\t\t\t\t    display:inline-block;\n\t\t\t\t\t\t\t    width: 100%;\n\t\t\t\t\t\t\t  }\n\t\t\t\t\t\t\t<\/style><\/div><div class = \"text-block\"><div class = \"justify\" style = \"text-align:justify\"><\/div><style>\n\t\t\t\t\t\t\t  .justify:after {\n\t\t\t\t\t\t\t    content: \"\";\n\t\t\t\t\t\t\t    display:inline-block;\n\t\t\t\t\t\t\t    width: 100%;\n\t\t\t\t\t\t\t  }\n\t\t\t\t\t\t\t<\/style><\/div><div class = \"text-block\"><div class = \"justify\" style = \"text-align:justify\"><\/div><style>\n\t\t\t\t\t\t\t  .justify:after {\n\t\t\t\t\t\t\t    content: \"\";\n\t\t\t\t\t\t\t    display:inline-block;\n\t\t\t\t\t\t\t    width: 100%;\n\t\t\t\t\t\t\t  }\n\t\t\t\t\t\t\t<\/style><\/div><div class = \"text-block\"><div class = \"justify\" style = \"text-align:justify\"><\/div><style>\n\t\t\t\t\t\t\t  .justify:after {\n\t\t\t\t\t\t\t    content: \"\";\n\t\t\t\t\t\t\t    display:inline-block;\n\t\t\t\t\t\t\t    width: 100%;\n\t\t\t\t\t\t\t  }\n\t\t\t\t\t\t\t<\/style><\/div><\/div>"}},{"id":1054725,"guid":"F3A48810DFB043CEBF1C0DD651829120","order_id":2,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/a83c8da8a362624cca1144a775f190cc12cd44f2e5b4fc540ca28ee2d82d9dcf\/b5j6bct6x.png\" \/><\/div>"}},{"id":1054726,"guid":"5B0F23B58F9047FA89E336D26BA393C8","order_id":3,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/a83c8da8a362624cca1144a775f190cc12cd44f2e5b4fc540ca28ee2d82d9dcf\/b5j8bct6x.png\" \/><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#FFED92","section_duration":0,"critical":[],"critical_id":null,"duration":0}],"document":null,"materials":[],"description":"<div class = \"text-blocks\"><div class = \"text-block\">Photoidentification is a method used by biologists to classify animals primarily to track endangered species. Different methods of identification, either manual or computational, have been developed since the 1990s, which until now have remained in use. However, these methods can introduce a factor of subjectivity when classifying an individual animal, creating uncertainty or inaccuracy in the results obtained as a result of the human criteria involved. For this reason, one of the main objectives in photoidentification is to implement an automated mechanism that is free of biases, is portable, and is easily used. The main aim of this work is to develop an autonomous and portable photoidentification system through the optimization of image classification algorithms that have high statistical dependence, with the goal of classifying images of the dorsal fin of the blue whale through offline information processing on a mobile device. The new proposed methodology is based on the Scale Invariant Feature Transform (SIFT) that, in conjunction with statistical discriminators such as the variance and the standard deviation, fits the extracted data and selects the closest pixels that make up the edges of the dorsal fin of the blue whale. In this way, we ensure the elimination of the most common external factors that could affect the quality of the image, thus avoiding the elimination of relevant sections of the dorsal fin. The blue whale photoidentification method presented in this work has been developed at the Instituto Polit\u00e9cnico Nacional on the coast of Baja California Sur. The results shown have been validated qualitatively and quantitatively in terms of sensitivity, specificity and accuracy on the Jetson Tegra TK1 mobile platform. The presented solution balances the results obtained with the computational cost of the execution of the algorithm, and yields a portable system that could be beneficial for field studies.<\/div><\/div>","changed_on":1602605162}