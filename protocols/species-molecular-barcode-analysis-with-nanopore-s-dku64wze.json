{"access":{"can_view":true,"can_edit":false,"can_remove":false,"can_add":false,"can_publish":false,"can_get_doi":false,"can_share":true,"can_move":true,"can_move_outside":true,"can_transfer":true,"can_download":true,"limited_run":false,"limited_private_links":false,"limited_blind_links":false,"is_locked":false},"authors":[{"name":"Gideon Erkenswick","affiliation":"Field Projects International","affiliation_url":null,"username":"gideon-erkenswick","link":null,"user_image_file":{"guid":"00000000000000000000000000000001","file_name":"avatar.png","url":"https://www.protocols.io/img/avatars/001.png","mime":"image/png","size":0,"width":100,"height":100,"avg_color":"","scan_status":0,"created_at":0},"note":"","is_verified_user":true},{"name":"Mrinalini Watsa","affiliation":"San Diego Zoo Wildlife Alliance","affiliation_url":null,"username":"mrinalini-watsa","link":null,"user_image_file":{"guid":"00000000000000000000000000000001","file_name":"avatar.png","url":"https://www.protocols.io/img/avatars/001.png","mime":"image/png","size":0,"width":100,"height":100,"avg_color":"","scan_status":0,"created_at":0},"note":"","is_verified_user":true},{"name":"Zane Libke","affiliation":"Field Projects International","affiliation_url":null,"username":"zane-libke","link":"","user_image_file":{"guid":"00000000000000000000000000000001","file_name":"avatar.png","url":"https://www.protocols.io/img/avatars/001.png","mime":"image/png","size":0,"width":100,"height":100,"avg_color":"","scan_status":0,"created_at":0},"note":"","is_verified_user":true},{"name":"Pamela Sánchez-Vendizú","affiliation":"Field Projects International; Programa de Doctorado en Ciencias mención Ecología y Evolución, Escuela Graduados, Facultad de Ciencias, Universidad Austral de Chile, Valdivia, Chile","affiliation_url":"https://www.uach.cl/","username":"pamela-snchezvendiz","link":"https://www.psvbio.com/","user_image_file":{"guid":"00000000000000000000000000000001","file_name":"avatar.png","url":"https://www.protocols.io/img/avatars/001.png","mime":"image/png","size":0,"width":100,"height":100,"avg_color":"","scan_status":0,"created_at":0},"note":"","is_verified_user":true},{"name":"Stefan Prost","affiliation":"University of Oulu","affiliation_url":null,"username":"","link":null,"user_image_file":{"guid":"00000000000000000000000000000001","file_name":"avatar.png","url":"https://www.protocols.io/img/avatars/001.png","mime":"image/png","size":0,"width":100,"height":100,"avg_color":"","scan_status":0,"created_at":0},"note":"","is_verified_user":false}],"before_start":"{\"blocks\":[{\"key\":\"f8g6h\",\"text\":\"Software dependencies:\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"26cle\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"c93v0\",\"text\":\"Please ensure the following are installed on your device. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"d3n3v\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"dvgn3\",\"text\":\"DOCKER (https://www.docker.com/)\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":8,\"length\":23}],\"data\":{}},{\"key\":\"cubjt\",\"text\":\"DORADO (https://github.com/nanoporetech/dorado/)\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":1,\"offset\":8,\"length\":39}],\"data\":{}},{\"key\":\"fjb40\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"cee5o\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"link\",\"mutability\":\"MUTABLE\",\"data\":{\"guid\":\"93F823066E2B11EFA3E30A58A9FEAC02\",\"url\":\"https://www.docker.com\"}},\"1\":{\"type\":\"link\",\"mutability\":\"MUTABLE\",\"data\":{\"guid\":\"94351FA9779311EF8CC50A58A9FEAC02\",\"url\":\"https://github.com/nanoporetech/dorado\"}}}}","book_chapter":null,"can_accept_authorship":false,"can_be_copied":true,"can_claim_authorship":false,"can_manage_keywords":true,"can_remove_fork":false,"can_sign":false,"child_steps":{},"cited_protocols":[],"collection_items":[],"created_on":1725831053,"creator":{"name":"Gideon Erkenswick","affiliation":"Field Projects International","affiliation_url":null,"username":"gideon-erkenswick","link":null,"user_image_file":{"guid":"00000000000000000000000000000001","file_name":"avatar.png","url":"https://www.protocols.io/img/avatars/001.png","mime":"image/png","size":0,"width":100,"height":100,"avg_color":"","scan_status":0,"created_at":0},"badges":[{"id":3,"name":"Power author!","image":{"source":"/img/badges/silver.svg","placeholder":"/img/badges/silver.svg"}}],"affiliations":[{"affiliation":"Field Projects International","url":null,"job_title":null,"is_default":true}]},"cross_cloud_origin":null,"description":"{\"blocks\":[{\"key\":\"67id9\",\"text\":\"End-to-end workflow to generate cleaned consensus sequences from multiplexed amplicons sequenced with Nanopore sequencing technology. Includes read basecalling, quality control, data filtering, read demultiplexing, consensus sequence generation, and a data summary. The workflow assumes that individual samples have been uniquely indexed to allow highly multiplexed sequencing runs. The demultiplexing code is annotated to indicate different demultiplexing strategies utilized in the study. This workflow was used in the publication \\\"Decoding the Peruvian Amazon with in situ DNA barcoding of vertebrate and plant taxa\\\", and the last section of the workflow consists of a custom R script that generates summary statistics specific to the publication. Overall, this workflow can be modified to suit multiple markers, and is applicable to teaching in a classroom setting with the accompanying docker image.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","disclaimer":"{\"blocks\":[{\"key\":\"em7io\",\"text\":\"This is a step-wise bioinformatic workflow to analyze nanopore amplicon sequence data. It includes third party software that was not created nor is maintained by the authors. The end-to-end workflow cannot be replicated without carrying out each of the steps sequentially, and will require tweaks to the input parameters. The final section of the workflow, 'data summary' was created for use with specific spreadsheets used for this study, and will not function in a generic sense on other datasets. This section should be viewed as one example of many potential ways to summarize data.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","document":"","documents":null,"doi":"dx.doi.org/10.17504/protocols.io.6qpvr8y1blmk/v1","doi_status":2,"ethics_statement":"","fork_id":null,"fork_info":null,"fork_info_status":"not_fork","forks":[],"funders":[{"funder_name":"Gordon and Betty Moore Foundation","grant_id":"9772"},{"funder_name":"Gordon and Betty Moore Foundation","grant_id":"9776"},{"funder_name":"United States Forest Service","grant_id":"21-DG-11132762-302"}],"groups":[{"id":105694,"uri":"insitulabs","title":"In Situ Laboratories","is_public":true,"image":{"source":"https://content.protocols.io/files/npsb4hy6.jpg","placeholder":"https://content.protocols.io/files/npsb4hy6.jpg"},"tech_support":{"email":"info@insitulabs.org","phone":null,"use_email":false,"hide_contact":false,"url":null}}],"guid":"25E2E2BB00E2442E8B01557E6F0388F2","guidelines":"{\"blocks\":[{\"key\":\"2uv3o\",\"text\":\"This is not an automated bioinformatics workflow. To replicate the analyses with new data, carefully review and then carry out each step sequentially. Basic Linux command-line literacy is a prerequisite for using this pipeline.  All steps are performed inside freely available Docker containers, eliminating most software compatibility challenges. Take careful note of which Docker image is being used for each step.  Minor adjustments to input parameters and custom code sections is often necessary, especially pertaining to the section on \\\"read demultiplexing\\\".\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"daha5\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"4jtqd\",\"text\":\"Dorado basecaller will run most efficiently with a GPU (review software documentation)\",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"7qk1c\",\"text\":\"Consider parallelizing NGSpeciesID consensus sequence formation and NCBI blast to decrease computational time\",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","has_references":true,"has_step_reagents":false,"has_versions":false,"id":107134,"image":{"source":"https://content.protocols.io/files/rme74hy6.jpg","webp_source":"https://content.protocols.io/files/rme64hy6.webp","placeholder":"https://content.protocols.io/files/rjb64hy6.jpg","webp_placeholder":""},"image_attribution":"{\"blocks\":[{\"key\":\"35mef\",\"text\":\"Hannah Kim\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","in_trash":false,"is_bookmarked":false,"is_contact_suspended":false,"is_content_confidential":false,"is_content_warning":false,"is_doi_reserved":false,"is_in_pending_publishing":false,"is_in_transfer":false,"is_owner":true,"is_research":true,"is_retracted":false,"is_shared_directly":false,"is_subprotocol":null,"is_unlisted":false,"item_id":1294884,"journal":null,"journals":[],"keywords":"nanopore,species identification,molecular barcode,gene markers,coi,cytB,amplicon sequencing,dna barcoding,ngspeciesid,field genomics,in situ","last_modified":1727726888,"link":"","location":null,"manuscript_citation":"{\"blocks\":[{\"key\":\"55foo\",\"text\":\"Decoding the Peruvian Amazon with in situ DNA barcoding of vertebrate and plant taxa. Scientific Data (in review). \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":85}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","materials":[],"materials_text":"{\"blocks\":[{\"key\":\"6ad12\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","ownership_history":null,"parent_collections":[],"parent_protocols":[],"peer_reviewed":false,"protocol_references":"{\"blocks\":[{\"key\":\"enq48\",\"text\":\"Sahlin K, Lim MCW, Prost S. NGSpeciesID: DNA barcode and amplicon consensus generation from long-read sequencing data. Ecol Evol. 2021 Jan 11;11(3):1392-1398. doi: 10.1002/ece3.7146. PMID: 33598139; PMCID: PMC7863402.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","public":true,"public_fork_note":"","published_on":1727726888,"references":[],"related_equipments":[],"related_materials":[],"reserved_doi":"","retraction_reason":null,"samples":{},"shared_access_id":265,"show_comparison":false,"sign_info":null,"space_access":{"can_view":false,"can_edit":false,"can_remove":false,"can_add":false,"can_publish":true,"can_get_doi":true,"can_share":false,"can_move":false,"can_move_outside":false,"can_transfer":false,"can_download":false,"limited_run":false,"limited_private_links":false,"limited_blind_links":false,"is_locked":false},"space_id":105369,"state_version_id":3592,"stats":{"is_voted":false,"number_of_views":53,"number_of_steps":25,"number_of_bookmarks":0,"number_of_comments":2,"number_of_bookmarked_comments":0,"number_of_steps_comments":1,"number_of_protocol_comments":1,"number_of_exports":0,"number_of_runs":0,"number_of_votes":1,"number_of_reagents":0,"number_of_equipments":0,"number_of_collections":0,"number_of_forks":{"private":0,"public":0},"number_of_accessible_forks":0},"status":{"id":1,"info":"We use this protocol and it's working"},"steps":[{"id":2220822,"guid":"5C75DAEE06FD40DB8388A7B35470B909","previous_id":0,"previous_guid":null,"section":"\u003cp\u003ePrepare Working Environment\u003c/p\u003e","section_color":"#A492FF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"cqr29\",\"text\":\"Create a working directory\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107134,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"1","cases":[],"critical":null},{"id":2220823,"guid":"78A0994146804A37907D00B38633ABA2","previous_id":2220834,"previous_guid":"1594CA05574B4CB8A39412FAEF989824","section":"\u003cp\u003eBasecalling Raw Sequence Data \u003c/p\u003e","section_color":"#94EBFF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"fo42g\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"2p6g2\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"cv2hj\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"an3o4\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"8lfsp\",\"text\":\"This command will perform basecalling on all sequence files inside path/to/working/directory/1.all.pod5s\\\\\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":67,\"length\":38}],\"entityRanges\":[],\"data\":{}},{\"key\":\"1bro9\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"f12il\",\"text\":\"Must select a basecalling model:\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"ejfm6\",\"text\":\"- Fast (fast)\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"e0f3c\",\"text\":\"- High Accurancy (hac) *RECOMMENDED FOR AMPLICON SEQUENCE DATA*\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":24,\"length\":39}],\"entityRanges\":[],\"data\":{}},{\"key\":\"8ea80\",\"text\":\"- Super high accuracy (sup) ** TOO SLOW FOR MOST SERVERS\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":28,\"length\":28}],\"entityRanges\":[],\"data\":{}},{\"key\":\"ejesq\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":1,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"38vra\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"notes\",\"mutability\":\"IMMUTABLE\",\"data\":{\"blocks\":[{\"data\":{},\"depth\":0,\"entityRanges\":[],\"inlineStyleRanges\":[],\"key\":\"bn6rm\",\"text\":\"At the time of publication there is was no Docker image for Dorado software, this must be installed separately on the local operating system.\",\"type\":\"unstyled\"}],\"entityMap\":{}}},\"1\":{\"type\":\"command\",\"mutability\":\"IMMUTABLE\",\"data\":{\"can_edit\":true,\"command_name\":\"dorado basecaller\",\"description\":\"\",\"guid\":\"294325386E2D11EF93280A58A9FEAC02\",\"name\":\"\\n${DORAD} basecaller hac ${PODS} --emit-moves --no-trim \\u003e ${HOMEFOL}/2.sam.output/${OUTFILE}.sam\\n\",\"os_name\":\"linux\",\"os_version\":\"\"}}}}","data":null,"protocol_id":107134,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"5","cases":[],"critical":null},{"id":2220824,"guid":"43C1F5D9ADFF4F4DA76C313C0B40B839","previous_id":2220835,"previous_guid":"48CAE94E53504B49B2889FA81D4FA9DF","section":"\u003cp\u003eQC \u0026amp; Filtering\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"7jmj0\",\"text\":\"Run Docker image for pycoQC and create summary plots for the basecalled reads\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"eq8to\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"39mf4\",\"text\":\"Exit Docker before next step\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":28}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"command\",\"mutability\":\"IMMUTABLE\",\"data\":{\"can_edit\":true,\"command_name\":\"pycoQC\",\"description\":\"\",\"guid\":\"BC09C08F6E2D11EFA3E30A58A9FEAC02\",\"name\":\"# run docker\\ndocker run -it -v ${HOMEFOL}:/data nanozoo/pycoqc\\n\\nOUTFILE=example_outfile\\n\\n\\n# run pycoQC\\npycoQC --file /data/2.sam.output/sequencingsummary.${OUTFILE}.txt --outfile /data/${OUTFILE}_pycoQC.html\",\"os_name\":\"linux\",\"os_version\":\"\"}}}}","data":null,"protocol_id":107134,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"7","cases":[],"critical":null},{"id":2220825,"guid":"20B0A121B566441B80933B3EEEB0AD0E","previous_id":2220838,"previous_guid":"A01692DF6E6741409FDF538679416E13","section":"\u003cp\u003eDemultiplex Sequence Data\u003c/p\u003e","section_color":"#FFED92","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"5gmg8\",\"text\":\"Demultiplexing is carried out in 1 or 2 parts, depending on the experimental design:\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"3lrcr\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"92coh\",\"text\":\"Part 1: separating reads based on an outer ONT index kit (usually added by a ligation reaction)\",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"85cq8\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"2co61\",\"text\":\"Part 2: separating reads based on an inner index (usually added by PCR).\",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"clpt3\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"67dl9\",\"text\":\"If the design involved a dual-indexing strategy,   and then carry out Part 2. If not using a dual-indexing strategy, choose whichever part is relevant, either Part 1 or Part 2.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":47}],\"entityRanges\":[{\"key\":0,\"offset\":49,\"length\":1}],\"data\":{}},{\"key\":\"althq\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"gotostep\",\"mutability\":\"MUTABLE\",\"data\":{\"guid\":\"E6EB68ED86AF47CE8B010FFF1083625A\",\"step_guid\":\"A2FAB450DF0B427C984D354BBAD04BF6\",\"title\":\"\"}}}}","data":null,"protocol_id":107134,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"11","cases":[],"critical":null},{"id":2220826,"guid":"62C71A978985485B92BF5DF8CD67A66A","previous_id":2237837,"previous_guid":"F6C040235E8D4FB2800E9EEE5968669C","section":"\u003cp\u003eGenerate Consensus Sequence\u003c/p\u003e","section_color":"#EA9F6C","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"6i7dv\",\"text\":\"Determine fragment size within each outer index group using NanoPlot\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"cdvml\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"9b8nm\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"7oo4j\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"8vk5o\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":1,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"a9stg\",\"text\":\"Remain in the same Docker image for next step\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":45}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"notes\",\"mutability\":\"IMMUTABLE\",\"data\":{\"blocks\":[{\"data\":{},\"depth\":0,\"entityRanges\":[],\"inlineStyleRanges\":[],\"key\":\"anosp\",\"text\":\"If the NanoPlot command (below) fails, exit the Docker image, install NanoPlot to the local machine and run it outside of Docker. NanoPlot normally works fine within Docker, but some users have noted glitches. In our experience, it has been more efficient to run NanoPlot another way, than to fix the glitch within docker.\",\"type\":\"unstyled\"}],\"entityMap\":{}}},\"1\":{\"type\":\"command\",\"mutability\":\"IMMUTABLE\",\"data\":{\"can_edit\":true,\"command_name\":\"Nanoplot (loop)\",\"description\":\"\",\"guid\":\"E3B066D8761611EFA7CE0A58A9FEAC02\",\"name\":\"# from inside the docker, make sure that you have exited the NGSpeciesID environment\\n\\ndocker run -it -v ${HOMEFOL}:/data insitulab/junglegenomics\\n\\ncd /data/5.demux/\\n\\n# make a list of all the outer barcodes\\nls | grep barcode[0-9] -\\u003e barcode_outer_list.txt \\nnano barcode_outer_list.txt # add \\\"unclassified\\\" then save to same file\\n\\n\\nFILENAME=\\\"./barcode_outer_list.txt\\\"\\nLINES=$(cat $FILENAME)\\n\\nfor LINE in $LINES\\ndo\\n  echo \\\"$LINE\\\"\\n  cd $LINE\\n  rm all_$LINE.fastq\\n  foo=$(ls .)\\n  echo \\\"$foo\\\"\\n  cat *.fastq \\u003e all_$LINE.fastq\\n  fooN=$(grep -c \\\"^+$\\\" all_$LINE.fastq)\\n  echo \\\"$fooN\\\" \\n  if (($fooN \\u003e 20)); then # set minimum number of reads for consensus analysis to take place\\n    echo \\\"reads \\u003e 20 : creating output directory and making histogram\\\"\\n    mkdir nanoplot_$LINE\\n    NanoPlot --fastq all_$LINE.fastq -o ./nanoplot_$LINE\\n    cd ../   \\n  else\\n    echo \\\"reads \\u003c 20: skipping $LINE\\\"\\n    cd ../\\n  fi\\ndone\",\"os_name\":\"linux\",\"os_version\":\"\"}}}}","data":null,"protocol_id":107134,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"14","cases":[],"critical":null},{"id":2220827,"guid":"F217DAA66187478393D953B5F6A653E5","previous_id":2235843,"previous_guid":"DA5ECFDE36F940989CA2330CA436CF2B","section":"\u003cp\u003eOrganizing Consensus Sequence and Metadata\u003c/p\u003e","section_color":"#E57785","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"8dpkq\",\"text\":\"Locate and remove any files that might be created that are totally empty.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"51a99\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"egpcj\",\"text\":\"Then, consolidate full paths to all consensus sequences generated; the path information is used to rename the sequences prior to comparing them with public reference records\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"1qpdn\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"2vfo\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"7pdj6\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"8r944\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"948t2\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":1,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"aon69\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"59bh5\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"7r3lt\",\"text\":\"Remain in the same Docker container for next step\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":49}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"command\",\"mutability\":\"IMMUTABLE\",\"data\":{\"can_edit\":true,\"command_name\":\"Remove empty files\",\"description\":\"\",\"guid\":\"AA73DA8C7EC211EF837D0A58A9FEAC02\",\"name\":\"cd /data/5.demux\\n\\n# show fasta files that may be created which are totally empty\\nfind . -type f -name 'consensus.fasta' -empty -print\\n\\n# delete fasta files that may be created which are totally empty\\nfind . -type f -name 'consensus.fasta' -empty -print -delete\\n\\n\",\"os_name\":\"linux\",\"os_version\":\"\"}},\"1\":{\"type\":\"command\",\"mutability\":\"IMMUTABLE\",\"data\":{\"can_edit\":true,\"command_name\":\"Make a list of paths to consensus sequences\",\"description\":\"\",\"guid\":\"BC8ECBCA7EC211EF93050A58A9FEAC02\",\"name\":\"cd /data/5.demux\\n\\n# creates a text document in the working directory that provides the full path to every consensus file that was created\\nfind \\\"$(pwd -P)\\\" -type f -name 'consensus.fasta' \\u003e ./consensus_fullpaths.txt\\n\",\"os_name\":\"linux\",\"os_version\":\"\"}}}}","data":null,"protocol_id":107134,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"16","cases":[],"critical":null},{"id":2220828,"guid":"B1F3824B3D264CC19A150DDED05E17A8","previous_id":2235844,"previous_guid":"DC4F0F3E60F0421E9D8BEDEAC4A2E2C5","section":"\u003cp\u003eBLASTn Analysis\u003c/p\u003e","section_color":"#EA94FF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"ok4h\",\"text\":\"The first command will search for all matching records in NCBI GenBank, and may take hours to complete depending on the number of consensus sequences being analyzed. Consider adjusting the matching criteria and the output file according to preference.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"9qc3o\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"24dac\",\"text\":\"See an example of the output to explore the results.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"fsjnp\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"fehl8\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"eg5qt\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":1,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"70g39\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"93i35\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"command\",\"mutability\":\"IMMUTABLE\",\"data\":{\"can_edit\":true,\"command_name\":\"blastn\",\"description\":\"From inside docker image from previous step\",\"guid\":\"BCC824AA761711EFA7CE0A58A9FEAC02\",\"name\":\"#blast all consensus records (returning verbose \\\"default\\\" information plus the \\\"title\\\" of each hit)\\n/software/ncbi-blast-2.12.0+/bin/blastn -query /data/5.demux/NGSpecies_all_consensus.fasta -remote -db nt -outfmt \\\"7 std stitle\\\" -max_target_seqs 10 -out /data/sample_NCBIblastN_e6.txt -evalue 1e-6\\n\\n# OPTIONAL: this will remove all commented lines in the output file so that it can be opened in a traditional spreadsheet viewer such as Excel\\nsed '/^#/d' classification_NCBIblastN_e6.txt \\u003e NCBIblastN_e6_minimal.txt\",\"os_name\":\"linux\",\"os_version\":\"\"}},\"1\":{\"type\":\"image\",\"mutability\":\"IMMUTABLE\",\"data\":{\"alt\":\"blast_hits.png\",\"guid\":\"CF5BEBBA7E9811EF837D0A58A9FEAC02\",\"height\":296,\"id\":502943,\"is_video\":false,\"legend\":\"{\\\"blocks\\\":[{\\\"key\\\":\\\"e72ci\\\",\\\"text\\\":\\\"In orange are the consensus codes and in green are the blast results.\\\",\\\"type\\\":\\\"unstyled\\\",\\\"depth\\\":0,\\\"inlineStyleRanges\\\":[],\\\"entityRanges\\\":[],\\\"data\\\":{}}],\\\"entityMap\\\":{}}\",\"mime\":\"image/png\",\"nestedSelector\":null,\"original_name\":\"Screenshot 2024-09-29 at 4.24.32 PM.png\",\"placeholder\":\"https://content.protocols.io/files/rk8sb2cnp.png\",\"shadow\":false,\"source\":\"https://content.protocols.io/files/rme9b2cnp.jpg\",\"webp_source\":\"https://content.protocols.io/files/rme8b2cnp.webp\",\"width\":550}}}}","data":null,"protocol_id":107134,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"18","cases":[],"critical":null},{"id":2220829,"guid":"207752AFB2594A4B829FF9B7772CDF08","previous_id":2220828,"previous_guid":"B1F3824B3D264CC19A150DDED05E17A8","section":"\u003cp\u003eSequence Data Clean-Up\u003c/p\u003e","section_color":"#A492FF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"2ff79\",\"text\":\"Use any desired software or program to merge the following into a single tab- or comma-delimited spreadsheet (one consensus sequence per row)\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"fcfj7\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"9nkeq\",\"text\":\"Consensus sequences\",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"8nrur\",\"text\":\"Sample metadata\",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"dcasq\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"fdbuk\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"4mied\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"atdk6\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"d6395\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":1,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"9kqq3\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"notes\",\"mutability\":\"IMMUTABLE\",\"data\":{\"blocks\":[{\"data\":{},\"depth\":0,\"entityRanges\":[],\"inlineStyleRanges\":[],\"key\":\"etg9l\",\"text\":\"{r} can use the \\\"seqinr\\\" package to import the consensus fasta file into a data frame object that can be merged with any other data frame objects by the information in the sequence headers. Below, is an example of commands that could be used to create a data frame from the NGSpecies_all_consensus.fasta.\",\"type\":\"unstyled\"},{\"data\":{},\"depth\":0,\"entityRanges\":[],\"inlineStyleRanges\":[],\"key\":\"ce2m5\",\"text\":\"\",\"type\":\"unstyled\"},{\"data\":{},\"depth\":0,\"entityRanges\":[],\"inlineStyleRanges\":[],\"key\":\"dv65a\",\"text\":\"\",\"type\":\"unstyled\"}],\"entityMap\":{}}},\"1\":{\"type\":\"command\",\"mutability\":\"IMMUTABLE\",\"data\":{\"can_edit\":true,\"command_name\":\"seqinr_example\",\"description\":\"\",\"guid\":\"03B5E96A761911EFA7CE0A58A9FEAC02\",\"name\":\"library(seqinr)\\n\\nfasta_file_path \\u003c- \\\"rugezi_2024-07-05_NGSpecies_all_consensus.fasta\\\"\\n\\n#### Function to read a FASTA file and convert it to a data frame\\nfasta_to_dataframe \\u003c- function(fasta_file_path) {\\n  # Read the FASTA file\\n  fasta_data \\u003c- read.fasta(file = fasta_file_path, seqtype = \\\"AA\\\", as.string = TRUE)\\n  # Extract headers and sequences\\n  headers \\u003c- sapply(fasta_data, attr, \\\"name\\\")\\n  sequences \\u003c- sapply(fasta_data, getSequence)\\n  # Convert sequences to character vectors\\n  sequences \\u003c- sapply(sequences, function(seq) paste(seq, collapse = \\\"\\\"))\\n  # Create a data frame\\n  df \\u003c- data.frame(Header = headers, Sequence = sequences, stringsAsFactors = FALSE)\\n  return(df)\\n}\\n\\nconsensus \\u003c- fasta_to_dataframe(fasta_file_path)\\n\",\"os_name\":\"linux\",\"os_version\":\"\"}}}}","data":null,"protocol_id":107134,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"19","cases":[],"critical":null},{"id":2220830,"guid":"23DD237C1498430AA6131CB91140B1C5","previous_id":2238403,"previous_guid":"4F01E62E71E8420A96E4F1C397F5ABC9","section":"\u003cp\u003eSummarizing Data\u003c/p\u003e","section_color":"#94EBFF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"21v\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"9b76o\",\"text\":\"The following script is unique to the format of the data that was used in our publication. It will not work in a generic sense on other data sets, but is provided as a record of what was performed for this publication and can serve as a valuable example to related studies in the future.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"bofo2\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"eg3oq\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"e9rp3\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"command\",\"mutability\":\"IMMUTABLE\",\"data\":{\"can_edit\":true,\"command_name\":\"custom r script\",\"description\":\"\",\"guid\":\"A37C81B376E711EFAE630A58A9FEAC02\",\"name\":\"# last updated 2024-09-19 by GideonE\\n\\n#______ Summary Information for 'Decoding the Amazon' ________#\\n\\n\\n#%%%%%%%% Install then load required packages \\nlibrary(dplyr)\\nlibrary(ggplot2)\\nlibrary(plyr)\\nlibrary(reshape2)\\nlibrary(readr)\\nlibrary(tidyr)\\n\\n\\n#%%%%%%%% Import all related metadata data\\nbarcodes \\u003c- read.csv(\\\"lab_final.csv\\\",header = TRUE) # sample sheet from the molecular laboratory\\ntaxa \\u003c- read.csv(\\\"taxonomy_final.csv\\\",header = TRUE) # taxonomy data from BOLD system\\ncollection \\u003c- read.csv(\\\"collection_data_final.csv\\\", header = TRUE) # collection data fro BOLD system\\n\\n\\n\\n#%%%%%%%% Merge data frames together, 2 at a time, and then perform some basic data clean-up\\nalldata \\u003c- merge(barcodes,collection, by=\\\"Sample.ID\\\")\\n\\nalldata \\u003c- merge(alldata,taxa, by=\\\"Sample.ID\\\")\\n\\ncolnames(alldata) # show column names of combined data\\n\\n# \\\"Green Lab\\\" site was stored in the \\\"Extra.info\\\" column, move this to institution variable\\ntable(alldata$Extra.Info) # view all unique values in 'Extra.info'\\ntable(alldata$Institution) # view all unique values in 'Institution'\\nalldata[alldata$Extra.Info==\\\"GreenLab\\\",]$Institution\\u003c-\\\"Green Lab\\\"\\ntable(alldata$Institution) # check 'Institution' again for 'Green Lab'\\n\\n## remove variables that are not wanted for data summaries\\nnames(alldata)\\npatterns \\u003c- c(\\\"Trace\\\", \\\"Accession\\\", \\\"Email\\\", \\\"Stage\\\", \\\"Image\\\",\\\"Contam\\\",\\\"Tribe\\\",\\\"Depth\\\",\\\"GPS\\\",\\\"Event\\\",\\\"Coord\\\") # define search patterns for columns to remove\\nregex_pattern \\u003c- paste(patterns, collapse = \\\"|\\\") # insert patterns into a list of \\\"OR\\\" regex expressions\\ncols_to_remove \\u003c- grep(regex_pattern, names(alldata), value = TRUE) # create vector of column names that match any of the patterns\\nalldata2 \\u003c- alldata %\\u003e% select(-one_of(cols_to_remove)) # remove columns that match any of the names in the vector\\nnrow(alldata2)\\n\\n#remove all unwanted rows, mainly samples from the coast, to keep data set to Amazonian secies.\\n# Define the Sample.ID values to be removed, all that are nonAmazonian\\nids_to_remove \\u003c- c(\\\"TUNKI-0138\\\", \\\"TUNKI-0139\\\", \\\"TUNKI-0140\\\", \\\"TUNKI-233\\\", \\\"TUNKI-0012\\\", \\n                   \\\"TUNKI-0079\\\", \\\"TUNKI-0080\\\", \\\"TUNKI-0081\\\", \\\"TUNKI-0082\\\", \\\"TUNKI-0083\\\", \\n                   \\\"TUNKI-0094\\\", \\\"TUNKI-0095\\\", \\\"TUNKI-0264\\\", \\\"TUNKI-0016\\\", \\\"TUNKI-0233\\\")\\nalldata2 \\u003c- alldata2 %\\u003e% filter(!Sample.ID %in% ids_to_remove) # remove target samples\\nnrow(alldata2) #count number of rows remaining in data set\\n\\n## remove all values of \\\"0[n]\\\", replace with zeros\\n# Function to replace \\\"0[n]\\\" with blank\\nreplace_zero_n_brackets \\u003c- function(x) {\\n  gsub(\\\"0\\\\\\\\[n\\\\\\\\]\\\", \\\"0\\\", x)\\n}\\n\\n\\n# Apply the function to all columns of the data frame\\nalldata2 \\u003c- alldata2 %\\u003e% mutate_all(~ replace_zero_n_brackets(.))\\n\\n\\n#%%%%%%%% Data Summaries\\nnrow(alldata2) # counter records in data frame\\nnames(alldata2) # show all variable names in data frame\\n\\n## correctly identified (field identification versus genetic reference identity)\\nalldata2$IDmatching\\u003c-ifelse(alldata2$Identification == alldata2$Species,1,0)\\nlength(alldata2$IDmatching)\\ntable(alldata2$IDmatching)\\nwrite.csv(alldata2[alldata2$IDmatching==0,],\\\"mismatches.csv\\\",row.names = F) # export mismatches to CVS file\\n\\n## sequences by state department\\nwrite.csv(ddply(alldata2,.(State.Province),nrow),\\\"state.department.csv\\\")\\n\\n## sequences by order \\norders\\u003c-ddply(alldata2,.(Order),nrow) # count number of sequences per Order\\nnames(orders)[2]\\u003c-\\\"count\\\" # correct variable name\\nwrite.csv(ddply(alldata2,.(Order),nrow),\\\"order.csv\\\") # export sequence count by Order\\n\\n## pie charts of sequences by Order for each taxonomic Class\\nclass.orders\\u003c-ddply(alldata2,.(Class,Order),nrow) # count sequences by Order by Class\\nnames(class.orders)[3]\\u003c-\\\"count\\\" # correct variable name\\n\\n# create list of data frames for each Class\\nclass.orders_l\\u003c-split(class.orders,class.orders$Class) \\n\\n# function to generate pie chart\\ngenerate_pie_chart \\u003c- function(df) {\\n  df \\u003c- df %\\u003e%\\n    arrange(desc(count)) %\\u003e%\\n    mutate(\\n      prop = count / sum(count) * 100,\\n      Order = paste(Order, \\\"(\\\", round(prop, 1), \\\"%)\\\", sep = \\\"\\\")\\n    )\\n  # Determine number of legend columns\\n  legend_cols \\u003c- ifelse(nrow(df) \\u003e 6, 2, 1)\\n  \\n  ggplot(df, aes(x = \\\"\\\", y = prop, fill = Order)) +\\n    geom_bar(stat = \\\"identity\\\", width = 1, color = \\\"white\\\") +\\n    coord_polar(\\\"y\\\", start = 0) +\\n    theme_void() +\\n    scale_fill_viridis_d() +\\n    labs(title = paste(unique(df$Class)), fill = \\\"Order\\\") +\\n    guides(fill = guide_legend(ncol = legend_cols))\\n}\\n# run function across all objects in the list of data frames\\nplots \\u003c- lapply(class.orders_l, generate_pie_chart)\\n\\n# export each plot in turn\\nggsave(filename = \\\"plot1.png\\\",plot = plots[[1]], device = 'png',width = 800, height = 700, dpi = 150, units = \\\"px\\\", bg=\\\"white\\\")\\nggsave(filename = \\\"plot2.png\\\",plot = plots[[2]], device = 'png',width = 800, height = 700, dpi = 150, units = \\\"px\\\", bg=\\\"white\\\")\\nggsave(filename = \\\"plot3.png\\\",plot = plots[[3]], device = 'png',width = 800, height = 700, dpi = 150, units = \\\"px\\\", bg=\\\"white\\\")\\nggsave(filename = \\\"plot4.png\\\",plot = plots[[4]], device = 'png',width = 800, height = 700, dpi = 150, units = \\\"px\\\", bg=\\\"white\\\")\\nggsave(filename = \\\"plot5.png\\\",plot = plots[[5]], device = 'png',width = 800, height = 700, dpi = 150, units = \\\"px\\\", bg=\\\"white\\\")\\n\\n# display all plots in single figure\\ngrid.arrange(grobs = plots, ncol = 2)\\n\\n\\n## sequences by family \\nwrite.csv(ddply(alldata2,.(Family),nrow),\\\"family.csv\\\")\\n\\n## sequences by subfamily\\nnrow(ddply(alldata2,.(Subfamily),nrow))\\n\\n## sequences by genus \\nnrow(ddply(alldata2,.(Genus),nrow))\\n\\n## sequences by species \\nnrow(ddply(alldata2,.(Species),nrow))\\n\\n## sequences by subspecies \\nnrow(ddply(alldata2,.(Subspecies),nrow))\\n\\n## Table 4: summary table per gene marker\\nnames(alldata2) # show variable names of full data set\\nddply(alldata2,.(Class),nrow) # number of individuals per Class\\nnames(alldata2)[7:12]\\u003c-c(\\\"RBCL\\\",\\\"18S\\\",\\\"CO1\\\",\\\"MATK\\\",\\\"CYTB\\\",\\\"TRNH-PSBA\\\") # correct gene marker names\\nunique(alldata2$Class) # display all unique Class values\\nalldata3\\u003c-alldata2[c(1,39,44,7:12)] # make filtered, working copy of data set\\nnames(alldata3) # show varible names of filtered dataset\\n# convert all gene markeres to binary 1 (present) 0 (absent)\\nalldata3[4:9]\\u003c-alldata3[4:9] %\\u003e% mutate_all(~ifelse(is.na(.), NA, ifelse(. != 0, 1, 0)))\\nalldata3.melt\\u003c-melt(alldata3,id.vars = c(\\\"Sample.ID\\\",\\\"Class\\\",\\\"Species\\\")) # transform filtered data to long format\\nalldata3.melt\\u003c-alldata3.melt[alldata3.melt$value\\u003e0,] # remove all records with a sequence\\nalldata3_class\\u003c-ddply(alldata3.melt,.(Class),nrow);alldata3_seq # count number of sequences per Class\\nalldata3_gene_seq\\u003c-ddply(alldata3.melt,.(Class,variable),nrow);alldata3_seq # count number of sequences per gene per Class\\nalldata3_class\\u003c-ddply(alldata3.melt,.(Class,Species),nrow);alldata3_class # count species per Class\\nalldata3_sum1\\u003c-ddply(alldata3.melt,.(Class,Species,variable),summarize,seq_num=sum(value));alldata3_sum1 # count sequences per species per gene per Class\\nalldata3_sum2\\u003c-ddply(alldata3_sum1,.(Class,variable),nrow);alldata3_sum2 # species per gene per class\\n\\n\\n\\n#%%%%%%%% complimenting the Mammal gap analysis (Pacheco, V. et al. Disproportion between the Peruvian Amazonian megadiverse mammalian fauna and the available molecular information. Zoologia 41, e23110 (2024).)\\n\\ngap_mammals\\u003c-read.csv('Gaps_mammals.csv') # import data table from publication\\nnames(gap_mammals) # show variable names\\ngap_mammals\\u003c-gap_mammals[-9] # filter unwanted variable\\nnames(gap_mammals)[5:8]\\u003c-c(\\\"peru_12S\\\",\\\"peru_CO1\\\",\\\"peru_CYTB\\\",\\\"peru_MIT\\\");names(gap_mammals) # rename gene marker variables with 'peru' prefix\\ngap_mammals\\u003c-gap_mammals %\\u003e% mutate_at(vars(names(gap_mammals)[5:8]),  ~replace(., . == \\\"N\\\", \\\"0\\\")) # convert gene markers to binary variables\\ngap_mammals\\u003c-gap_mammals %\\u003e% mutate_at(vars(names(gap_mammals)[5:8]), as.integer) # ensure gene markers variable is an integer\\ngap_mammals$peru_prior_seq \\u003c- rowSums(gap_mammals[5:8]) # sum across all available gene markers per species and store in new column\\ngap_mammals \\u003c- gap_mammals %\\u003e% mutate(Species = gsub('\\\"', '', Species)) # remove quotation marks\\ngap_mammals[c(5:9)] \\u003c- gap_mammals[c(5:9)] %\\u003e% mutate_all(~ifelse(. != \\\"0\\\", \\\"1\\\", \\\"0\\\")) # convert data to binary again\\ngap_mammals[c(5:9)] \\u003c- gap_mammals[c(5:9)] %\\u003e% mutate_all(as.integer)  # ensure binary gene marker values are integers\\ncolSums(gap_mammals[c(5:9)]) # count sequence records for each column (last column indicates any sequence record for a species)\\n\\n\\nnames(alldata2) # show variable names of new data set\\nalldata2m\\u003c-alldata2[alldata2$Class==\\\"Mammalia\\\",c(1,39,43:44,7:12)];names(alldata2m) # filter to only mammals and variables of interest, and make new working data frame\\nnames(alldata2m)[5:10]\\u003c-c(\\\"RBCL\\\",\\\"g18S\\\",\\\"CO1\\\",\\\"MATK\\\",\\\"CYTB\\\",\\\"TRNH\\\");names(alldata2m) # correct gene marker names\\nalldata2m[5:10] \\u003c- alldata2m[5:10] %\\u003e% mutate_all(~ifelse(. != \\\"0\\\", \\\"1\\\", \\\"0\\\")) # make gene marker values binary\\nalldata2m[5:10] \\u003c- alldata2m[5:10] %\\u003e% mutate_all(as.integer) # ensure binary gene marker values are integers\\n\\n# count number of sequences per gene marker by species\\nalldata2m\\u003c-ddply(alldata2m,.(Class,Genus,Species),summarize,\\n      us_RBCL=sum(RBCL,na.rm=T),\\n      us_18S=sum(g18S,na.rm=T),\\n      us_CO1=sum(CO1,na.rm=T),\\n      us_MATK=sum(MATK,na.rm=T),\\n      us_CYTB=sum(CYTB,na.rm=T),\\n      us_TRNH=sum(TRNH,na.rm=T))\\n\\nnames(alldata2m) # check variable names\\nalldata2m[4:9]\\u003c-alldata2m[4:9] %\\u003e% mutate_all(~ifelse(. \\u003e= 1, 1, .)) # convert gene marker variabales to binary values\\n\\nnames(alldata2m) # check variable names\\nalldata2m$peru_seq_new\\u003c-rowSums(alldata2m[4:9]) # create new variable of gene markers generated per species\\n\\nmmerge2\\u003c-merge(alldata2m,gap_mammals,by = \\\"Species\\\", all=T) # merge new and prior data sets\\ncolSums(mmerge2[18],na.rm = T)\\n\\ntable(mmerge2$Species) # count number of all species in merged data\\nmmerge2\\u003c-mmerge2[mmerge2$Species!=\\\"\\\",] # remove empty rows\\n\\n# following command will count how many mammals of the prior data list were included in this study\\ntable(mmerge2$Class, useNA = \\\"ifany\\\")\\n\\nnames(mmerge2) # show variable names of merged data\\nmmerge2[c(4:10,14:18)] \\u003c- mmerge2[c(4:10,14:18)] %\\u003e% mutate_all(~replace_na(., 0)) # replace NA values with 0s\\nmmerge2[c(4:10,14:18)] \\u003c- mmerge2[c(4:10,14:18)] %\\u003e% mutate_all(~ifelse(. \\u003e 1, 1, .)) # make all values binary\\n\\n## calculate how many new sequences per species per gene\\nnames(mmerge2) # show variable names of merged data\\n\\n#how many species that had no prior genetic record\\nnrow(gap_mammals[gap_mammals$peru_prior_seq==0,]) # 146 total\\n\\n# calculate several new values per species\\nmmerge2 \\u003c- mmerge2 %\\u003e%\\n  mutate(\\n    CO1_diff=ifelse(us_CO1 == 1 \\u0026 peru_CO1 == 0,1,0), # value of 1 is we generated a COI record that did not previously exist\\n    CYTB_diff=ifelse(us_CYTB == 1 \\u0026 peru_CYTB == 0,1,0), # value of 1 if we generated a cytB record that did not previously exit\\n    new_species_ref=ifelse(peru_seq_new ==1 \\u0026 peru_prior_seq == 0,1,0) # value of 1 if we generated a sequence record for a species that had none\\n  )\\nnames(mmerge2)\\n\\n# sum values for all variables to count total number of new gene and species records\\ncolSums(mmerge2[c(4:10,14:21)])\\n\\nnew_mammals\\u003c-mmerge2[mmerge2$new_species_ref==1,] # subset to just mammals in which a first gene record was generated by this study\\n\\ncolSums(new_mammals[c(4:10,14:21)]) # sum values for all variables\\n\\n\\n\\n#%%%%%%%% Complimenting the Bird gap analysis (Arana, A. et al. Lack of local genetic representation in one of the regions with the highest bird species richness, the Peruvian Amazonia. PLoS One 19, e0296305 (2024).)\\ngap_bird\\u003c-read.csv('Gaps_aves.csv') # import data table from publication\\ngap_bird2\\u003c-gap_bird # create working data frame\\nnames(gap_bird2) # show variable names\\nnames(gap_bird2)[5:10]\\u003c-c(\\\"Amazonian_birds\\\",\\\"CO1_peru\\\",\\\"CO1_world\\\",\\\"CYTB_world\\\",\\\"18S_world\\\",\\\"12S_world\\\");names(gap_bird2) # rename gene marker variables with 'peru' prefix\\ngap_bird2\\u003c-gap_bird2[!is.na(gap_bird2$Amazonian_birds),] # filter to only Amazonian birds\\ntable(gap_bird2$CO1_world) # show table of records in 'CO1_workd\\\" variable\\ngap_bird2$CO1_world[is.na(gap_bird2$CO1_world)]\\u003c-\\\"N\\\" # insert \\\"N\\\" for all records that are NA\\ngap_bird2$CO1_world[gap_bird2$CO1_world %in% c(\\\"public\\\",\\\"private\\\")]\\u003c-\\\"K\\\" # replace public and private values with \\\"K\\\"\\ngap_bird2\\u003c-gap_bird2 %\\u003e% mutate_at(vars(\\\"CO1_peru\\\",\\\"CO1_world\\\",\\\"CYTB_world\\\",\\\"18S_world\\\",\\\"12S_world\\\"),  ~ifelse(is.na(.) | . != \\\"K\\\", 0, 1)) # make all gene marker variables binary values\\n\\nnames(gap_bird2) # show variable names\\ncolSums(gap_bird2[6:10]) # sum values for all gene marker variables in prior data set\\n\\n\\nnames(alldata2) # show variable names of new data set\\nalldata2b\\u003c-alldata2[alldata2$Class==\\\"Aves\\\",c(1,39,44,7:12)];names(alldata2b) # filter to only birds and variables of interest, and make new working data frame\\nnames(alldata2b)[4:9]\\u003c-c(\\\"RBCL\\\",\\\"g18S\\\",\\\"CO1\\\",\\\"MATK\\\",\\\"CYTB\\\",\\\"TRNH\\\");names(alldata2b) # correct gene marker names\\nalldata2b[4:9] \\u003c- alldata2b[4:9] %\\u003e% mutate_all(~ifelse(. != \\\"0\\\", \\\"1\\\", \\\"0\\\")) # make gene marker values binary\\nalldata2b[4:9] \\u003c- alldata2b[4:9] %\\u003e% mutate_all(as.integer) # ensure binary gene marker values are integers\\n\\n# count number of sequences per gene marker by species\\nalldata2b\\u003c-ddply(alldata2b,.(Class,Species),summarize,\\n                 us_RBCL=sum(RBCL,na.rm=T),\\n                 us_18S=sum(g18S,na.rm=T),\\n                 us_CO1=sum(CO1,na.rm=T),\\n                 us_MATK=sum(MATK,na.rm=T),\\n                 us_CYTB=sum(CYTB,na.rm=T),\\n                 us_TRNH=sum(TRNH,na.rm=T))\\n\\nalldata2b[3:8]\\u003c-alldata2b[3:8] %\\u003e% mutate_all(~ifelse(. \\u003e= 1, 1, .)) # convert gene marker variabales to binary values\\n\\nnames(alldata2b) # check variable names\\nalldata2b$peru_new_seq\\u003c-rowSums(alldata2b[3:8]) # create new variable of gene markers generated per species\\n\\nbmerge\\u003c-merge(alldata2b, gap_bird2, by.x=\\\"Species\\\", by.y=\\\"Scientific_name\\\", all=T) # merge new and prior data sets\\n\\nbmerge\\u003c-bmerge[bmerge$Species!=\\\"\\\",] #remove blank records after merge\\n\\n# how many birds and mammals did we cover of the existing species list\\ntable(bmerge$Class, useNA = \\\"ifany\\\")\\n\\nnames(bmerge)  # check variable names\\nbmerge[c(3:9,14:18)] \\u003c- bmerge[c(3:9,14:18)] %\\u003e% mutate_all(~replace_na(., 0)) # replace NA values with 0s\\nbmerge$world_prior_seq \\u003c- rowSums(bmerge[14:18]);names(bmerge) # sum values across prior sequence records per species\\nbmerge[c(3:9,14:19)] \\u003c- bmerge[c(3:9,14:19)] %\\u003e% mutate_all(~ifelse(. \\u003e 1, 1, .)) # convert all numerical values to binary\\n\\nnames(bmerge) # check variable names\\n\\n# calculate several new values per species\\nbmerge \\u003c- bmerge %\\u003e%\\n  mutate(\\n    CO1peru_diff=ifelse(us_CO1 == 1 \\u0026 CO1_peru == 0,1,0), # value of 1 if new COI record from Peruvian specimen generated by this study\\n    CO1world_diff=ifelse(us_CO1 == 1 \\u0026 CO1_world == 0,1,0), # value of 1 if new CO1 record for each species was generated by this study\\n    CYTBworld_diff=ifelse(us_CYTB == 1 \\u0026 CYTB_world == 0,1,0), # value of 1 if new cytB record for each species was generated by this study\\n    x18Sworld_diff=ifelse(us_18S == 1 \\u0026 '18S_world' == 0,1,0), # value of 1 if new 18S record for each species was generated by this study\\n    new_species_ref=ifelse(peru_new_seq == 1 \\u0026 world_prior_seq == 0,1,0) # value of 1 if first gene marker reference for each species was generated by this study\\n  )\\nnames(bmerge)\\n\\n# sum values for all variables to count total number of new gene and species records\\ncolSums(bmerge[c(3:9,14:24)])\\n\\n# subset to just mammals in which a first gene record was generated by this study\\nnew_birds\\u003c-bmerge[bmerge$new_species_ref==1,]\\n\\n# sum values for all variables\\ncolSums(new_birds[c(3:9,14:24)])\",\"os_name\":\"linux\",\"os_version\":\"\"}}}}","data":null,"protocol_id":107134,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"21","cases":[],"critical":null},{"id":2220832,"guid":"B809B32EC4DD42B8BD448A1A74A42F48","previous_id":2220822,"previous_guid":"5C75DAEE06FD40DB8388A7B35470B909","section":"\u003cp\u003ePrepare Working Environment\u003c/p\u003e","section_color":"#A492FF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"2i9h1\",\"text\":\"Run the Docker application from the command line or inside the Docker GUI and retrieve the required Docker images. The \\\"pull\\\" command will download images from the online Docker Hub repository to the local environment.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":171,\"length\":10}],\"data\":{}},{\"key\":\"cubb\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":1,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"a0icb\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"link\",\"mutability\":\"MUTABLE\",\"data\":{\"guid\":\"491CEA70147743708CE7FBCBE5FF3D5D\",\"url\":\"https://hub.docker.com/\"}},\"1\":{\"type\":\"command\",\"mutability\":\"IMMUTABLE\",\"data\":{\"can_edit\":true,\"command_name\":\"docker pull\",\"description\":\"\",\"guid\":\"FB64075A6E2B11EF93280A58A9FEAC02\",\"name\":\"docker pull nanozoo/pycoqc\\ndocker pull genomicpariscentre/guppy-gpu\\ndocker pull insitulab/junglegenomics\",\"os_name\":\"OSx\",\"os_version\":\"\"}}}}","data":null,"protocol_id":107134,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"2","cases":[],"critical":null},{"id":2220833,"guid":"B59552D725B64378BFD14E36769D0AD2","previous_id":2220832,"previous_guid":"B809B32EC4DD42B8BD448A1A74A42F48","section":"\u003cp\u003ePrepare Working Environment\u003c/p\u003e","section_color":"#A492FF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"chfpp\",\"text\":\"Create sub-folders within the working directory\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"963rn\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"7aod0\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"command\",\"mutability\":\"IMMUTABLE\",\"data\":{\"can_edit\":true,\"command_name\":\"mkdir\",\"description\":\"\",\"guid\":\"47D76FEE6E2C11EFA3E30A58A9FEAC02\",\"name\":\"cd [path/to/working/directory]\\n\\nmkdir 0.raw.data\\nchmod 775 0.raw.data\\n\\nmkdir 1.all.pod5s\\nchmod 775 1.all.pod5s\\n\\nmkdir 2.sam.output\\nchmod 775 2.sam.output/\\n\\nmkdir 3.fastq\\nchmod 775 3.fastq\\n\\nmkdir 4.filt.fastq\\nchmod 775 4.filt.fastq\\n\\nmkdir 5.demux\\nchmod 775 5.demux\",\"os_name\":\"linux\",\"os_version\":\"\"}}}}","data":null,"protocol_id":107134,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"3","cases":[],"critical":null},{"id":2220834,"guid":"1594CA05574B4CB8A39412FAEF989824","previous_id":2220833,"previous_guid":"B59552D725B64378BFD14E36769D0AD2","section":"\u003cp\u003ePrepare Working Environment\u003c/p\u003e","section_color":"#A492FF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"af2iq\",\"text\":\"Establish variables that will be used to simplify command line operations\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"64saq\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"1hqmp\",\"text\":\"Manually move all pod5 files into path/to/working/director/1.all.pod5s. This is also easily achieved with common command-line tools.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":34,\"length\":36}],\"entityRanges\":[],\"data\":{}},{\"key\":\"dk4lt\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"arvir\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"4fchh\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"191hg\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":1,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"8uu3g\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"command\",\"mutability\":\"IMMUTABLE\",\"data\":{\"can_edit\":true,\"command_name\":\"create variables\",\"description\":\"\",\"guid\":\"951EBD026E2C11EF93280A58A9FEAC02\",\"name\":\"\\nHOMEFOL=/path/to/working/directory\\nPODS=$HOMEFOL/1.all.pod5s\\nOUTFILE=example_outfile\\nDORAD=/path/to/dorado/executable\\n\\n\",\"os_name\":\"linux\",\"os_version\":\"\"}},\"1\":{\"type\":\"command\",\"mutability\":\"IMMUTABLE\",\"data\":{\"can_edit\":true,\"command_name\":\"find all pod5s and move to 1.all.pod5s\",\"description\":\"\",\"guid\":\"0F8E73207EB611EF837D0A58A9FEAC02\",\"name\":\"find 0.raw.data/ -mindepth 1 -type f -iname '*.pod5' -print|xargs cp -t 1.all.pod5s/\",\"os_name\":\"linux\",\"os_version\":\"\"}}}}","data":null,"protocol_id":107134,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"4","cases":[],"critical":null},{"id":2220835,"guid":"48CAE94E53504B49B2889FA81D4FA9DF","previous_id":2220823,"previous_guid":"78A0994146804A37907D00B38633ABA2","section":"\u003cp\u003eBasecalling Raw Sequence Data \u003c/p\u003e","section_color":"#94EBFF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"341om\",\"text\":\"Create a summary file of basecalled data\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"dpd9n\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"cfubb\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"command\",\"mutability\":\"IMMUTABLE\",\"data\":{\"can_edit\":true,\"command_name\":\"dorado summary\",\"description\":\"\",\"guid\":\"67172E0A6E2D11EFA3E30A58A9FEAC02\",\"name\":\"${DORAD} summary ${HOMEFOL}/2.sam.output/${OUTFILE}.sam \\u003e ${HOMEFOL}/2.sam.output/sequencingsummary.${OUTFILE}.txt\",\"os_name\":\"linux\",\"os_version\":\"\"}}}}","data":null,"protocol_id":107134,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"6","cases":[],"critical":null},{"id":2220836,"guid":"DDF28C71AED24FFF95316B7537880A63","previous_id":2220824,"previous_guid":"43C1F5D9ADFF4F4DA76C313C0B40B839","section":"\u003cp\u003eQC \u0026amp; Filtering\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"ag5se\",\"text\":\"Convert basecalled reads in the \\\".sam\\\" file to a \\\".fastq\\\" file\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"5nh0d\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"dth3f\",\"text\":\"Remain in same Docker container for next step\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":45}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"command\",\"mutability\":\"IMMUTABLE\",\"data\":{\"can_edit\":true,\"command_name\":\"samtools fastq\",\"description\":\"\",\"guid\":\"135D80026E2E11EF93280A58A9FEAC02\",\"name\":\"docker run -it -v ${HOMEFOL}:/data insitulab/junglegenomics\\n\\nOUTFILE=example_outfile\\n\\nsamtools fastq -t /data/2.sam.output/${OUTFILE}.sam \\u003e /data/3.fastq/${OUTFILE}.fastq\",\"os_name\":\"linux\",\"os_version\":\"\"}}}}","data":null,"protocol_id":107134,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"8","cases":[],"critical":null},{"id":2220837,"guid":"8142033DB6974751B460D9B1C54060A6","previous_id":2220836,"previous_guid":"DDF28C71AED24FFF95316B7537880A63","section":"\u003cp\u003eQC \u0026amp; Filtering\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"2t71n\",\"text\":\"Filter reads by quality and size criteria. Modify size constraints and quality based on the pycoQC results above and the region you want to target.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"cp346\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"5rl62\",\"text\":\"Remain in same Docker container for next step.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":46}],\"entityRanges\":[],\"data\":{}},{\"key\":\"24cnd\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"7mdg1\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"command\",\"mutability\":\"IMMUTABLE\",\"data\":{\"can_edit\":true,\"command_name\":\"NanoFilt\",\"description\":\"\",\"guid\":\"93EBF1AC6E2E11EF93280A58A9FEAC02\",\"name\":\"# FILTER CRITERIA: \\n# filter reads below 325 and above 525 bases\\n#filter to reads with q score \\u003e= 8\\n\\nNanoFilt -q 8 -l 325 --maxlength 525 --logfile ${OUTFILE}.filt.log /data/3.fastq/${OUTFILE}.fastq \\u003e /data/4.filt.fastq/${OUTFILE}.325to525bp.q8.fastq\\n\",\"os_name\":\"linux\",\"os_version\":\"\"}}}}","data":null,"protocol_id":107134,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"9","cases":[],"critical":null},{"id":2220838,"guid":"A01692DF6E6741409FDF538679416E13","previous_id":2248674,"previous_guid":"C128E93CCDC64AFC9FEF7AB14C30D80D","section":"\u003cp\u003eQC \u0026amp; Filtering\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"10m12\",\"text\":\"Calculate percentage recovery\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"8eonu\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"37avb\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"bi0ei\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"13sjr\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"1ci7d\",\"text\":\"Exit the Docker container before the next step\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":46}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"command\",\"mutability\":\"IMMUTABLE\",\"data\":{\"can_edit\":true,\"command_name\":\"calculate percent recovery\",\"description\":\"\",\"guid\":\"703F8F017EC011EF837D0A58A9FEAC02\",\"name\":\"#counting total reads in un filtered file\\necho $(cat /data/3.fastq/${OUTFILE}.fastq|wc -l)/4|bc\\n\\n# For example 33933 reads\\n\\necho $(cat /data/4.filt.fastq/${OUTFILE}.325to525bp.q8.fastq|wc -l)/4|bc\\n# For example 28708 reads\\n\\n# %recovery for FAST files would then be = 28708*100/33933 = 84.6%\",\"os_name\":\"linux\",\"os_version\":\"\"}}}}","data":null,"protocol_id":107134,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"10","cases":[],"critical":null},{"id":2222321,"guid":"A2FAB450DF0B427C984D354BBAD04BF6","previous_id":2220825,"previous_guid":"20B0A121B566441B80933B3EEEB0AD0E","section":"\u003cp\u003eDemultiplex Sequence Data\u003c/p\u003e","section_color":"#FFED92","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"79t36\",\"text\":\"Part 1: Dumultiplexing outer ONT indices\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"3san3\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"eg8i7\",\"text\":\"Remain in same Docker container for next step\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":45}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"command\",\"mutability\":\"IMMUTABLE\",\"data\":{\"can_edit\":true,\"command_name\":\"guppy barcoder\",\"description\":\"\",\"guid\":\"E837B0286EDA11EFAB5F0A58A9FEAC02\",\"name\":\"# enter guppy software docker for demultiplexing\\ndocker run -it -v ${HOMEFOL}:/data genomicpariscentre/guppy-cpu\\n\\n#command structure\\n#guppy_barcoder -i \\u003cinput folder\\u003e -s \\u003coutput folder\\u003e --fastq_out --enable_trim_barcodes --trim_adapters --config configuration.cfg\\n\\n#our command for just NBD114.24\\n#assuming you are inside folder data\\nguppy_barcoder -i /data/4.filt.fastq/ -s /data/5.demux/ --fastq_out --config configuration.cfg --barcode_kits SQK-NBD114-24\",\"os_name\":\"linux\",\"os_version\":\"\"}}}}","data":null,"protocol_id":107134,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"12","cases":[],"critical":null},{"id":2222323,"guid":"816A667A662B4D8584CA6136824AD614","previous_id":2237831,"previous_guid":"5FC2832C898741108EF97D6D998B099F","section":"\u003cp\u003eDemultiplex Sequence Data\u003c/p\u003e","section_color":"#FFED92","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"322uj\",\"text\":\"Part 2: Demultiplex the inner indices\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"7vq8\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"fca8p\",\"text\":\"Remain in same Docker container for next step\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":45}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"command\",\"mutability\":\"IMMUTABLE\",\"data\":{\"can_edit\":true,\"command_name\":\"guppy barcoder loop\",\"description\":\"\",\"guid\":\"CAD8BB09760C11EFA7CE0A58A9FEAC02\",\"name\":\"#find the file:\\ncd /opt/ont/guppy/data/barcoding\\n#make a copy\\ncp barcodes_masked.fasta original_barcodes_masked.fasta\\n\\n#install nano in the docker image\\nbash -c 'apt-get -y update \\u0026\\u0026 apt -y install nano'\\n\\nnano barcodes_masked.fasta\\n\\n# edit the barcode masking file.\\n{\\n\\u003eBC_1st\\nGNNNNNNNNNNNNNNNNNNNNNNNNTTTCTGTTGGTGCTGATATTGC # if starts with \\\"N\\\" process fails\\n\\u003eBC_2nd\\nGNNNNNNNNNNNNNNNNNNNNNNNNACTTGCCTGTCGCTCTATCTT # if starts with \\\"N\\\" process fails\\n}\\n\\n# check if the change was made\\ncat barcodes_masked.fasta | head -n 20\\n\\n#command structure (REFERENCE ONLY)\\n#guppy_barcoder -i \\u003cinput folder\\u003e -s \\u003coutput folder\\u003e --fastq_out --trim_barcodes --trim_adapters --config configuration.cfg\\n#our command for just barcoding by PCR only (REFERENCE ONLY)\\n#guppy_barcoder -i 4.filt_fastq/ -s 5.demux/ --fastq_out --config configuration.cfg --barcode_kits EXP-PBC096\\n\\n \\ncd /data/5.demux/\\n \\nparent_directory=\\\"/data/5.demux/\\\"\\n\\n# Loop through each subfolder in the parent directory\\nfor subfolder in \\\"$parent_directory\\\"/*/; do\\n    # Get the base name of the subfolder\\n    subfolder_name=$(basename \\\"$subfolder\\\")\\n    subfolder_inners=\\\"${subfolder%/}/${subfolder_name}_inners\\\"\\n\\n    # Enter the subfolder\\n    echo \\\"Processing subfolder: $subfolder\\\"\\n    cd \\\"$subfolder\\\" || continue\\n\\n    # Perform your operation here\\n    mkdir \\\"$subfolder_inners\\\"\\n    guppy_barcoder -i ./ -s \\\"$subfolder_inners\\\" --fastq_out --enable_trim_barcodes \\\\\\n    --config configuration.cfg -t 48 --barcode_kits EXP-PBC096\\n\\n    # Return to the parent directory\\n    cd \\\"$parent_directory\\\"\\ndone\",\"os_name\":\"linux\",\"os_version\":\"\"}}}}","data":null,"protocol_id":107134,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"13","cases":[],"critical":null},{"id":2235843,"guid":"DA5ECFDE36F940989CA2330CA436CF2B","previous_id":2220826,"previous_guid":"62C71A978985485B92BF5DF8CD67A66A","section":"\u003cp\u003eGenerate Consensus Sequence\u003c/p\u003e","section_color":"#EA9F6C","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"9fvr\",\"text\":\"After determining the target fragment size from plots produced in the prior step, run the following code block separately for each outer index. For each iteration of this code block, you will want to adjust all the sections highlighted in yellow in the the example image below. Don't worry, the code itself is in a command listed at the end of this step.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"6emi\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"1e2tj\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"b9eqv\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"f6sub\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"bcq6s\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":1,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"emfgk\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"sfb6\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"1b8dk\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":2,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"am8rn\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"6q3u6\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"c5goj\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":3,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"557hk\",\"text\":\"This process make take hours to complete, depending on the quantity of reads being analyzed. Suggest using 'tmux' so that the operation continues even if the the comman-line window is accidentally closed.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"9hcc9\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"akavi\",\"text\":\"Remain in the same Docker container for next step\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":49}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"image\",\"mutability\":\"IMMUTABLE\",\"data\":{\"height\":509,\"id\":500788,\"is_video\":false,\"legend\":\"{\\\"blocks\\\":[{\\\"key\\\":\\\"1dnig\\\",\\\"text\\\":\\\"For each iteration of this code block, update the highlighted areas to refer to the index of interest and the desired parameters for NGSpeciesID\\\",\\\"type\\\":\\\"unstyled\\\",\\\"depth\\\":0,\\\"inlineStyleRanges\\\":[],\\\"entityRanges\\\":[],\\\"data\\\":{}}],\\\"entityMap\\\":{}}\",\"mime\":\"image/png\",\"originalFile\":{},\"original_name\":\"Screenshot 2024-09-20 at 1.35.36 PM.png\",\"placeholder\":\"https://protocols-files.s3.amazonaws.com/files/rjbx4hy6.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\\u0026X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20241001%2Fus-east-1%2Fs3%2Faws4_request\\u0026X-Amz-Date=20241001T200117Z\\u0026X-Amz-Expires=604800\\u0026X-Amz-SignedHeaders=host\\u0026X-Amz-Signature=3431926bbf598b3bfaf5f0325c6939822bed71a715681943031ce1b8ce8c46ce\",\"shadow\":true,\"source\":\"https://protocols-files.s3.amazonaws.com/files/rjbw4hy6.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\\u0026X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20241001%2Fus-east-1%2Fs3%2Faws4_request\\u0026X-Amz-Date=20241001T200117Z\\u0026X-Amz-Expires=604800\\u0026X-Amz-SignedHeaders=host\\u0026X-Amz-Signature=01398abd29f2efa943cf0a1e89c32bd7a1a6e4c40e116c868d1bfa640062cb98\",\"type\":1,\"width\":550}},\"1\":{\"type\":\"notes\",\"mutability\":\"IMMUTABLE\",\"data\":{\"blocks\":[{\"data\":{},\"depth\":0,\"entityRanges\":[],\"inlineStyleRanges\":[],\"key\":\"f4rec\",\"text\":\"These are useful commands to know of if the NGSpeciesID consensus formation step must be repeated several times.\",\"type\":\"unstyled\"},{\"data\":{},\"depth\":0,\"entityRanges\":[],\"inlineStyleRanges\":[],\"key\":\"8c8t7\",\"text\":\"\",\"type\":\"unstyled\"},{\"data\":{},\"depth\":0,\"entityRanges\":[],\"inlineStyleRanges\":[],\"key\":\"2fhdn\",\"text\":\"## to remove all \\\"ngspecies*\\\" folders, from an appropriate parent directory\",\"type\":\"unstyled\"},{\"data\":{},\"depth\":0,\"entityRanges\":[],\"inlineStyleRanges\":[],\"key\":\"e14g9\",\"text\":\"find . -type d -name 'NGspecies*' -exec rm -rf {} +\",\"type\":\"unstyled\"},{\"data\":{},\"depth\":0,\"entityRanges\":[],\"inlineStyleRanges\":[],\"key\":\"a5s4i\",\"text\":\"\",\"type\":\"unstyled\"},{\"data\":{},\"depth\":0,\"entityRanges\":[],\"inlineStyleRanges\":[],\"key\":\"3o2hd\",\"text\":\"## to remove all seqtk* files, from an appropriate parent director\",\"type\":\"unstyled\"},{\"data\":{},\"depth\":0,\"entityRanges\":[],\"inlineStyleRanges\":[],\"key\":\"2q2mg\",\"text\":\"find . -type f -name 'seqtk*' -exec rm -rf {} +\",\"type\":\"unstyled\"},{\"data\":{},\"depth\":0,\"entityRanges\":[],\"inlineStyleRanges\":[],\"key\":\"c47hl\",\"text\":\"\",\"type\":\"unstyled\"},{\"data\":{},\"depth\":0,\"entityRanges\":[],\"inlineStyleRanges\":[],\"key\":\"aljkr\",\"text\":\"## to troubleshoot the NGSpeciesID command on a single sample (example)\",\"type\":\"unstyled\"},{\"data\":{},\"depth\":0,\"entityRanges\":[],\"inlineStyleRanges\":[],\"key\":\"9a0a1\",\"text\":\"NGSpeciesID --fastq \\\"seqtk_all.barcode01.fastq\\\" --ont --consensus --medaka \\\\\",\"type\":\"unstyled\"},{\"data\":{},\"depth\":0,\"entityRanges\":[],\"inlineStyleRanges\":[],\"key\":\"99cre\",\"text\":\"--outfolder \\\"./NGspecies650_Outer01_Inner01\\\" --abundance_ratio .06 \\\\\",\"type\":\"unstyled\"},{\"data\":{},\"depth\":0,\"entityRanges\":[],\"inlineStyleRanges\":[],\"key\":\"d5u6q\",\"text\":\"--rc_identity_threshold .92 --m 650 --s 50 --primer_file /data/5.demux_outer_guppy/rugezi_primers.fasta\",\"type\":\"unstyled\"}],\"entityMap\":{}}},\"2\":{\"type\":\"notes\",\"mutability\":\"IMMUTABLE\",\"data\":{\"blocks\":[{\"data\":{},\"depth\":0,\"entityRanges\":[],\"inlineStyleRanges\":[],\"key\":\"bunma\",\"text\":\"Warning and errors result if the '--primer-file' refers to an improperly formatted file or a location where the file doesn't exist. One option is to remove this parameter and remove primer sites later with another software such as 'cutadapt'.\",\"type\":\"unstyled\"}],\"entityMap\":{}}},\"3\":{\"type\":\"command\",\"mutability\":\"IMMUTABLE\",\"data\":{\"can_edit\":true,\"command_name\":\"NGSpeciesID\",\"description\":\"\",\"guid\":\"31DB34F3761711EFA7CE0A58A9FEAC02\",\"name\":\"docker run -it -v ${HOMEFOL}:/data insitulab/junglegenomics\\n\\ncd /data/$OUTFILE/5.demux/barcode01/barcode01_inners\\n\\nfor i in {01..96}; do\\n  echo \\\"Outer BC 1 - Inner BC${i}\\\"\\n  if [[ -d \\\"barcode${i}\\\" ]]; then\\n    cd \\\"barcode${i}\\\"\\n    rm \\\"all.barcode${i}.fastq\\\"\\n    cat *.fastq \\u003e \\\"all.barcode${i}.fastq\\\"\\n    fooN=$(grep -c \\\"^+$\\\" \\\"all.barcode${i}.fastq\\\")\\n    echo \\\"$fooN\\\"\\n    if (( fooN \\u003e 8 )); then\\n      echo \\\"reads \\u003e 8 : correcting fastq headers with seqtk\\\"\\n      /software/seqtk/seqtk seq -Cl60 \\\"all.barcode${i}.fastq\\\" \\u003e \\\"temp.fastq\\\"\\n      /software/seqtk/seqtk rename \\\"temp.fastq\\\" \\\"out01_inner${i}\\\" \\u003e \\\"seqtk_all.barcode${i}.fastq\\\"\\n      rm \\\"temp.fastq\\\"\\n      NGSpeciesID --fastq \\\"seqtk_all.barcode${i}.fastq\\\" --ont --consensus --medaka \\\\\\n      --primer_file /data/5.demux/primers.fasta \\\\\\n      --outfolder \\\"./NGspecies_Outer01_Inner${i}\\\" --abundance_ratio .08 \\\\\\n      --rc_identity_threshold .92 --m 400 --s 60 --sample_size 300\\n    else\\n      echo \\\"reads \\u003c 8: skipping barcode${i}\\\"\\n    fi\\n    cd ../\\n  fi\\ndone\",\"os_name\":\"linux\",\"os_version\":\"\"}}}}","data":null,"protocol_id":107134,"case_id":0,"critical_ids":"10,40","duration":0,"original_id":0,"number":"15","cases":[],"critical":[{"id":10,"title":"Computational Step","icon":"ComputationalIcon"},{"id":40,"title":"Overnight Step","icon":"Overnight"}]},{"id":2235844,"guid":"DC4F0F3E60F0421E9D8BEDEAC4A2E2C5","previous_id":2220827,"previous_guid":"F217DAA66187478393D953B5F6A653E5","section":"\u003cp\u003eOrganizing Consensus Sequence and Metadata\u003c/p\u003e","section_color":"#E57785","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"28q0l\",\"text\":\"Create a single fasta file with all consensus sequences, including any cases of more than one per sample. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"el6jh\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"7jha\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"1dtm6\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"753ns\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"5ui40\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":1,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"dv63\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"6gvlu\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"btvl2\",\"text\":\"Remain in the same Docker container for the next step\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":53}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"notes\",\"mutability\":\"IMMUTABLE\",\"data\":{\"blocks\":[{\"data\":{},\"depth\":0,\"entityRanges\":[],\"inlineStyleRanges\":[],\"key\":\"5otkt\",\"text\":\"Do NOT attempt to run the following script in one copy-paste action. Read the mark-down and execute the script one command at a time.\",\"type\":\"unstyled\"}],\"entityMap\":{}}},\"1\":{\"type\":\"command\",\"mutability\":\"IMMUTABLE\",\"data\":{\"can_edit\":true,\"command_name\":\"Custom R script for Finding Consensus Sequences\",\"description\":\"\",\"guid\":\"8FCF4F0F7EC211EF837D0A58A9FEAC02\",\"name\":\"# exit the NGSpeciesID environment\\nconda deactivate\\n\\n#run r console\\nR\\n\\n#load packages\\nlibrary(stringr)\\nlibrary(seqinr)\\n\\n# import all the paths to the consensus files\\npth\\u003c-read.table('consensus_fullpaths.txt',header = F)\\nnames(pth)\\u003c-\\\"path\\\" # correct column name\\npth$seqcount\\u003c-'' # add empty column\\npth$consensus\\u003c-'' # add empty column\\npth$reads\\u003c-'' # add empty column\\n\\npth$path\\u003c-as.character(pth$path)\\n\\n#some consensus files have more than one sequence, referred to as segments.\\n# here we count how many per file\\nfor (i in 1:nrow(pth)) {\\n  print(i)\\n  pth$seqcount[i]\\u003c-length(names(read.fasta(pth$path[i])))\\n  print(pth$seqcount[i])\\n}\\n\\n# check that there are only 1s and 2s\\ntable(pth$seqcount) \\n\\n# convert the sequence count variable to a number\\npth$seqcount\\u003c-as.numeric(pth$seqcount)\\n\\n#____ NOTE _______ from this point onward, execute each of the commands line-by-line or the script will not complete (ignore error messages from R) _______________\\n\\n#replicate the rows that have more than 1 sequence\\npth2\\u003c-pth[rep(1:nrow(pth),times=pth$seqcount),]\\n\\n# when there are multiple sequences, number them sequentially to not miss them during import, rarely there are two sequences per consensus fasta, the code below will label the first as '1' and leave the second as '2'\\npth2[duplicated(pth2$path, fromLast = T),]$seqcount\\u003c-1\\npth_dups\\u003c-pth2[duplicated(pth2$path)|duplicated(pth2$path, fromLast = T),];pth_dups\\n#(ignore)pth_dups\\u003c-pth2[duplicated(pth2$path)|duplicated(pth2$path, fromLast = T),]\\n\\n\\n# loop through all consensus files importing the sequence and the header\\nfor (i in 1:nrow(pth2)) {\\n  pth2$consensus[i]\\u003c-read.fasta(pth2$path[i],as.string = T, seqonly = T )[[pth2$seqcount[i]]]\\n  pth2$reads[i]\\u003c-names(read.fasta(pth2$path[i]))[pth2$seqcount[i]]\\n}\\n\\n\\n#____ NOTE _______ adjust regex expressions as needed to extract desired information_______________\\n\\n# extract the number of supporting reads\\npth2$reads\\u003c-str_remove(pth2$reads,'^.*supporting_reads_');pth2$reads\\u003c-str_remove(pth2$reads,'_.*$')\\n# extract the consensus variants\\npth2$variants\\u003c-str_extract(pth2$path,'(?\\u003c=Outer.._Inner..\\\\\\\\/).*?(?=\\\\\\\\/consensus.fasta)')\\n#pth2$variants\\u003c-str_replace(pth2$variants,'\\\\\\\\/','_')\\n#extract the index for each consensus sequence\\npth2$bc\\u003c-str_extract(pth2$path,'(?\\u003c=NGspecies_).*?(?=\\\\\\\\/medaka)')\\n\\n\\n# (OPTIONAL) subset to sequences with reads \\u003e 10\\n# (OPTIONAL) consensus[consensus$reads\\u003e=10,]\\n\\n# write a fasta file that can be blasted to NCBI or bold\\nwrite.fasta(sequences = as.list(pth2$consensus),\\n            names = paste(pth2$bc,'_',pth2$variants,'_','reads_',\\n                          pth2$reads,sep=''),\\n            file.out = 'NGSpecies_all_consensus.fasta')\",\"os_name\":\"R\",\"os_version\":\"\"}}}}","data":null,"protocol_id":107134,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"17","cases":[],"critical":null},{"id":2237831,"guid":"5FC2832C898741108EF97D6D998B099F","previous_id":2222321,"previous_guid":"A2FAB450DF0B427C984D354BBAD04BF6","section":"\u003cp\u003eDemultiplex Sequence Data\u003c/p\u003e","section_color":"#FFED92","section_duration":0,"is_substep":true,"step":"{\"blocks\":[{\"key\":\"f7vnu\",\"text\":\"Check demultiplexing success by counting the number of reads in the unclassified folder\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"3u07\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"647p2\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"4lm62\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"70ej2\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":1,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"7crm9\",\"text\":\"Manually perform the following calculation with the data you obtain on the command line:\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"italic\",\"offset\":0,\"length\":88}],\"entityRanges\":[],\"data\":{}},{\"key\":\"4b78l\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"1ndpf\",\"text\":\"Percent recovery = 1 - ('unclassified_reads' / 'total number of reads')*100 = XX%\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"a6caj\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"fsmoo\",\"text\":\"Remain in same Docker container for next step\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":45}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"notes\",\"mutability\":\"IMMUTABLE\",\"data\":{\"blocks\":[{\"data\":{},\"depth\":0,\"entityRanges\":[],\"inlineStyleRanges\":[],\"key\":\"e39h9\",\"text\":\"If the operation fails, it may be because the docker container does not have the \\\"bc\\\" command. While inside the docker container, correct this by running the following lines of code\",\"type\":\"unstyled\"},{\"data\":{},\"depth\":0,\"entityRanges\":[],\"inlineStyleRanges\":[],\"key\":\"ba6ik\",\"text\":\"\",\"type\":\"unstyled\"},{\"data\":{},\"depth\":0,\"entityRanges\":[],\"inlineStyleRanges\":[],\"key\":\"9hln9\",\"text\":\"sudo apt-get update\",\"type\":\"unstyled\"},{\"data\":{},\"depth\":0,\"entityRanges\":[],\"inlineStyleRanges\":[],\"key\":\"84rj5\",\"text\":\"sudo apt-get -y install bc\",\"type\":\"unstyled\"},{\"data\":{},\"depth\":0,\"entityRanges\":[],\"inlineStyleRanges\":[],\"key\":\"8gcep\",\"text\":\"\",\"type\":\"unstyled\"},{\"data\":{},\"depth\":0,\"entityRanges\":[],\"inlineStyleRanges\":[],\"key\":\"8abhr\",\"text\":\"once complete repeat the commands below\",\"type\":\"unstyled\"}],\"entityMap\":{}}},\"1\":{\"type\":\"command\",\"mutability\":\"IMMUTABLE\",\"data\":{\"can_edit\":true,\"command_name\":\"bc\",\"description\":\"\",\"guid\":\"98563255777611EFAE630A58A9FEAC02\",\"name\":\"#update permission of unclassified folder\\nchmod 777 /data/5.demux/unclassified/\\ncd /data/5.demux/unclassified/\\ncat *.fastq \\u003e all.fastq\\n\\napt-get update\\napt-get install bc\\n\\necho $(cat all.fastq |wc -l)/4|bc\\n\\n='unclassifed reads'\",\"os_name\":\"linux\",\"os_version\":\"\"}}}}","data":null,"protocol_id":107134,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"12.1","cases":[],"critical":null},{"id":2237834,"guid":"B17601539B1E4844A0A6337C4FE1E833","previous_id":2222323,"previous_guid":"816A667A662B4D8584CA6136824AD614","section":"\u003cp\u003eDemultiplex Sequence Data\u003c/p\u003e","section_color":"#FFED92","section_duration":0,"is_substep":true,"step":"{\"blocks\":[{\"key\":\"ag7ou\",\"text\":\"Count outer index demultiplex success\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"29nbj\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"4veee\",\"text\":\"Remain in same Docker container for next step\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":45}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"command\",\"mutability\":\"IMMUTABLE\",\"data\":{\"can_edit\":true,\"command_name\":\"bc\",\"description\":\"\",\"guid\":\"8F1A2D7B777711EFAE630A58A9FEAC02\",\"name\":\"parent_directory=\\\"/data/5.demux\\\"\\noutput_file=\\\"outer_read_counts.tsv\\\"\\n\\n# Initialize the output file with headers\\necho -e \\\"subfolder\\\\tread count\\\" \\u003e \\\"$output_file\\\"\\n\\n# Loop through each subfolder in the parent directory\\nfor subfolder in \\\"$parent_directory\\\"/*/; do\\n # Get the base name of the subfolder\\n subfolder_name=$(basename \\\"$subfolder\\\")\\n\\n # Initialize the read count for the subfolder\\n read_count=0\\n\\n # Loop through each .fastq file in the subfolder and count the reads\\n for fastq_file in \\\"$subfolder\\\"/*.fastq; do\\n if [ -e \\\"$fastq_file\\\" ]; then\\n count=$(grep -c \\\"^@\\\" \\\"$fastq_file\\\")\\n read_count=$((read_count + count))\\n fi\\n done\\n\\n # Append the subfolder name and read count to the output file\\n echo -e \\\"${subfolder_name}\\\\t${read_count}\\\" \\u003e\\u003e \\\"$output_file\\\"\\ndone\",\"os_name\":\"linux\",\"os_version\":\"\"}}}}","data":null,"protocol_id":107134,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"13.1","cases":[],"critical":null},{"id":2237837,"guid":"F6C040235E8D4FB2800E9EEE5968669C","previous_id":2237834,"previous_guid":"B17601539B1E4844A0A6337C4FE1E833","section":"\u003cp\u003eDemultiplex Sequence Data\u003c/p\u003e","section_color":"#FFED92","section_duration":0,"is_substep":true,"step":"{\"blocks\":[{\"key\":\"4apq6\",\"text\":\"Count inner index demultiplex success\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"3ltgi\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"4l7eg\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"8vban\",\"text\":\"Exit Docker container for next step\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":35}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"command\",\"mutability\":\"IMMUTABLE\",\"data\":{\"can_edit\":true,\"command_name\":\"bc\",\"description\":\"\",\"guid\":\"B01198E1777711EF82E30A58A9FEAC02\",\"name\":\"parent_directory=\\\"/data/5.demux\\\"\\noutput_file=\\\"inner_read_counts.tsv\\\"\\n\\n# Initialize the output file with headers\\necho -e \\\"relative_path\\\\tread_count\\\" \\u003e \\\"$output_file\\\"\\n\\n# Loop through each subfolder in the parent directory\\nfor subfolder in \\\"$parent_directory\\\"/*/; do\\n    subfolder_inners=\\\"${subfolder%/}/$(basename \\\"$subfolder\\\")_inners\\\"\\n    \\n    # Check if the subfolder_inners directory exists\\n    if [ -d \\\"$subfolder_inners\\\" ]; then\\n        # Loop through each folder in subfolder_inners\\n        for inner_subfolder in \\\"$subfolder_inners\\\"/*/; do\\n            # Initialize the read count for the inner subfolder\\n            read_count=0\\n            \\n            # Loop through each .fastq file in the inner subfolder and count the reads\\n            for fastq_file in \\\"$inner_subfolder\\\"/*.fastq; do\\n                if [ -e \\\"$fastq_file\\\" ]; then\\n                    count=$(grep -c \\\"^@\\\" \\\"$fastq_file\\\")\\n                    read_count=$((read_count + count))\\n                fi\\n            done\\n            \\n            # Get the relative path of the inner subfolder\\n            relative_path=\\\"${inner_subfolder#$parent_directory/}\\\"\\n            \\n            # Append the relative path and read count to the output file\\n            echo -e \\\"${relative_path}\\\\t${read_count}\\\" \\u003e\\u003e \\\"$output_file\\\"\\n        done\\n    fi\\ndone\",\"os_name\":\"linux\",\"os_version\":\"\"}}}}","data":null,"protocol_id":107134,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"13.2","cases":[],"critical":null},{"id":2238403,"guid":"4F01E62E71E8420A96E4F1C397F5ABC9","previous_id":2220829,"previous_guid":"207752AFB2594A4B829FF9B7772CDF08","section":"\u003cp\u003eSequence Data Clean-Up\u003c/p\u003e","section_color":"#A492FF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"4ggut\",\"text\":\"Visually inspect the results and consider using the following tools, as needed\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"aji9j\",\"text\":\" MAFFT alignment tool to check sequence directionality and its place on a phylogenetic tree to locate potential contamination and lab indexing errors\",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":1,\"length\":5}],\"data\":{}},{\"key\":\"fb1pv\",\"text\":\"cutadapt to remove PCR primer sites, which often introduce errors to the sequences.\",\"type\":\"unordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":1,\"offset\":0,\"length\":8}],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"link\",\"mutability\":\"MUTABLE\",\"data\":{\"guid\":\"EC93BB788536495FAACDF062E2F521D2\",\"url\":\"https://mafft.cbrc.jp/alignment/server/index.html\"}},\"1\":{\"type\":\"link\",\"mutability\":\"MUTABLE\",\"data\":{\"guid\":\"88A6D0C92FF14A74AB0E7BE9D77BB777\",\"url\":\"https://github.com/marcelm/cutadapt/\"}}}}","data":null,"protocol_id":107134,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"20","cases":[],"critical":null},{"id":2248674,"guid":"C128E93CCDC64AFC9FEF7AB14C30D80D","previous_id":2220837,"previous_guid":"8142033DB6974751B460D9B1C54060A6","section":"\u003cp\u003eQC \u0026amp; Filtering\u003c/p\u003e","section_color":"#7794FE","section_duration":0,"is_substep":true,"step":"{\"blocks\":[{\"key\":\"3r68b\",\"text\":\"OPTIONAL:\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"4lh7d\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"64int\",\"text\":\"NanoFilt is being deprecated soon, so consider moving to chopper instead.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"a3ump\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"60jh4\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"3m45i\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"a8krf\",\"text\":\"To run chopper, use this command.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"6p6a3\",\"text\":\"Note: Please edit the Q score and minimum and maximum lengths to filter to. Also edit the output file name appropriately.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"em22p\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"83l4v\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"e3sjr\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":1,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"8gi8b\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"command\",\"mutability\":\"IMMUTABLE\",\"data\":{\"can_edit\":true,\"command_name\":\"install chopper\",\"description\":\"\",\"guid\":\"85ED01337EB711EF837D0A58A9FEAC02\",\"name\":\"#download the installation file.\\nwget https://github.com/wdecoster/chopper/releases/download/v0.9.0/chopper-linux.zip\\n\\n#make it executable\\nchmod +x chopper\",\"os_name\":\"linux\",\"os_version\":\"\"}},\"1\":{\"type\":\"command\",\"mutability\":\"IMMUTABLE\",\"data\":{\"can_edit\":true,\"command_name\":\"filter with chopper\",\"description\":\"\",\"guid\":\"B1F477387EBF11EF837D0A58A9FEAC02\",\"name\":\"/home/rocky/bioinfotools/chopper -q 10 --minlength 200 --maxlength 600 -i $OUTFILE.fastq \\u003e $OUTFILE.100to800bp.q7.fastq\",\"os_name\":\"\",\"os_version\":\"\"}}}}","data":null,"protocol_id":107134,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"9.1","cases":[],"critical":null}],"template_id":0,"title":"Species Molecular Barcode Analysis with Nanopore Sequence Data ","title_html":"\u003cp\u003eSpecies Molecular Barcode Analysis with Nanopore Sequence Data \u003c/p\u003e","type_id":1,"units":[{"id":1,"type_id":3,"name":"µL","can_manage":0,"read_only":0},{"id":2,"type_id":3,"name":"mL","can_manage":0,"read_only":0},{"id":3,"type_id":3,"name":"L","can_manage":0,"read_only":0},{"id":4,"type_id":3,"name":"µg","can_manage":0,"read_only":0},{"id":5,"type_id":3,"name":"mg","can_manage":0,"read_only":0},{"id":6,"type_id":3,"name":"g","can_manage":0,"read_only":0},{"id":7,"type_id":3,"name":"kg","can_manage":0,"read_only":0},{"id":8,"type_id":3,"name":"ng","can_manage":0,"read_only":0},{"id":9,"type_id":3,"name":"Hz","can_manage":0,"read_only":0},{"id":10,"type_id":24,"name":"°C","can_manage":0,"read_only":0},{"id":11,"type_id":24,"name":"°К","can_manage":0,"read_only":0},{"id":12,"type_id":24,"name":"°F","can_manage":0,"read_only":0},{"id":13,"type_id":25,"name":"Mass Percent","can_manage":0,"read_only":0},{"id":14,"type_id":25,"name":"% volume","can_manage":0,"read_only":0},{"id":15,"type_id":25,"name":"Mass / % volume","can_manage":0,"read_only":0},{"id":16,"type_id":25,"name":"Parts per Million (PPM)","can_manage":0,"read_only":0},{"id":17,"type_id":25,"name":"Parts per Billion (PPB)","can_manage":0,"read_only":0},{"id":18,"type_id":25,"name":"Parts per Trillion (PPT)","can_manage":0,"read_only":0},{"id":19,"type_id":25,"name":"Mole Fraction","can_manage":0,"read_only":0},{"id":20,"type_id":25,"name":"Mole Percent","can_manage":0,"read_only":0},{"id":21,"type_id":25,"name":"Molarity (M)","can_manage":0,"read_only":1},{"id":22,"type_id":25,"name":"Molarity (M)","can_manage":0,"read_only":0},{"id":23,"type_id":25,"name":"Genome copies per ml","can_manage":0,"read_only":0},{"id":24,"type_id":3,"name":"μV","can_manage":0,"read_only":0},{"id":25,"type_id":3,"name":"ms","can_manage":0,"read_only":0},{"id":26,"type_id":3,"name":"pg","can_manage":0,"read_only":0},{"id":27,"type_id":25,"name":"Molarity dilutions","can_manage":0,"read_only":0},{"id":28,"type_id":25,"name":"millimolar (mM)","can_manage":0,"read_only":0},{"id":29,"type_id":25,"name":"micromolar (µM)","can_manage":0,"read_only":0},{"id":30,"type_id":25,"name":"nanomolar (nM)","can_manage":0,"read_only":0},{"id":31,"type_id":25,"name":"picomolar (pM)","can_manage":0,"read_only":0},{"id":32,"type_id":24,"name":"Room temperature","can_manage":0,"read_only":0},{"id":33,"type_id":30,"name":"rpm","can_manage":0,"read_only":0},{"id":34,"type_id":30,"name":"x g","can_manage":0,"read_only":0},{"id":165,"type_id":24,"name":"On ice","can_manage":0,"read_only":0},{"id":200,"type_id":32,"name":"cm","can_manage":0,"read_only":0},{"id":201,"type_id":32,"name":"mm","can_manage":0,"read_only":0},{"id":202,"type_id":32,"name":"µm","can_manage":0,"read_only":0},{"id":203,"type_id":32,"name":"nm","can_manage":0,"read_only":0},{"id":204,"type_id":25,"name":"mg/mL","can_manage":0,"read_only":0},{"id":205,"type_id":25,"name":"µg/µL","can_manage":0,"read_only":0},{"id":206,"type_id":25,"name":"% (v/v)","can_manage":0,"read_only":0},{"id":207,"type_id":3,"name":"V","can_manage":0,"read_only":0},{"id":1324,"type_id":30,"name":"rcf","can_manage":0,"read_only":0},{"id":1359,"type_id":35,"name":"Bar","can_manage":0,"read_only":0},{"id":1360,"type_id":35,"name":"Pa","can_manage":0,"read_only":0}],"uri":"species-molecular-barcode-analysis-with-nanopore-s-dku64wze","url":"https://www.protocols.io/view/species-molecular-barcode-analysis-with-nanopore-s-dku64wze","version_class":107134,"version_data":{"id":0,"code":"dku64wze","version_class":107134,"parent_id":null,"parent_uri":null,"is_same_owner":false,"is_parent_public":false,"has_pending_merge_request":false,"has_approved_merge_request":false,"merge_request":null},"version_id":0,"version_uri":"species-molecular-barcode-analysis-with-nanopore-s-6qpvr8y1blmk/v1","versions":[{"id":107134,"title":"Species Molecular Barcode Analysis with Nanopore Sequence Data ","title_html":"\u003cp\u003eSpecies Molecular Barcode Analysis with Nanopore Sequence Data \u003c/p\u003e","image":{"source":"https://content.protocols.io/files/rme74hy6.jpg","webp_source":null,"placeholder":"https://content.protocols.io/files/rme74hy6.jpg","webp_placeholder":null},"doi":"dx.doi.org/10.17504/protocols.io.6qpvr8y1blmk/v1","uri":"species-molecular-barcode-analysis-with-nanopore-s-dku64wze","published_on":1727726888,"modified_on":1727726888,"version_class":107134,"version_id":0,"version_code":"dku64wze","version_uri":"species-molecular-barcode-analysis-with-nanopore-s-6qpvr8y1blmk/v1","created_on":1725831053,"categories":null,"type_id":1,"creator":{"name":"Gideon Erkenswick","affiliation":"Field Projects International","affiliation_url":null,"username":"gideon-erkenswick","link":null,"user_image_file":{"guid":"00000000000000000000000000000001","file_name":"avatar.png","url":"https://www.protocols.io/img/avatars/001.png","mime":"image/png","size":0,"width":100,"height":100,"avg_color":"","scan_status":0,"created_at":0}},"stats":{"number_of_comments":2,"last_comment_time":1727655406}}],"warning":""}