{"access":{"can_view":true,"can_edit":false,"can_remove":false,"can_add":false,"can_publish":false,"can_get_doi":false,"can_share":true,"can_move":true,"can_move_outside":true,"can_transfer":true,"can_download":true,"limited_run":false,"limited_private_links":false,"limited_blind_links":false,"is_locked":false},"authors":[{"name":"Michael X. Henderson","affiliation":"Van Andel institute","affiliation_url":null,"username":"","link":null,"user_image_file":{"guid":"00000000000000000000000000000001","file_name":"avatar.png","url":"https://www.protocols.io/img/avatars/001.png","mime":"image/png","size":0,"width":100,"height":100,"avg_color":"","scan_status":0,"created_at":0},"note":"ORCHID:  0000-0001-9710-0726","is_verified_user":false}],"before_start":"","book_chapter":null,"can_accept_authorship":false,"can_be_copied":true,"can_claim_authorship":false,"can_manage_keywords":true,"can_remove_fork":false,"can_sign":false,"child_steps":{},"cited_protocols":[],"collection_items":[],"created_on":1692280256,"creator":{"name":"Michael Henderson","affiliation":"Van Andel Research Institute","affiliation_url":null,"username":"michael-henderson","link":null,"user_image_file":{"guid":"00000000000000000000000000000001","file_name":"avatar.png","url":"https://www.protocols.io/img/avatars/001.png","mime":"image/png","size":0,"width":100,"height":100,"avg_color":"","scan_status":0,"created_at":0},"badges":[{"id":4,"name":"Gold power author!","image":{"source":"/img/badges/gold.svg","placeholder":"/img/badges/gold.svg"}}],"affiliations":[{"affiliation":"Van Andel Research Institute","url":null,"job_title":null,"is_default":true}]},"cross_cloud_origin":null,"description":"{\"blocks\":[{\"key\":\"8jhnn\",\"text\":\"This protocol describes QUINT workflow for fluorescence. It was updated 9/17/2024. It is based on the published QUINT workflow established by Yates and colleagues (PMID: 31849633).\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","disclaimer":"","document":"","documents":[{"id":397719,"guid":"","type_id":0,"filename":"","key":"","color":"","height":0,"width":0,"is_document":null,"original_file_id":null,"thumb_url":"https://www.protocols.io/img/extensions/pdf.png","size":4845362,"is_private":0,"is_new":0,"ofn":"812-2118.pdf","url":"https://content.protocols.io/files/nenzbn3x7.pdf","bucket_name":null,"s3_webp_url":"","file_id":397719}],"doi":"dx.doi.org/10.17504/protocols.io.4r3l22y6jl1y/v2","doi_status":2,"ethics_statement":"","fork_id":null,"fork_info":null,"fork_info_status":"not_fork","forks":[],"funders":[{"funder_name":"Aligning Science Across Parkinson’s","grant_id":"ASAP-020616"},{"funder_name":"National Institute on Aging","grant_id":"R01-AG077573"}],"groups":[{"id":8831,"uri":"asap-network","title":"ASAP Collaborative Research Network","is_public":false,"image":{"source":"https://s3.amazonaws.com/protocols-files/public/6f37aae407d1c3261f56707cf7d8e3a47c4d284af7e8d2ae19cb40776fda17a7/cj6mcz36.jpg","placeholder":"https://s3.amazonaws.com/protocols-files/public/6f37aae407d1c3261f56707cf7d8e3a47c4d284af7e8d2ae19cb40776fda17a7/cj6mcz36.jpg"},"tech_support":{"email":null,"phone":null,"use_email":false,"hide_contact":false,"url":null}},{"id":38149,"uri":"team-biederer","title":"Team Biederer","is_public":false,"image":{"source":"https://s3.amazonaws.com/protocols-files/files/95FB144D59F111EC9E610A58A9FEAC02-placeholder.png","placeholder":"https://s3.amazonaws.com/protocols-files/files/95FB144D59F111EC9E610A58A9FEAC02-placeholder.png"},"tech_support":{"email":null,"phone":null,"use_email":false,"hide_contact":false,"url":null}},{"id":39015,"uri":"henderson-lab","title":"Henderson Lab","is_public":false,"image":{"source":"https://s3.amazonaws.com/protocols-files/files/48AACC12641011ECA7B50A58A9FEAC02-placeholder.png","placeholder":"https://s3.amazonaws.com/protocols-files/files/48AACC12641011ECA7B50A58A9FEAC02-placeholder.png"},"tech_support":{"email":null,"phone":null,"use_email":false,"hide_contact":false,"url":null}}],"guid":"1F282D73711311EF9DD00A58A9FEAC02","guidelines":"{\"blocks\":[{\"key\":\"dq2te\",\"text\":\"Purpose\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":7}],\"entityRanges\":[],\"data\":{}},{\"key\":\"c5st2\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"9qcuc\",\"text\":\"The purpose of this workflow is to enable mouse brain segmentation, registration, and quantification of regional signals. The simplest segmentation is done in QuPath because this program handles whole slide images and has good segmentation algorithms. Registration is done using 3 programs: QuickNII (aligns to a 3D atlas, typically the 2017 CCFv3 Allen Brain Atlas), VisuAlign (allows for non-linear warp transformation of the atlas to match sections), QMask (masks each side of the brain to allow for bilateral assessment of brain regions). Segmentations and registrations are then brought together in Nutil, enabling the generation of quantitative measures for every region of the brain.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"bf0q9\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"drjpq\",\"text\":\"Necessary Programs and Locations\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":32}],\"entityRanges\":[],\"data\":{}},{\"key\":\"1lou1\",\"text\":\"\\n1. QuPath: https://qupath.github.io/\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":12,\"length\":25}],\"data\":{}},{\"key\":\"crb2v\",\"text\":\"2. DeepSlice: https://www.deepslice.com.au/\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":1,\"offset\":14,\"length\":29}],\"data\":{}},{\"key\":\"94r62\",\"text\":\"3. QuickNII: https://www.nitrc.org/projects/quicknii (SELECT ABA Mouse Edition) \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":2,\"offset\":13,\"length\":39}],\"data\":{}},{\"key\":\"fpdu2\",\"text\":\"4. VisuAlign: https://www.nitrc.org/projects/visualign/ \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":3,\"offset\":14,\"length\":41}],\"data\":{}},{\"key\":\"29srh\",\"text\":\"5. QMask: https://www.nitrc.org/frs/?group_id=1341\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":4,\"offset\":10,\"length\":40}],\"data\":{}},{\"key\":\"2unvr\",\"text\":\"               a. Listed as QuickMask.zip \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"mfi8\",\"text\":\"6. Nutil: https://www.nitrc.org/projects/nutil/\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":5,\"offset\":10,\"length\":37}],\"data\":{}},{\"key\":\"5a5hv\",\"text\":\"               *QuickNII, VisuAlign, and Nutil can be a bit finicky, and we have found it is best to have these folders on the desktop.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"3kt8c\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"e47b6\",\"text\":\"Scanned Slides  \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":14},{\"style\":\"bold\",\"offset\":15,\"length\":1}],\"entityRanges\":[],\"data\":{}},{\"key\":\"8g4v7\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"95kf1\",\"text\":\"To enable high throughput, slides are scanned on the Axioscan microscope. After slide scanning, images will be found at \\\\\\\\pn.vai.org\\\\projects_primary\\\\henderson\\\\vari-core-generated-data\\\\Axioscan\\\\RNAScope. Move the slides into either the Human or Mouse folder and then into its corresponding stain and channel folder. If a folder does not exist, create one following the naming convention (i.e., Stain3_Slc17a7_Gad1_pS129).\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"a3ee8\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"999t3\",\"text\":\"Folder Organization \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":20}],\"entityRanges\":[],\"data\":{}},{\"key\":\"bsola\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"ah8dq\",\"text\":\"The programs for registration and quantification rely on having exact file paths from which to call the data. Therefore, it is easiest to set these folders up from the beginning and using the following layout: \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"1tfel\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"2b5r4\",\"text\":\"1. QUINT Workflow \\n     a. slide#stain# \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"dqdah\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":6,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"hbfl\",\"text\":\"\\n\\n       i. QVN (for QuickNII, VisuAlign, Nutil) \\n          1. Atlas \\n          2. Input \\n          3. Mask \\n          4. Output_Left \\n          5. Output_Right \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"link\",\"mutability\":\"MUTABLE\",\"data\":{\"guid\":\"D46E6A22ABD144F3865BA4C678D8E0BA\",\"url\":\"https://qupath.github.io/\"}},\"1\":{\"type\":\"link\",\"mutability\":\"MUTABLE\",\"data\":{\"guid\":\"92DEF2F4828C4434924D55528BA34598\",\"url\":\"https://qupath.github.io/\"}},\"2\":{\"type\":\"link\",\"mutability\":\"MUTABLE\",\"data\":{\"guid\":\"30AFEC589B3D44C19B0A7BEE72026C0C\",\"url\":\"https://www.nitrc.org/projects/quicknii\"}},\"3\":{\"type\":\"link\",\"mutability\":\"MUTABLE\",\"data\":{\"guid\":\"80F5ED5624004A5799B8B84E32547236\",\"url\":\"https://www.nitrc.org/projects/visualign/\"}},\"4\":{\"type\":\"link\",\"mutability\":\"MUTABLE\",\"data\":{\"guid\":\"0F72F5F95F964B5B9517D6FF48293919\",\"url\":\"https://www.nitrc.org/frs/?group_id=1341\"}},\"5\":{\"type\":\"link\",\"mutability\":\"MUTABLE\",\"data\":{\"guid\":\"DE28D09F4D3A4366B563CD41058CF7CE\",\"url\":\"https://www.nitrc.org/projects/nutil/\"}},\"6\":{\"type\":\"notes\",\"mutability\":\"IMMUTABLE\",\"data\":{\"blocks\":[{\"data\":{},\"depth\":0,\"entityRanges\":[],\"inlineStyleRanges\":[],\"key\":\"f7n1f\",\"text\":\"*This folder must be empty when you select it for your QuPath project in step #2 under the QuPath Visualization/Segmentation section. Once that is completed, you can then continue to create the following subfolders. \",\"type\":\"unstyled\"}],\"entityMap\":{}}}}}","has_references":false,"has_step_reagents":false,"has_versions":true,"id":107483,"image":{"source":"https://www.protocols.io/img/default_protocol.png","webp_source":null,"placeholder":"https://www.protocols.io/img/default_protocol.png","webp_placeholder":null},"image_attribution":"","in_trash":false,"is_bookmarked":false,"is_contact_suspended":false,"is_content_confidential":false,"is_content_warning":false,"is_doi_reserved":false,"is_in_pending_publishing":false,"is_in_transfer":false,"is_owner":true,"is_research":true,"is_retracted":false,"is_shared_directly":false,"is_subprotocol":null,"is_unlisted":false,"item_id":1296745,"journal":null,"journals":[],"keywords":"ASAPCRN","last_modified":1726606465,"link":"","location":null,"manuscript_citation":"","materials":[],"materials_text":"","ownership_history":[{"name":"Michael Henderson","affiliation":"Van Andel Research Institute","affiliation_url":null,"username":"michael-henderson","link":null,"user_image_file":{"guid":"00000000000000000000000000000001","file_name":"avatar.png","url":"https://www.protocols.io/img/avatars/001.png","mime":"image/png","size":0,"width":100,"height":100,"avg_color":"","scan_status":0,"created_at":0},"change_time":1726606128}],"parent_collections":[],"parent_protocols":[],"peer_reviewed":false,"protocol_references":"","public":true,"public_fork_note":"","published_on":1726606465,"references":[],"related_equipments":[],"related_materials":[],"reserved_doi":"","retraction_reason":null,"samples":{},"shared_access_id":265,"show_comparison":true,"sign_info":null,"space_access":{"can_view":false,"can_edit":false,"can_remove":false,"can_add":false,"can_publish":true,"can_get_doi":true,"can_share":false,"can_move":false,"can_move_outside":false,"can_transfer":false,"can_download":false,"limited_run":false,"limited_private_links":false,"limited_blind_links":false,"is_locked":false},"space_id":8782,"state_version_id":1253,"stats":{"is_voted":false,"number_of_views":432,"number_of_steps":116,"number_of_bookmarks":0,"number_of_comments":0,"number_of_bookmarked_comments":0,"number_of_steps_comments":0,"number_of_protocol_comments":0,"number_of_exports":0,"number_of_runs":0,"number_of_votes":0,"number_of_reagents":0,"number_of_equipments":0,"number_of_collections":0,"number_of_forks":{"private":0,"public":0},"number_of_accessible_forks":0},"status":{"id":1,"info":"We use this protocol and it's working"},"steps":[{"id":2226952,"guid":"1F9B2D1E711311EF9DD00A58A9FEAC02","previous_id":0,"previous_guid":null,"section":"\u003cp\u003eQuPath Visualization/Segmentation\u003c/p\u003e","section_color":"#A492FF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"273cg\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"dr74l\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"cb74b\",\"text\":\"Open the QuPath application. Select ‘Create project’.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":9,\"length\":6}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"notes\",\"mutability\":\"IMMUTABLE\",\"data\":{\"blocks\":[{\"data\":{},\"depth\":0,\"entityRanges\":[],\"inlineStyleRanges\":[],\"key\":\"7l24h\",\"text\":\"QuPath is a visualization and segmentation platform optimized for whole slide images. This is the place where you can visualize all your slides and create the output that will be used for all other programs.\",\"type\":\"unstyled\"},{\"data\":{},\"depth\":0,\"entityRanges\":[{\"key\":0,\"length\":1,\"offset\":0}],\"inlineStyleRanges\":[],\"key\":\"lkqb3\",\"text\":\" \",\"type\":\"atomic\"}],\"entityMap\":{\"0\":{\"data\":{\"height\":202,\"id\":419899,\"is_video\":false,\"legend\":\"{\\\"blocks\\\":null,\\\"entityMap\\\":null}\",\"mime\":\"image/png\",\"original_name\":\"image.png\",\"placeholder\":\"https://content.protocols.io/files/n4b7bn3x7.jpg\",\"source\":\"https://content.protocols.io/files/n4b5bn3x7.jpg\",\"type\":1,\"webp_placeholder\":\"https://content.protocols.io/files/n4b6bn3x7.webp\",\"webp_source\":\"https://content.protocols.io/files/n4b4bn3x7.webp\",\"width\":550},\"mutability\":\"MUTABLE\",\"type\":\"image\"}}}}}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843572,"number":"1","cases":[],"critical":null},{"id":2226953,"guid":"1F9B80B0711311EF9DD00A58A9FEAC02","previous_id":2232983,"previous_guid":"AC8A94FB9A7B465C884D1F0777E03341","section":"\u003cp\u003eQuPath Visualization/Segmentation\u003c/p\u003e","section_color":"#94EBFF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"do851\",\"text\":\"Select your slide/stain folder within your QUINT Workflow project folder (i.e., slide24stain19).\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843573,"number":"4","cases":[],"critical":null},{"id":2226954,"guid":"1F9BB305711311EF9DD00A58A9FEAC02","previous_id":2226953,"previous_guid":"1F9B80B0711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuPath Visualization/Segmentation\u003c/p\u003e","section_color":"#94EBFF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"bd95k\",\"text\":\"Select ‘Add images’ \\u003e ‘Choose files’. Navigate to the image file and select ‘Open’. Set image type to Fluorescence. Select ‘Import’.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843574,"number":"5","cases":[],"critical":null},{"id":2226955,"guid":"1F9BE423711311EF9DD00A58A9FEAC02","previous_id":2226954,"previous_guid":"1F9BB305711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuPath Visualization/Segmentation\u003c/p\u003e","section_color":"#94EBFF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"8ucs\",\"text\":\"Double click on the first image for it to appear in the viewing window.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843575,"number":"6","cases":[],"critical":null},{"id":2226956,"guid":"1F9C1531711311EF9DD00A58A9FEAC02","previous_id":2226955,"previous_guid":"1F9BE423711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuPath Visualization/Segmentation\u003c/p\u003e","section_color":"#94EBFF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"bapz3\",\"text\":\"Open the Brightness \\u0026 contrast window \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"liybb\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"c9jdx\",\"text\":\"and leave it open.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"2uqh4\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"image\",\"mutability\":\"MUTABLE\",\"data\":{\"height\":25,\"id\":419903,\"is_video\":false,\"legend\":\"{\\\"blocks\\\":null,\\\"entityMap\\\":null}\",\"mime\":\"image/png\",\"original_name\":\"image.png\",\"placeholder\":\"https://content.protocols.io/files/nepcbn3x7.png\",\"source\":\"https://content.protocols.io/files/n4b9bn3x7.jpg\",\"type\":1,\"webp_source\":\"https://content.protocols.io/files/n4b8bn3x7.webp\",\"width\":38}}}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843576,"number":"7","cases":[],"critical":null},{"id":2226957,"guid":"1F9C505A711311EF9DD00A58A9FEAC02","previous_id":2226956,"previous_guid":"1F9C1531711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuPath Visualization/Segmentation\u003c/p\u003e","section_color":"#94EBFF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"dkt0d\",\"text\":\"Select ‘Automate’ \\u003e ‘Show script editor’. Run the following script (change the channel names to the corresponding channels for your stain). This will change your channel names to the appropriate names. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"kbkam\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"image\",\"mutability\":\"MUTABLE\",\"data\":{\"height\":125,\"id\":419905,\"is_video\":false,\"legend\":\"{\\\"blocks\\\":null,\\\"entityMap\\\":null}\",\"mime\":\"image/png\",\"original_name\":\"image.png\",\"placeholder\":\"https://content.protocols.io/files/n4cdbn3x7.jpg\",\"source\":\"https://content.protocols.io/files/n4cbbn3x7.jpg\",\"type\":1,\"webp_placeholder\":\"https://content.protocols.io/files/n4ccbn3x7.webp\",\"webp_source\":\"https://content.protocols.io/files/n4cabn3x7.webp\",\"width\":226}}}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843577,"number":"8","cases":[],"critical":null},{"id":2226958,"guid":"1F9C8844711311EF9DD00A58A9FEAC02","previous_id":2226957,"previous_guid":"1F9C505A711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuPath Visualization/Segmentation\u003c/p\u003e","section_color":"#94EBFF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"bj2l2\",\"text\":\"Stay on the first image. In the script editor window select ‘Run’ \\u003e ‘Run for project’. Move all the images over to the selected column except for the first image. You cannot run a script for the whole project on an image that you have currently open in the viewer. Select ‘OK’. Close the script editor.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843578,"number":"9","cases":[],"critical":null},{"id":2226959,"guid":"1F9CB2EB711311EF9DD00A58A9FEAC02","previous_id":2226958,"previous_guid":"1F9C8844711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuPath Visualization/Segmentation\u003c/p\u003e","section_color":"#94EBFF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"4r316\",\"text\":\"For each image, adjust the Min and Max display in the Brightness \\u0026 contrast window for each channel as needed to make the scan easier to see. This only changes your visual, no actual properties of the scan. Pathology Stain Segmentation\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843579,"number":"10","cases":[],"critical":null},{"id":2226960,"guid":"1F9CDF92711311EF9DD00A58A9FEAC02","previous_id":2226959,"previous_guid":"1F9CB2EB711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuPath Visualization/Segmentation\u003c/p\u003e","section_color":"#94EBFF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"e7u41\",\"text\":\"Create annotation classifications for any new channel names you have previously not worked with. Select the ‘Annotations’ tab \\u003e three dots in the bottom right of the window \\u003e populate from image channels. Ensure that the class color matches the channel color.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"pgmjv\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"image\",\"mutability\":\"MUTABLE\",\"data\":{\"height\":211,\"id\":419909,\"is_video\":false,\"legend\":\"{\\\"blocks\\\":null,\\\"entityMap\\\":null}\",\"mime\":\"image/png\",\"original_name\":\"image.png\",\"placeholder\":\"https://content.protocols.io/files/n4chbn3x7.jpg\",\"source\":\"https://content.protocols.io/files/n4cfbn3x7.jpg\",\"type\":1,\"webp_placeholder\":\"https://content.protocols.io/files/n4cgbn3x7.webp\",\"webp_source\":\"https://content.protocols.io/files/n4cebn3x7.webp\",\"width\":318}}}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843580,"number":"11","cases":[],"critical":null},{"id":2226961,"guid":"1F9D1911711311EF9DD00A58A9FEAC02","previous_id":2226960,"previous_guid":"1F9CDF92711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuPath Visualization/Segmentation: Image Export for Registration\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"xuvxo\",\"text\":\"Select the rectangle button\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"zrlsf\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"clvmf\",\"text\":\" and select your ROI around the first brain. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"image\",\"mutability\":\"MUTABLE\",\"data\":{\"height\":24,\"id\":419913,\"is_video\":false,\"legend\":\"{\\\"blocks\\\":null,\\\"entityMap\\\":null}\",\"mime\":\"image/png\",\"original_name\":\"image.png\",\"placeholder\":\"https://content.protocols.io/files/nepibn3x7.png\",\"source\":\"https://content.protocols.io/files/n4cjbn3x7.jpg\",\"type\":1,\"webp_source\":\"https://content.protocols.io/files/n4cibn3x7.webp\",\"width\":31}}}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843581,"number":"12","cases":[],"critical":null},{"id":2226962,"guid":"1F9D4F55711311EF9DD00A58A9FEAC02","previous_id":2226961,"previous_guid":"1F9D1911711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuPath Visualization/Segmentation: Image Export for Registration\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"63osf\",\"text\":\"Lock the rectangle by selecting the annotation (the rectangle will appear yellow). Right click inside the rectangle, select ‘Annotations’ \\u003e ‘Lock’. This will lock the rectangle, so it is not accidentally moved.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843582,"number":"13","cases":[],"critical":null},{"id":2226963,"guid":"1F9D775D711311EF9DD00A58A9FEAC02","previous_id":2226962,"previous_guid":"1F9D4F55711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuPath Visualization/Segmentation: Image Export for Registration\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"762h1\",\"text\":\"MAKE SURE THE RECTANGLE IS SELECTED (YELLOW) AS YOU COMPLETE THIS STEP. Select ‘File’ \\u003e ‘Export Images’ \\u003e ‘Rendered RBG (with overlays)’. Set the export format to (PNG). Set the downsample factor to 12.0. Select OK.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843583,"number":"14","cases":[],"critical":null},{"id":2226964,"guid":"1F9DA211711311EF9DD00A58A9FEAC02","previous_id":2226963,"previous_guid":"1F9D775D711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuPath Visualization/Segmentation: Image Export for Registration\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"21ajp\",\"text\":\"Save in the QVN folder with the appropriate naming designation (i.e., sl18st3sc1_s041, sl18st3sc2_s042_).\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843584,"number":"15","cases":[],"critical":null},{"id":2226965,"guid":"1F9DC948711311EF9DD00A58A9FEAC02","previous_id":2226964,"previous_guid":"1F9DA211711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuPath Visualization/Segmentation: Image Export for Registration\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"88k0b\",\"text\":\"Repeat steps 10-13 for each image.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843585,"number":"16","cases":[],"critical":null},{"id":2226966,"guid":"1F9DF019711311EF9DD00A58A9FEAC02","previous_id":2226965,"previous_guid":"1F9DC948711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuPath Visualization/Segmentation: Cell Detection\u003c/p\u003e","section_color":"#FFED92","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"a3l83\",\"text\":\"Select ‘Analyze’ \\u003e ‘Cell Detection’ \\u003e ‘Cell Detection’ to open the cell detection window.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843586,"number":"17","cases":[],"critical":null},{"id":2226967,"guid":"1F9E1653711311EF9DD00A58A9FEAC02","previous_id":2226966,"previous_guid":"1F9DF019711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuPath Visualization/Segmentation: Cell Detection\u003c/p\u003e","section_color":"#FFED92","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"3oqil\",\"text\":\"Adjust the Cell Detection parameters as needed. The most helpful parameters to adjust are Sigma, Minimum Area, Maximum Area, Threshold, and Cell Expansion.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"40g92\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"et0u9\",\"text\":\"a. Minimum Area and Maximum Area will be dependent on whether you are analyzing mouse or human tissue.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"49p8t\",\"text\":\"b. Keep all checkboxes checked “Split by Shape”, “Include Cell Nucleus”, “Smooth Boundaries”, and “Make Measurements”.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"d0vhc\",\"text\":\"c. A lower Sigma value will break up nuclei more. A higher Sigma value will combine nuclei more often. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"ftih4\",\"text\":\"d. Once you are satisfied with the parameters, you can save the Cell Detection script to \\neasily apply it to your other images (‘Workflow’ tab -\\u003e Create script). The same cell \\ndetection parameters must be applied to all images.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843587,"number":"18","cases":[],"critical":null},{"id":2226968,"guid":"1F9E4267711311EF9DD00A58A9FEAC02","previous_id":2226967,"previous_guid":"1F9E1653711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuPath Visualization/Segmentation: Cell Detection\u003c/p\u003e","section_color":"#FFED92","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"buqm4\",\"text\":\"Remove cells from areas of damaged tissue or outside the brain. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"fr1lu\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"arljl\",\"text\":\"a. Select scrub tool \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"cqc00\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"2ho8\",\"text\":\" and select button \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"f64hn\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":1,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"dt034\",\"text\":\"and drag over areas with cells to remove. Once \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"6mpr4\",\"text\":\"the right cells are highlighted, hit backspace and delete. Turn off select button and \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"50kp5\",\"text\":\"select move tool\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"58k3m\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":2,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"5ffli\",\"text\":\"to return to normal when finished.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"26dms\",\"text\":\"b. Alternatively, Ctrl+click individual cells and delete with backspace.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"image\",\"mutability\":\"IMMUTABLE\",\"data\":{\"height\":26,\"id\":499685,\"is_video\":false,\"legend\":\"{\\\"blocks\\\":null,\\\"entityMap\\\":null}\",\"mime\":\"image/png\",\"originalFile\":{},\"original_name\":\"image.png\",\"placeholder\":\"\",\"source\":\"https://protocols-files.s3.amazonaws.com/files/rh9fcafgf.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\\u0026X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20240918%2Fus-east-1%2Fs3%2Faws4_request\\u0026X-Amz-Date=20240918T200121Z\\u0026X-Amz-Expires=604800\\u0026X-Amz-SignedHeaders=host\\u0026X-Amz-Signature=6df9d0e8701bfa698400d02c94f380db8c6a41110bed1abd321133d56497f666\",\"type\":1,\"width\":31}},\"1\":{\"type\":\"image\",\"mutability\":\"IMMUTABLE\",\"data\":{\"height\":24,\"id\":499686,\"is_video\":false,\"legend\":\"{\\\"blocks\\\":null,\\\"entityMap\\\":null}\",\"mime\":\"image/png\",\"originalFile\":{},\"original_name\":\"image.png\",\"placeholder\":\"\",\"source\":\"https://protocols-files.s3.amazonaws.com/files/rh9gcafgf.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\\u0026X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20240918%2Fus-east-1%2Fs3%2Faws4_request\\u0026X-Amz-Date=20240918T200121Z\\u0026X-Amz-Expires=604800\\u0026X-Amz-SignedHeaders=host\\u0026X-Amz-Signature=216c4e27ea7af21e90a5ab431d4dfc79918b212bedc8d8ffc407af90c926f9f5\",\"type\":1,\"width\":26}},\"2\":{\"type\":\"image\",\"mutability\":\"IMMUTABLE\",\"data\":{\"height\":28,\"id\":499687,\"is_video\":false,\"legend\":\"{\\\"blocks\\\":null,\\\"entityMap\\\":null}\",\"mime\":\"image/png\",\"originalFile\":{},\"original_name\":\"image.png\",\"placeholder\":\"\",\"source\":\"https://protocols-files.s3.amazonaws.com/files/rh9hcafgf.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\\u0026X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20240918%2Fus-east-1%2Fs3%2Faws4_request\\u0026X-Amz-Date=20240918T200121Z\\u0026X-Amz-Expires=604800\\u0026X-Amz-SignedHeaders=host\\u0026X-Amz-Signature=18f955e156a59c67e0d425e3c31abff76fa138096f44dc1dfca056e4f97b911b\",\"type\":1,\"width\":35}}}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843588,"number":"19","cases":[],"critical":null},{"id":2226969,"guid":"1F9E6900711311EF9DD00A58A9FEAC02","previous_id":2226968,"previous_guid":"1F9E4267711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuPath Visualization/Segmentation: Training Object Classifiers\u003c/p\u003e","section_color":"#EA9F6C","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"a4mfe\",\"text\":\"Select the three dots to the right of ‘Auto Set’ \\u003e ‘Add/Remove…’ \\u003e ‘Add class’. Name the new class ‘Training’. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843589,"number":"20","cases":[],"critical":null},{"id":2226970,"guid":"1F9E9370711311EF9DD00A58A9FEAC02","previous_id":2226969,"previous_guid":"1F9E6900711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuPath Visualization/Segmentation: Training Object Classifiers\u003c/p\u003e","section_color":"#EA9F6C","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"dvcmh\",\"text\":\"Choose 6-7 regions across the image set to use as training images. These regions should be \\nones that contain a variety of staining to properly train the classifier. Take regions from \\nmore than one section get a broad range of what your positive cells look like (like 1-2 \\nregions per image).\\n\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843590,"number":"21","cases":[],"critical":null},{"id":2226971,"guid":"1F9EBA3F711311EF9DD00A58A9FEAC02","previous_id":2226970,"previous_guid":"1F9E9370711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuPath Visualization/Segmentation: Training Object Classifiers\u003c/p\u003e","section_color":"#EA9F6C","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"a51b4\",\"text\":\"For each annotation rectangle created for the training classifier, set its class to ‘Training’ by \\nright clicking in the annotation rectangle \\u003e ‘Set class’ \\u003e ‘Training’. Save (File/Save or Ctrl+S) \\nafter making final annotation.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843591,"number":"22","cases":[],"critical":null},{"id":2226972,"guid":"1F9EE172711311EF9DD00A58A9FEAC02","previous_id":2226971,"previous_guid":"1F9EBA3F711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuPath Visualization/Segmentation: Training Object Classifiers\u003c/p\u003e","section_color":"#EA9F6C","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"1mg07\",\"text\":\"Once you have created all your training annotations, select ‘Classify’ \\u003e ‘Training images’ \\u003e ‘Create training image’. Set the classification of your combined training annotations to ‘Training’ and select ‘Rectangles only’. Set the image type of your combined training annotations to ‘Fluorescence’.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843592,"number":"23","cases":[],"critical":null},{"id":2226973,"guid":"1F9F095B711311EF9DD00A58A9FEAC02","previous_id":2226972,"previous_guid":"1F9EE172711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuPath Visualization/Segmentation: Training Object Classifiers\u003c/p\u003e","section_color":"#EA9F6C","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"23rq5\",\"text\":\"Rename training image (right click on image\\u003e rename image) to the channel name you will \\ntrain the classifier to detect. Create a duplicate of the combined training annotations for \\neach different channel you have (excluding your nuclear stain). Rename the image to \\ninclude the channel name. To duplicate, right click on the combined training annotation \\nimage and select ‘Duplicate image(s)’. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843593,"number":"24","cases":[],"critical":null},{"id":2226974,"guid":"1F9F302E711311EF9DD00A58A9FEAC02","previous_id":2226973,"previous_guid":"1F9F095B711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuPath Visualization/Segmentation: Training Object Classifiers\u003c/p\u003e","section_color":"#EA9F6C","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"3s268\",\"text\":\"Draw a rectangle annotation around each training image. Lock the annotation. Run cell detection with the same parameters as your individual images.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843594,"number":"25","cases":[],"critical":null},{"id":2226975,"guid":"1F9F571F711311EF9DD00A58A9FEAC02","previous_id":2226974,"previous_guid":"1F9F302E711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuPath Visualization/Segmentation: Training Object Classifiers\u003c/p\u003e","section_color":"#EA9F6C","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"fr6vn\",\"text\":\" Select ‘Classify’ \\u003e ‘Object classification’ \\u003e ‘Train object classifier’. Set the object filter to ‘Cells’, the classifier to ‘Artificial neural network (ANN_MLP)’, features to ‘Selected measurements’, classes to ‘All classes’, and training to ‘All annotations’. Select ‘Select’ to the right of ‘Selected measurements’ and select all measurements corresponding to the selected training channel (input channel name in Filter type box and hit select all, apply). Leave the window open. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"6736s\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"9oi9q\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"bhjm2\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"4vup9\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"2cg7m\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"1h0bn\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"c8e45\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"image\",\"mutability\":\"IMMUTABLE\",\"data\":{\"height\":351,\"id\":499690,\"is_video\":false,\"legend\":\"{\\\"blocks\\\":null,\\\"entityMap\\\":null}\",\"mime\":\"image/png\",\"originalFile\":{},\"original_name\":\"image.png\",\"placeholder\":\"https://protocols-files.s3.amazonaws.com/files/rh9mcafgf.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\\u0026X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20240918%2Fus-east-1%2Fs3%2Faws4_request\\u0026X-Amz-Date=20240918T200121Z\\u0026X-Amz-Expires=604800\\u0026X-Amz-SignedHeaders=host\\u0026X-Amz-Signature=8dba24da4146bb5884fed5c25634f8baa22186cd2739d87b33aeeb5968835d0d\",\"source\":\"https://protocols-files.s3.amazonaws.com/files/rh9kcafgf.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\\u0026X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20240918%2Fus-east-1%2Fs3%2Faws4_request\\u0026X-Amz-Date=20240918T200121Z\\u0026X-Amz-Expires=604800\\u0026X-Amz-SignedHeaders=host\\u0026X-Amz-Signature=f662d6d1216d71dc45fd6d836ad67bdd7f1b4d7b5594a698f79311550e3e8302\",\"type\":1,\"width\":281}}}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843595,"number":"26","cases":[],"critical":null},{"id":2226976,"guid":"1F9F8001711311EF9DD00A58A9FEAC02","previous_id":2226975,"previous_guid":"1F9F571F711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuPath Visualization/Segmentation: Training Object Classifiers\u003c/p\u003e","section_color":"#EA9F6C","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"plqag\",\"text\":\"Open the points window\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"5jvgk\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"i8pbt\",\"text\":\"Select ‘Add’ two times to add two annotations. Set the first annotation to ‘Ignore*’ by right clicking on the annotation and select ‘Set class’ \\u003e ‘Ignore*’. Set the second annotation to the channel you are training.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"4mg55\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"b6340\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"b5eo1\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":1,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"6p2fr\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"72pqn\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"image\",\"mutability\":\"MUTABLE\",\"data\":{\"height\":24,\"id\":419915,\"is_video\":false,\"legend\":\"{\\\"blocks\\\":null,\\\"entityMap\\\":null}\",\"mime\":\"image/png\",\"original_name\":\"image.png\",\"placeholder\":\"https://content.protocols.io/files/nepmbn3x7.png\",\"source\":\"https://content.protocols.io/files/n4cmbn3x7.jpg\",\"type\":1,\"webp_source\":\"https://content.protocols.io/files/n4ckbn3x7.webp\",\"width\":34}},\"1\":{\"type\":\"image\",\"mutability\":\"IMMUTABLE\",\"data\":{\"height\":400,\"id\":499693,\"is_video\":false,\"legend\":\"{\\\"blocks\\\":null,\\\"entityMap\\\":null}\",\"mime\":\"image/png\",\"originalFile\":{},\"original_name\":\"image.png\",\"placeholder\":\"https://protocols-files.s3.amazonaws.com/files/rh9qcafgf.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\\u0026X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20240918%2Fus-east-1%2Fs3%2Faws4_request\\u0026X-Amz-Date=20240918T200121Z\\u0026X-Amz-Expires=604800\\u0026X-Amz-SignedHeaders=host\\u0026X-Amz-Signature=90938dfa55df7f743c7f3573eed1cc2efbfbe864273b352891475bbf2832209b\",\"source\":\"https://protocols-files.s3.amazonaws.com/files/rh9pcafgf.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\\u0026X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20240918%2Fus-east-1%2Fs3%2Faws4_request\\u0026X-Amz-Date=20240918T200121Z\\u0026X-Amz-Expires=604800\\u0026X-Amz-SignedHeaders=host\\u0026X-Amz-Signature=7213d8b04906eae8e28f5540b9873617ede10ed66344f2ce6622073b90443288\",\"type\":1,\"width\":307}}}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843596,"number":"27","cases":[],"critical":null},{"id":2226977,"guid":"1F9FBE40711311EF9DD00A58A9FEAC02","previous_id":2226976,"previous_guid":"1F9F8001711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuPath Visualization/Segmentation: Training Object Classifiers\u003c/p\u003e","section_color":"#EA9F6C","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"abjhh\",\"text\":\"In the Brightness \\u0026 contrast window, turn off all channels except the channel you are training. To better visualize stain, hide detected cells by clicking detection objects button\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"8sgh8\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"2n9qc\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"7sndj\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"4lvm6\",\"text\":\"highlight channel of interest and play with channel min/max to optimize stain and eliminate background, show cells by using same button as before.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"image\",\"mutability\":\"IMMUTABLE\",\"data\":{\"height\":32,\"id\":499702,\"is_video\":false,\"legend\":\"{\\\"blocks\\\":null,\\\"entityMap\\\":null}\",\"mime\":\"image/png\",\"originalFile\":{},\"original_name\":\"image.png\",\"placeholder\":\"\",\"source\":\"https://protocols-files.s3.amazonaws.com/files/rh9ycafgf.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\\u0026X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20240918%2Fus-east-1%2Fs3%2Faws4_request\\u0026X-Amz-Date=20240918T200121Z\\u0026X-Amz-Expires=604800\\u0026X-Amz-SignedHeaders=host\\u0026X-Amz-Signature=ab10e8ca325073c8f064f4ce2bb31c7d1627745ea087dd9c6055f6f3ad4f81f8\",\"type\":1,\"width\":36}}}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843597,"number":"28","cases":[],"critical":null},{"id":2226978,"guid":"1F9FFC8A711311EF9DD00A58A9FEAC02","previous_id":2226977,"previous_guid":"1F9FBE40711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuPath Visualization/Segmentation: Training Object Classifiers\u003c/p\u003e","section_color":"#EA9F6C","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"a8p8f\",\"text\":\"Train the classifier by using the points annotations to identify cells as either positive for the channel or ignore. Continue training the classifier until you are satisfied with the predicted output. Select live update to view how the points you select are affecting the classifier(place at least 1 point for each class before viewing live update). \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843598,"number":"29","cases":[],"critical":null},{"id":2226979,"guid":"1FA02643711311EF9DD00A58A9FEAC02","previous_id":2226978,"previous_guid":"1F9FFC8A711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuPath Visualization/Segmentation: Training Object Classifiers\u003c/p\u003e","section_color":"#EA9F6C","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"dut7m\",\"text\":\"Give the classifier a name with the slide number, stain number, the channel, and the date (i.e., slide24stain19_Nr4a2_12.16.22). Select ‘Save’.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843599,"number":"30","cases":[],"critical":null},{"id":2226980,"guid":"1FA04FDB711311EF9DD00A58A9FEAC02","previous_id":2226979,"previous_guid":"1FA02643711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuPath Visualization/Segmentation: Training Object Classifiers\u003c/p\u003e","section_color":"#EA9F6C","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"5mg6v\",\"text\":\"Repeat steps 24-28 for every training image.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843600,"number":"31","cases":[],"critical":null},{"id":2226981,"guid":"1FA0788A711311EF9DD00A58A9FEAC02","previous_id":2226980,"previous_guid":"1FA04FDB711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuPath Visualization/Segmentation: Training Object Classifiers\u003c/p\u003e","section_color":"#EA9F6C","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"2q5to\",\"text\":\"Select ‘Classify’ \\u003e ‘Object classification’ \\u003e ‘Create composite classifier’. Move the individual classifiers to the ‘selected’ side of the window in the order you want them to be applied. Enter a name for the combined classifier (i.e., sl18st19_composite_11.22.22) and select ‘Save \\u0026 apply’.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843601,"number":"32","cases":[],"critical":null},{"id":2226982,"guid":"1FA0A10A711311EF9DD00A58A9FEAC02","previous_id":2226981,"previous_guid":"1FA0788A711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuPath Visualization/Segmentation: Training Object Classifiers\u003c/p\u003e","section_color":"#EA9F6C","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"4ibus\",\"text\":\"For each whole brain image, select ‘Classify’ \\u003e ‘Object classification \\u003e ‘Load object classifier’, select the composite classifier you just created and ‘Apply classifier’.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843602,"number":"33","cases":[],"critical":null},{"id":2226983,"guid":"1FA0CAFB711311EF9DD00A58A9FEAC02","previous_id":2226982,"previous_guid":"1FA0A10A711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuPath Visualization/Segmentation: Training Object Classifiers\u003c/p\u003e","section_color":"#EA9F6C","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"e2j76\",\"text\":\"To show sub-classes identified from your composite classifier (cells identified as positive for multiple channels) navigate to the ‘Annotations’ tab \\u003e three dots button in the bottom right of the window \\u003e ‘Populate from existing objects’ \\u003e ‘All classes (including sub-classes)’. Select ‘Yes’ when asked if you want to keep the existing available classes.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843603,"number":"34","cases":[],"critical":null},{"id":2226984,"guid":"1FA0F4F9711311EF9DD00A58A9FEAC02","previous_id":2226983,"previous_guid":"1FA0CAFB711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuPath Visualization/Segmentation: Training Object Classifiers\u003c/p\u003e","section_color":"#EA9F6C","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"2gd6i\",\"text\":\"Write down the 6-digit web color code for each sub-class in your annotation window. You will need this information for Nutil. Double click the channels listed in the annotations tab to view the color code.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"2wi93\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"image\",\"mutability\":\"MUTABLE\",\"data\":{\"height\":280,\"id\":419917,\"is_video\":false,\"legend\":\"{\\\"blocks\\\":null,\\\"entityMap\\\":null}\",\"mime\":\"image/png\",\"original_name\":\"image.png\",\"placeholder\":\"https://content.protocols.io/files/n4crbn3x7.jpg\",\"source\":\"https://content.protocols.io/files/n4cpbn3x7.jpg\",\"type\":1,\"webp_placeholder\":\"https://content.protocols.io/files/n4cqbn3x7.webp\",\"webp_source\":\"https://content.protocols.io/files/n4cnbn3x7.webp\",\"width\":550}}}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843604,"number":"35","cases":[],"critical":null},{"id":2226985,"guid":"1FA12C9B711311EF9DD00A58A9FEAC02","previous_id":2226984,"previous_guid":"1FA0F4F9711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuPath Visualization/Segmentation: Export Segmentation\u003c/p\u003e","section_color":"#E57785","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"5j70i\",\"text\":\"Navigate to each scene image and rename the annotation that is off the entire brain image. Rename by right-clicking on the selected annotation image \\u003e ‘Annotations’ \\u003e ‘Set properties’. Rename the annotation using the following naming convention: ‘sl18st19sc1input_s041_’ ; ‘sl18st19sc2input_s042_’.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843605,"number":"36","cases":[],"critical":null},{"id":2226986,"guid":"1FA1530F711311EF9DD00A58A9FEAC02","previous_id":2232767,"previous_guid":"5C887EE4643F4358AC806259914AC263","section":"\u003cp\u003eQuPath Visualization/Segmentation: Export Segmentation\u003c/p\u003e","section_color":"#E57785","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"d374t\",\"text\":\" Navigate to one of your combined training images.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843606,"number":"38","cases":[],"critical":null},{"id":2226987,"guid":"1FA17B81711311EF9DD00A58A9FEAC02","previous_id":2226986,"previous_guid":"1FA1530F711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuPath Visualization/Segmentation: Export Segmentation\u003c/p\u003e","section_color":"#E57785","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"ecg4m\",\"text\":\"Select ‘Automate’ \\u003e ‘Show script editor’. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843607,"number":"39","cases":[],"critical":null},{"id":2226988,"guid":"1FA1A49A711311EF9DD00A58A9FEAC02","previous_id":2226987,"previous_guid":"1FA17B81711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuPath Visualization/Segmentation: Export Segmentation\u003c/p\u003e","section_color":"#E57785","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"9t00u\",\"text\":\"Enter the script in the blue box below at line 1. You can export multiple cell classifications together to simplify the downstream Nutil input. To do so, add more lines with\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"zccft\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"zmom6\",\"text\":\"“.addLabel(‘Name of classification’, #).\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":null,\"entityRanges\":null,\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"image\",\"mutability\":\"MUTABLE\",\"data\":{\"height\":56,\"id\":419921,\"is_video\":false,\"legend\":\"{\\\"blocks\\\":null,\\\"entityMap\\\":null}\",\"mime\":\"image/png\",\"original_name\":\"image.png\",\"placeholder\":\"https://content.protocols.io/files/n4cvbn3x7.jpg\",\"source\":\"https://content.protocols.io/files/n4ctbn3x7.jpg\",\"type\":1,\"webp_placeholder\":\"https://content.protocols.io/files/n4cubn3x7.webp\",\"webp_source\":\"https://content.protocols.io/files/n4csbn3x7.webp\",\"width\":284}}}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843608,"number":"40","cases":[],"critical":null},{"id":2226989,"guid":"1FA1DA95711311EF9DD00A58A9FEAC02","previous_id":2226988,"previous_guid":"1FA1A49A711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuPath Visualization/Segmentation: Export Segmentation\u003c/p\u003e","section_color":"#E57785","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"498mc\",\"text\":\"Select ‘Run’ \\u003e ‘Run for project’. Move each scene image over to the ‘Selected’ window and select ‘OK’. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"eueoh\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"6lag4\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"6cfaa\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":1,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"ba1qp\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"code_insert\",\"mutability\":\"IMMUTABLE\",\"data\":{\"blocks\":[{\"data\":{},\"depth\":0,\"entityRanges\":[],\"inlineStyleRanges\":[],\"key\":\"7p9rt\",\"text\":\"import qupath.lib.images.servers.LabeledImageServer\\ndef imageData = getCurrentImageData()\\n// Define output path (relative to project)\\ndef name = GeneralTools.getNameWithoutExtension(imageData.getServer().getMetadata().getName())\\ndef pathOutput = buildFilePath(PROJECT_BASE_DIR, 'export', name)\\nmkdirs(pathOutput)\\n// Export at full resolution\\ndouble downsample = 1.0\\n// Create an ImageServer where the pixels are derived from annotations\\ndef labelServer = new LabeledImageServer.Builder(imageData)\\n.backgroundLabel(0, ColorTools.WHITE) // Specify background label (usually 0 or 255)\\n.downsample(downsample) // Choose server resolution; this should match the resolution at which tiles are exported\\n.addLabel('Slc17a7', 1) // Choose output labels (the order matters!)\\n.addLabel(‘Gad1’, 2)\\n.useCellNuclei()\\n.multichannelOutput(false) // If true, each label refers to the channel of a multichannel binary image (required for multiclass probability)\\n.build()\\n// Export each region\\nint i = 0\\nfor (annotation in getAnnotationObjects()) {\\nname = annotation.getName()\\nif (annotation.getROI().getRoiName() == \\\"Rectangle\\\") {\\ndef region = RegionRequest.createInstance(\\nlabelServer.getPath(), downsample, annotation.getROI())\\ni++\\ndef outputPath = buildFilePath(pathOutput, name + '.png')\\nwriteImageRegion(labelServer, region, outputPath)\\n}}\\n\",\"type\":\"unstyled\"}],\"entityMap\":{}}},\"1\":{\"type\":\"command\",\"mutability\":\"IMMUTABLE\",\"data\":{\"can_edit\":true,\"command_name\":\"\",\"description\":\"\",\"guid\":\"648537A6752111EF86620A58A9FEAC02\",\"name\":\"import qupath.lib.images.servers.LabeledImageServer\\ndef imageData = getCurrentImageData()\\n// Define output path (relative to project)\\ndef name = GeneralTools.getNameWithoutExtension(imageData.getServer().getMetadata().getName())\\ndef pathOutput = buildFilePath(PROJECT_BASE_DIR, 'export', name)\\nmkdirs(pathOutput)\\n// Export at full resolution\\ndouble downsample = 1.0\\n// Create an ImageServer where the pixels are derived from annotations\\ndef labelServer = new LabeledImageServer.Builder(imageData)\\n .backgroundLabel(0, ColorTools.WHITE) // Specify background label (usually 0 or 255)\\n .downsample(downsample) // Choose server resolution; this should match the resolution at which tiles are exported\\n .addLabel('Slc17a7', 1) // Choose output labels (the order matters!)\\n .addLabel(‘Gad1’, 2)\\n .useCellNuclei()\\n .multichannelOutput(false) // If true, each label refers to the channel of a multichannel binary image (required for multiclass probability)\\n .build()\\n// Export each region\\nint i = 0\\nfor (annotation in getAnnotationObjects()) {\\nname = annotation.getName()\\nif (annotation.getROI().getRoiName() == \\\"Rectangle\\\") {\\n \\t\\tdef region = RegionRequest.createInstance(\\n labelServer.getPath(), downsample, annotation.getROI())\\n \\t\\ti++\\n def outputPath = buildFilePath(pathOutput, name + '.png')\\n \\t\\twriteImageRegion(labelServer, region, outputPath)\\n}}\\n\",\"os_name\":\"\",\"os_version\":\"\"}}}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843609,"number":"41","cases":[],"critical":null},{"id":2226993,"guid":"1FA2A8CE711311EF9DD00A58A9FEAC02","previous_id":2233015,"previous_guid":"B8F4523494504222886B057FF685E737","section":"\u003cp\u003eQuickNII Brain Atlas Registration\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"3mvae\",\"text\":\"Open the QuickNII program folder.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":9,\"length\":8}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843613,"number":"61","cases":[],"critical":null},{"id":2226994,"guid":"1FA2DEE6711311EF9DD00A58A9FEAC02","previous_id":2226993,"previous_guid":"1FA2A8CE711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuickNII Brain Atlas Registration\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"euv5b\",\"text\":\"Open Filebuilder. (FileBuilder loads your registration images by default settings without \\nautomated alignment, Skip to step 68 if using DeepSlice).\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":5,\"length\":11},{\"style\":\"bold\",\"offset\":137,\"length\":9},{\"style\":\"italic\",\"offset\":120,\"length\":7}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843614,"number":"62","cases":[],"critical":null},{"id":2226995,"guid":"1FA314AA711311EF9DD00A58A9FEAC02","previous_id":2226994,"previous_guid":"1FA2DEE6711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuickNII Brain Atlas Registration\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"osm1\",\"text\":\"Navigate to the QVN folder with the brain image exports from QuPath. These images are not the segmentation exports, but the original brain image exports. These images must all be surrounded by a yellow rectangle.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":16,\"length\":3}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843615,"number":"63","cases":[],"critical":null},{"id":2226996,"guid":"1FA34CAF711311EF9DD00A58A9FEAC02","previous_id":2226995,"previous_guid":"1FA314AA711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuickNII Brain Atlas Registration\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"etles\",\"text\":\"Select all the images to be registered and select ‘Open’. It is useful to add a shortcut of your QUINT Workflow folder to your desktop for simpler navigation.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"italic\",\"offset\":58,\"length\":100}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843616,"number":"64","cases":[],"critical":null},{"id":2226997,"guid":"1FA37EA6711311EF9DD00A58A9FEAC02","previous_id":2226996,"previous_guid":"1FA34CAF711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuickNII Brain Atlas Registration\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"5rhtp\",\"text\":\"Select ‘Save XML’. Navigate to the QVN folder and save as ‘Filebuilder XML’. Make sure to save this file in the same folder as the brain image exports from QuPath.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843617,"number":"65","cases":[],"critical":null},{"id":2226998,"guid":"1FA3A9A9711311EF9DD00A58A9FEAC02","previous_id":2226997,"previous_guid":"1FA37EA6711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuickNII Brain Atlas Registration\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"dc0gs\",\"text\":\"Close Filebuilder.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843618,"number":"66","cases":[],"critical":null},{"id":2226999,"guid":"1FA3CE40711311EF9DD00A58A9FEAC02","previous_id":2226998,"previous_guid":"1FA3A9A9711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuickNII Brain Atlas Registration\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"bm181\",\"text\":\"Open the QuickNII application. Select ‘Manage data’ \\u003e ‘Load’ and select the XML file that was just generated in step 66 (DeepSlice: load results.XML from QVN folder). \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":121,\"length\":10}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843619,"number":"67","cases":[],"critical":null},{"id":2227000,"guid":"1FA3F375711311EF9DD00A58A9FEAC02","previous_id":2226999,"previous_guid":"1FA3CE40711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuickNII Brain Atlas Registration\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"3bbfp\",\"text\":\"Double click on the first image in Filebuilder to have it show up in the viewing window in the QuickNII application.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"4so44\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"237t1\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"3bd5d\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"image\",\"mutability\":\"IMMUTABLE\",\"data\":{\"height\":313.20000000000005,\"id\":499821,\"is_video\":false,\"legend\":\"{\\\"blocks\\\":null,\\\"entityMap\\\":null}\",\"mime\":\"image/png\",\"originalFile\":{},\"original_name\":\"image.png\",\"placeholder\":\"https://protocols-files.s3.amazonaws.com/files/ridqcafgf.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\\u0026X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20240918%2Fus-east-1%2Fs3%2Faws4_request\\u0026X-Amz-Date=20240918T200121Z\\u0026X-Amz-Expires=604800\\u0026X-Amz-SignedHeaders=host\\u0026X-Amz-Signature=7a5a04e0e8b0a65e6860dad676c60e5895d3aeb96b1071a602e451dc78fb7d78\",\"source\":\"https://protocols-files.s3.amazonaws.com/files/ridpcafgf.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\\u0026X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20240918%2Fus-east-1%2Fs3%2Faws4_request\\u0026X-Amz-Date=20240918T200121Z\\u0026X-Amz-Expires=604800\\u0026X-Amz-SignedHeaders=host\\u0026X-Amz-Signature=196e9d07d7a1cd726f13cda579ce06bd50214e04675217f2cd030620e0753c6f\",\"type\":1,\"width\":580}}}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843620,"number":"68","cases":[],"critical":null},{"id":2227001,"guid":"1FA41921711311EF9DD00A58A9FEAC02","previous_id":2227000,"previous_guid":"1FA3F375711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuickNII Brain Atlas Registration\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"3319b\",\"text\":\"Select ‘Rainbow 2017’ from the drop-down menu in the upper left-hand corner of the toolbar (1).\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843621,"number":"69","cases":[],"critical":null},{"id":2227002,"guid":"1FA443D4711311EF9DD00A58A9FEAC02","previous_id":2227001,"previous_guid":"1FA41921711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuickNII Brain Atlas Registration\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"aobu0\",\"text\":\"You can adjust how you see the atlas overlay by dragging the vertical transparency bar on the left side of the screen (2).\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843622,"number":"70","cases":[],"critical":null},{"id":2227003,"guid":"1FA46F49711311EF9DD00A58A9FEAC02","previous_id":2227002,"previous_guid":"1FA443D4711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuickNII Brain Atlas Registration\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"9go6t\",\"text\":\"For the first section, find the anteroposterior position. To do this, drag the sagittal red dot (3) to the correct rostro-caudal position. Select ‘Store’ to save the position.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843623,"number":"71","cases":[],"critical":null},{"id":2227004,"guid":"1FA498DB711311EF9DD00A58A9FEAC02","previous_id":2227003,"previous_guid":"1FA46F49711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuickNII Brain Atlas Registration\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"fh43i\",\"text\":\"Repeat step 72 for the last section. This will bring all other sections to the approximately correct position.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843624,"number":"72","cases":[],"critical":null},{"id":2227005,"guid":"1FA4C1B7711311EF9DD00A58A9FEAC02","previous_id":2227004,"previous_guid":"1FA498DB711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuickNII Brain Atlas Registration\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"9k5i7\",\"text\":\"Adjust each individual section to the appropriate place in the atlas. Many adjustments may need to be made until the correct plane of section is identified. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"fg2l\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"9jvr6\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"bc1j3\",\"text\":\"    a. Rotation: clockwise or counterclockwise (4).\\n    b. Brain size: in the x and y direction (5). \\n    c. Rostro-caudal position: adjust sagittal view. \\n    d. Left-right plane: adjust horizontal view. \\n    e. Front-back plane: adjust sagittal view.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":7,\"length\":8},{\"style\":\"bold\",\"offset\":59,\"length\":10},{\"style\":\"bold\",\"offset\":109,\"length\":22},{\"style\":\"bold\",\"offset\":163,\"length\":16},{\"style\":\"bold\",\"offset\":213,\"length\":16}],\"entityRanges\":[],\"data\":{}},{\"key\":\"gaslq\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"notes\",\"mutability\":\"IMMUTABLE\",\"data\":{\"blocks\":[{\"data\":{},\"depth\":0,\"entityRanges\":[],\"inlineStyleRanges\":[{\"length\":4,\"offset\":0,\"style\":\"bold\"},{\"length\":135,\"offset\":209,\"style\":\"italic\"}],\"key\":\"b5un4\",\"text\":\"NOTE: All the atlas needs to remain in view, or it will be lost for analysis. Keep the atlas image smaller than the brain image. All of the Atlas needs to remain in the viewer or it will be lost for analysis. Alignment will not be perfect, only the plane of section, but the better job you do here, the easier VisuAlign transformations will be.\",\"type\":\"unstyled\"}],\"entityMap\":{}}}}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843625,"number":"73","cases":[],"critical":null},{"id":2227006,"guid":"1FA50B67711311EF9DD00A58A9FEAC02","previous_id":2227005,"previous_guid":"1FA4C1B7711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuickNII Brain Atlas Registration\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"fprcd\",\"text\":\"Select ‘Store’ before moving off a section or it will not save!\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"12","duration":0,"original_id":1843626,"number":"74","cases":[],"critical":[{"id":12,"title":"Critical step","icon":"CriticalIcon"}]},{"id":2227007,"guid":"1FA53755711311EF9DD00A58A9FEAC02","previous_id":2227006,"previous_guid":"1FA50B67711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuickNII Brain Atlas Registration\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"d5v7s\",\"text\":\" Navigate to the next section by double clicking on the section in the Filebuilder, or by selecting the \\u003c and \\u003e arrows in the upper-right corner. Edit all sections as noted in step 13\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843627,"number":"75","cases":[],"critical":null},{"id":2227008,"guid":"1FA55F49711311EF9DD00A58A9FEAC02","previous_id":2227007,"previous_guid":"1FA53755711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuickNII Brain Atlas Registration\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"2l203\",\"text\":\"Select ‘Manage data’ \\u003e ‘Export Propagation’ and save this XML filed as “QuickN XML.xml” within the QVN folder. It is not automatically recognized as a .xml file, hence the need to add “.xml” to the end of the name.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"italic\",\"offset\":110,\"length\":104}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843628,"number":"76","cases":[],"critical":null},{"id":2227009,"guid":"1FA58776711311EF9DD00A58A9FEAC02","previous_id":2227008,"previous_guid":"1FA55F49711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuickNII Brain Atlas Registration\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"2k99v\",\"text\":\"Select ‘Save JSON’ and name it “QuickN JSON” within the QVN folder. This JSON file is used for VisuAlign. Make sure to save the JSON file in the same folder as the brain image exports from QuPath and the Filebuilder XML file.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843629,"number":"77","cases":[],"critical":null},{"id":2227010,"guid":"1FA5AF74711311EF9DD00A58A9FEAC02","previous_id":2227009,"previous_guid":"1FA58776711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQMask\u003c/p\u003e","section_color":"#FFED92","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"cd7kh\",\"text\":\" In the QuickNII application, go back to the first section. Show just the rainbow atlas image.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843630,"number":"78","cases":[],"critical":null},{"id":2227011,"guid":"1FA5D7F8711311EF9DD00A58A9FEAC02","previous_id":2227010,"previous_guid":"1FA5AF74711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQMask\u003c/p\u003e","section_color":"#FFED92","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"8340g\",\"text\":\"Adjust the horizontal plane to a hemispheric split (completely vertical). Ensure proper bisecting by confirming it within the coronal plane. You want to perfectly bisect the coronal plan. Change the angle if needed.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"bfylf\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"image\",\"mutability\":\"MUTABLE\",\"data\":{\"height\":168,\"id\":419925,\"is_video\":false,\"legend\":\"{\\\"blocks\\\":null,\\\"entityMap\\\":null}\",\"mime\":\"image/png\",\"original_name\":\"image.png\",\"placeholder\":\"https://content.protocols.io/files/n4czbn3x7.jpg\",\"source\":\"https://content.protocols.io/files/n4cxbn3x7.jpg\",\"type\":1,\"webp_placeholder\":\"https://content.protocols.io/files/n4cybn3x7.webp\",\"webp_source\":\"https://content.protocols.io/files/n4cwbn3x7.webp\",\"width\":550}}}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843631,"number":"79","cases":[],"critical":null},{"id":2227012,"guid":"1FA611B2711311EF9DD00A58A9FEAC02","previous_id":2227011,"previous_guid":"1FA5D7F8711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQMask\u003c/p\u003e","section_color":"#FFED92","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"2h0o1\",\"text\":\"Hover the cursor over the brain viewing window and record the x-y-z coordinates (shown in the top left of the window) for the following three parts of the brain: top left, top right, and bottom left. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"wqcrp\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"image\",\"mutability\":\"MUTABLE\",\"data\":{\"height\":173,\"id\":419929,\"is_video\":false,\"legend\":\"{\\\"blocks\\\":null,\\\"entityMap\\\":null}\",\"mime\":\"image/png\",\"original_name\":\"image.png\",\"placeholder\":\"https://content.protocols.io/files/n4c5bn3x7.jpg\",\"source\":\"https://content.protocols.io/files/n4c3bn3x7.jpg\",\"type\":1,\"webp_placeholder\":\"https://content.protocols.io/files/n4c4bn3x7.webp\",\"webp_source\":\"https://content.protocols.io/files/n4c2bn3x7.webp\",\"width\":250}}}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843632,"number":"80","cases":[],"critical":null},{"id":2227013,"guid":"1FA649B9711311EF9DD00A58A9FEAC02","previous_id":2227012,"previous_guid":"1FA611B2711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQMask\u003c/p\u003e","section_color":"#FFED92","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"1056s\",\"text\":\"Open the QMask tool and select ‘Pick XML’ and open the QuickN XML file generated in QuickNII.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843633,"number":"81","cases":[],"critical":null},{"id":2227014,"guid":"1FA673F7711311EF9DD00A58A9FEAC02","previous_id":2227013,"previous_guid":"1FA649B9711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQMask\u003c/p\u003e","section_color":"#FFED92","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"9uje9\",\"text\":\"Enter the x-y-z coordinates.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843634,"number":"82","cases":[],"critical":null},{"id":2227015,"guid":"1FA69BEC711311EF9DD00A58A9FEAC02","previous_id":2227014,"previous_guid":"1FA673F7711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQMask\u003c/p\u003e","section_color":"#FFED92","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"e002f\",\"text\":\"Select ‘Destination’ and navigate to the Mask folder within your current project folder and select ‘Open’.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843635,"number":"83","cases":[],"critical":null},{"id":2227016,"guid":"1FA6C790711311EF9DD00A58A9FEAC02","previous_id":2227015,"previous_guid":"1FA69BEC711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQMask\u003c/p\u003e","section_color":"#FFED92","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"dprsv\",\"text\":\"Select ‘Go’. The mask output should be a black and white PNG. Close QuickNII and the QMask tool. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"9a5bg\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"image\",\"mutability\":\"MUTABLE\",\"data\":{\"height\":193,\"id\":419933,\"is_video\":false,\"legend\":\"{\\\"blocks\\\":null,\\\"entityMap\\\":null}\",\"mime\":\"image/png\",\"original_name\":\"image.png\",\"placeholder\":\"https://content.protocols.io/files/n4c9bn3x7.jpg\",\"source\":\"https://content.protocols.io/files/n4c7bn3x7.jpg\",\"type\":1,\"webp_placeholder\":\"https://content.protocols.io/files/n4c8bn3x7.webp\",\"webp_source\":\"https://content.protocols.io/files/n4c6bn3x7.webp\",\"width\":503}}}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843636,"number":"84","cases":[],"critical":null},{"id":2227017,"guid":"1FA6FD64711311EF9DD00A58A9FEAC02","previous_id":2227016,"previous_guid":"1FA6C790711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQMask\u003c/p\u003e","section_color":"#FFED92","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"10dfe\",\"text\":\"Ensure the mask files are named using the appropriate naming convention (i.e., sl18st3sc1_s041_mask).\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843637,"number":"85","cases":[],"critical":null},{"id":2227018,"guid":"1FA725C1711311EF9DD00A58A9FEAC02","previous_id":2227017,"previous_guid":"1FA6FD64711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQMask\u003c/p\u003e","section_color":"#FFED92","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"bn6v0\",\"text\":\"You can check to see if your mask outputs accurately bisect for a hemispheric split by comparing the mask output to the output from VisuAlign. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843638,"number":"86","cases":[],"critical":null},{"id":2227019,"guid":"1FA74DDE711311EF9DD00A58A9FEAC02","previous_id":2227018,"previous_guid":"1FA725C1711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eVisuAlign\u003c/p\u003e","section_color":"#EA9F6C","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"edck3\",\"text\":\"Open the VisuAlign application.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":9,\"length\":9}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843639,"number":"87","cases":[],"critical":null},{"id":2227020,"guid":"1FA77A7B711311EF9DD00A58A9FEAC02","previous_id":2227019,"previous_guid":"1FA74DDE711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eVisuAlign\u003c/p\u003e","section_color":"#EA9F6C","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"el74f\",\"text\":\"Select ‘File’ \\u003e ‘Open’ and select the QuickN JSON file you created in QuickNII.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843640,"number":"88","cases":[],"critical":null},{"id":2227021,"guid":"1FA7A1C7711311EF9DD00A58A9FEAC02","previous_id":2227020,"previous_guid":"1FA77A7B711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eVisuAlign\u003c/p\u003e","section_color":"#EA9F6C","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"9alen\",\"text\":\"Drag the opacity bar all the way to the right towards ‘Outline’. This will display an outline of all the regions. This is the easiest format for transformation. You can change the color of the outline and the marker for easier visualization.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843641,"number":"89","cases":[],"critical":null},{"id":2227022,"guid":"1FA7CB76711311EF9DD00A58A9FEAC02","previous_id":2227021,"previous_guid":"1FA7A1C7711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eVisuAlign\u003c/p\u003e","section_color":"#EA9F6C","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"1u8o6\",\"text\":\"Align all regions properly.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843642,"number":"90","cases":[],"critical":null},{"id":2227023,"guid":"1FA7F530711311EF9DD00A58A9FEAC02","previous_id":2227022,"previous_guid":"1FA7CB76711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eVisuAlign\u003c/p\u003e","section_color":"#EA9F6C","section_duration":0,"is_substep":true,"step":"{\"blocks\":[{\"key\":\"sdtd\",\"text\":\" Hover over an atlas region.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843643,"number":"90.1","cases":[],"critical":null},{"id":2227024,"guid":"1FA81D4E711311EF9DD00A58A9FEAC02","previous_id":2227023,"previous_guid":"1FA7F530711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eVisuAlign\u003c/p\u003e","section_color":"#EA9F6C","section_duration":0,"is_substep":true,"step":"{\"blocks\":[{\"key\":\"2f5hd\",\"text\":\"To create a marker, click the space bar. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843644,"number":"90.2","cases":[],"critical":null},{"id":2227025,"guid":"1FA8479C711311EF9DD00A58A9FEAC02","previous_id":2227024,"previous_guid":"1FA81D4E711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eVisuAlign\u003c/p\u003e","section_color":"#EA9F6C","section_duration":0,"is_substep":true,"step":"{\"blocks\":[{\"key\":\"btbnn\",\"text\":\"Drag the maker symbol to the correct location. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"b4wap\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"image\",\"mutability\":\"MUTABLE\",\"data\":{\"height\":294,\"id\":419937,\"is_video\":false,\"legend\":\"{\\\"blocks\\\":null,\\\"entityMap\\\":null}\",\"mime\":\"image/png\",\"original_name\":\"image.png\",\"placeholder\":\"https://content.protocols.io/files/n4ddbn3x7.jpg\",\"source\":\"https://content.protocols.io/files/n4dbbn3x7.jpg\",\"type\":1,\"webp_placeholder\":\"https://content.protocols.io/files/n4dcbn3x7.webp\",\"webp_source\":\"https://content.protocols.io/files/n4dabn3x7.webp\",\"width\":550}}}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843645,"number":"90.3","cases":[],"critical":null},{"id":2227026,"guid":"1FA87FA6711311EF9DD00A58A9FEAC02","previous_id":2227025,"previous_guid":"1FA8479C711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eVisuAlign\u003c/p\u003e","section_color":"#EA9F6C","section_duration":0,"is_substep":true,"step":"{\"blocks\":[{\"key\":\"c85tb\",\"text\":\"Markers can be moved at any point. To delete a maker, hover over the maker and click delete on the keyboard.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843646,"number":"90.4","cases":[],"critical":null},{"id":2227028,"guid":"1FA8D1C7711311EF9DD00A58A9FEAC02","previous_id":2233024,"previous_guid":"F488C180EFEB4A0DB925BB48E18FF8E2","section":"\u003cp\u003eVisuAlign\u003c/p\u003e","section_color":"#EA9F6C","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"fadt9\",\"text\":\"Select the \\u003c and \\u003e arrows at the top-right to navigate between sections. There is no need to save \\nor store these as in QuickNII. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843648,"number":"91","cases":[],"critical":null},{"id":2227029,"guid":"1FA8FA2D711311EF9DD00A58A9FEAC02","previous_id":2227028,"previous_guid":"1FA8D1C7711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eVisuAlign\u003c/p\u003e","section_color":"#EA9F6C","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"3tc6t\",\"text\":\"Once all images are complete, select ‘File’ \\u003e ‘Save as’ and save as ‘VisuAlign JSON’ in the QVN folder. This can be opened again to continue aligning later.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843649,"number":"92","cases":[],"critical":null},{"id":2227030,"guid":"1FA922BD711311EF9DD00A58A9FEAC02","previous_id":2227029,"previous_guid":"1FA8FA2D711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eVisuAlign\u003c/p\u003e","section_color":"#EA9F6C","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"faaig\",\"text\":\"Select ‘File’ \\u003e ‘Export’ and navigate to the Atlas folder and select ‘Select Folder’. This will export the files needed for Nutil. These are also the images that you can compare to the Mask outputs to determine the accuracy of your hemispheric split.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":124,\"length\":5}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843650,"number":"93","cases":[],"critical":null},{"id":2227031,"guid":"1FA95068711311EF9DD00A58A9FEAC02","previous_id":2227030,"previous_guid":"1FA922BD711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eNutil\u003c/p\u003e","section_color":"#E57785","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"5qmar\",\"text\":\"Open the Nutil application and navigate to the ‘Operation’ tab. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843651,"number":"94","cases":[],"critical":null},{"id":2227032,"guid":"1FA97BE9711311EF9DD00A58A9FEAC02","previous_id":2227031,"previous_guid":"1FA95068711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eNutil\u003c/p\u003e","section_color":"#E57785","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"8ca9u\",\"text\":\"Select ‘New’. Select ‘Quantifier’ from the drop-down menu and select ‘Ok’.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843652,"number":"95","cases":[],"critical":null},{"id":2227033,"guid":"1FA9A6CF711311EF9DD00A58A9FEAC02","previous_id":2227032,"previous_guid":"1FA97BE9711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eNutil\u003c/p\u003e","section_color":"#E57785","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"8e7lq\",\"text\":\"Select ‘Save’ to save the overall Nutil project (i.e., “sl24st19.nut”).\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843653,"number":"96","cases":[],"critical":null},{"id":2227034,"guid":"1FA9D073711311EF9DD00A58A9FEAC02","previous_id":2227033,"previous_guid":"1FA9A6CF711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eNutil\u003c/p\u003e","section_color":"#E57785","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"9jbrf\",\"text\":\"Name each project using the following naming convention: ‘sl#st#_classifier_left/right’.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843654,"number":"97","cases":[],"critical":null},{"id":2227035,"guid":"1FA9F854711311EF9DD00A58A9FEAC02","previous_id":2227034,"previous_guid":"1FA9D073711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eNutil\u003c/p\u003e","section_color":"#E57785","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"5f6tr\",\"text\":\"Set the ‘Segmentation folder’ to the ‘Input’ folder within the QVN folder.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843655,"number":"98","cases":[],"critical":null},{"id":2227036,"guid":"1FAA2062711311EF9DD00A58A9FEAC02","previous_id":2227035,"previous_guid":"1FA9F854711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eNutil\u003c/p\u003e","section_color":"#E57785","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"a8d57\",\"text\":\"Set the ‘Brain atlas map folder’ to the ‘Atlas’ folder within the QVN folder.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843656,"number":"99","cases":[],"critical":null},{"id":2227037,"guid":"1FAA48B8711311EF9DD00A58A9FEAC02","previous_id":2227036,"previous_guid":"1FAA2062711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eNutil\u003c/p\u003e","section_color":"#E57785","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"dn26u\",\"text\":\"Select ‘Reference atlas’ to the ‘Allen Mouse Brain 2017’.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843657,"number":"100","cases":[],"critical":null},{"id":2227038,"guid":"1FAA70F3711311EF9DD00A58A9FEAC02","previous_id":2227037,"previous_guid":"1FAA48B8711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eNutil\u003c/p\u003e","section_color":"#E57785","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"1f5r1\",\"text\":\"Set the ‘XML or JSON anchoring file’ to the ‘VisuAlign JSON.json’ file.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843658,"number":"101","cases":[],"critical":null},{"id":2227039,"guid":"1FAA9998711311EF9DD00A58A9FEAC02","previous_id":2227038,"previous_guid":"1FAA70F3711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eNutil\u003c/p\u003e","section_color":"#E57785","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"2i6et\",\"text\":\"Set the ‘Output folder’ to the ‘Output_left’ or ‘Output_right’ folder within the QVN folder depending on which hemisphere you are running.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":1843659,"number":"102","cases":[],"critical":null},{"id":2232767,"guid":"5C887EE4643F4358AC806259914AC263","previous_id":2226985,"previous_guid":"1FA12C9B711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuPath Visualization/Segmentation: Export Segmentation\u003c/p\u003e","section_color":"#E57785","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"4nekg\",\"text\":\"Scenes with smaller annotation regions that you used to make your training images will have a second segmentation. Delete the segmentation image that corresponds to the smaller annotation,\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"37","cases":[],"critical":null},{"id":2232772,"guid":"13D824DA896741CA9473D3D9697E5662","previous_id":2233023,"previous_guid":"3739A85201CF4BE7AD2A98CFB269D731","section":"\u003cp\u003eQuPath Visualization/Segmentation: Alternate Segmentations, Pixel Classifier for Florescence\u003c/p\u003e","section_color":"#EA94FF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"6f47s\",\"text\":\"Isolate the image display to show only the channel you want to segment for. Optimize stain visualization by playing with display min/max.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"45","cases":[],"critical":null},{"id":2232778,"guid":"5A6AD07790034A419B1FED1E95613AA1","previous_id":2232772,"previous_guid":"13D824DA896741CA9473D3D9697E5662","section":"\u003cp\u003eQuPath Visualization/Segmentation: Alternate Segmentations, Pixel Classifier for Florescence\u003c/p\u003e","section_color":"#EA94FF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"2upta\",\"text\":\"Create thresholder: Classify\\u003ePixel Classifier\\u003eCreate Thresholder\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"6vt73\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"f6kk6\",\"text\":\"\\na. Set Resolution: We usually use Very High (.69um/px) (Note  Resolution for Nutil processing later in            workflow).\\nb. Set Channel to channel of interest\\nc. Leave Prefilter as Gaussian and Smoothing sigma at 0\\nd. Before playing with the threshold, set Above threshold to the classification that works for you. This can be Positive from the default classes, or you can make your own (3 dots next to auto set in Classes tab\\u003eAdd/Remove\\u003eAdd Class –edit color by double clicking  class in classes window). Set Below threshold to Ignore*.\\ne. Optimize threshold – this value is based on fluorescence intensity as seen in display min/max - usually in the thousands  range. Ensure the classifier is only detecting positive signal and adjust threshold number as necessary.\\ni. You can utilize the C Classifier button to turn on/off the classifier and scrollbar to adjust opacity of detected signal. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":1,\"length\":3},{\"style\":\"bold\",\"offset\":126,\"length\":2},{\"style\":\"bold\",\"offset\":164,\"length\":1},{\"style\":\"bold\",\"offset\":220,\"length\":3},{\"style\":\"bold\",\"offset\":543,\"length\":2},{\"style\":\"bold\",\"offset\":773,\"length\":2}],\"entityRanges\":[],\"data\":{}},{\"key\":\"8rpuo\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"eqgc9\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":1,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"94thp\",\"text\":\"\\nf. Give your classifier a name and Create objects to apply it to the open image\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":1,\"length\":2}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"image\",\"mutability\":\"IMMUTABLE\",\"data\":{\"height\":343,\"id\":499705,\"is_video\":false,\"legend\":\"{\\\"blocks\\\":null,\\\"entityMap\\\":null}\",\"mime\":\"image/png\",\"originalFile\":{},\"original_name\":\"image.png\",\"placeholder\":\"https://protocols-files.s3.amazonaws.com/files/rh94cafgf.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\\u0026X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20240918%2Fus-east-1%2Fs3%2Faws4_request\\u0026X-Amz-Date=20240918T200122Z\\u0026X-Amz-Expires=604800\\u0026X-Amz-SignedHeaders=host\\u0026X-Amz-Signature=d602fd929b6b6cdd8b1a4e700080109d0a31be313e833bd6bfa0108b23d37247\",\"source\":\"https://protocols-files.s3.amazonaws.com/files/rh93cafgf.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\\u0026X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20240918%2Fus-east-1%2Fs3%2Faws4_request\\u0026X-Amz-Date=20240918T200122Z\\u0026X-Amz-Expires=604800\\u0026X-Amz-SignedHeaders=host\\u0026X-Amz-Signature=64d13221c02a26e7a6e92a4a7790dc7b4316efcec5f3acc9a8681d6f42801373\",\"type\":1,\"width\":357}},\"1\":{\"type\":\"image\",\"mutability\":\"IMMUTABLE\",\"data\":{\"height\":67,\"id\":499707,\"is_video\":false,\"legend\":\"{\\\"blocks\\\":null,\\\"entityMap\\\":null}\",\"mime\":\"image/png\",\"originalFile\":{},\"original_name\":\"image.png\",\"placeholder\":\"https://protocols-files.s3.amazonaws.com/files/rh96cafgf.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\\u0026X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20240918%2Fus-east-1%2Fs3%2Faws4_request\\u0026X-Amz-Date=20240918T200122Z\\u0026X-Amz-Expires=604800\\u0026X-Amz-SignedHeaders=host\\u0026X-Amz-Signature=e55b51a96b56b68149909c52a16b032ff4fefa5dd91828ec107d5ca368ac1596\",\"source\":\"https://protocols-files.s3.amazonaws.com/files/rh95cafgf.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\\u0026X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20240918%2Fus-east-1%2Fs3%2Faws4_request\\u0026X-Amz-Date=20240918T200122Z\\u0026X-Amz-Expires=604800\\u0026X-Amz-SignedHeaders=host\\u0026X-Amz-Signature=007397781790199997545d45064b7975c3673a0165da1c64fe326b71955b069f\",\"type\":1,\"width\":179}}}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"46","cases":[],"critical":null},{"id":2232782,"guid":"236465ABA23C4F508477D097DD2A66DF","previous_id":2232778,"previous_guid":"5A6AD07790034A419B1FED1E95613AA1","section":"\u003cp\u003eQuPath Visualization/Segmentation: Alternate Segmentations, Pixel Classifier for Florescence\u003c/p\u003e","section_color":"#EA94FF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"3mpcs\",\"text\":\"You can apply the classifier you just made to other images by loading the classifier when other images are open: Classify\\u003ePixel Classifier\\u003eLoad pixel classifier\\u003eChoose model\\u003eSelect made classifier. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"italic\",\"offset\":113,\"length\":85}],\"entityRanges\":[],\"data\":{}},{\"key\":\"2hbqn\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"2s7si\",\"text\":\"a. You can also generate a workflow by selecting ‘Create script’ at the bottom of the workflow tab. This will turn all the commands executed on the open image into Groovy script. You can batch run this script for other images in your project by going to Run\\u003eRun for project and selecting for desired images \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":2}],\"entityRanges\":[],\"data\":{}},{\"key\":\"699mp\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"1uhs0\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"fs96r\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"b3s98\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"a25dv\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":1,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"card5\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"notes\",\"mutability\":\"IMMUTABLE\",\"data\":{\"blocks\":[{\"data\":{},\"depth\":0,\"entityRanges\":[],\"inlineStyleRanges\":[],\"key\":\"2d11\",\"text\":\"After running script, be sure to save changes to the image you have opened before switching\\noff images to avoid losing work\",\"type\":\"unstyled\"}],\"entityMap\":{}}},\"1\":{\"type\":\"image\",\"mutability\":\"IMMUTABLE\",\"data\":{\"height\":350,\"id\":499709,\"is_video\":false,\"legend\":\"{\\\"blocks\\\":null,\\\"entityMap\\\":null}\",\"mime\":\"image/png\",\"originalFile\":{},\"original_name\":\"image.png\",\"placeholder\":\"https://protocols-files.s3.amazonaws.com/files/rh98cafgf.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\\u0026X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20240918%2Fus-east-1%2Fs3%2Faws4_request\\u0026X-Amz-Date=20240918T200122Z\\u0026X-Amz-Expires=604800\\u0026X-Amz-SignedHeaders=host\\u0026X-Amz-Signature=52028089bc61fe96b1d61dea0af477d1f8e3770b01bd13e139a5a90b03fa3b43\",\"source\":\"https://protocols-files.s3.amazonaws.com/files/rh97cafgf.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\\u0026X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20240918%2Fus-east-1%2Fs3%2Faws4_request\\u0026X-Amz-Date=20240918T200122Z\\u0026X-Amz-Expires=604800\\u0026X-Amz-SignedHeaders=host\\u0026X-Amz-Signature=579dd29729c09b8df5a74dc0b06bb512c945a3ea0071868955e19c3454dc263e\",\"type\":1,\"width\":550}}}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"47","cases":[],"critical":null},{"id":2232788,"guid":"A9CC95644C2A48A6BF1FF8180168C29F","previous_id":2232782,"previous_guid":"236465ABA23C4F508477D097DD2A66DF","section":"\u003cp\u003eQuPath Visualization/Segmentation: Alternate Segmentations, Pixel Classifier for Florescence\u003c/p\u003e","section_color":"#EA94FF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"63u0\",\"text\":\"Export segmentation image using tweaked script from brightfield workflow below. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"94l4c\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"cj8dn\",\"text\":\"a. Note in line 13, (.addLabel(‘Insert class here’, 1)) includes the name of the class given to \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":2}],\"entityRanges\":[],\"data\":{}},{\"key\":\"fv45a\",\"text\":\"the annotation generated by your classifier. This can be found by selecting the \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"9fqql\",\"text\":\"annotation and locating Classification in the Measurements box underneath it.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"40gir\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"fv9v0\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"2a270\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":1,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"5ta8p\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"64itc\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":2,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"d654\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"425kv\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"image\",\"mutability\":\"IMMUTABLE\",\"data\":{\"height\":340,\"id\":499711,\"is_video\":false,\"legend\":\"{\\\"blocks\\\":null,\\\"entityMap\\\":null}\",\"mime\":\"image/png\",\"originalFile\":{},\"original_name\":\"image.png\",\"placeholder\":\"https://protocols-files.s3.amazonaws.com/files/riaacafgf.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\\u0026X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20240918%2Fus-east-1%2Fs3%2Faws4_request\\u0026X-Amz-Date=20240918T200122Z\\u0026X-Amz-Expires=604800\\u0026X-Amz-SignedHeaders=host\\u0026X-Amz-Signature=f5a12907f463cbae014d78aac2c650da6066a3d688ea1d987411f16a84e4dac4\",\"source\":\"https://protocols-files.s3.amazonaws.com/files/rh99cafgf.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\\u0026X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20240918%2Fus-east-1%2Fs3%2Faws4_request\\u0026X-Amz-Date=20240918T200122Z\\u0026X-Amz-Expires=604800\\u0026X-Amz-SignedHeaders=host\\u0026X-Amz-Signature=9ca672aa89207cd97b61314fb395eb6a8416bedbffb31ea70119af7779351660\",\"type\":1,\"width\":550}},\"1\":{\"type\":\"image\",\"mutability\":\"IMMUTABLE\",\"data\":{\"height\":581.0545454545438,\"id\":499713,\"is_video\":false,\"legend\":\"{\\\"blocks\\\":null,\\\"entityMap\\\":null}\",\"mime\":\"image/png\",\"originalFile\":{},\"original_name\":\"image.png\",\"placeholder\":\"https://protocols-files.s3.amazonaws.com/files/riaccafgf.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\\u0026X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20240918%2Fus-east-1%2Fs3%2Faws4_request\\u0026X-Amz-Date=20240918T200122Z\\u0026X-Amz-Expires=604800\\u0026X-Amz-SignedHeaders=host\\u0026X-Amz-Signature=de51aaff85edde3d0c27d814597c3349378f3cf69d3a66bcfa8ad85651f9d2fe\",\"source\":\"https://protocols-files.s3.amazonaws.com/files/riabcafgf.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\\u0026X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20240918%2Fus-east-1%2Fs3%2Faws4_request\\u0026X-Amz-Date=20240918T200122Z\\u0026X-Amz-Expires=604800\\u0026X-Amz-SignedHeaders=host\\u0026X-Amz-Signature=d9158ff29d1fbab0325701d9e47297f1edbbd132401eadd5164199141820501b\",\"type\":1,\"width\":580}},\"2\":{\"type\":\"command\",\"mutability\":\"IMMUTABLE\",\"data\":{\"can_edit\":true,\"command_name\":\"\",\"description\":\"\",\"guid\":\"46A18B72752111EF86620A58A9FEAC02\",\"name\":\"import qupath.lib.images.servers.LabeledImageServer\\ndef imageData = getCurrentImageData()\\n// Define output path (relative to project)\\ndef name = GeneralTools.getNameWithoutExtension(imageData.getServer().getMetadata().getName())\\ndef pathOutput = buildFilePath(PROJECT_BASE_DIR, 'export', name)\\nmkdirs(pathOutput)\\n// Export at full resolution\\ndouble downsample = 1.0\\n// Create an ImageServer where the pixels are derived from annotations\\ndef labelServer = new LabeledImageServer.Builder(imageData)\\n .backgroundLabel(0, ColorTools.WHITE) // Specify background label (usually 0 or 255)\\n .downsample(downsample) // Choose server resolution; this should match the resolution at which tiles are exported\\n .addLabel('psyn', 1) // Choose output labels (the order matters!)\\n .multichannelOutput(false) // If true, each label refers to the channel of a multichannel binary image (required for multiclass probability)\\n .build()\\n// Export each region\\nint i = 0\\nfor (annotation in getAnnotationObjects()) {\\n if (annotation.getROI().getRoiName() == \\\"Rectangle\\\") {\\n     def region = RegionRequest.createInstance(\\n         labelServer.getPath(), downsample, annotation.getROI())\\n     i++\\n     def outputPath = buildFilePath(pathOutput, name + '.png')\\n     writeImageRegion(labelServer, region, outputPath)\\n}}\\n\",\"os_name\":\"\",\"os_version\":\"\"}}}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"48","cases":[],"critical":null},{"id":2232789,"guid":"A94CDF5FD66543DEB16E88E065BCE0EC","previous_id":2232788,"previous_guid":"A9CC95644C2A48A6BF1FF8180168C29F","section":"\u003cp\u003eQuPath Visualization/Segmentation: Alternate Segmentations, Pixel Classifier for Florescence\u003c/p\u003e","section_color":"#EA94FF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"bu0s0\",\"text\":\"Find exported images in your folder scheme under QuPath\\\\export. The images should be the \\nexact same dimensions of the earlier region of interest image you created as a PNG with a \\ndownsize factor of 12. \\n\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"bb5hi\",\"text\":\"a. The segmentation image should have a white background with segmented pixels in the \\ncolor of the annotation class. (Nutil will ask you to insert the object color as a 6-digit alphanumeric web color code. This can be found by double clicking your annotation’s class in the Classes tab\\u003eSelecting Custom Color from Dropdown\\u003eSelecting Web\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":1},{\"style\":\"italic\",\"offset\":227,\"length\":110}],\"entityRanges\":[],\"data\":{}},{\"key\":\"3dcga\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"8prl0\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"6t86o\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"image\",\"mutability\":\"IMMUTABLE\",\"data\":{\"height\":232,\"id\":499730,\"is_video\":false,\"legend\":\"{\\\"blocks\\\":null,\\\"entityMap\\\":null}\",\"mime\":\"image/png\",\"originalFile\":{},\"original_name\":\"image.png\",\"placeholder\":\"https://protocols-files.s3.amazonaws.com/files/riavcafgf.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\\u0026X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20240918%2Fus-east-1%2Fs3%2Faws4_request\\u0026X-Amz-Date=20240918T200122Z\\u0026X-Amz-Expires=604800\\u0026X-Amz-SignedHeaders=host\\u0026X-Amz-Signature=1dee450a2b09d3e74e05e1e4c9b4175ed13263fa2e9f56ec17434adf67632c6a\",\"source\":\"https://protocols-files.s3.amazonaws.com/files/riaucafgf.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\\u0026X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20240918%2Fus-east-1%2Fs3%2Faws4_request\\u0026X-Amz-Date=20240918T200122Z\\u0026X-Amz-Expires=604800\\u0026X-Amz-SignedHeaders=host\\u0026X-Amz-Signature=6491b9ab514dac5fd6c09a19cebb0bfd2267c6b994262d470fee2199c27e0477\",\"type\":1,\"width\":550}}}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"49","cases":[],"critical":null},{"id":2232973,"guid":"3FDAE1695C9F4A9B9E4C0038C3839081","previous_id":2232789,"previous_guid":"A94CDF5FD66543DEB16E88E065BCE0EC","section":"\u003cp\u003eQuPath Visualization/Segmentation: Alternate Segmentations, Pixel Classifier for Florescence\u003c/p\u003e","section_color":"#EA94FF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"apt6m\",\"text\":\"Place the image into “Input” folder that will be used in final Nutil step.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":22,\"length\":5}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"50","cases":[],"critical":null},{"id":2232983,"guid":"AC8A94FB9A7B465C884D1F0777E03341","previous_id":2232984,"previous_guid":"A2A6DAE2FC6E4EFF90FC521AB5937206","section":"","section_color":"","section_duration":0,"is_substep":false,"step":"","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"3","cases":[],"critical":null},{"id":2232984,"guid":"A2A6DAE2FC6E4EFF90FC521AB5937206","previous_id":2226952,"previous_guid":"1F9B2D1E711311EF9DD00A58A9FEAC02","section":"","section_color":"","section_duration":0,"is_substep":false,"step":"","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"2","cases":[],"critical":null},{"id":2232985,"guid":"62EBDE3C9E634E3DB58563BA08DD3B92","previous_id":2232999,"previous_guid":"F20B0C05FAD544A1AA844B68B02ACC39","section":"\u003cp\u003eDeepSlice Automated Alignment\u003c/p\u003e","section_color":"#94EBFF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"crd22\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"11t9r\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"gior\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"7a5qp\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"60e6r\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"8c1ro\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"9b9v3\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":1,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"8lf9k\",\"text\":\"     \\nOpen DeepSlice in your web browser.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":11,\"length\":9}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"notes\",\"mutability\":\"IMMUTABLE\",\"data\":{\"blocks\":[{\"data\":{},\"depth\":0,\"entityRanges\":[],\"inlineStyleRanges\":[{\"length\":529,\"offset\":0,\"style\":\"italic\"}],\"key\":\"eelqu\",\"text\":\"DeepSlice is a deep neural network that automatically aligns mouse histology images through the Allen Brain Atlas coordinate framework. Alignments are viewable and refinable in QuickNII and set up sections to give a good starting point near and around each section’s correct plane. DeepSlice’s alignment is not completely accurate and further fine tuning in QuickNII is necessary. This is a newly developed tool and not imperative for the workflow but helps speed the process of registration and substitutes the Filebuilder step.\",\"type\":\"unstyled\"}],\"entityMap\":{}}},\"1\":{\"type\":\"image\",\"mutability\":\"IMMUTABLE\",\"data\":{\"height\":302.6545454545454,\"id\":499775,\"is_video\":false,\"legend\":\"{\\\"blocks\\\":null,\\\"entityMap\\\":null}\",\"mime\":\"image/png\",\"originalFile\":{},\"original_name\":\"image.png\",\"placeholder\":\"https://protocols-files.s3.amazonaws.com/files/ricacafgf.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\\u0026X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20240918%2Fus-east-1%2Fs3%2Faws4_request\\u0026X-Amz-Date=20240918T200122Z\\u0026X-Amz-Expires=604800\\u0026X-Amz-SignedHeaders=host\\u0026X-Amz-Signature=02b4fbc101927edc1e7618d565f30a52a97e1975b825465ed817ad8a6d843b1b\",\"source\":\"https://protocols-files.s3.amazonaws.com/files/rib9cafgf.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\\u0026X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20240918%2Fus-east-1%2Fs3%2Faws4_request\\u0026X-Amz-Date=20240918T200122Z\\u0026X-Amz-Expires=604800\\u0026X-Amz-SignedHeaders=host\\u0026X-Amz-Signature=0348f5008dcf59975683b1f87b19232798486b7f8047d796f995fa8b42623cb7\",\"type\":1,\"width\":580}}}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"55","cases":[],"critical":null},{"id":2232987,"guid":"870DF5FE64B5486994A6252A21FFBE6A","previous_id":2232973,"previous_guid":"3FDAE1695C9F4A9B9E4C0038C3839081","section":"\u003cp\u003eQuPath Visualization/Segmentation: Alternate Segmentations, Subcellular Segmentation\u003c/p\u003e","section_color":"#A492FF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"5ujit\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"4n527\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"3bin4\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"c4i7s\",\"text\":\"After running cell detection and object classifiers, open Subcellular spot detection window: Analyze\\u003eCell Detection\\u003eSubcellular detection (experimental)\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"aocco\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"24olq\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":1,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"8o9u5\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"notes\",\"mutability\":\"IMMUTABLE\",\"data\":{\"blocks\":[{\"data\":{},\"depth\":0,\"entityRanges\":[],\"inlineStyleRanges\":[{\"length\":74,\"offset\":0,\"style\":\"italic\"}],\"key\":\"bpnrf\",\"text\":\"Restricts pixel classifier to only within detected cells (inclusion area).\",\"type\":\"unstyled\"}],\"entityMap\":{}}},\"1\":{\"type\":\"image\",\"mutability\":\"IMMUTABLE\",\"data\":{\"height\":427,\"id\":499733,\"is_video\":false,\"legend\":\"{\\\"blocks\\\":null,\\\"entityMap\\\":null}\",\"mime\":\"image/png\",\"originalFile\":{},\"original_name\":\"image.png\",\"placeholder\":\"https://protocols-files.s3.amazonaws.com/files/riaycafgf.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\\u0026X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20240918%2Fus-east-1%2Fs3%2Faws4_request\\u0026X-Amz-Date=20240918T200122Z\\u0026X-Amz-Expires=604800\\u0026X-Amz-SignedHeaders=host\\u0026X-Amz-Signature=6c83665f57287440d4c8f43de42e7d5c8691e1bd8b340570d45e7be23d1f94ff\",\"source\":\"https://protocols-files.s3.amazonaws.com/files/riaxcafgf.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\\u0026X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20240918%2Fus-east-1%2Fs3%2Faws4_request\\u0026X-Amz-Date=20240918T200122Z\\u0026X-Amz-Expires=604800\\u0026X-Amz-SignedHeaders=host\\u0026X-Amz-Signature=b8ca8463b2f4ae15335b45a7b8e4f57653c862f6255ae89c4c87a4788341302d\",\"type\":1,\"width\":462}}}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"51","cases":[],"critical":null},{"id":2232991,"guid":"7258418661094B599C19829FC5FEAAE7","previous_id":2232994,"previous_guid":"245E13C2105F4E5CB19590799C21E2B7","section":"\u003cp\u003eQuPath Visualization/Segmentation: Alternate Segmentations, Subcellular Segmentation\u003c/p\u003e","section_color":"#A492FF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"704uf\",\"text\":\"To restrict subcellular detection to a specific cell type right click on class for desired cell type(s)\\u003eSelect objects by classification\\n\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"italic\",\"offset\":104,\"length\":32}],\"entityRanges\":[],\"data\":{}},{\"key\":\"323cf\",\"text\":\"a.  Selected class cells should appear yellow with all other cells remaining their \\noriginal color\\nb. Run the subcell detection command\\n(if you want to run the subcellular detection for all cells, this step is not necessary)\\n\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":3},{\"style\":\"bold\",\"offset\":99,\"length\":2}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"52","cases":[],"critical":null},{"id":2232993,"guid":"8B9E662BF3524706A578FCED80217AEE","previous_id":2232987,"previous_guid":"870DF5FE64B5486994A6252A21FFBE6A","section":"\u003cp\u003eQuPath Visualization/Segmentation: Alternate Segmentations, Subcellular Segmentation\u003c/p\u003e","section_color":"#A492FF","section_duration":0,"is_substep":true,"step":"{\"blocks\":[{\"key\":\"b729p\",\"text\":\"Set the detection threshold to the fluorescence value of your pixel classifier\\n\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"aet7e\",\"text\":\"a. The order of the channels in the display window corresponds to the numbering in the subcellular spot detection window. Set the threshold in the channel number of interest and leave the other two at -1 to ignore.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":3}],\"entityRanges\":[],\"data\":{}},{\"key\":\"audjl\",\"text\":\"b. Check split by shape to get individual stain objects within each cell\",\"type\":\"align-left\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":3}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"51.1","cases":[],"critical":null},{"id":2232994,"guid":"245E13C2105F4E5CB19590799C21E2B7","previous_id":2232993,"previous_guid":"8B9E662BF3524706A578FCED80217AEE","section":"\u003cp\u003eQuPath Visualization/Segmentation: Alternate Segmentations, Subcellular Segmentation\u003c/p\u003e","section_color":"#A492FF","section_duration":0,"is_substep":true,"step":"{\"blocks\":[{\"key\":\"16uk2\",\"text\":\"Adjust max spot size (adjust to something significantly larger than a single cell area\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"51.2","cases":[],"critical":null},{"id":2232998,"guid":"9C43A76B993548189AE9D477E0F8C344","previous_id":2232991,"previous_guid":"7258418661094B599C19829FC5FEAAE7","section":"\u003cp\u003eQuPath Visualization/Segmentation: Alternate Segmentations, Subcellular Segmentation\u003c/p\u003e","section_color":"#A492FF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"afiit\",\"text\":\" Export subcellular segmentation by running this script adapted from pixel classifier export script (note line 13* include the name of class of subcellular object -\\u003e can be obtained by clicking 3 dots next to Auto set in Annotation Classes tab\\u003ePopulate from existing objects (All classes (including sub-classes)):\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"italic\",\"offset\":244,\"length\":69}],\"entityRanges\":[],\"data\":{}},{\"key\":\"8jkfu\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"ade68\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"8gu9g\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"5f206\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":1,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"ebfa9\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"3jror\",\"text\":\"The same principles for file location in fluorescent pixel classifier export applies here.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"bneov\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"a6rqa\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"image\",\"mutability\":\"IMMUTABLE\",\"data\":{\"height\":562.0727272727298,\"id\":499767,\"is_video\":false,\"legend\":\"{\\\"blocks\\\":null,\\\"entityMap\\\":null}\",\"mime\":\"image/png\",\"originalFile\":{},\"original_name\":\"image.png\",\"placeholder\":\"https://protocols-files.s3.amazonaws.com/files/rib2cafgf.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\\u0026X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20240918%2Fus-east-1%2Fs3%2Faws4_request\\u0026X-Amz-Date=20240918T200122Z\\u0026X-Amz-Expires=604800\\u0026X-Amz-SignedHeaders=host\\u0026X-Amz-Signature=65b2d363b6b80b9cad9b93eb05136e265ac4ddf831e0ef67c5ab8f177f58cdc4\",\"source\":\"https://protocols-files.s3.amazonaws.com/files/ribzcafgf.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\\u0026X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20240918%2Fus-east-1%2Fs3%2Faws4_request\\u0026X-Amz-Date=20240918T200122Z\\u0026X-Amz-Expires=604800\\u0026X-Amz-SignedHeaders=host\\u0026X-Amz-Signature=cbeac8ee353940958d9d702932f642b3028efd5c551435f7adaa0ce07b92604b\",\"type\":1,\"width\":580}},\"1\":{\"type\":\"command\",\"mutability\":\"IMMUTABLE\",\"data\":{\"can_edit\":true,\"command_name\":\"\",\"description\":\"\",\"guid\":\"7D4527D2752111EF86620A58A9FEAC02\",\"name\":\"import qupath.lib.images.servers.LabeledImageServer\\ndef imageData = getCurrentImageData()\\n// Define output path (relative to project)\\ndef name = GeneralTools.getNameWithoutExtension(imageData.getServer().getMetadata().getName())\\ndef pathOutput = buildFilePath(PROJECT_BASE_DIR, 'export', name)\\nmkdirs(pathOutput) \\n// Export at full resolution\\ndouble downsample = 1.0\\n// Create an ImageServer where the pixels are derived from annotations\\ndef labelServer = new LabeledImageServer.Builder(imageData)\\n    .backgroundLabel(0, ColorTools.WHITE) // Specify background label (usually 0 or 255)\\n    .downsample(1)    // Choose server resolution; this should match the resolution at which tiles are exported\\n    .addLabel('Subcellular spot: Channel 2 object', 1)\\n    .multichannelOutput(false) // If true, each label refers to the channel of a multichannel binary image (required for multiclass probability)\\n    .useDetections()\\n    .build()\\n// Export each region\\nint i = 0\\nfor (annotation in getAnnotationObjects()) {\\n  if (annotation.getROI().getRoiName() == \\\"Rectangle\\\") {\\n    def region = RegionRequest.createInstance(\\n        labelServer.getPath(), downsample, annotation.getROI())\\n    i++\\n    def outputPath = buildFilePath(pathOutput, name + '.png')\\n    writeImageRegion(labelServer, region, outputPath)\\n}}\\n\",\"os_name\":\"\",\"os_version\":\"\"}}}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"53","cases":[],"critical":null},{"id":2232999,"guid":"F20B0C05FAD544A1AA844B68B02ACC39","previous_id":2232998,"previous_guid":"9C43A76B993548189AE9D477E0F8C344","section":"\u003cp\u003eQuPath Visualization/Segmentation: Alternate Segmentations, Subcellular Segmentation\u003c/p\u003e","section_color":"#A492FF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"8o1nv\",\"text\":\"Neurite Area: Using the pixel classifier export that detects positive area signal everywhere, and the subcellular detection that detects only in cells, we can get neurite area (positive area outside of cells) by using the post-processing tool, Nutil2Usable. Subtracting subcellular area from total area will leave us with only area outside of cells (aka neurite). There is a protocol in N2U that instructs on how to go about that analysis.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"4j808\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"683nd\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"1f8k0\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"84o5v\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"image\",\"mutability\":\"IMMUTABLE\",\"data\":{\"height\":301,\"id\":499773,\"is_video\":false,\"legend\":\"{\\\"blocks\\\":null,\\\"entityMap\\\":null}\",\"mime\":\"image/png\",\"originalFile\":{},\"original_name\":\"image.png\",\"placeholder\":\"https://protocols-files.s3.amazonaws.com/files/rib8cafgf.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\\u0026X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20240918%2Fus-east-1%2Fs3%2Faws4_request\\u0026X-Amz-Date=20240918T200122Z\\u0026X-Amz-Expires=604800\\u0026X-Amz-SignedHeaders=host\\u0026X-Amz-Signature=96f896f13f0ca0261ac0983efceee2d8046cd3e32f21386b9855672604006be6\",\"source\":\"https://protocols-files.s3.amazonaws.com/files/rib7cafgf.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\\u0026X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20240918%2Fus-east-1%2Fs3%2Faws4_request\\u0026X-Amz-Date=20240918T200122Z\\u0026X-Amz-Expires=604800\\u0026X-Amz-SignedHeaders=host\\u0026X-Amz-Signature=e5f118d04ca4292091d819eed9fe1e1c9d114da99764e19c6a221191c8bcde34\",\"type\":1,\"width\":550}}}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"54","cases":[],"critical":null},{"id":2233007,"guid":"118B2937ECF44D4EBAFE9C84AAF25D66","previous_id":2232985,"previous_guid":"62EBDE3C9E634E3DB58563BA08DD3B92","section":"\u003cp\u003eDeepSlice Automated Alignment\u003c/p\u003e","section_color":"#94EBFF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"2kltg\",\"text\":\"Select Choose Files.\\n\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"italic\",\"offset\":7,\"length\":12}],\"entityRanges\":[],\"data\":{}},{\"key\":\"6g7rl\",\"text\":\"a. Upload all images for registration from the QVN folder\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":3}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"56","cases":[],"critical":null},{"id":2233009,"guid":"925F6F95C73B4B72826FB0D4D245E85C","previous_id":2233007,"previous_guid":"118B2937ECF44D4EBAFE9C84AAF25D66","section":"\u003cp\u003eDeepSlice Automated Alignment\u003c/p\u003e","section_color":"#94EBFF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"1litd\",\"text\":\"Ensure Mouse is selected for species, and Model Ensemble is checked (uses two DeepSlice \\nversions to optimize alignment ).\\n\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"italic\",\"offset\":6,\"length\":6},{\"style\":\"italic\",\"offset\":42,\"length\":14}],\"entityRanges\":[],\"data\":{}},{\"key\":\"aqk1s\",\"text\":\"a. Avoid checking Angle Integration (this aligns all your brain sections to the same angle, which is inaccurate when blocks have different cutting angles) \\nb. Avoid checking Using Cutting Index (this suggests your sections numbers (_s###) correspond to serial section numbers spaced equally apart) \\nc. Optional to allow DeepSlice to use your data to improve the neural network and its predictive accuracy.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":1},{\"style\":\"bold\",\"offset\":156,\"length\":2},{\"style\":\"bold\",\"offset\":299,\"length\":1},{\"style\":\"italic\",\"offset\":18,\"length\":17},{\"style\":\"italic\",\"offset\":174,\"length\":19}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"57","cases":[],"critical":null},{"id":2233012,"guid":"1A5976C16B2E4ACF82FB46A483C99652","previous_id":2233009,"previous_guid":"925F6F95C73B4B72826FB0D4D245E85C","section":"\u003cp\u003eDeepSlice Automated Alignment\u003c/p\u003e","section_color":"#94EBFF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"9k528\",\"text\":\"Select Submit.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":7,\"length\":7}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"58","cases":[],"critical":null},{"id":2233014,"guid":"2AD5B9051F0B4A6FBF5D11DC55A14E7C","previous_id":2233012,"previous_guid":"1A5976C16B2E4ACF82FB46A483C99652","section":"\u003cp\u003eDeepSlice Automated Alignment\u003c/p\u003e","section_color":"#94EBFF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"deu9u\",\"text\":\"After all sections/slices are processed, press Download XML\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"59","cases":[],"critical":null},{"id":2233015,"guid":"B8F4523494504222886B057FF685E737","previous_id":2233014,"previous_guid":"2AD5B9051F0B4A6FBF5D11DC55A14E7C","section":"\u003cp\u003eDeepSlice Automated Alignment\u003c/p\u003e","section_color":"#94EBFF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"a9943\",\"text\":\"Insert the downloaded XML (titled by default ‘results.XML’) into your QVN folder with all your \\nimages for registration.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"60","cases":[],"critical":null},{"id":2233021,"guid":"ACE05B46E70A4EB3A61FE1DAA1C46E9F","previous_id":2226989,"previous_guid":"1FA1DA95711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eQuPath Visualization/Segmentation: Export Segmentation\u003c/p\u003e","section_color":"#E57785","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"1d8tg\",\"text\":\"Find the exported images in the export folder. The segmentation image should be white with objects in their WEB ID color. The images should be the exact same dimensions of the earlier region of interest image you created as a PNG with a downsize factor of 12. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"42","cases":[],"critical":null},{"id":2233022,"guid":"B4395C802EF744469F4FD5E580D0080C","previous_id":2233021,"previous_guid":"ACE05B46E70A4EB3A61FE1DAA1C46E9F","section":"\u003cp\u003eQuPath Visualization/Segmentation: Export Segmentation\u003c/p\u003e","section_color":"#E57785","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"7m8l8\",\"text\":\"Scenes with smaller annotation regions that you used to make your training images will \\nhave a second segmentation. Delete the segmentation image that corresponds to the \\nsmaller annotation.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"43","cases":[],"critical":null},{"id":2233023,"guid":"3739A85201CF4BE7AD2A98CFB269D731","previous_id":2233022,"previous_guid":"B4395C802EF744469F4FD5E580D0080C","section":"\u003cp\u003eQuPath Visualization/Segmentation: Export Segmentation\u003c/p\u003e","section_color":"#E57785","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"1pv0m\",\"text\":\"Copy the images to the ‘Input’ folder in the QVN folder. These images will be used in the \\nfinal step of Nutil. Close the QuPath application.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"44","cases":[],"critical":null},{"id":2233024,"guid":"F488C180EFEB4A0DB925BB48E18FF8E2","previous_id":2227026,"previous_guid":"1FA87FA6711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eVisuAlign\u003c/p\u003e","section_color":"#EA9F6C","section_duration":0,"is_substep":true,"step":"{\"blocks\":[{\"key\":\"7cs4u\",\"text\":\" Start with the outer alignments first then move inwards. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"90.5","cases":[],"critical":null},{"id":2233025,"guid":"46797166485045538C9E9AB314A03C40","previous_id":2233026,"previous_guid":"2EF2D16C8ED94ED6B7111629E237D81C","section":"\u003cp\u003eNutil\u003c/p\u003e","section_color":"#E57785","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"aclg6\",\"text\":\"     \\nIn the advanced settings, set ‘Custom masks (optional)’ to ‘Yes’. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"105","cases":[],"critical":null},{"id":2233026,"guid":"2EF2D16C8ED94ED6B7111629E237D81C","previous_id":2233027,"previous_guid":"BAB0D7895D5F4737B7570FA546546668","section":"\u003cp\u003eNutil\u003c/p\u003e","section_color":"#E57785","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"bsn0e\",\"text\":\" Set ‘Object Splitting’ to ‘No’.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"7tra4\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"9tv8s\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"c8sn2\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"image\",\"mutability\":\"IMMUTABLE\",\"data\":{\"height\":238.32727272727274,\"id\":499823,\"is_video\":false,\"legend\":\"{\\\"blocks\\\":null,\\\"entityMap\\\":null}\",\"mime\":\"image/png\",\"originalFile\":{},\"original_name\":\"image.png\",\"placeholder\":\"https://protocols-files.s3.amazonaws.com/files/ridscafgf.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\\u0026X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20240918%2Fus-east-1%2Fs3%2Faws4_request\\u0026X-Amz-Date=20240918T200122Z\\u0026X-Amz-Expires=604800\\u0026X-Amz-SignedHeaders=host\\u0026X-Amz-Signature=85c188309ed9399c8dba9d18d804d839a1a9e5818c235bed70e0814f134896af\",\"source\":\"https://protocols-files.s3.amazonaws.com/files/ridrcafgf.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\\u0026X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20240918%2Fus-east-1%2Fs3%2Faws4_request\\u0026X-Amz-Date=20240918T200122Z\\u0026X-Amz-Expires=604800\\u0026X-Amz-SignedHeaders=host\\u0026X-Amz-Signature=d09429bf3d5a200360f050948bd706fe334129d266257de60503638749e77108\",\"type\":1,\"width\":580}}}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"104","cases":[],"critical":null},{"id":2233027,"guid":"BAB0D7895D5F4737B7570FA546546668","previous_id":2227039,"previous_guid":"1FAA9998711311EF9DD00A58A9FEAC02","section":"\u003cp\u003eNutil\u003c/p\u003e","section_color":"#E57785","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"8aj4m\",\"text\":\"Change the ‘Object colour’ to match the WEB ID code for the classifier you are currently \\nrunning.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"103","cases":[],"critical":null},{"id":2233028,"guid":"3C064F86BF5F47879629F0084ED05968","previous_id":2233025,"previous_guid":"46797166485045538C9E9AB314A03C40","section":"\u003cp\u003eNutil\u003c/p\u003e","section_color":"#E57785","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"9foek\",\"text\":\"Set the ‘Custom mask folder’ to the ‘Mask’ folder within the QVN folder.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"106","cases":[],"critical":null},{"id":2233059,"guid":"87D20E3C101F440A8177A186490CB3CC","previous_id":2233028,"previous_guid":"3C064F86BF5F47879629F0084ED05968","section":"\u003cp\u003eNutil\u003c/p\u003e","section_color":"#E57785","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"c240u\",\"text\":\"Set the ‘Custom mask colour’ to either white or black depending on which hemisphere you are \\ncurrently running. For output left, set the mask color to white. For output right, set the mask \\ncolor to black. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"107","cases":[],"critical":null},{"id":2233060,"guid":"67ADD6FBAECF4BAB8BF43688223ACBC3","previous_id":2233059,"previous_guid":"87D20E3C101F440A8177A186490CB3CC","section":"\u003cp\u003eNutil\u003c/p\u003e","section_color":"#E57785","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"3j5hi\",\"text\":\"Once all settings are in place, select ‘Start’. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"fa8v5\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"4o92v\",\"text\":\" \",\"type\":\"atomic\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":0,\"length\":1}],\"data\":{}},{\"key\":\"477hc\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"image\",\"mutability\":\"IMMUTABLE\",\"data\":{\"height\":146.5818181818182,\"id\":499825,\"is_video\":false,\"legend\":\"{\\\"blocks\\\":null,\\\"entityMap\\\":null}\",\"mime\":\"image/png\",\"originalFile\":{},\"original_name\":\"image.png\",\"placeholder\":\"https://protocols-files.s3.amazonaws.com/files/riducafgf.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\\u0026X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20240918%2Fus-east-1%2Fs3%2Faws4_request\\u0026X-Amz-Date=20240918T200122Z\\u0026X-Amz-Expires=604800\\u0026X-Amz-SignedHeaders=host\\u0026X-Amz-Signature=ea14148738658b6a888a727f29028e6084606b9695bc21db0b7f8ac8c2199035\",\"source\":\"https://protocols-files.s3.amazonaws.com/files/ridtcafgf.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\\u0026X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20240918%2Fus-east-1%2Fs3%2Faws4_request\\u0026X-Amz-Date=20240918T200122Z\\u0026X-Amz-Expires=604800\\u0026X-Amz-SignedHeaders=host\\u0026X-Amz-Signature=4c11cddef3e006ee3913a42135cc10fa49f8952ed7ef18d127b7ec64c08c0a06\",\"type\":1,\"width\":580}}}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"108","cases":[],"critical":null},{"id":2233061,"guid":"93B17D2378B64D0CB21832A05DB0DE85","previous_id":2233060,"previous_guid":"67ADD6FBAECF4BAB8BF43688223ACBC3","section":"\u003cp\u003eNutil\u003c/p\u003e","section_color":"#E57785","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"4lv3a\",\"text\":\"     \\nRepeat for every classifier combination you have and for each hemisphere, remembering to change any settings to match. Double check that every image has a Nutil output. If outputs are missing, run Nutil again.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"anb6q\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":107483,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"109","cases":[],"critical":null}],"template_id":4,"title":"QUINT Workflow for Fluorescence","title_html":"QUINT Workflow for Fluorescence","type_id":1,"units":[{"id":1,"type_id":3,"name":"µL","can_manage":0,"read_only":0},{"id":2,"type_id":3,"name":"mL","can_manage":0,"read_only":0},{"id":3,"type_id":3,"name":"L","can_manage":0,"read_only":0},{"id":4,"type_id":3,"name":"µg","can_manage":0,"read_only":0},{"id":5,"type_id":3,"name":"mg","can_manage":0,"read_only":0},{"id":6,"type_id":3,"name":"g","can_manage":0,"read_only":0},{"id":7,"type_id":3,"name":"kg","can_manage":0,"read_only":0},{"id":8,"type_id":3,"name":"ng","can_manage":0,"read_only":0},{"id":9,"type_id":3,"name":"Hz","can_manage":0,"read_only":0},{"id":10,"type_id":24,"name":"°C","can_manage":0,"read_only":0},{"id":11,"type_id":24,"name":"°К","can_manage":0,"read_only":0},{"id":12,"type_id":24,"name":"°F","can_manage":0,"read_only":0},{"id":13,"type_id":25,"name":"Mass Percent","can_manage":0,"read_only":0},{"id":14,"type_id":25,"name":"% volume","can_manage":0,"read_only":0},{"id":15,"type_id":25,"name":"Mass / % volume","can_manage":0,"read_only":0},{"id":16,"type_id":25,"name":"Parts per Million (PPM)","can_manage":0,"read_only":0},{"id":17,"type_id":25,"name":"Parts per Billion (PPB)","can_manage":0,"read_only":0},{"id":18,"type_id":25,"name":"Parts per Trillion (PPT)","can_manage":0,"read_only":0},{"id":19,"type_id":25,"name":"Mole Fraction","can_manage":0,"read_only":0},{"id":20,"type_id":25,"name":"Mole Percent","can_manage":0,"read_only":0},{"id":21,"type_id":25,"name":"Molarity (M)","can_manage":0,"read_only":1},{"id":22,"type_id":25,"name":"Molarity (M)","can_manage":0,"read_only":0},{"id":23,"type_id":25,"name":"Genome copies per ml","can_manage":0,"read_only":0},{"id":24,"type_id":3,"name":"μV","can_manage":0,"read_only":0},{"id":25,"type_id":3,"name":"ms","can_manage":0,"read_only":0},{"id":26,"type_id":3,"name":"pg","can_manage":0,"read_only":0},{"id":27,"type_id":25,"name":"Molarity dilutions","can_manage":0,"read_only":0},{"id":28,"type_id":25,"name":"millimolar (mM)","can_manage":0,"read_only":0},{"id":29,"type_id":25,"name":"micromolar (µM)","can_manage":0,"read_only":0},{"id":30,"type_id":25,"name":"nanomolar (nM)","can_manage":0,"read_only":0},{"id":31,"type_id":25,"name":"picomolar (pM)","can_manage":0,"read_only":0},{"id":32,"type_id":24,"name":"Room temperature","can_manage":0,"read_only":0},{"id":33,"type_id":30,"name":"rpm","can_manage":0,"read_only":0},{"id":34,"type_id":30,"name":"x g","can_manage":0,"read_only":0},{"id":165,"type_id":24,"name":"On ice","can_manage":0,"read_only":0},{"id":200,"type_id":32,"name":"cm","can_manage":0,"read_only":0},{"id":201,"type_id":32,"name":"mm","can_manage":0,"read_only":0},{"id":202,"type_id":32,"name":"µm","can_manage":0,"read_only":0},{"id":203,"type_id":32,"name":"nm","can_manage":0,"read_only":0},{"id":204,"type_id":25,"name":"mg/mL","can_manage":0,"read_only":0},{"id":205,"type_id":25,"name":"µg/µL","can_manage":0,"read_only":0},{"id":206,"type_id":25,"name":"% (v/v)","can_manage":0,"read_only":0},{"id":207,"type_id":3,"name":"V","can_manage":0,"read_only":0},{"id":1324,"type_id":30,"name":"rcf","can_manage":0,"read_only":0},{"id":1359,"type_id":35,"name":"Bar","can_manage":0,"read_only":0},{"id":1360,"type_id":35,"name":"Pa","can_manage":0,"read_only":0}],"uri":"quint-workflow-for-fluorescence-dk734zqn","url":"https://www.protocols.io/view/quint-workflow-for-fluorescence-dk734zqn","version_class":90667,"version_data":{"id":1,"code":"dk734zqn","version_class":90667,"parent_id":90667,"parent_uri":"quint-workflow-for-fluorescence-c4sjywcn","is_same_owner":true,"is_parent_public":true,"has_pending_merge_request":false,"has_approved_merge_request":true,"merge_request":{"id":2926,"creator":{"name":"Lindsay Meyerdirk","affiliation":"Van Andel Institute","affiliation_url":null,"username":"n4vle1y1y1s4xle1","link":null,"user_image_file":{"guid":"00000000000000000000000000000001","file_name":"avatar.png","url":"https://www.protocols.io/img/avatars/001.png","mime":"image/png","size":0,"width":100,"height":100,"avg_color":"","scan_status":0,"created_at":0}},"created_on":1726597284,"can_manage":true}},"version_id":1,"version_uri":"quint-workflow-for-fluorescence-4r3l22y6jl1y/v2","versions":[{"id":90667,"title":"QUINT Workflow for Fluorescence","title_html":"QUINT Workflow for Fluorescence","image":{"source":"https://www.protocols.io/img/default_protocol.png","webp_source":null,"placeholder":"https://www.protocols.io/img/default_protocol.png","webp_placeholder":null},"doi":"dx.doi.org/10.17504/protocols.io.4r3l22y6jl1y/v1","uri":"quint-workflow-for-fluorescence-c4sjywcn","published_on":1699976688,"modified_on":1717170998,"version_class":90667,"version_id":0,"version_code":"c4sjywcn","version_uri":"quint-workflow-for-fluorescence-4r3l22y6jl1y/v1","created_on":1692280256,"categories":null,"type_id":1,"creator":{"name":"Michael Henderson","affiliation":"Van Andel Research Institute","affiliation_url":null,"username":"michael-henderson","link":null,"user_image_file":{"guid":"00000000000000000000000000000001","file_name":"avatar.png","url":"https://www.protocols.io/img/avatars/001.png","mime":"image/png","size":0,"width":100,"height":100,"avg_color":"","scan_status":0,"created_at":0}},"stats":{"number_of_comments":0,"last_comment_time":0}},{"id":107483,"title":"QUINT Workflow for Fluorescence","title_html":"QUINT Workflow for Fluorescence","image":{"source":"https://www.protocols.io/img/default_protocol.png","webp_source":null,"placeholder":"https://www.protocols.io/img/default_protocol.png","webp_placeholder":null},"doi":"dx.doi.org/10.17504/protocols.io.4r3l22y6jl1y/v2","uri":"quint-workflow-for-fluorescence-dk734zqn","published_on":1726606465,"modified_on":1726606465,"version_class":90667,"version_id":1,"version_code":"dk734zqn","version_uri":"quint-workflow-for-fluorescence-4r3l22y6jl1y/v2","created_on":1692280256,"categories":null,"type_id":1,"creator":{"name":"Michael Henderson","affiliation":"Van Andel Research Institute","affiliation_url":null,"username":"michael-henderson","link":null,"user_image_file":{"guid":"00000000000000000000000000000001","file_name":"avatar.png","url":"https://www.protocols.io/img/avatars/001.png","mime":"image/png","size":0,"width":100,"height":100,"avg_color":"","scan_status":0,"created_at":0}},"stats":{"number_of_comments":0,"last_comment_time":0}}],"warning":""}