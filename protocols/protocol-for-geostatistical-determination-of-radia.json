{"id":31598,"title":"Protocol for Geostatistical Determination of Radiation Dosimetry Maps of Population-Scale Exposures","title_html":"<p>Protocol for Geostatistical Determination of Radiation Dosimetry Maps of Population-Scale Exposures<\/p>","image":{"source":"https:\/\/s3.amazonaws.com\/protocols-files\/public\/9320c53043cebfd096c26b8dc25173ef3c96973eff8c022a1c7251fe6a070124\/bwm4bazi7.png","placeholder":"https:\/\/s3.amazonaws.com\/protocols-files\/public\/9320c53043cebfd096c26b8dc25173ef3c96973eff8c022a1c7251fe6a070124\/bwm4bazi7.png"},"doi":"dx.doi.org\/10.17504\/protocols.io.ba4nigve","doi_status":2,"uri":"protocol-for-geostatistical-determination-of-radia-ba4nigve","type_id":1,"published_on":1587744518,"parent_protocols":[],"parent_collections":[],"cited_protocols":[],"version_id":0,"created_on":1578498045,"categories":null,"creator":{"name":"Eliseos Mucaki","affiliation":null,"affiliations":[],"username":"eliseos-mucaki","link":null,"image":{"source":"\/img\/avatars\/003.png","placeholder":"\/img\/avatars\/003.png"},"badges":[{"id":2,"image":{"source":"\/img\/badges\/bronze.svg","placeholder":"\/img\/badges\/bronze.svg"},"name":"Author"}],"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},"journal":null,"journal_name":null,"journal_link":null,"article_citation":null,"public":1,"has_versions":0,"link":null,"total_collections":0,"number_of_steps":9,"authors":[{"name":"Eliseos Mucaki","affiliation":"Western University","affiliations":[],"username":"eliseos-mucaki","link":null,"image":{"source":"\/img\/avatars\/003.png","placeholder":"\/img\/avatars\/003.png"},"badges":[],"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},{"name":"Peter Rogan","affiliation":"Western University","affiliations":[],"username":"peter-rogan","link":null,"image":{"source":"\/img\/avatars\/004.png","placeholder":"\/img\/avatars\/004.png"},"badges":[],"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false}],"versions":[],"groups":[],"is_owner":1,"has_subprotocols":0,"is_subprotocol":0,"is_bookmarked":0,"can_be_copied":1,"can_remove_fork":1,"fork_id":null,"url":"https:\/\/www.protocols.io\/view\/protocol-for-geostatistical-determination-of-radia-ba4nigve","forks_count":{"private":0,"public":0},"access":{"can_view":1,"can_remove":0,"can_add":0,"can_edit":0,"can_publish":0,"can_get_doi":0,"can_share":1,"can_move":1,"can_move_outside":1,"can_transfer":1,"can_download":1,"is_locked":0},"guid":"309E88A0322B11EAA92BD9331BCC4644","state_version_id":5764,"steps":[{"id":867600,"guid":"22A6ECE0323211EAA92BD9331BCC4644","previous_id":null,"previous_guid":null,"modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"8A9EFDEEA83A466A85C7370917A08085","order_id":1,"type_id":6,"title":"Section","source":{"title":"Derivation and Processing of ground-truth HPAC radiation plumes"}},{"id":1054724,"guid":"72CF3CC95DC6480B869E5A94B0172461","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Nuclear detonation scenarios created by the Hazard Prediction and Capability software (HPAC; <\/div><div class = \"text-block\"><a href=\"https:\/\/www.acq.osd.mil\/ncbdp\/nm\/narp\/Radiation_Data\/Specialized_Radiological.htm\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">https:\/\/www.acq.osd.mil\/ncbdp\/nm\/narp\/Radiation_Data\/Specialized_Radiological.htm<\/span><\/a><\/div><div class = \"text-block\">) were derived for 22 North American cities and surrounding regions (simulations performed by the University of Ontario Institute of Technology (UOIT) Health Physics and Environmental Safety Research Group; plumes were simulated using HPAC v4.04 which models the dispersion of radiation (as well as chemical and biological releases) assuming only the location of the epicenter, historical prevailing wind direction and speeds, intensity and weather conditions). The files contain HPAC plume coordinate (WGS1984) and dose values (in cGy) for all scenarios discussed in the manuscript. Each scenario file has been made available in a Zenodo archive (<\/div><div class = \"text-block\"><a href=\"https:\/\/doi.org\/10.5281\/zenodo.3572574\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">https:\/\/doi.org\/10.5281\/zenodo.3572574<\/span><\/a><\/div><div class = \"text-block\">): <\/div><div class = \"text-block\">The plumes provided are in XML format, which is not compatible with ArcMap software (<\/div><div class = \"text-block\"><a href=\"https:\/\/desktop.arcgis.com\/en\/arcmap\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">https:\/\/desktop.arcgis.com\/en\/arcmap\/<\/span><\/a><\/div><div class = \"text-block\">). To import this data into ArcMap, the  XML files for the HPAC plume are first converted to a tab-delimited X,Y,Z format (Latitude, Longitude, and Dose) using a Perl script \"XML-to-XY-Converter.Smooth-Circle-of-Zeros.All-Files.pl\". This program also adds an unirradiated contour (\"0 cGy\") surrounding the HPAC plume, as the presence of unirradiated samples circumscribing the plume was found to be crucial for accurate dose estimation by kriging (see below). These 0 cGy locations serve as the geographic boundary for the kriging procedure.<\/div><div class = \"text-block\">This (and all other programs described in this protocol) can be found in the above mentioned Zenodo archive:<\/div><div class = \"text-block\">All HPAC scenarios that were processed by the aforementioned XML-to-XY-Converter program can be found in the Zenodo archive:<\/div><div class = \"text-block\"><span style = \"font-weight:bold;\">Note:<\/span><span> In this protocol, we provide images which illustrate the steps using the ArcMap software and custom software scripts to derive a radiation exposure map by geostatistical analysis of individual samples. These images are generated during the processing of a simulated nuclear incident scenario (single replicate) in the vicinity of Columbia, South Carolina , i.e. a worked example similar to those included in the accompanying manuscript.<\/span><\/div><\/div>"}},{"id":1054725,"guid":"9B210ED0323211EAA92BD9331BCC4644","order_id":2,"type_id":9,"title":"dataset","source":{"name":"HPAC Plume Data (XML Format)","link":"https:\/\/zenodo.org\/api\/files\/0d10690b-c7a6-423d-b20d-dea524559077\/HPAC-Plumes.Unprocessed.zip?versionId=5e23736b-2601-4126-a99d-7a41a4c322a0"}},{"id":1054726,"guid":"06BD5120323411EAA92BD9331BCC4644","order_id":3,"type_id":9,"title":"dataset","source":{"name":"Geostatistical Sampling Project: All Scripts","link":"https:\/\/zenodo.org\/api\/files\/0d10690b-c7a6-423d-b20d-dea524559077\/Geostatistical-Sampling-Project.All-Scripts.zip"}},{"id":1054727,"guid":"44E30BC0323411EAA92BD9331BCC4644","order_id":4,"type_id":9,"title":"dataset","source":{"name":"HPAC Plume Data (Processed to Tab-Delimited Format)","link":"https:\/\/zenodo.org\/api\/files\/0d10690b-c7a6-423d-b20d-dea524559077\/HPAC-Plumes.Processed.zip?versionId=2ec49a62-5119-4e38-9004-fd438f224404"}}],"cases":[],"data":null,"section":null,"section_color":"#A492FF","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":867604,"guid":"B8C296F0323411EAA92BD9331BCC4644","previous_id":867600,"previous_guid":"22A6ECE0323211EAA92BD9331BCC4644","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"444EEFAABB474A92984AED68B90207B0","order_id":1,"type_id":6,"title":"Section","source":{"title":"Acquisition of United States (US) Census Data for Geostatistical Analysis"}},{"id":1054724,"guid":"8FE9BB3847524C55AC0D2C818BCE14B0","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\"><span>1. Download<\/span><span style = \"font-weight:bold;\"> <\/span><span>US state and sub-division boundary files (in KML [<\/span><\/div><div class = \"text-block\"><a href=\"https:\/\/developers.google.com\/kml\/documentation\/kml_tut\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">Keyhole Markup Language<\/span><\/a><\/div><div class = \"text-block\">] format) from the US census bureau (<\/div><div class = \"text-block\"><a href=\"https:\/\/www2.census.gov\/geo\/tiger\/GENZ2016\/shp\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">https:\/\/www2.census.gov\/geo\/tiger\/GENZ2016\/shp\/<\/span><\/a><\/div><div class = \"text-block\">). <\/div><div class = \"text-block\">2. Determine the population of the regions surrounding the scenario of interest from: A) the US Census (\u201c<\/div><div class = \"text-block\"><a href=\"https:\/\/www.census.gov\/data\/tables\/2017\/demo\/popest\/total-cities-and-towns.html\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">Incorporated Places and Minor Civil Divisions Datasets: Subcounty Resident Population Estimates: April 1, 2010 to July 1, 2017<\/span><\/a><\/div><div class = \"text-block\">\u201d), B) the <\/div><div class = \"text-block\"><a href=\"https:\/\/factfinder.census.gov\/faces\/nav\/jsf\/pages\/index.xhtml\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">American Fact Finder; <\/span><\/a><\/div><div class = \"text-block\">and\/or the <\/div><div class = \"text-block\"><a href=\"https:\/\/www.hometownlocator.com\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">Home Town Locator<\/span><\/a><\/div><div class = \"text-block\">.<\/div><\/div>"}}],"cases":[],"data":null,"section":null,"section_color":"#94EBFF","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":867605,"guid":"0934C450323511EAA92BD9331BCC4644","previous_id":867604,"previous_guid":"B8C296F0323411EAA92BD9331BCC4644","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"816001A285354195A292A518A88F3FAF","order_id":1,"type_id":6,"title":"Section","source":{"title":"Acquisition of United States (US) Census Data for Geostatistical Analysis"}},{"id":1054724,"guid":"FFF04BE25C7E40F384B888C337E10603","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\"><span style = \"font-weight:bold;\">Processing and Import of US state and sub-division boundary files to ArcMap <\/span><\/div><div class = \"text-block\">Before importing the US state and sub-division boundary files to ArcMap, the KML files required editing. Exceptions handled US states with multiple sub-divisions that share the same name, so that ArcMap did not also select unintended sub-divisions found outside of the radiation plume. Sub-division names with spaces or dashes were also modified by concatenating them prior to \u2018KMLtoLayer\u2019 conversion to avoid their unintended truncation. <\/div><div class = \"text-block\">1. Correct KML files by using the script \"KML-Name-Correcting-Program.pl\" (available through Zenodo;  <\/div><div class = \"text-block\"><a href=\"https:\/\/doi.org\/10.5281\/zenodo.3572574\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">https:\/\/doi.org\/10.5281\/zenodo.3572574<\/span><\/a><\/div><div class = \"text-block\">). To run:<\/div><div class = \"text-block\"><ul style = \"list-style-type:disc;\"><li style = \"counter-reset:ol0;list-style-type:disc;\">Place program in folder with all KML files you wish to modify<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">To Run: \"perl KML-Name-Correcting-Program.pl\"<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\"><\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">2. Import the modified KML boundary files to ArcMap using the software's \u2018KMLtoLayer\u2019 tool (additional parameters are not required for this step). When this process finishes, the KML boundary file will be displayed on the map.<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\"><\/li><li style = \"counter-reset:ol0;list-style-type:disc;\"><a href=\"#\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\"> <\/span><\/a><\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">  <\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">3. Use ArcMap's \"Split\" command to allow ArcMap to be able to identify each sub-division within the boundary file, and allows the user to display specific subdivisions within the KML boundary file. <\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">\"Input Features\": Select the KML file of interest -> \"Polygon\"<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">\"Split Features\": Repeat \"Input Features\" step (splitting the file on itself)<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">\"Split Field\": Select \"Name\"<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">\"Target Workspace\": Create a new Geodatabase (name it \"StateName_Split\"), highlight the Geodatabase and click \"Add\".<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">\"XY Tolerance\": Leave blank<\/li><\/ul><\/div><div class = \"text-block\">2. Import the modified KML boundary files to ArcMap using the software's \u2018KMLtoLayer\u2019 tool (additional parameters are not required for this step). When this process finishes, the KML boundary file will be displayed on the map.<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/9320c53043cebfd096c26b8dc25173ef3c96973eff8c022a1c7251fe6a070124\/bwnjbazi7.png\" \/><\/div><div class = \"text-block\">3. Use ArcMap's \"Split\" command to allow ArcMap to be able to identify each sub-division within the boundary file, and allows the user to display specific subdivisions within the KML boundary file. <\/div><div class = \"text-block\"><ul style = \"list-style-type:disc;\"><li style = \"counter-reset:ol0;list-style-type:disc;\">\"Input Features\": Select the KML file of interest -> \"Polygon\"<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">\"Split Features\": Repeat \"Input Features\" step (splitting the file on itself)<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">\"Split Field\": Select \"Name\"<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">\"Target Workspace\": Create a new Geodatabase (name it \"StateName_Split\"), highlight the Geodatabase and click \"Add\".<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">\"XY Tolerance\": Leave blank<\/li><\/ul><\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/9320c53043cebfd096c26b8dc25173ef3c96973eff8c022a1c7251fe6a070124\/bwnhbazi7.png\" \/><\/div><div class = \"text-block\">Click OK. This process may take several minutes. When complete, click \"Add Data\" and open the newly created Geodatabase. This database will contain a file for each sub-division, which can be used for downstream steps.<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/9320c53043cebfd096c26b8dc25173ef3c96973eff8c022a1c7251fe6a070124\/bwnibazi7.png\" \/><\/div><\/div>"}},{"id":1054725,"guid":"3A31B4F03EFF478583F948908A49FD23","order_id":2,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/9320c53043cebfd096c26b8dc25173ef3c96973eff8c022a1c7251fe6a070124\/bwnjbazi7.png\" \/><\/div>"}},{"id":1054726,"guid":"08649F34B03946738741D3150CFE8A37","order_id":3,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/9320c53043cebfd096c26b8dc25173ef3c96973eff8c022a1c7251fe6a070124\/bwnhbazi7.png\" \/><\/div>"}},{"id":1054727,"guid":"3AF80285DD1240CB8B8AC67A3B27D209","order_id":4,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/9320c53043cebfd096c26b8dc25173ef3c96973eff8c022a1c7251fe6a070124\/bwnibazi7.png\" \/><\/div>"}}],"cases":[],"data":null,"section":null,"section_color":"#94EBFF","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":867620,"guid":"E86B6B20323911EAA92BD9331BCC4644","previous_id":867605,"previous_guid":"0934C450323511EAA92BD9331BCC4644","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"C124EF12F54C47C493FFC0FBA84CF228","order_id":1,"type_id":6,"title":"Section","source":{"title":"Simulated analyses of population-scale, nuclear radiation scenarios"}},{"id":1054724,"guid":"9C8B2810459C498F8F2379C3AC4E17EA","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\"><span style = \"font-weight:bold;\">Creating a set of random locations, i.e. points, to simulate random sampling of 0.1% of the population in each geographic subdivision<\/span><\/div><div class = \"text-block\"><ol style = \"list-style-type: decimal;\"><li style = \"counter-reset:ol0;\">Upload the HPAC-generated radiation plume files for the scenario of interest on ArcMap (see Section 4 on how to add data to ArcMap) and visually determine which sub-divisions it overlaps. <\/li><li style = \"counter-reset:ol0;\">Use Census data to determine the population of each of these sub-divisions.<\/li><li style = \"counter-reset:ol0;\">Random sampling locations are created for each sub-division using the ArcMap tool, \u2018CreateRandomPoints_management\u2019. We created a Python script to perform this task manually. This python script has to be edited for each scenario, as users must manually select the subdivision and assign the number of random points for that sub-division (in our study, that number was 0.1% of the population of that sub-division; if sub-division is made up of multiple unconnected segments, the population was divided evenly between each part) in the Python code:<\/li><\/ol><\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">import arcpy<\/div><div class = \"text-block\">import sys<\/div><div class = \"text-block\"># where any output will be written<\/div><div class = \"text-block\">arcpy.env.workspace = \"C:\/PATH\/TO\/OUTPUT\/WORKSPACE\/\"<\/div><div class = \"text-block\"># create 10 sets of random points<\/div><div class = \"text-block\">for x in range(0, 10):<\/div><div class = \"text-block\">    # path to split KML Geodatabase from Section 2.1<\/div><div class = \"text-block\">    outlocation = \"C:\/PATH\/TO\/KMLSplit\/StateName_Split.gdb\" <\/div><div class = \"text-block\">    # repeat the following 2 lines for each subdivision of interest<\/div><div class = \"text-block\">    featureclass = \"C:\/PATH\/TO\/KMLSplit\/StateName_Split.gdb\/Subdivision1Name\"<\/div><div class = \"text-block\">    arcpy.CreateRandomPoints_management(outlocation, \"Subdivision1NameRandPts\", featureclass, \"\", 465, \"\", \"POINT\") # where 465 is the number of random points to draw in this subdivision<\/div><div class = \"text-block\">    # repeat above two lines for each subdivision of interest<\/div><div class = \"text-block\">    # merge the random points as one file<\/div><div class = \"text-block\">    merge_name = \"MergedPoints%d\" % x<\/div><div class = \"text-block\">    arcpy.Merge_management([\"Subdivision1Name\", \"Subdivision2Name\", ...], merge_name)<\/div><div class = \"text-block\">    # add XY coordinates to the created random points<\/div><div class = \"text-block\">    arcpy.AddXY_management(merge_name)<\/div><\/div><\/code><\/pre><\/div><div class = \"text-block\">4. Run the Python script through ArcMap (Geoprocessing -> Python)<\/div><div class = \"text-block\"><ul style = \"list-style-type:disc;\"><\/ul><\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/9320c53043cebfd096c26b8dc25173ef3c96973eff8c022a1c7251fe6a070124\/bwppbazi7.png\" \/><\/div><div class = \"text-block\">Program run time depends on the number of cycles assigned (each cycle is a completely different set of samples, used as separate \"replicates\" in our study), and the number of sub-divisions that the HPAC plume overlaps, but can take over an hour. ArcMap crashing during this process was a reoccurring problem. To alleviate this, we performed this step in 10-25 cycle batches. To perform a new set of cycles, save the completed batch of random sample locations, adjust the for loop in the code to include additional cycles (i.e. if for loop was set to \"0, 25\", we adjust the values to \"26, 50\"), and rerun the program in the Python window in ArcMap. Therefore, if the program crashes at this step, the initial batch or random s is still saved. If ArcMap does crash, open this latest save and re-run the script.<\/div><div class = \"text-block\">The program described above creates the random sample locations in ArcMap. Next, we extract these random sample locations and convert them into a text file format for downstream processing steps. To do so, we run the export Python script described below. This script was originally a part of the previously described Python script, but as ArcMap would often crash during this final step of the process, we decided to perform this task with a separate program explicitly written for this purpose. The following script is also provided in the Zenodo archive, under the name \"Random-Point-Exporting-Script.py\":<\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">import arcpy<\/div><div class = \"text-block\">import sys<\/div><div class = \"text-block\">arcpy.env.workspace = \"C:\/Users\/ROGANLAB\/Desktop\/HPAC-Data\/Jacksonville_FL-DirectionChange\"<\/div><div class = \"text-block\"># set for loop to the total number of cycles generated in the previous program<\/div><div class = \"text-block\">for x in range(0, 25):<\/div><div class = \"text-block\">\tmerge_name = \"MergedPoints%d\" % x<\/div><div class = \"text-block\">\toutput_file = \"StateName_March_%d.txt\" % x<\/div><div class = \"text-block\">\tarcpy.ExportXYv_stats(merge_name,\"FID\", \"COMMA\",output_file,\"ADD_FIELD_NAMES\")<\/div><\/div><\/code><\/pre><\/div><\/div>"}},{"id":1054725,"guid":"64A406C478114B9B81F8F514087AC7DC","order_id":2,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/9320c53043cebfd096c26b8dc25173ef3c96973eff8c022a1c7251fe6a070124\/bwppbazi7.png\" \/><\/div>"}}],"cases":[],"data":null,"section":null,"section_color":"#84CE84","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":867630,"guid":"3171F8B0324011EAA92BD9331BCC4644","previous_id":867620,"previous_guid":"E86B6B20323911EAA92BD9331BCC4644","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"DB7F142C8338402AAB303311578F8708","order_id":1,"type_id":6,"title":"Section","source":{"title":"Simulated analyses of population-scale, nuclear radiation scenarios"}},{"id":1054724,"guid":"8F704BC323CC4B27997D200D3A31798F","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Next, the random selected sample locations exported in Section 3 (or the densification-directed sampling locations selected by densification; see Section 5) are assigned radiation dose values corresponding to the adjacent outer HPAC contour. This is done by the script \"XML-to-XY-Conversion.REM-Assigner.Multiple-Files.pl\", which compares the location of a sample to its location relative to the HPAC plume (the processed HPAC plume data file from Section 1). The values assigned to these sample locations are meant to simulate the values obtained by dosimetry methods. This program, like all other scripts described in this protocol, is available in the Zenodo archive.<\/div><div class = \"text-block\">Note that the program must be edited to direct the program towards the following:<\/div><div class = \"text-block\"><ul style = \"list-style-type:disc;\"><li style = \"counter-reset:ol0;list-style-type:disc;\">\"$filename\" should be assigned the HPAC Plume the random locations are being assigned to (full path to file)<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">\"$randompointspath\" should be assigned the path to the folder which contains each of the exported random point files<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">To Run: \"perl XML-to-XY-Conversion.REM-Assigner.Multiple-Files.pl\"<\/li><\/ul><\/div><div class = \"text-block\">The program creates text files (one for each input file) with a new column which assigns the random sample locations a radiation value (in cGy) based on its location relative to the HPAC plume it is being compared to. If the sample does not overlap the HPAC plume, it will be assigned a value of 0 cGy.<\/div><\/div>"}}],"cases":[],"data":null,"section":null,"section_color":"#84CE84","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":867670,"guid":"71E148A0325511EAA92BD9331BCC4644","previous_id":867630,"previous_guid":"3171F8B0324011EAA92BD9331BCC4644","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"3662C28682D64821935DC7B262761214","order_id":1,"type_id":6,"title":"Section","source":{"title":"Empirical Bayesian kriging"}},{"id":1054724,"guid":"AEBDE9372D284CBA879AF73618D2EC81","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">The following section describes how to generate a plume in ArcMap using Empirical Bayesian kriging.<\/div><div class = \"text-block\"><ol style = \"list-style-type: decimal;\"><li style = \"counter-reset:ol0;\">Import the HPAC plume and\/or the random point data (from Section 3.1) to ArcMap using the \"Add Data\" function<\/li><li style = \"counter-reset:ol0;\">Right-Click the imported data in the \"Table of Contents\" window, and select \"Display XY Data...\"<\/li><li style = \"counter-reset:ol0;\">In the \"Display XY Data\" dialog box, assign the X Field \"Longitude\", the Y Field \"Latitude\" and the Z Field \"Data\". Then under \"Description\", click Edit. This will open the Spatial Reference Properties dialog box. Select: \"Geographic Coordinate System\" -> \"World\" -> \"WGS 1984\". Click OK. Then click OK in the original dialog box. <\/li><li style = \"counter-reset:ol0;\"><a href=\"#\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\"> <\/span><\/a><\/li><li style = \"counter-reset:ol0;\"> <\/li><li style = \"counter-reset:ol0;\">The imported data should now appear on the map, and a new \"event\" for this data should appear in the \"Table of Contents\". Right-click this event, and select \"Zoom To Layer\" to quickly orient the map to location of the imported data.<\/li><li style = \"counter-reset:ol0;\">Open the Geostatistical Wizard (under the Geostatistical Analysis toolbar; if this does not appear, make sure the extension is activated under Customize -> Extensions). This will open a dialog box. On the right, select Geostatistical Methods -> Empirical Bayesian Kriging. Under \"Input Data\", select the event created in step 3 (the \"Display XY Data\" step) as your Source Dataset, and \"Data\" (or field 3 if your data doesn't have headers) as the Data Field. Click Next. We used default values for our analysis. Click Next again and then click Finish. A \"Method Report\" should appear on screen, and the Empirical Bayesian kriging-based plume should appear on the map.<\/li><li style = \"counter-reset:ol0;\"><a href=\"#\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\"> <\/span><\/a><\/li><li style = \"counter-reset:ol0;\"> <\/li><li style = \"counter-reset:ol0;\">On the Table Of Contents, double-click the newly derived intermediate plume. Give the plume a specific name. Then under \"Symbology\", click \"Classify\". Under \"Method\", select Equal Intervals, and under classes, reduce to 7. This will change the plume to have a color assigned to 0-100 cGy, 100-200 cGy, 200-300 cGy, ... 600-700 cGy. This keeps plumes consistent, and allows for easier identification of the plume's 2 Gy threshold. We recommend assigning the 0-100 cGy symbol of the plume to \"No Color\", as this symbol essentially draws on the map where the plume is not located.<\/li><\/ol><\/div><div class = \"text-block\">In the \"Display XY Data\" dialog box, assign the X Field \"Longitude\", the Y Field \"Latitude\" and the Z Field \"Data\". Then under \"Description\", click Edit. This will open the Spatial Reference Properties dialog box. Select: \"Geographic Coordinate System\" -> \"World\" -> \"WGS 1984\". Click OK. Then click OK in the original dialog box. <\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/9320c53043cebfd096c26b8dc25173ef3c96973eff8c022a1c7251fe6a070124\/bwndbazi7.png\" \/><\/div><div class = \"text-block\"><ol style = \"list-style-type: decimal;\"><li style = \"counter-reset:ol0;\">The imported data should now appear on the map, and a new \"event\" for this data should appear in the \"Table of Contents\". Right-click this event, and select \"Zoom To Layer\" to quickly orient the map to location of the imported data.<\/li><li style = \"counter-reset:ol0;\">Open the Geostatistical Wizard (under the Geostatistical Analysis toolbar; if this does not appear, make sure the extension is activated under Customize -> Extensions). This will open a dialog box. On the right, select Geostatistical Methods -> Empirical Bayesian Kriging. Under \"Input Data\", select the event created in step 3 (the \"Display XY Data\" step) as your Source Dataset, and \"Data\" (or field 3 if your data doesn't have headers) as the Data Field. Click Next. We used default values for our analysis. Click Next again and then click Finish. A \"Method Report\" should appear on screen, and the Empirical Bayesian kriging-based plume should appear on the map.<\/li><li style = \"counter-reset:ol0;\"><a href=\"#\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\"> <\/span><\/a><\/li><li style = \"counter-reset:ol0;\"> <\/li><li style = \"counter-reset:ol0;\">On the Table Of Contents, double-click the newly derived intermediate plume. Give the plume a specific name. Then under \"Symbology\", click \"Classify\". Under \"Method\", select Equal Intervals, and under classes, reduce to 7. This will change the plume to have a color assigned to 0-100 cGy, 100-200 cGy, 200-300 cGy, ... 600-700 cGy. This keeps plumes consistent, and allows for easier identification of the plume's 2 Gy threshold. We recommend assigning the 0-100 cGy symbol of the plume to \"No Color\", as this symbol essentially draws on the map where the plume is not located.<\/li><\/ol><\/div><div class = \"text-block\">Open the Geostatistical Wizard (under the Geostatistical Analysis toolbar; if this does not appear, make sure the extension is activated under Customize -> Extensions). This will open a dialog box. On the right, select Geostatistical Methods -> Empirical Bayesian Kriging. Under \"Input Data\", select the event created in step 3 (the \"Display XY Data\" step) as your Source Dataset, and \"Data\" (or field 3 if your data doesn't have headers) as the Data Field. Click Next. We used default values for our analysis. Click Next again and then click Finish. A \"Method Report\" should appear on screen, and the Empirical Bayesian kriging-based plume should appear on the map.<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/9320c53043cebfd096c26b8dc25173ef3c96973eff8c022a1c7251fe6a070124\/bwpzbazi7.png\" \/><\/div><div class = \"text-block\"><ol style = \"list-style-type: decimal;\"><\/ol><\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/9320c53043cebfd096c26b8dc25173ef3c96973eff8c022a1c7251fe6a070124\/bwnmbazi7.png\" \/><\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/9320c53043cebfd096c26b8dc25173ef3c96973eff8c022a1c7251fe6a070124\/bwnwbazi7.png\" \/><\/div><\/div>"}},{"id":1054725,"guid":"D2A6B3C5DA74481A8036843DB7AB1152","order_id":2,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/9320c53043cebfd096c26b8dc25173ef3c96973eff8c022a1c7251fe6a070124\/bwndbazi7.png\" \/><\/div>"}},{"id":1054726,"guid":"B22BB1144DE846F5B6922DCF6FFD9BA8","order_id":3,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/9320c53043cebfd096c26b8dc25173ef3c96973eff8c022a1c7251fe6a070124\/bwpzbazi7.png\" \/><\/div>"}},{"id":1054727,"guid":"1267CD8E5A9949849453BB1291FE8F1C","order_id":4,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/9320c53043cebfd096c26b8dc25173ef3c96973eff8c022a1c7251fe6a070124\/bwnmbazi7.png\" \/><\/div>"}},{"id":1054728,"guid":"D2851E15C2164130938266100F01E9EF","order_id":5,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/9320c53043cebfd096c26b8dc25173ef3c96973eff8c022a1c7251fe6a070124\/bwnwbazi7.png\" \/><\/div>"}}],"cases":[],"data":null,"section":null,"section_color":"#FFED92","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":867676,"guid":"6A6937A0325911EAA92BD9331BCC4644","previous_id":867670,"previous_guid":"71E148A0325511EAA92BD9331BCC4644","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"3C40B70E764D47679113199D60AFF4EC","order_id":1,"type_id":6,"title":"Section","source":{"title":"Determining New Sampling Locations using Densification"}},{"id":1054724,"guid":"74357F367CB54B3A9DCDEC15EA4FE42A","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">The \u201cDensify Sampling Network\u201d tool of the Geostatistical toolbox determine the lower confidence regions in the kriging-derived map, i.e. regions with highest variance specifying radiation dose. We applied this tool to limit results to regions that would most likely exceed a pre-defined radiation level threshold (2Gy). In practice, the locations selected by densification would be used to direct first responders to new locations for subsequent rounds of data acquisition in order to improve the accuracy of the kriging-derived map. <\/div><div class = \"text-block\"><ol style = \"list-style-type: decimal;\"><li style = \"counter-reset:ol0;\">In the Geostatistical Toolbox, select \"Densify Sampling Network\". This will open a dialog box.<\/li><li style = \"counter-reset:ol0;\">Under \"Input Geostatistical Layer\", select the plume generated in Section 4.<\/li><li style = \"counter-reset:ol0;\">Under \"Number of output points\", we chose 200. This will generate 200 new sampling locations. <\/li><li style = \"counter-reset:ol0;\">Under \"Selection Criteria\", select the QUARTILE_THRESHOLD_UPPER option<\/li><li style = \"counter-reset:ol0;\">Under \"Threshold Value\", select 200 (will place points near regions expected to have a 200 cGy [2Gy] level of radiation, based on the current iteration of the plume)<\/li><li style = \"counter-reset:ol0;\">(Optional) Adding an inhibition distance of 1 meter eliminates the issue where densification selects the same location multiple times.  <\/li><li style = \"counter-reset:ol0;\"><a href=\"#\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\"> <\/span><\/a><\/li><li style = \"counter-reset:ol0;\">  <\/li><li style = \"counter-reset:ol0;\">When densification is complete, we add coordinates to the densification-directed sampling locations using the ArcMap function \"Add XY Coordinates\" (under the Data Management toolbox) as they are not automatically assigned. Simply select the output from the densification step as the input for this step and click OK. This step takes 10-20 seconds.<\/li><li style = \"counter-reset:ol0;\">Export the data. Right-click the densification result in the Table of Contents and select \"Open Attributes Table\". Click the top left drop-down menu and select Export. Click the folder icon under 'Output Table' and change \"Save as Type\" to Text File, and give the file a name.<\/li><li style = \"counter-reset:ol0;\"><a href=\"#\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\"> <\/span><\/a><\/li><li style = \"counter-reset:ol0;\"> <\/li><li style = \"counter-reset:ol0;\">Repeat Section 3.1 for the exported file to assign the densification-directed sampling locations radiation values based on their location relative to the HPAC plume. <\/li><li style = \"counter-reset:ol0;\">Combine the new sampling locations with the initial set of sampling locations (simply combine the two files).<\/li><li style = \"counter-reset:ol0;\">Repeat Section 4 to generate a new plume, based on both the initial sampling data points and the new densification-directed sampling locations.<\/li><\/ol><\/div><div class = \"text-block\">(Optional) Adding an inhibition distance of 1 meter eliminates the issue where densification selects the same location multiple times.  <\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/9320c53043cebfd096c26b8dc25173ef3c96973eff8c022a1c7251fe6a070124\/bwn5bazi7.png\" \/><\/div><div class = \"text-block\"><ol style = \"list-style-type: decimal;\"><li style = \"counter-reset:ol0;\">When densification is complete, we add coordinates to the densification-directed sampling locations using the ArcMap function \"Add XY Coordinates\" (under the Data Management toolbox) as they are not automatically assigned. Simply select the output from the densification step as the input for this step and click OK. This step takes 10-20 seconds.<\/li><li style = \"counter-reset:ol0;\">Export the data. Right-click the densification result in the Table of Contents and select \"Open Attributes Table\". Click the top left drop-down menu and select Export. Click the folder icon under 'Output Table' and change \"Save as Type\" to Text File, and give the file a name.<\/li><li style = \"counter-reset:ol0;\"><a href=\"#\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\"> <\/span><\/a><\/li><li style = \"counter-reset:ol0;\"> <\/li><li style = \"counter-reset:ol0;\">Repeat Section 3.1 for the exported file to assign the densification-directed sampling locations radiation values based on their location relative to the HPAC plume. <\/li><li style = \"counter-reset:ol0;\">Combine the new sampling locations with the initial set of sampling locations (simply combine the two files).<\/li><li style = \"counter-reset:ol0;\">Repeat Section 4 to generate a new plume, based on both the initial sampling data points and the new densification-directed sampling locations.<\/li><\/ol><\/div><div class = \"text-block\">Export the data. Right-click the densification result in the Table of Contents and select \"Open Attributes Table\". Click the top left drop-down menu and select Export. Click the folder icon under 'Output Table' and change \"Save as Type\" to Text File, and give the file a name.<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/9320c53043cebfd096c26b8dc25173ef3c96973eff8c022a1c7251fe6a070124\/bwn9bazi7.png\" \/><\/div><div class = \"text-block\"><ol style = \"list-style-type: decimal;\"><li style = \"counter-reset:ol0;\">Repeat Section 3.1 for the exported file to assign the densification-directed sampling locations radiation values based on their location relative to the HPAC plume. <\/li><li style = \"counter-reset:ol0;\">Combine the new sampling locations with the initial set of sampling locations (simply combine the two files).<\/li><li style = \"counter-reset:ol0;\">Repeat Section 4 to generate a new plume, based on both the initial sampling data points and the new densification-directed sampling locations.<\/li><\/ol><\/div><div class = \"text-block\">Densification is a compute intensive step, requiring approximately 1 hour on a desktop with an Intel i7-4770 processor [3.4Ghz] and 16GB of RAM. Note that reducing the number of requested sampling locations decreases overall processing time. <\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/9320c53043cebfd096c26b8dc25173ef3c96973eff8c022a1c7251fe6a070124\/bwnxbazi7.png\" \/><\/div><\/div>"}},{"id":1054725,"guid":"C2B33A11FCB74902BDE9C7A3DB5CA1CB","order_id":2,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/9320c53043cebfd096c26b8dc25173ef3c96973eff8c022a1c7251fe6a070124\/bwn5bazi7.png\" \/><\/div>"}},{"id":1054726,"guid":"C7DC73BE44184F35926DFB7DE5D3163F","order_id":3,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/9320c53043cebfd096c26b8dc25173ef3c96973eff8c022a1c7251fe6a070124\/bwn9bazi7.png\" \/><\/div>"}},{"id":1054727,"guid":"7DF2A2792A494CCFB4F21717F7A8BFA6","order_id":4,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/9320c53043cebfd096c26b8dc25173ef3c96973eff8c022a1c7251fe6a070124\/bwnxbazi7.png\" \/><\/div>"}}],"cases":[],"data":null,"section":null,"section_color":"#EA9F6C","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":867677,"guid":"7AE7C830325911EAA92BD9331BCC4644","previous_id":867676,"previous_guid":"6A6937A0325911EAA92BD9331BCC4644","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"D9F4D3B2D93C4ABDABF09579374818A5","order_id":1,"type_id":6,"title":"Section","source":{"title":"Radiation Plume Reconstruction with Iterative Kriging and Densification"}},{"id":1054724,"guid":"94F1939313C7477082CDBB3A03260A50","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">The steps described in Section 3 are meant to simulate an initial batch of samples after a nuclear event, while the steps described in Section 5 are meant to simulate additional sampling data from locations assigned by the ArcMap software. While the samples from Section 3 create an initial plume, the combination of the data points from Section 3 and Section 5 create a second, much more accurate plume (see the final figure in Section 5). The plume is improved further when Sections 4 and 5 are repeated. These is referred to as an \"iteration\" of our protocol.<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/9320c53043cebfd096c26b8dc25173ef3c96973eff8c022a1c7251fe6a070124\/bwpabazi7.png\" \/><\/div><div class = \"text-block\">The first derived plume is based only on the initial random sampling locations: Sections 3 -> 3.1 -> 4. The first iteration is a combination of the initial sampling and additional sampling locations based on the first densification step: Sections: 3 -> 3.1 -> 4 (first plume generated) -> 5 -> 3.1 -> 4 (second plume generated).<\/div><div class = \"text-block\">Each additional iteration consists of repeating Sections 5 -> 3.1 -> 4 (Perform densification -> Determine new location's radiation value -> Combine new points with all previous samples -> Perform Kriging on all available sample data). This iterative process is continued until the latest plume is not significantly different from the plume generated in the previous iteration. To determine if the iterative process is no longer significantly changing the plume, see the next section (6.1).<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/9320c53043cebfd096c26b8dc25173ef3c96973eff8c022a1c7251fe6a070124\/bwnvbazi7.png\" \/><\/div><\/div>"}},{"id":1054725,"guid":"E2C8CD0ED8594EC3B90EBDED907F2E25","order_id":2,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/9320c53043cebfd096c26b8dc25173ef3c96973eff8c022a1c7251fe6a070124\/bwpabazi7.png\" \/><\/div>"}},{"id":1054726,"guid":"2DFDDB000D9142048B1153B9F302E71D","order_id":3,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/9320c53043cebfd096c26b8dc25173ef3c96973eff8c022a1c7251fe6a070124\/bwnvbazi7.png\" \/><\/div>"}}],"cases":[],"data":null,"section":null,"section_color":"#E57785","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":867721,"guid":"77A9FE20326011EAA92BD9331BCC4644","previous_id":867677,"previous_guid":"7AE7C830325911EAA92BD9331BCC4644","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"87B04ACFF2994E7F9A907134D0D9F362","order_id":1,"type_id":6,"title":"Section","source":{"title":"How to Compare Two Plumes to Each Other"}},{"id":1054724,"guid":"384B6EB3668A4B2288F0ED91CA9D2BBD","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Plume comparisons are performed for the following two tasks:<\/div><div class = \"text-block\"><ul style = \"list-style-type:disc;\"><li style = \"counter-reset:ol0;list-style-type:disc;\">Determine if additional kriging and densification does not improve geographic coverage relative to the previous plume iteration<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">Determine the accuracy of the plume relative to the HPAC plume<\/li><\/ul><\/div><div class = \"text-block\">The actual steps to perform these two tasks are similar to one another: 1) Use kriging to generate a layer (which represents a radiation plume) to be compared [previous iteration to current iteration; or current iteration to HPAC plume]; 2) Convert those plumes into polygons; 3) Create a Union of the two polygons; 4) Use \"Shape_Area\" to compute the amount of overlap between the different levels of radiation between the two plumes. <\/div><div class = \"text-block\"><ol style = \"list-style-type: decimal;\"><li style = \"counter-reset:ol0;\">Use kriging to generate each plume, as described in Section 4. It is crucial that the \"Class\" [radiation levels] are the same between the two plumes.<\/li><li style = \"counter-reset:ol0;\">In ArcMap, perform \"GA Contour to Layer\" (Geostatistical Analyst toolbox) twice for each kriging layer to be compared. In the opened dialog box, select the kriging layer for the \"Input Geostatistical Layer\", with \"Contour Type\" as \"SAME_AS_LAYER\". Click Classification to expand the window. Under Classification Type, select Equal Interval. Click OK. Repeat for the second kriging layer.<\/li><li style = \"counter-reset:ol0;\">In ArcMap, perform \"Feature To Polygon\" (Data Management toolbox) twice for each contour generated in the previous step. Simply select the contour in the previous section and click OK. Repeat for the second kriging layer.<\/li><li style = \"counter-reset:ol0;\">(optional) Unfortunately, when creating the polygon, the radiation level assigned to each contour is lost. To add this back, right-click the polygon file in the Table of Contents and click Open Attributes Table. Add a new column. For each line, type in the radiation value (determine this by clicking the line and observing the highlighted region of the plume on the map). Repeat for the second polygon.<\/li><li style = \"counter-reset:ol0;\">Create a Union between the two polygons: Geoprocessing -> Union. In the dialog box, select each polygon to be combined. The order in which the polygon is selected affects the order they will appear in the Attributes Table, so be mindful (e.g. for consistency, I always pick the current iteration of the plume second).<\/li><li style = \"counter-reset:ol0;\"><a href=\"#\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\"> <\/span><\/a><\/li><li style = \"counter-reset:ol0;\"> <\/li><li style = \"counter-reset:ol0;\">Right-click the Union in the Table of Contents, and click Open Attributes Table. Each line represents a region where the two plumes overlapped. Export this table as described in Section 5. Open the file in Excel.<\/li><li style = \"counter-reset:ol0;\"><\/li><li style = \"counter-reset:ol0;\"><a href=\"#\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\"> <\/span><\/a><\/li><li style = \"counter-reset:ol0;\"> <\/li><li style = \"counter-reset:ol0;\">The protocol diverges in the analysis of the Union between the two plumes. When comparing two iterations of the derived plume (in Excel):<\/li><li style = \"counter-reset:ol0;\">Order the columns in terms of increasing radiation values for one of the plumes.<\/li><li style = \"counter-reset:ol0;\">For each radiation level for one plume, determine whether the intersecting region of the second plume has the same radiation value. Sum the Shape_Area column for the intersecting segments of the plume where the radiation level matches, as well as the intersecting segments that do not match. Determine the percentage of the area of the two intersecting plumes that are in agreement (have the same radiation level) by dividing the Shape_Area of matching intersecting segments by the sum of the matching and non-matching segments (which should equal the total area of that radiation level for the first plume).<\/li><li style = \"counter-reset:ol0;\">If the area of the radiation level of a contour of one plume exceeds 90% of the area of the other plume over all radiation levels, then the iterative process is discontinued (the 90% threshold can be changed by the user).<\/li><li style = \"counter-reset:ol0;\"><\/li><li style = \"counter-reset:ol0;\">Comparing the current iteration of the radiation plume with the HPAC plume is similar to comparing plumes from consecutive iterations, but we instead group the regions of each plume that are above and below 2Gy (or 200 cGy), which was a threshold selected based on US government recommendations for eligibility of clinical treatment of acute radiation syndrome by cytokine therapies.<\/li><li style = \"counter-reset:ol0;\">Determine the regions of overlap between the HPAC and the intermediate plume that both represent a radiation value \u2265 2Gy, and sum the Shape_Area of each overlap.<\/li><li style = \"counter-reset:ol0;\">Determine the regions of overlap where the HPAC plume represents a radiation level \u2265 2Gy but the intermediate plume represents a radiation level < 2 Gy, and sum the Shape_Area of each overlap.<\/li><li style = \"counter-reset:ol0;\">Compute the accuracy of the intermediate plume by dividing the total Shape_Area of the overlapping \u2265 2Gy regions (Step 1) with the total Shape_Area of the HPAC plume's regions \u2265 2Gy (Step 1 + Step 2). <\/li><\/ol><\/div><div class = \"text-block\">Create a Union between the two polygons: Geoprocessing -> Union. In the dialog box, select each polygon to be combined. The order in which the polygon is selected affects the order they will appear in the Attributes Table, so be mindful (e.g. for consistency, I always pick the current iteration of the plume second).<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/9320c53043cebfd096c26b8dc25173ef3c96973eff8c022a1c7251fe6a070124\/bwpbbazi7.png\" \/><\/div><div class = \"text-block\"><ol style = \"list-style-type: decimal;\"><li style = \"counter-reset:ol0;\">Right-click the Union in the Table of Contents, and click Open Attributes Table. Each line represents a region where the two plumes overlapped. Export this table as described in Section 5. Open the file in Excel.<\/li><li style = \"counter-reset:ol0;\"><\/li><li style = \"counter-reset:ol0;\"><a href=\"#\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\"> <\/span><\/a><\/li><li style = \"counter-reset:ol0;\"> <\/li><li style = \"counter-reset:ol0;\">The protocol diverges in the analysis of the Union between the two plumes. When comparing two iterations of the derived plume (in Excel):<\/li><li style = \"counter-reset:ol0;\">Order the columns in terms of increasing radiation values for one of the plumes.<\/li><li style = \"counter-reset:ol0;\">For each radiation level for one plume, determine whether the intersecting region of the second plume has the same radiation value. Sum the Shape_Area column for the intersecting segments of the plume where the radiation level matches, as well as the intersecting segments that do not match. Determine the percentage of the area of the two intersecting plumes that are in agreement (have the same radiation level) by dividing the Shape_Area of matching intersecting segments by the sum of the matching and non-matching segments (which should equal the total area of that radiation level for the first plume).<\/li><li style = \"counter-reset:ol0;\">If the area of the radiation level of a contour of one plume exceeds 90% of the area of the other plume over all radiation levels, then the iterative process is discontinued (the 90% threshold can be changed by the user).<\/li><li style = \"counter-reset:ol0;\"><\/li><li style = \"counter-reset:ol0;\">Comparing the current iteration of the radiation plume with the HPAC plume is similar to comparing plumes from consecutive iterations, but we instead group the regions of each plume that are above and below 2Gy (or 200 cGy), which was a threshold selected based on US government recommendations for eligibility of clinical treatment of acute radiation syndrome by cytokine therapies.<\/li><li style = \"counter-reset:ol0;\">Determine the regions of overlap between the HPAC and the intermediate plume that both represent a radiation value \u2265 2Gy, and sum the Shape_Area of each overlap.<\/li><li style = \"counter-reset:ol0;\">Determine the regions of overlap where the HPAC plume represents a radiation level \u2265 2Gy but the intermediate plume represents a radiation level < 2 Gy, and sum the Shape_Area of each overlap.<\/li><li style = \"counter-reset:ol0;\">Compute the accuracy of the intermediate plume by dividing the total Shape_Area of the overlapping \u2265 2Gy regions (Step 1) with the total Shape_Area of the HPAC plume's regions \u2265 2Gy (Step 1 + Step 2). <\/li><\/ol><\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/9320c53043cebfd096c26b8dc25173ef3c96973eff8c022a1c7251fe6a070124\/bwpebazi7.png\" \/><\/div><div class = \"text-block\">The protocol diverges in the analysis of the Union between the two plumes. When comparing two iterations of the derived plume (in Excel):<\/div><div class = \"text-block\"><ol style = \"list-style-type: decimal;\"><li style = \"counter-reset:ol0;\">Order the columns in terms of increasing radiation values for one of the plumes.<\/li><li style = \"counter-reset:ol0;\">For each radiation level for one plume, determine whether the intersecting region of the second plume has the same radiation value. Sum the Shape_Area column for the intersecting segments of the plume where the radiation level matches, as well as the intersecting segments that do not match. Determine the percentage of the area of the two intersecting plumes that are in agreement (have the same radiation level) by dividing the Shape_Area of matching intersecting segments by the sum of the matching and non-matching segments (which should equal the total area of that radiation level for the first plume).<\/li><li style = \"counter-reset:ol0;\">If the area of the radiation level of a contour of one plume exceeds 90% of the area of the other plume over all radiation levels, then the iterative process is discontinued (the 90% threshold can be changed by the user).<\/li><li style = \"counter-reset:ol0;\"><\/li><li style = \"counter-reset:ol0;\">Comparing the current iteration of the radiation plume with the HPAC plume is similar to comparing plumes from consecutive iterations, but we instead group the regions of each plume that are above and below 2Gy (or 200 cGy), which was a threshold selected based on US government recommendations for eligibility of clinical treatment of acute radiation syndrome by cytokine therapies.<\/li><li style = \"counter-reset:ol0;\">Determine the regions of overlap between the HPAC and the intermediate plume that both represent a radiation value \u2265 2Gy, and sum the Shape_Area of each overlap.<\/li><li style = \"counter-reset:ol0;\">Determine the regions of overlap where the HPAC plume represents a radiation level \u2265 2Gy but the intermediate plume represents a radiation level < 2 Gy, and sum the Shape_Area of each overlap.<\/li><li style = \"counter-reset:ol0;\">Compute the accuracy of the intermediate plume by dividing the total Shape_Area of the overlapping \u2265 2Gy regions (Step 1) with the total Shape_Area of the HPAC plume's regions \u2265 2Gy (Step 1 + Step 2). <\/li><\/ol><\/div><div class = \"text-block\">Comparing the current iteration of the radiation plume with the HPAC plume is similar to comparing plumes from consecutive iterations, but we instead group the regions of each plume that are above and below 2Gy (or 200 cGy), which was a threshold selected based on US government recommendations for eligibility of clinical treatment of acute radiation syndrome by cytokine therapies.<\/div><div class = \"text-block\"><ol style = \"list-style-type: decimal;\"><li style = \"counter-reset:ol0;\">Determine the regions of overlap between the HPAC and the intermediate plume that both represent a radiation value \u2265 2Gy, and sum the Shape_Area of each overlap.<\/li><li style = \"counter-reset:ol0;\">Determine the regions of overlap where the HPAC plume represents a radiation level \u2265 2Gy but the intermediate plume represents a radiation level < 2 Gy, and sum the Shape_Area of each overlap.<\/li><li style = \"counter-reset:ol0;\">Compute the accuracy of the intermediate plume by dividing the total Shape_Area of the overlapping \u2265 2Gy regions (Step 1) with the total Shape_Area of the HPAC plume's regions \u2265 2Gy (Step 1 + Step 2). <\/li><\/ol><\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/9320c53043cebfd096c26b8dc25173ef3c96973eff8c022a1c7251fe6a070124\/bwphbazi7.png\" \/><\/div><\/div>"}},{"id":1054725,"guid":"9512A15AB27F4DCFAEF8FB69DB82CB09","order_id":2,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/9320c53043cebfd096c26b8dc25173ef3c96973eff8c022a1c7251fe6a070124\/bwpbbazi7.png\" \/><\/div>"}},{"id":1054726,"guid":"9F63B2DA6BE34E9EA252025E3867D6DF","order_id":3,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/9320c53043cebfd096c26b8dc25173ef3c96973eff8c022a1c7251fe6a070124\/bwpebazi7.png\" \/><\/div>"}},{"id":1054727,"guid":"A67E50ECC67A49E1BD95929DCE44F825","order_id":4,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/9320c53043cebfd096c26b8dc25173ef3c96973eff8c022a1c7251fe6a070124\/bwphbazi7.png\" \/><\/div>"}}],"cases":[],"data":null,"section":null,"section_color":"#EA94FF","section_duration":0,"critical":null,"critical_id":null,"duration":0}],"document":null,"materials":[{"id":349013,"mol_weight":0,"name":"ArcMap 10 Software","linfor":"","url":"https:\/\/www.esri.com\/en-us\/home","sku":"ESRI: Redlands, California","cas_number":"","rrid":"","public":0,"vendor":{"name":"ESRI","affiliation":null,"affiliations":[],"username":null,"link":"https:\/\/www.esri.com\/en-us\/home","image":{"source":"https:\/\/www.protocols.io\/img\/vendors\/placeholder.png","placeholder":"https:\/\/www.protocols.io\/img\/vendors\/placeholder.png"},"badges":[],"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false,"id":892},"can_edit":0,"stats":{"total_protocols":0}}],"description":"<div class = \"text-blocks\"><div class = \"text-block\">Accurate radiation dose estimates are critical for determining eligibility for therapies by timely triaging of exposed individuals after large-scale radiation events. However, the universal assessment of a large population subjected to a nuclear spill incident or detonation is not feasible. Even with high-throughput dosimetry analysis, test volumes far exceed the capacities of first responders to measure radiation exposures directly, or to acquire and process samples for follow-on biodosimetry testing. We aimed to design a protocol which can significantly reduce data acquisition and processing requirements for timely treatment of eligible, affected individuals in population-scale radiation exposures.<\/div><div class = \"text-block\">Method in Brief: The spatial boundaries of graduated radiation exposures were determined by targeted, multistep geostatistical analysis of small population samples. Physical radiation plumes modelled nuclear detonation scenarios of simulated exposures at 22 US locations. Models assumed only location of the epicenter and historical, prevailing wind directions\/speeds. Initially, locations proximate to these sites were randomly sampled (0.1% of population). Empirical Bayesian kriging established radiation dose contour levels circumscribing these sites. Densification of each plume identified critical locations for additional sampling. After repeated kriging and densification, overlapping grids between each pair of contours of successive plumes were compared based on their diagonal Bray-Curtis distances and root-mean-square deviations, which provided criteria (<10% difference) to discontinue sampling.<\/div><\/div>","changed_on":1587744518}