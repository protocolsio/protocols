{"id":50125,"title":"Serial Sectioning Optical Histology - Cell Census Network -data acquisition and processing","title_html":"<p>Serial Sectioning Optical Histology - Cell Census Network -data acquisition and processing<\/p>","image":{"source":"https:\/\/www.protocols.io\/img\/default_protocol.png","placeholder":"https:\/\/www.protocols.io\/img\/default_protocol.png"},"doi":null,"doi_status":0,"uri":"serial-sectioning-optical-histology-cell-census-ne-bu7mnzk6","type_id":4,"template_id":3,"published_on":1621541385,"parent_protocols":[],"parent_collections":[],"cited_protocols":[],"version_id":0,"version_data":{"id":"0","code":"bu7mnzk6","parent_id":0,"parent_uri":null,"is_same_owner":false,"has_pending_merge_request":false,"has_approved_merge_request":false},"created_on":1621539400,"modified_on":null,"categories":null,"public":1,"is_unlisted":0,"creator":{"name":"shuaibin  Chang","affiliation":"Boston University","affiliations":[{"affiliation":"Boston University","url":"","is_default":1}],"username":"shuaibin--chang","note":null,"link":null,"image":{"source":"\/img\/avatars\/013.png","placeholder":"\/img\/avatars\/013.png"},"badges":[{"id":2,"image":{"source":"\/img\/badges\/bronze.svg","placeholder":"\/img\/badges\/bronze.svg"},"name":"Author"}],"verified":0,"is_verified_user":false,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},"journal":null,"journal_name":null,"journal_link":null,"article_citation":null,"has_versions":0,"link":null,"total_collections":0,"number_of_steps":0,"authors":[{"name":"shuaibin  Chang","affiliation":"Boston University","affiliations":[],"username":"shuaibin--chang","note":"","link":null,"image":{"source":"\/img\/avatars\/013.png","placeholder":"\/img\/avatars\/013.png"},"badges":[],"verified":1,"is_verified_user":true,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},{"name":"Jiarui Yang","affiliation":"Boston University","affiliations":[],"username":"jiarui-yang","note":"","link":null,"image":{"source":"\/img\/avatars\/009.png","placeholder":"\/img\/avatars\/009.png"},"badges":[],"verified":1,"is_verified_user":true,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false}],"versions":[],"groups":[{"id":17131,"uri":"boston-university3","title":"Boston university","image":{"source":"https:\/\/www.protocols.io\/img\/group_placeholder.png","placeholder":"https:\/\/www.protocols.io\/img\/group_placeholder.png"},"tech_support":{"email":null,"phone":null,"hide_contact":0,"use_email":0,"url":null},"is_member":1,"request":{"id":17131,"uri":"boston-university3","title":"Boston university","image":{"source":"https:\/\/www.protocols.io\/img\/group_placeholder.png","placeholder":"https:\/\/www.protocols.io\/img\/group_placeholder.png"},"tech_support":{"email":null,"phone":null,"hide_contact":0,"use_email":0,"url":null},"is_member":1,"description":null,"research_interests":null,"website":null,"location":null,"affiliation":null,"status":{"is_visible":true,"access_level":0},"stats":{"files":[],"total_members":0,"total_followers":0,"total_child_groups":0,"total_parent_groups":0,"has_collaborations":0},"user_status":{"is_member":true,"is_confirmed":true,"is_invited":false,"is_owner":true,"is_admin":false,"is_following":false},"join_link":null,"token":null,"owner":{"name":" ","affiliation":null,"affiliations":[],"username":null,"note":null,"link":null,"image":{"source":null,"placeholder":null},"badges":[],"verified":0,"is_verified_user":false,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},"is_protocol_requested":0,"is_group_requested":0,"is_my":false,"is_request":false,"is_confirmed":1,"is_declined":0,"requester":{"name":" ","affiliation":null,"affiliation_url":null,"username":null,"link":null},"protocol":{"id":0,"title":"Serial Sectioning Optical Histology - Cell Census Network -data acquisition and processing","title_html":"Serial Sectioning Optical Histology - Cell Census Network -data acquisition and processing","image":{"source":null,"placeholder":null},"doi":null,"doi_status":0,"uri":"serial-sectioning-optical-histology-cell-census-ne-bu7mnzk6","type_id":4,"template_id":0,"published_on":null,"stats":{"number_of_views":0,"number_of_steps":0,"number_of_bookmarks":0,"number_of_comments":0,"number_of_exports":0,"number_of_runs":0,"number_of_votes":0,"is_voted":0},"parent_protocols":[],"parent_collections":[],"cited_protocols":[]},"created_on":1621541385,"resolve_on":0,"resolved_user":{"name":" ","affiliation":null,"affiliations":[],"username":null,"note":null,"link":null,"image":{"source":null,"placeholder":null},"badges":[],"verified":0,"is_verified_user":false,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},"shared":false}}],"is_owner":1,"has_subprotocols":0,"is_subprotocol":0,"is_bookmarked":0,"can_claim_authorship":0,"can_accept_authorship":0,"can_be_copied":1,"can_remove_fork":1,"fork_id":null,"url":"https:\/\/www.protocols.io\/view\/serial-sectioning-optical-histology-cell-census-ne-bu7mnzk6","forks_count":{"private":0,"public":0},"access":{"can_view":1,"can_remove":1,"can_add":0,"can_edit":0,"can_publish":0,"can_get_doi":1,"can_share":1,"can_move":1,"can_move_outside":1,"can_transfer":1,"can_download":1,"is_locked":0},"guid":"8544EF20B9A211EBB02515370CE210A8","state_version_id":207,"steps":[],"document":"<div class = \"text-blocks\"><div class = \"text-block\"><div class = \"justify\" style = \"text-align:center\"><span style = \"font-weight:bold;\">Serial Sectioning Optical Histology - Cell Census Network-data acquisition and processing<\/span><\/div><\/div><div class = \"text-block\"><div class = \"justify\" style = \"text-align:center\">Shuaibin Chang, Jiarui Yang, and the Boas lab, BU<\/div><\/div><div class = \"text-block\"><span style = \"font-weight:bold;\">Table of contents<\/span><\/div><div class = \"text-block\">Table of contents\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026......\u2026\u2026....2<\/div><div class = \"text-block\">Table of figures\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026......\u2026.\u2026...2<\/div><div class = \"text-block\">Abstract\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026......\u2026......\u20262<\/div><div class = \"text-block\">Introduction\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026.\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026......\u2026....\u2026..3<\/div><div class = \"text-block\">Data acquisition\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026......\u2026.\u2026\u2026..3<\/div><div class = \"text-block\">Metadata\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026.\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026......\u2026....\u2026..4<\/div><div class = \"text-block\">Serial Sectioning PSOCT Reconstruction\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026......\u2026\u2026\u2026....4<\/div><div class = \"text-block\">   Method\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026.\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026......\u2026....\u2026..4<\/div><div class = \"text-block\">   Implementation\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026......\u2026.\u2026\u2026\u20265<\/div><div class = \"text-block\">       FOV curvature correction\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026......\u2026\u2026\u2026\u2026..5<\/div><div class = \"text-block\">       Grid distortion correction\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026......\u2026\u2026\u2026...6<\/div><div class = \"text-block\">       Image stitching\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026......\u2026\u2026\u20267<\/div><div class = \"text-block\">       Vessel and fiber segmentation\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026......\u2026\u2026\u2026.8<\/div><div class = \"text-block\">       Optical property fitting\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026......\u2026\u2026\u202611<\/div><div class = \"text-block\">Reference\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026......\u2026....11<\/div><div class = \"text-block\"><span style = \"font-weight:bold;\">Table of Figures<\/span><\/div><div class = \"text-block\">Figure 1. Measured FOV curvature\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026......\u2026..\u2026.....\u2026.5<\/div><div class = \"text-block\">Figure 2. Merged distorted and perfect grid pattern. Red: distorted grid pattern. Green: perfect grid pattern generated from MATLAB. Yellow: overlap\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026.\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026......\u2026........................\u2026..7<\/div><div class = \"text-block\">Figure 3. AIP of one slice. The artifacts in the AIP shows the vibratome didn\u2019t have a clean cut at the vessels and pia\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026......\u2026..........8<\/div><div class = \"text-block\">Figure 4. Surface profile of one slice, unit in pixels. Pixel step size is 3um. The slight variation in tissue surface can be clearly seen\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026......\u2026....\u2026.8<\/div><div class = \"text-block\">Figure 5. reconstructed volume of a brain block \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026.\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026........\u2026....10<\/div><div class = \"text-block\">Figure 6. Z projection of segmented vessel network from the previous brain block\u2026..\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026......\u2026.......10<\/div><div class = \"text-block\">Figure 7. Back-scattering coefficient of one slice\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026......\u2026.....\u2026.11<\/div><div class = \"text-block\">Figure 8. Scattering coefficient of the same slice as back-scattering coefficient\u2026\u2026.\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026......\u2026.......\u202611<\/div><div class = \"text-block\">Figure 9. birefringence of a different slice\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026......\u2026...\u2026\u2026.....\u2026.11<\/div><div class = \"text-block\"><span style = \"font-weight:bold;\">Abstract<\/span><\/div><div class = \"text-block\">No current imaging technology can directly and without significant distortion visualize the defining microscopic features of the human brain. Ex vivo histological techniques yield exquisite planar images, but the cutting, mounting and staining they require induce slice-specific distortions, introducing cross-slice differences that prohibit true 3D analysis. Clearing techniques such as CLARITY have proven difficult to apply to large blocks of human tissue, and cause dramatic distortions as well. Thus, we have only a poor understanding of human brain structures that occur at a scale of 1-100\u03bcm, in which neurons are organized into functional cohorts. This impairs our ability to classify cell types, as the functional properties of any given cell are a function of both its molecular characteristics and the spatial context within which it resides. To date, mesoscopic features such as cortical laminae which are critical components of this spatial context, have only been quantified in studies of 2D histologic images acquired in a small number of subjects and\/or over a small region of the brain, typically in the coronal orientation, implying that features that are oblique or orthogonal to the coronal plane are difficult to properly analyze. <\/div><div class = \"text-block\">Our consortium will develop and utilize an imaging infrastructure to create a human brain cell census and instantiate it in a coordinate system that will enable an immediate impact of all in vivo MRI studies of the human brain. Our imaging pipeline begins with 150 \u03bcm isotropic ex vivo structural MRIs and 500 \u03bcm 90 direction diffusion MRI. 4x4x2 cm tissue blocks will then be imaged with serial sectioning polarization sensitive optical coherence tomography (PS-OCT) to obtain 20 \u03bcm isotropic resolution images of cyto- and myelo-architectural features and fiber tractography. Registration with the MRI is preserved because imaging is performed before sectioning. Serial sections with 150 \u03bcm thickness are cut from the block face, cleared, and subsequently imaged by selective plane imaging microscopy (SPIM) with 1 \u03bcm isotropic resolution, and with multiplexed histological staining of multiple molecular markers that will facilitate cellular classification. Segmentation of common features amongst the SPIM, OCT, and MRI, permits registration of the cellular information from SPIM back to the MRI coordinate system with OCT serving as an important intermediary permitting registration of SPIM with MRI with micrometer resolution. Our aims are designed to establish our imaging workflow and build a cell census atlas for language regions in human frontal cortex, resulting in a clear path forward for obtaining the cell census for the entire human brain.<\/div><div class = \"text-block\">For this protocol, we will be focusing at the data acquisition and imaging processing of serial sectioning PSOCT.<\/div><div class = \"text-block\"><span style = \"font-weight:bold;\">Introduction<\/span><\/div><div class = \"text-block\">This document describes the methods and materials used to process data generated from a serial sectioning PSOCT system and to quantify a few features that includes: vascular structures, axonal structures, scattering coefficient, back-scattering coefficient and birefringence.<\/div><div class = \"text-block\"><span style = \"font-weight:bold;\">Data acquisition<\/span><\/div><div class = \"text-block\">The data acquisition machine is a home-built polarization sensitive Optical Coherence Tomography system combined with a custom vibratome and XYZ motorized stages. Custom LabVIEW software was used to synchronize all hardwares and digitizing the signal. For more details of the hardware and software, please contact dboas@bu.edu.<\/div><div class = \"text-block\"><span style = \"font-weight:bold;\">Metadata<\/span><\/div><div class = \"text-block\">The imaging step size is 3um isotropic(n=1.37 for brain tissue) and the resolution is 6 um isotropic. To increase the throughput and to reduce the distortion, slices were cut at 400um thickness. Due to the 150um confocal parameter of our PSOCT system, each slice was imaged three times prior to cut with increasing focus depth. The Field of View of the system is 3x3mm^2 and the overlap between adjacent tiles is about 10%. <\/div><div class = \"text-block\">The raw data for each tile is saved in 16bit binary file. Each file consists of the cross and co polarization of the PSOCT system, the total size of one file is about 1.5GB. After post processing, which consists of distortion correction, shading correction(optional) and rough cropping, each tile is separated into two 16bit binary files storing the cross and co polarization separately. The size of post-processed file is about 0.5GB each.<\/div><div class = \"text-block\">Each dataset is associated with the following metadata:<\/div><div class = \"text-block\">\tBrain block index<\/div><div class = \"text-block\">\tImaging date<\/div><div class = \"text-block\">\tImaging system<\/div><div class = \"text-block\">\tA config file recording the imaging configuration<\/div><div class = \"text-block\">\tA log file recording the time(date to second) when each tile is imaged and the stage coordinates, local storage free space, etc.<\/div><div class = \"text-block\">\tA log file recording the time spent for pushing the file to the SCC(a BU based remote server), for monitoring the ethernet speed<\/div><div class = \"text-block\"><span style = \"font-weight:bold;\">PSOCT image reconstruction<\/span><\/div><div class = \"text-block\">Method<\/div><div class = \"text-block\">Image distortion originates from the optical system\u2019s deviation from paraxial assumption and telecentricity. Larger scanning angle of the beams results in larger FOV, but also means further away from the paraxial assumption. The use of paired scanning mirrors causes the non-telecentricity. The overall distortion causes unflat image height in OCT B-lines, which we name it as FOV curvature distortion. The distortion also causes wrapping in the XY dimension, which we name it as grid distortion. The initial part of reconstruction involves the distortion correction of the raw data and rough cropping to reduce the data size. Right after distortion correction, we produce and stitch the Average Intensity Projection(AIP) and the tissue surface height, both of which serve as quality controls of the acquired data. Next, the volumetric OCT reflectivity of the whole brain block is reconstructed, from which the vessel and fiber structure can be extracted using custom MATLAB code. Fitting the depth profile of reflectivity, cross polarization channel and co polarization channel reveals the optical properties of the brain tissue, which includes the scattering coefficient, back-scattering coefficient and birefringence.<\/div><div class = \"text-block\"><span style = \"font-weight:bold;\">Implementation<\/span><\/div><div class = \"text-block\"><span style = \"font-weight:bold;\">FOV curvature correction<\/span><\/div><div class = \"text-block\">The FOV curvature is originated from the optical system, hence it remains the same for all tiles regardless of tile position or tissue type. By summing up all tiles from a single slice, if the number of tiles is large enough to smooth out the tile-dependent surface variations, the summed C-scan volume will possess a tissue surface that\u2019s identical to the FOV curvature. The curvature can be extracted, inverted, and apply to each tile to correct such distortion using the code below:<\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">function [curved_C_scan]=FOV_curvature_correction(C_line, curvature, z, x, y)<\/div><div class = \"text-block\">%author: Shuaibin Chang<\/div><div class = \"text-block\">%date: 09\/30\/2019<\/div><div class = \"text-block\">%This is the FOV curvature correction scripts. The output is the corrected<\/div><div class = \"text-block\">%stack, after trimming out the bottom part which has a lot of 0s<\/div><div class = \"text-block\">%C-line is the uncorrected C scan, curvature is the 2D matrix used to<\/div><div class = \"text-block\">%corrected the whole volume<\/div><div class = \"text-block\">%z0 is the number of pixels after correction that's free from the 0s, x, y<\/div><div class = \"text-block\">%is the dimension of the stack in x and y directions<\/div><div class = \"text-block\">z0=z-(max(curvature(:))-min(curvature(:)))-5;<\/div><div class = \"text-block\">curved_C_scan=zeros(z0,x,y);<\/div><div class = \"text-block\">for X=1:x<\/div><div class = \"text-block\">for Y=1:y<\/div><div class = \"text-block\">depth=curvature(X,Y);<\/div><div class = \"text-block\">curved_C_scan(:,X,Y)=C_line((depth+1):(depth+z0),X,Y);<\/div><div class = \"text-block\">end<\/div><div class = \"text-block\">end<\/div><\/div><\/code><\/pre><\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/files\/dmfsbh77p.jpg\" \/><\/div><div class = \"text-block\"><span style = \"font-weight:bold;\">Grid distortion correction<\/span><\/div><div class = \"text-block\"><span>Like the FOV curvature correction, the grid distortion is also constant for all tiles. To pre-measure the grid distortion, a grid target from Thorlabs <\/span><a href=\"https:\/\/www.thorlabs.com\/newgrouppage9.cfm?objectgroup_id=7501\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">https:\/\/www.thorlabs.com\/newgrouppage9.cfm?objectgroup_id=7501<\/span><\/a><span> can be used before imaging the sample. The image of the grid target is encoded with the distortion in X and Y dimensions. In MATLAB one can generate a perfect grid pattern with the same orientation and spacing. Using the bUnwarpJ plugin of Imagej, which registers the distorted grid pattern to the perfect grid pattern, a registration matrix that encloses the registration coordinates can be found. However, the registration matrix is in compressed fashion and cannot be directly used. After converting it into the coordinates and weights matrix, the following code does the grid distortion correction while throwing away the outermost pixels to make the image square:<\/span><\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">function[corrected_C_line]=Grid_correction(C_line, grid_matrix, x1, x0, y1, y0, z)<\/div><div class = \"text-block\">%author: Shuaibin Chang<\/div><div class = \"text-block\">%date: 09\/30\/2019<\/div><div class = \"text-block\">%this is the grid distortion correction scripts, the output is the corrected<\/div><div class = \"text-block\">%and trimmed C scan<\/div><div class = \"text-block\">%C_line is the pre-corrected C scan, grid_matrix is the 3x1100x1100 element matrix used to correct the C scan at each depth<\/div><div class = \"text-block\">%becaused the edge of the C scan becomes 0 after correction, we will trim<\/div><div class = \"text-block\">%the stack after correction. x0,x1,y0,y1 defines the range of the<\/div><div class = \"text-block\">%stack that's free from the 0s<\/div><div class = \"text-block\">corrected_C_line=zeros(z, x1-x0, y1-y0);<\/div><div class = \"text-block\">for Z=1:z<\/div><div class = \"text-block\">    for k = x0:x1<\/div><div class = \"text-block\">        for j = y0:y1<\/div><div class = \"text-block\">           corrected_C_line(Z,k,j)=...<\/div><div class = \"text-block\">               grid_matrix(1,k,j)*grid_matrix(2,k,j)*C_line(Z,grid_matrix(3,k,j),grid_matrix(4,k,j))+...<\/div><div class = \"text-block\">               (1-grid_matrix(1,k,j))*grid_matrix(2,k,j)*C_line(Z,grid_matrix(3,k,j)+1,grid_matrix(4,k,j))+...<\/div><div class = \"text-block\">               grid_matrix(1,k,j)*(1-grid_matrix(2,k,j))*C_line(Z,grid_matrix(3,k,j),grid_matrix(4,k,j)+1)+...<\/div><div class = \"text-block\">               (1-grid_matrix(1,k,j))*(1-grid_matrix(2,k,j))*C_line(Z,grid_matrix(3,k,j)+1,grid_matrix(4,k,j)+1);<\/div><div class = \"text-block\">        end<\/div><div class = \"text-block\">    end<\/div><div class = \"text-block\">end<\/div><\/div><\/code><\/pre><\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/files\/dmgabh77p.jpg\" \/><\/div><div class = \"text-block\"><span style = \"font-weight:bold;\">Image stitching<\/span><\/div><div class = \"text-block\">AIP can be generated from the average signals in Z dimension. AIP stitching uses the stitching plugin of Imagej. Various blending methods can be chosen to remove the stitching artifacts originated from non-perfect laser alignment. To find the tissue surface, the MATLAB function findchangepts() can be used, which tries to find the point where the mean of samples before the current point and after the current point change abruptly. The registered AIP coordinates can be used to stitch the surface profile and the volume image. <\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/files\/dmgebh77p.jpg\" \/><\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/files\/dmgsbh77p.jpg\" \/><\/div><div class = \"text-block\"><span style = \"font-weight:bold;\">Vessel and fiber segmentation<\/span><\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"blob:https:\/\/www.protocols.io\/40780629-39ee-4ebd-870b-5504eecd0384\" \/><\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"blob:https:\/\/www.protocols.io\/94fe71bd-ce3f-4e76-8b67-578fd22a01e6\" \/><\/div><div class = \"text-block\">The expansion equation above approximates the local structure of the image up to second-order derivatives. \u2207_(o,\u03c3) and H_(o,\u03c3) are the gradient vector and Hessian matrix of the image computed at x_o at scale \u03c3. To calculate these differential operators of I(x) in a well-posed fashion we adopt concepts of linear scale-space theory. In this framework, differentiation is defined as a convolution with derivatives of Gaussians:<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"blob:https:\/\/www.protocols.io\/6b000881-9857-4c98-b969-15866f48c252\" \/><\/div><div class = \"text-block\">Where the D-dimensional Gaussian is defined as:<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"blob:https:\/\/www.protocols.io\/e76ca669-a599-40c0-bfa8-d1d12b62a98d\" \/><\/div><div class = \"text-block\">The third term in Equation (2.1) gives the second order directional derivative,<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"blob:https:\/\/www.protocols.io\/a7f7f055-8287-4589-96fa-ea7c12a054b3\" \/><\/div><div class = \"text-block\">The idea behind eigenvalue analysis of the Hessian is to extract the principal directions in which the local second order structure of the image can be decomposed. Let \u03bb_(\u03c3,k) denote the eigenvalue corresponding to the k-th normalized eigenvector u \u0302_(\u03c3,k) of the Hessian H_(o,\u03c3) all computed at scale \u03c3. From the definition of eigenvalues:<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"blob:https:\/\/www.protocols.io\/c9e74080-8b4a-41c9-8281-02c854ab0059\" \/><\/div><div class = \"text-block\">and it follows that<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"blob:https:\/\/www.protocols.io\/6b4cf991-14d3-4eab-a758-f496edee5d75\" \/><\/div><div class = \"text-block\">The eigenvalue decomposition extracts three orthonormal directions which are invariant up to a scaling factor when mapped by the Hessian matrix. In particular, a spherical neighborhood will be mapped onto an ellipsoid whose axes are along the directions given by the eigenvectors of the Hessian and the corresponding axis' semi-lengths are the magnitudes of the respective eigenvalues. This ellipsoid locally describes the second order structure of the image and can be used as an intuitive construct for the design of geometric similarity measures. We assume \u03bb_k to be the eigenvalue with the k-th smallest magnitude (|\u03bb_1 |\u2264|\u03bb_2 |\u2264|\u03bb_3 |) in this work.<\/div><div class = \"text-block\">In general, a pixel is considered to belong to a vessel if two conditions are met: (1) \u03bb_1 being small (ideally zero); (2) \u03bb_2 and \u03bb_3 of a large magnitude and equal sign (the sign is an indicator of brightness\/darkness). The respective eigenvectors point out singular directions: u \u0302_1 indicates the direction along the vessel and u \u0302_2 and u \u0302_3 form a base for the orthogonal plane. In PSOCT images, vessels show up as dark tubular vacuum compared to brighter surrounding tissue. In this work, we adopt a similarity measure to a tube:<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"blob:https:\/\/www.protocols.io\/4c52624b-a6f7-4811-afd5-603626650028\" \/><\/div><div class = \"text-block\">Where \u03b3_23\u22650 and \u03b3_12\u22650 controls the selectivity of the filter, and 0\u2264\u03b1\u22641 introduces asymmetrical behavior of the filter in the negative and positive regions of \u03bb_1. In practice, we found \u03b3_23=\u03b3_12=0.5 and \u03b1=0.25 generally work well with volumetric PSOCT data.<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/files\/dmfwbh77p.jpg\" \/><\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/files\/dmgibh77p.jpg\" \/><\/div><div class = \"text-block\"><span style = \"font-weight:bold;\">Optical property fitting<\/span><\/div><div class = \"text-block\">A non-linear model (Wang et al., 2017) was used to fit the depth profile of the OCT reflectivity signal, from which we extracted the scattering coefficient \u03bc_s and the relative back-scattering coefficient \u03bc_b^'. Note that \u03bc_b^' is a relative variable, depending on factors of the OCT system including the incident power and the spectrometer efficiency, and is proportional to the intrinsic back-scattering coefficient \u03bc_b:<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"blob:https:\/\/www.protocols.io\/089ffdbe-0e97-4fb9-92e9-49520c528bd8\" \/><\/div><div class = \"text-block\">where R(z) is the OCT reflectance signal versus depth, H(z) is the sensitivity roll-off function(Wang et al., 2017), h(z) is the axial point spread function of the microscope system, which depends on the focus depth Z_f and the effective Rayleigh range Z_Rs of the objective:<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"blob:https:\/\/www.protocols.io\/b2260b88-b742-466e-bede-69daade14639\" \/><\/div><div class = \"text-block\">After fitting the reflectivity, we applied the fitted parameters to the cross and co polarization signal and fit the birefringence:<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"blob:https:\/\/www.protocols.io\/c9f4a63a-bb1d-4696-b3af-dc7fc7e8b0c0\" \/><\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"blob:https:\/\/www.protocols.io\/61924008-a3f9-4d32-a350-39a4eaa618ac\" \/><\/div><div class = \"text-block\">Where A_cross and A_co is the amplitude of cross and co polarization signal, respectively. \u03b3 is the birefringence.<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/files\/dmf2bh77p.jpg\" \/><\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/files\/dmgnbh77p.jpg\" \/><\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/files\/dmf6bh77p.jpg\" \/><\/div><div class = \"text-block\">Figure7. Back-scattering coefficient of one slice.\t <\/div><div class = \"text-block\">Figure 8. Scattering coefficient of the same slice as back-scattering coefficient.\t <\/div><div class = \"text-block\">Figure 9. birefringence of a different slice.<\/div><div class = \"text-block\"><span style = \"font-weight:bold;\">References\t\t<\/span><\/div><div class = \"text-block\"><span>Wang, H., Magnain, C., Sakad\u017ei\u0107, S., Fischl, B., Boas, D.A., 2017. Characterizing the optical properties of human brain tissue with high numerical aperture optical coherence tomography. Biomed. Opt. Express 8, 5617. <\/span><a href=\"https:\/\/doi.org\/10.1364\/boe.8.005617\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">https:\/\/doi.org\/10.1364\/boe.8.005617<\/span><\/a><span><\/span><\/div><\/div>","materials":[],"description":"<div class = \"text-blocks\"><div class = \"text-block\">No current imaging technology can directly and without significant distortion visualize the defining microscopic features of the human brain. Ex vivo histological techniques yield exquisite planar images, but the cutting, mounting and staining they require induce slice-specific distortions, introducing cross-slice differences that prohibit true 3D analysis. Clearing techniques such as CLARITY have proven difficult to apply to large blocks of human tissue, and cause dramatic distortions as well. Thus, we have only a poor understanding of human brain structures that occur at a scale of 1-100\u03bcm, in which neurons are organized into functional cohorts. This impairs our ability to classify cell types, as the functional properties of any given cell are a function of both its molecular characteristics and the spatial context within which it resides. To date, mesoscopic features such as cortical laminae which are critical components of this spatial context, have only been quantified in studies of 2D histologic images acquired in a small number of subjects and\/or over a small region of the brain, typically in the coronal orientation, implying that features that are oblique or orthogonal to the coronal plane are difficult to properly analyze. <\/div><div class = \"text-block\">Our consortium will develop and utilize an imaging infrastructure to create a human brain cell census and instantiate it in a coordinate system that will enable an immediate impact of all in vivo MRI studies of the human brain. Our imaging pipeline begins with 150 \u03bcm isotropic ex vivo structural MRIs and 500 \u03bcm 90 direction diffusion MRI. 4x4x2 cm tissue blocks will then be imaged with serial sectioning polarization sensitive optical coherence tomography (PS-OCT) to obtain 20 \u03bcm isotropic resolution images of cyto- and myelo-architectural features and fiber tractography. Registration with the MRI is preserved because imaging is performed before sectioning. Serial sections with 150 \u03bcm thickness are cut from the block face, cleared, and subsequently imaged by selective plane imaging microscopy (SPIM) with 1 \u03bcm isotropic resolution, and with multiplexed histological staining of multiple molecular markers that will facilitate cellular classification. Segmentation of common features amongst the SPIM, OCT, and MRI, permits registration of the cellular information from SPIM back to the MRI coordinate system with OCT serving as an important intermediary permitting registration of SPIM with MRI with micrometer resolution. Our aims are designed to establish our imaging workflow and build a cell census atlas for language regions in human frontal cortex, resulting in a clear path forward for obtaining the cell census for the entire human brain.<\/div><div class = \"text-block\">For this protocol, we will be focusing at the data acquisition and imaging processing of serial sectioning PSOCT.<\/div><\/div>","changed_on":1621541385}