{"access":{"can_view":true,"can_edit":false,"can_remove":false,"can_add":false,"can_publish":false,"can_get_doi":false,"can_share":true,"can_move":true,"can_move_outside":true,"can_transfer":true,"can_download":true,"limited_run":false,"limited_private_links":false,"limited_blind_links":false,"is_locked":false},"authors":[{"name":"Kyu Sang Han","affiliation":"Johns Hopkins University","affiliation_url":"","username":"kyu-sang-han","link":"","image":{"source":"https://content.protocols.io/files/p6x4b7aex.jpg","placeholder":"https://content.protocols.io/files/p6x4b7aex.jpg","webp_source":"https://content.protocols.io/files/p6x3b7aex.webp"},"note":"","is_verified_user":true},{"name":"Pei-Hsun Wu","affiliation":"Johns Hopkins University","affiliation_url":null,"username":"peihsun-wu1","link":null,"image":{"source":"/img/avatars/007.png","placeholder":"/img/avatars/007.png","webp_source":""},"note":"","is_verified_user":true},{"name":"Joel Sunshine","affiliation":"Johns Hopkins Medicine","affiliation_url":null,"username":"n4wle102w1x4qle1","link":null,"image":{"source":"/img/avatars/010.png","placeholder":"/img/avatars/010.png","webp_source":""},"note":"","is_verified_user":false},{"name":"Ashley Kiemen","affiliation":"Johns Hopkins Medicine","affiliation_url":null,"username":"n4wle102w1z4sle1","link":null,"image":{"source":"/img/avatars/012.png","placeholder":"/img/avatars/012.png","webp_source":""},"note":"","is_verified_user":false},{"name":"Sashank Reddy","affiliation":"Johns Hopkins Medicine","affiliation_url":null,"username":"n4ule1w1u115ple1","link":null,"image":{"source":"/img/avatars/015.png","placeholder":"/img/avatars/015.png","webp_source":""},"note":"","is_verified_user":false},{"name":"Denis Wirtz","affiliation":"Johns Hopkins University; Johns Hopkins Medicine","affiliation_url":null,"username":"n4ule1w1u115qle1","link":null,"image":{"source":"/img/avatars/009.png","placeholder":"/img/avatars/009.png","webp_source":""},"note":"","is_verified_user":true}],"before_start":"","book_chapter":null,"can_accept_authorship":false,"can_be_copied":true,"can_claim_authorship":false,"can_manage_keywords":true,"can_remove_fork":false,"can_sign":false,"child_steps":{},"cited_protocols":[],"collection_items":[],"created_on":1711656986,"creator":{"name":"Kyu Sang Han","affiliation":"Johns Hopkins University","affiliation_url":"","username":"kyu-sang-han","link":"","image":{"source":"https://content.protocols.io/files/p6x4b7aex.jpg","placeholder":"https://content.protocols.io/files/p6x4b7aex.jpg","webp_source":"https://content.protocols.io/files/p6x3b7aex.webp"},"badges":[{"id":4,"name":"Gold power author!","image":{"source":"/img/badges/gold.svg","placeholder":"/img/badges/gold.svg"}}],"affiliations":[{"affiliation":"Johns Hopkins University","url":"","job_title":"Postdoctoral researcher","is_default":true}]},"cross_cloud_origin":null,"description":"{\"blocks\":[{\"key\":\"cj8mm\",\"text\":\"In this section, we describe steps to create a basic semantic segmentation algorithm using CODA. CODA uses a modified resnet50 network adapted for semantic segmentation using an implementation of DeepLab. Here, we describe how to generate training datasets of manual annotations for a set of images, how to format the data for deep learning, and how to train and apply a CODA deep learning model.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","disclaimer":"","document":"","documents":null,"doi":"dx.doi.org/10.17504/protocols.io.81wgbz1x3gpk/v1","doi_status":1,"ethics_statement":null,"fork_id":null,"fork_info":null,"forks":[],"funders":[{"funder_name":"National Cancer Institute","grant_id":"U54CA143868"},{"funder_name":"Institute of Arthritis and Musculoskeletal and Skin Diseases","grant_id":"U54AR081774"}],"groups":[{"id":1314,"uri":"human-biomolecular-atlas-program-hubmap-method-development","title":"Human BioMolecular Atlas Program (HuBMAP) Method Development Community","is_public":true,"image":{"source":"https://s3.amazonaws.com/protocols-files/public/878566e39a791455c5de855eebb601e890d5871d93466a1c1252d979f3a8c48e/brha6bxe.jpg","placeholder":"https://s3.amazonaws.com/protocols-files/public/878566e39a791455c5de855eebb601e890d5871d93466a1c1252d979f3a8c48e/brha6bxe.jpg"},"tech_support":{"email":"Jeff.spraggins@vanderbilt.edu","phone":null,"use_email":false,"hide_contact":true,"url":null}},{"id":99892,"uri":"tmc---johns-hopkins-university","title":"TMC - Johns Hopkins University","is_public":false,"image":{"source":"https://content.protocols.io/files/1C4FF7A1144411EEA01B0A58A9FEAC02-placeholder.png","placeholder":"https://content.protocols.io/files/1C4FF7A1144411EEA01B0A58A9FEAC02-placeholder.png"},"tech_support":{"email":null,"phone":null,"use_email":false,"hide_contact":false,"url":null}}],"guid":"55E25CBC66074FB58C77340AFBDCF828","guidelines":"","has_references":false,"has_step_reagents":false,"has_versions":false,"id":97509,"image":{"source":"https://www.protocols.io/img/default_protocol.png","webp_source":null,"placeholder":"https://www.protocols.io/img/default_protocol.png","webp_placeholder":null},"image_attribution":"","in_trash":false,"is_bookmarked":false,"is_contact_suspended":false,"is_content_confidential":false,"is_content_warning":false,"is_doi_reserved":false,"is_in_pending_publishing":false,"is_in_transfer":false,"is_owner":true,"is_research":true,"is_retracted":false,"is_shared_directly":false,"is_subprotocol":null,"is_unlisted":false,"item_id":1232820,"journal":null,"journals":[],"keywords":"","last_modified":1712006469,"link":"","location":null,"manuscript_citation":"{\"blocks\":[{\"key\":\"e6u50\",\"text\":\"Kiemen, A.L., Braxton, A.M., Grahn, M.P. et al. CODA: quantitative 3D reconstruction of large tissues at cellular resolution. Nat Methods 19, 1490–1499 (2022). https://doi.org/10.1038/s41592-022-01650-9\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"italic\",\"offset\":41,\"length\":6},{\"style\":\"italic\",\"offset\":126,\"length\":11},{\"style\":\"bold\",\"offset\":138,\"length\":2}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","materials":[],"materials_text":"","ownership_history":null,"parent_collections":[],"parent_protocols":[],"peer_reviewed":false,"protocol_references":"","public":true,"public_fork_note":"","published_on":1712006469,"references":[],"related_equipments":[],"related_materials":[],"reserved_doi":"","retraction_reason":null,"samples":{},"shared_access_id":100,"show_comparison":false,"sign_info":null,"space_access":{"can_view":false,"can_edit":false,"can_remove":false,"can_add":false,"can_publish":true,"can_get_doi":true,"can_share":false,"can_move":false,"can_move_outside":false,"can_transfer":false,"can_download":false,"limited_run":false,"limited_private_links":false,"limited_blind_links":false,"is_locked":false},"space_id":1381,"state_version_id":607,"stats":{"is_voted":false,"number_of_views":4,"number_of_steps":35,"number_of_bookmarks":0,"number_of_comments":0,"number_of_bookmarked_comments":0,"number_of_steps_comments":0,"number_of_protocol_comments":0,"number_of_exports":0,"number_of_runs":0,"number_of_votes":0,"number_of_reagents":0,"number_of_equipments":0,"number_of_collections":0,"number_of_forks":{"private":0,"public":0},"number_of_accessible_forks":0},"status":{"id":1,"info":"We use this protocol and it's working"},"steps":[{"id":1997062,"guid":"BDAAB3270FCE4DA19D8CBCD11CCDA35F","previous_id":0,"previous_guid":null,"section":"\u003cp\u003eDeep learning multi-labelling of tissue structures using training on manual annotations\u003c/p\u003e","section_color":"#A492FF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"499pn\",\"text\":\"Choose the biological structures you wish to segment in your images. Semantic segmentation algorithms must classify every pixel of every image with a label, so your list must be exhaustive. For example, in lung histology you could choose to annotate:\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"7gkmn\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"hsm3\",\"text\":\"a.       Bronchioles\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"5ov49\",\"text\":\"b.       Alveoli\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"b6ibe\",\"text\":\"c.       Vasculature\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"52cet\",\"text\":\"d.       Metastases\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"bliq2\",\"text\":\"e.       Nonexpanded lung\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"8c828\",\"text\":\"f.        Background\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"7cnvg\",\"text\":\"g.       Stroma\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"5ibb9\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"5v0o\",\"text\":\"Here, populations like fibroblasts and immune cells may be annotated inside of the ‘stroma’ layer. Background can encompass nontissue space as well as non-target noise within the histological images including red blood cells, shadows, and dust visible in the scanned images.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":97509,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"1","cases":[],"critical":null},{"id":1997063,"guid":"FF6AE6525B3341FDA67AC578C0E17C2D","previous_id":1997065,"previous_guid":"AFF0817475A240E5B451B605658DE676","section":"\u003cp\u003eDeep learning multi-labelling of tissue structures using training on manual annotations\u003c/p\u003e","section_color":"#A492FF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"75iig\",\"text\":\"Inside of pthannotations, create a subfolder named pthim where you copy a corresponding high-resolution (here 10x) tif image of each image that you are annotating.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"8slf\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"371l3\",\"text\":\"pthim=[pthannotations,'10x']; % copy a tif image here for each training image\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":30}],\"entityRanges\":[],\"data\":{}},{\"key\":\"fb6tg\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"4b0mo\",\"text\":\"Notes on the resolution you choose to train your model at: This choice highly depends on the resolution of structures you wish to label. If you want to quantify ‘bulk’ structures, low resolution (5x or lower) should be sufficient. If you want small structures such as small vasculature, small tubules, a medium resolution (~10x) should be sufficient. If you want to label individual cellular-sized strucutres, try ≥20x (you will need a computer with very high RAM and will have to very tediously annotate for this).\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"UNDERLINE\",\"offset\":0,\"length\":57}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":97509,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"3","cases":[],"critical":null},{"id":1997065,"guid":"AFF0817475A240E5B451B605658DE676","previous_id":1997062,"previous_guid":"BDAAB3270FCE4DA19D8CBCD11CCDA35F","section":"\u003cp\u003eDeep learning multi-labelling of tissue structures using training on manual annotations\u003c/p\u003e","section_color":"#A492FF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"bfs8p\",\"text\":\"Next, select some original resolution (.ndpi or .svs) images to annotate. Try first choosing 7 training images and 1 testing image, then add images as necessary until your model performs acceptably (\\u003e90% quantitative accuracy + passes visual inspection) on an independent (not seen in training) testing image. Put images you wish to annotate in a separate folder named ‘pthannotations’:\\n\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"8qfdt\",\"text\":\"pthannotations=[pth,'annotations']; % put images here to annotate for training\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":36}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":97509,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"2","cases":[],"critical":null},{"id":1997066,"guid":"FC53E3CEE8404D6E8421902138FABE4B","previous_id":1997063,"previous_guid":"FF6AE6525B3341FDA67AC578C0E17C2D","section":null,"section_color":null,"section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"dg5te\",\"text\":\"Inside of pthannotations, copy one additional 20x (.ndpi or .svs) image to a subfolder named ‘pthtest,’ with a corresponding high-resolution tif image saved in ‘pthtestim’. \\n\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"28na3\",\"text\":\"pthannotations_test=[pthannotations,'testing image']; % put image here to annotate for testing\\npthtestim=[pthannotations_test,'10x']; % copy a tif image here for each testing image\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":54},{\"style\":\"bold\",\"offset\":95,\"length\":39}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":97509,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"4","cases":[],"critical":null},{"id":1997068,"guid":"14D0965A13774EC985E425DB50EFA504","previous_id":1997066,"previous_guid":"FC53E3CEE8404D6E8421902138FABE4B","section":null,"section_color":null,"section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"f14f6\",\"text\":\"For each image you wish to annotate, open the file in Aperio ImageScope. To generate the xml files that will contain annotation data, select the Annotations button. This will open the Annotations window\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":54,\"length\":17},{\"style\":\"UNDERLINE\",\"offset\":54,\"length\":17}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":97509,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"5","cases":[],"critical":null},{"id":1997071,"guid":"BD69272E96A84C27B21A8DC29AE9181E","previous_id":1997068,"previous_guid":"14D0965A13774EC985E425DB50EFA504","section":null,"section_color":null,"section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"dltkk\",\"text\":\"Generate annotation layers by pressing the plus button, and rename layers by hovering over the text that says ‘Layer 1’, and clicking left, then right, then left on the mouse in quick succession (I don’t know why this works).\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":97509,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"6","cases":[],"critical":null},{"id":1997076,"guid":"657B2F23FC71483AA44783DA0EC4395A","previous_id":1997071,"previous_guid":"BD69272E96A84C27B21A8DC29AE9181E","section":null,"section_color":null,"section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"etd59\",\"text\":\"Make all layers for all structures you want to annotate in your sample. It is VERY IMPORTANT that all layers exist in the exact same order in all training and testing images you annotate. Create a layer even for structures that are not present in all images you annotate. If a layer is present in one image, it must be present in all images.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":97509,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"7","cases":[],"critical":null},{"id":1997077,"guid":"566E3A272C6047CF94154E15080E516D","previous_id":1997076,"previous_guid":"657B2F23FC71483AA44783DA0EC4395A","section":"","section_color":"","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"759ou\",\"text\":\"Next, create your annotations by selecting the pen tool in the ImageScope taskbar. Aim for ~25 annotations of each structure on each image. This is not always possible for rare structures. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":97509,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"8","cases":[],"critical":null},{"id":1997079,"guid":"DC6776FD56214D69A9D03902DFB17F93","previous_id":1997077,"previous_guid":"566E3A272C6047CF94154E15080E516D","section":"\u003cp\u003eNotes on annotating\u003c/p\u003e","section_color":"#94EBFF","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"3lk37\",\"text\":\"The quality of your segmentation model depends on the quality of your annotations. Zoom-in to high magnification to annotate, and try to annotate very cleanly along the edges of structures.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":97509,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"9","cases":[],"critical":null},{"id":1997080,"guid":"067C515E2DFC4AF7BEB6245DE764DE53","previous_id":1997079,"previous_guid":"DC6776FD56214D69A9D03902DFB17F93","section":"","section_color":"","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"40flk\",\"text\":\"Try to make all of annotations roughly the same size (do not make huge background annotations and tiny tissue annotations).\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":97509,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"10","cases":[],"critical":null},{"id":1997081,"guid":"62B0A6DDCEB34A9E8254061C8F9826B2","previous_id":1997080,"previous_guid":"067C515E2DFC4AF7BEB6245DE764DE53","section":"","section_color":"","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"a4ukj\",\"text\":\"If your annotations are overlapping, they must follow consistent ‘laws.’ One annotation layer must always dominate the other layer, so that MATLAB understands how to interpret overlapping masks. Consider creating a list of ‘nesting order’ before you begin annotating to organize which annotations are the ‘bottom layer’ up to the ‘top layer.’ For example, to annotate bronchiole inside of alveoli in lung histology, the alveolar annotation (yellow) will encircle the bronchiole annotation (green). A background annotation (blue) will circle noise inside the bronchiole. Here, the background layer is ‘dominant’ over the bronchiole layer, and the bronchiole layer is ‘dominant’ over the alveolar layer, in cases of overlap. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":97509,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"11","cases":[],"critical":null},{"id":1997086,"guid":"4CDC2AB36D484AA9AB909D649596E938","previous_id":1997081,"previous_guid":"62B0A6DDCEB34A9E8254061C8F9826B2","section":"\u003cp\u003eAfter annotation\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"a9bn2\",\"text\":\"When you’ve finished making annotations, you are ready to set up your MATLAB training function. This package requires several variable definitions that are listed inside the top section of the function ‘train_image_segmentation.’\\nFor the sample lung dataset, this function is filled out and saved as train_image_segmentation_lung. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":203,\"length\":24},{\"style\":\"bold\",\"offset\":300,\"length\":29}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":97509,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"12","cases":[],"critical":null},{"id":1997087,"guid":"221070E048F74A6FA6BDEE5012C7FB82","previous_id":1997086,"previous_guid":"4CDC2AB36D484AA9AB909D649596E938","section":"\u003cp\u003eAfter annotation\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"bgl8d\",\"text\":\"To create the inputs for this function you will need the followings\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":97509,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"13","cases":[],"critical":null},{"id":1997089,"guid":"2971748B633B45B7BF308AF4DD1299C7","previous_id":1997090,"previous_guid":"334108C3CD2041D5AFA9BA4C0E4ADC5A","section":"\u003cp\u003eAfter annotation\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"5pmuv\",\"text\":\"The size (in pixels) of the tiles you want to create for model training. By default this is set at 700, resulting in creation of 700 x 700 x 3 sized RGB tiles. Depending on your GPU memory, you may be able to increase this (model performance will be better for larger tiles) or you may need to decrease this.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"c60hn\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"3c0pr\",\"text\":\"sxy=700;\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":8}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":97509,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"21","cases":[],"critical":null},{"id":1997090,"guid":"334108C3CD2041D5AFA9BA4C0E4ADC5A","previous_id":1997091,"previous_guid":"7C0EF4939EB94BC7AC49FF7DF3A11615","section":"\u003cp\u003eAfter annotation\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"b1sc4\",\"text\":\"The date that your model was trained. This will define the output folder name where the trained model will be saved, such that unique folders are generated for different iterations of models made.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"5099l\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"3tv04\",\"text\":\"nm='12_15_2023';\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":16}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":97509,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"20","cases":[],"critical":null},{"id":1997091,"guid":"7C0EF4939EB94BC7AC49FF7DF3A11615","previous_id":1997093,"previous_guid":"C15F5E31101B4F13A6594DE199BCD310","section":"\u003cp\u003eAfter annotation\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"bu99c\",\"text\":\"The downsample factor of your high-resolution tif images compared to the images you annotated in ImageScope (this is the same number you gave as input to the function create_downsampled_tif_images to create your high-resolution tif images).\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":167,\"length\":30}],\"entityRanges\":[],\"data\":{}},{\"key\":\"b09if\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"2iado\",\"text\":\"umpix=2;\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":8}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":97509,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"19","cases":[],"critical":null},{"id":1997092,"guid":"57F3D2A462DE45A380EF51C95FFEF9C2","previous_id":1997087,"previous_guid":"221070E048F74A6FA6BDEE5012C7FB82","section":"\u003cp\u003eAfter annotation\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"c5jcr\",\"text\":\"The subfolder containing ‘.xml’ files with your training annotation information (created by ImageScope)\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"cnfkr\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"alhsi\",\"text\":\"pthannotations=[pth,'annotations']; % put images here to annotate for training\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":36}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":97509,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"14","cases":[],"critical":null},{"id":1997093,"guid":"C15F5E31101B4F13A6594DE199BCD310","previous_id":1997095,"previous_guid":"AE94885472A74F9A8F4C01A9DFC4AD39","section":"\u003cp\u003eAfter annotation\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"93gs9\",\"text\":\"The subfolder containing the full dataset of high-resolution tif images that you want to classify with your model after training is finished\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"3qo4c\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"4us1f\",\"text\":\"pthclassify=[pth,'10x'];\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":24}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":97509,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"18","cases":[],"critical":null},{"id":1997094,"guid":"FE85E4F2C40F4B60A1808863AF328EAB","previous_id":1997092,"previous_guid":"57F3D2A462DE45A380EF51C95FFEF9C2","section":"\u003cp\u003eAfter annotation\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"aaohs\",\"text\":\"The subfolder containing ‘.xml’ files with your testing annotation information (created by ImageScope)\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"3gs3h\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"bk3tj\",\"text\":\"pthannotations_test=[pthannotations,'testing image']; % put image here to annotate for testing \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":54}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":97509,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"15","cases":[],"critical":null},{"id":1997095,"guid":"AE94885472A74F9A8F4C01A9DFC4AD39","previous_id":1997096,"previous_guid":"D8B56256FC064D6F80FE00BFD051F855","section":"\u003cp\u003eAfter annotation\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"ecpr6\",\"text\":\"The subfolder containing high-resolution tif images corresponding to each annotated testing image\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"fkd6g\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"1n7q1\",\"text\":\"pthtestim=[pthannotations_test,'10x']; % copy a tif image here for each testing image\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":39}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":97509,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"17","cases":[],"critical":null},{"id":1997096,"guid":"D8B56256FC064D6F80FE00BFD051F855","previous_id":1997094,"previous_guid":"FE85E4F2C40F4B60A1808863AF328EAB","section":"\u003cp\u003eAfter annotation\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"6kd4e\",\"text\":\"The subfolder containing high-resolution tif images corresponding to each annotated training image\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"9r19f\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"6c980\",\"text\":\"pthim=[pthannotations,'10x']; % copy a tif image here for each training image\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":29}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":97509,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"16","cases":[],"critical":null},{"id":1997098,"guid":"3D55B7C5F206463A86A923D53ED94C3F","previous_id":1997089,"previous_guid":"2971748B633B45B7BF308AF4DD1299C7","section":"\u003cp\u003eAfter annotation\u003c/p\u003e","section_color":"#84CE84","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"5oqjk\",\"text\":\"The number of large training images you want to create. Each of these large images will be chopped into ~100 training tiles. A good number is around 15 but go lower or higher if you have very few (~5 images) or very many (\\u003e20 images) annotations.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"8ee5o\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"6jt0c\",\"text\":\"ntrain=15;\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":10}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":97509,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"22","cases":[],"critical":null},{"id":1997100,"guid":"4AC9C4315C7D4304A2E208F69C8C1686","previous_id":1997102,"previous_guid":"3F5BE84C01FA41DD808051A9B6E4DD99","section":"","section_color":"","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"66u5f\",\"text\":\"annotation_whitespace is a matrix of size [1 N] where N is the number of annotation layers you created in ImageScope. For each position within annotation_whitespace, indicate with 0 if you wish to remove the whitespace from your annotation (for example if you annotated a blood vessel and with to remove the luminal space from your annotation), indicate with 1 if you wish to keep only the whitespace in your\\nannotation (for example if you annotated fat and wish to remove the nonwhite lines dividing separate fat cells from your annotation), and indicate with 2 if you wish to keep both whitespace and nonwhite space within your annotation. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":21},{\"style\":\"bold\",\"offset\":143,\"length\":21}],\"entityRanges\":[],\"data\":{}},{\"key\":\"bse0r\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"7opiu\",\"text\":\"For example, for the four classes:\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"4ia3g\",\"text\":\"       Bronchioles\\n(remove whitespace [contains lumen])\",\"type\":\"ordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"dpdmf\",\"text\":\"       Alveoli\\n(remove whitespace [keep only the webbing])\",\"type\":\"ordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"5079b\",\"text\":\"       Vasculature\\n(remove whitespace [lumen of vasculature])\",\"type\":\"ordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"ujuf\",\"text\":\"       Metastases\\n(remove whitespace [whitespace around the edges of the cancer cells])\",\"type\":\"ordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"ah68\",\"text\":\"       Nonexpanded\\nlung (remove whitespace [keep only the webbing])\",\"type\":\"ordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"10d2o\",\"text\":\"       Background\\n(keep both [this class contains whitespace + noise like shadows])\",\"type\":\"ordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"85pm7\",\"text\":\"       Stroma\\n(remove whitespace [keep only the thin collagen fibers])\",\"type\":\"ordered-list-item\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"52i4t\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"87e5l\",\"text\":\"annotation_whitespace=[0 0 0 0 0 2 0];\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":38}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":97509,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"24","cases":[],"critical":null},{"id":1997102,"guid":"3F5BE84C01FA41DD808051A9B6E4DD99","previous_id":1997098,"previous_guid":"3D55B7C5F206463A86A923D53ED94C3F","section":"\u003cp\u003eThe variable ‘WS’ - how to create it\u003c/p\u003e","section_color":"#FFED92","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"77t50\",\"text\":\"The variable ‘WS’ is the most complicated to create, as it requires you to think critically about the annotation layers you created. Inside of this variable, you will define how to order your layers, whether to combine layers, and whether to keep or remove whitespace from your layers. For simplicity, WS is split into four components:\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":14,\"length\":2},{\"style\":\"bold\",\"offset\":302,\"length\":2}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":97509,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"23","cases":[],"critical":null},{"id":1997103,"guid":"C1B200B87BB04115A5947764653C7BA3","previous_id":1997100,"previous_guid":"4AC9C4315C7D4304A2E208F69C8C1686","section":"","section_color":"","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"bt3fb\",\"text\":\"add_whitespace_to is a matrix of size [1 2]. The first number defines the annotation layer to add whitespace to when it was removed from another class (where annotation_whitespace = 0) – this is usually the background class. The second number defines the annotation layer to add nonwhitespace to when it is removed from another class (where annotation_whitespace=1) – this is usually the stroma class. For example, for the four classes listed above, add whitespace to class 6 (background), and add nonwhitespace to class 6 (also background as this is not applicable to this model).\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":17},{\"style\":\"bold\",\"offset\":158,\"length\":21},{\"style\":\"bold\",\"offset\":341,\"length\":21}],\"entityRanges\":[],\"data\":{}},{\"key\":\"e1b1m\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"caaks\",\"text\":\"add_whitespace_to=[6 6];\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":24}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":97509,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"25","cases":[],"critical":null},{"id":1997104,"guid":"F7F11C8556684633972253F058ACCA7C","previous_id":1997103,"previous_guid":"C1B200B87BB04115A5947764653C7BA3","section":null,"section_color":null,"section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"3mdkb\",\"text\":\"nesting_order is a matrix of size [1 N] where N is the number of annotation layers you created in ImageScope. This variable allows you to define how overlapping annotations should be processed. Numbers on the left side of this variable are ‘below’ annotations listed to the right of them. For example, in the example above, we annotated a bronchiole inside of an alveolar annotation. This means bronchioles must be ‘above’ alveoli in the nesting order. Let’s assume that stroma is the ‘bottom layer,’ followed by alveoli, nonexpanded tissue, cancer, vasculature, bronchioles, and background. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":13}],\"entityRanges\":[],\"data\":{}},{\"key\":\"6jdq3\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"8d3t8\",\"text\":\"nesting_order=[7 2 5 4 3 1 6]; % stroma, alveoli, nonexpanded, cancer, vessels, bronch., backgrd\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":31}],\"entityRanges\":[],\"data\":{}},{\"key\":\"np7m\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"1ein2\",\"text\":\"In contrast, if none of your annotations overlap, nesting_order can be sequential:\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"c6hvv\",\"text\":\"nesting_order=[1 2 3 4 5]; % no particular nesting order\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":27}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":97509,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"26","cases":[],"critical":null},{"id":1997105,"guid":"9B376F40802040798E984F3678817C8B","previous_id":1997104,"previous_guid":"F7F11C8556684633972253F058ACCA7C","section":"","section_color":null,"section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"ct0ql\",\"text\":\"combine_classes is a matrix of size [1 N] where N is the number of annotation layers you created in ImageScope. This variable allows you to re-order or combine multiple classes. For example, if you originally annotate the seven classes listed above but decide to combine the alveoli and nonexpanded tissue classes your variable would look like:\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":15}],\"entityRanges\":[],\"data\":{}},{\"key\":\"1e9uq\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"esft6\",\"text\":\"combine_classes=[1 2 3 4 2 5 6];\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":32}],\"entityRanges\":[],\"data\":{}},{\"key\":\"1tilv\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"fmb9g\",\"text\":\"You now will create a deep learning model that has only 6 classes.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":97509,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"27","cases":[],"critical":null},{"id":1997106,"guid":"3446B8C49ED046AD9874559A634FE5C0","previous_id":1997108,"previous_guid":"E182510CB14A4AAE8C4519C72B79751B","section":"","section_color":null,"section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"7clon\",\"text\":\"Finally, create variables defining the names and RGB colors for the final tissue structures in your model. In our sample model, we have four classes (after we combined the classes fat and background using\\nthe combine_classes variable). For this, we define classNames and cmap. ClassNames is a string variable containing the names of each class. Note this variable cannot contain spaces in names, use\\nunderscore instead (“blood_vessels” instead of “blood vessels”). \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"54c30\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"52sd8\",\"text\":\"classNames=[\\\"bronchioles\\\",\\\"alveoli\\\",\\\"vasculature\\\",\\\"cancer\\\",\\\"nonexpanded\\\",\\\"whitespace\\\",\\\"stroma\\\"];\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":96}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":97509,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"29","cases":[],"critical":null},{"id":1997108,"guid":"E182510CB14A4AAE8C4519C72B79751B","previous_id":1997105,"previous_guid":"9B376F40802040798E984F3678817C8B","section":"","section_color":null,"section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"cg1ds\",\"text\":\"These four defined variables will be combined into the variable ‘WS’ in MATLAB.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":65,\"length\":2}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":97509,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"28","cases":[],"critical":null},{"id":1997114,"guid":"2DA2324157014526975B3AD3092CD099","previous_id":1997106,"previous_guid":"3446B8C49ED046AD9874559A634FE5C0","section":"","section_color":null,"section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"bpjh6\",\"text\":\"cmap is a matrix of size [N 3] for N final classes in your deep learning model. Each row of this matrix defines the RGB color of one class of your deep learning model in 8-bit space. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"cqlc9\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"4a38o\",\"text\":\"For example:\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"3o5c4\",\"text\":\"cmap=[150 099 023;...     % 1  bronchioles  (brown)\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":26}],\"entityRanges\":[],\"data\":{}},{\"key\":\"2eriu\",\"text\":\"     \\n023 080 150;...     % 2  alveoli     (dark blue)\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":26}],\"entityRanges\":[],\"data\":{}},{\"key\":\"a6fn5\",\"text\":\"     \\n150 031 023;...     % 3  vasculature (dark red)\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":25}],\"entityRanges\":[],\"data\":{}},{\"key\":\"4ifop\",\"text\":\"     \\n199 196 147;...     % 4  cancer      (v dark purple)\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":23}],\"entityRanges\":[],\"data\":{}},{\"key\":\"cqei6\",\"text\":\"     \\n023 080 150;...     % 5  nonexpanded (dark blue)\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":26}],\"entityRanges\":[],\"data\":{}},{\"key\":\"1cpq3\",\"text\":\"     \\n255 255 255;...     % 6  whitespace  (white)\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":25}],\"entityRanges\":[],\"data\":{}},{\"key\":\"33n1\",\"text\":\"     \\n242 167 227];...    % 7  collagen   (light pink)\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":26}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":97509,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"30","cases":[],"critical":null},{"id":1997115,"guid":"7EF75AED586644F691CB53D9CF131194","previous_id":1997114,"previous_guid":"2DA2324157014526975B3AD3092CD099","section":"","section_color":null,"section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"7gmvn\",\"text\":\"With these inputs, you are ready to train your model. If you call the function train_image_segmentation, this will train a deep learning model (saved in a folder inside pthannotations), test that model using the annotations inside pthannotations_test and will classify the images in the folder pthclassify. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":79,\"length\":24},{\"style\":\"bold\",\"offset\":169,\"length\":14},{\"style\":\"bold\",\"offset\":231,\"length\":19},{\"style\":\"bold\",\"offset\":294,\"length\":11}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":97509,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"31","cases":[],"critical":null},{"id":1997116,"guid":"7A881403DA1F45D08228138515E655A1","previous_id":1997115,"previous_guid":"7EF75AED586644F691CB53D9CF131194","section":"","section_color":null,"section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"a6ftg\",\"text\":\"If you do not receive satisfactory results, add additional annotations (either entirely new training images or additional annotations on the same training images) until satisfactory results are achieved.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":97509,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"32","cases":[],"critical":null},{"id":1997118,"guid":"D43E9674608941148AC62A11203A9BFF","previous_id":1997116,"previous_guid":"7A881403DA1F45D08228138515E655A1","section":"","section_color":null,"section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"4tcqi\",\"text\":\"The workflow in this section will create a subfolder inside pthannotations containing the trained deep learning model and training tiles. These tiles can take up large amounts of disk space, so delete them (but keep your model inside the folder ‘net.mat’). \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":60,\"length\":14}],\"entityRanges\":[],\"data\":{}},{\"key\":\"a0a2v\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"dumng\",\"text\":\"pthmodel=[pthannotations,nm];\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":29}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":97509,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"33","cases":[],"critical":null},{"id":1997119,"guid":"C15EB528FA164007BCA8F3695D0CB09C","previous_id":1997118,"previous_guid":"D43E9674608941148AC62A11203A9BFF","section":"","section_color":null,"section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"q11m\",\"text\":\"This workflow will also create a subfolder inside the high-resolution tif image path named [‘classification_’,nm], where nm is the date of the deep learning model training. Inside this subfolder will be the segmented, high-resolution tif images. \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":91,\"length\":22}],\"entityRanges\":[],\"data\":{}},{\"key\":\"8uoeg\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"f0jec\",\"text\":\"pthclassified=[pth10x,'classification_',nm];\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":44}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":97509,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"34","cases":[],"critical":null},{"id":1997120,"guid":"267FC488746B49B994C8A458F6FDB162","previous_id":1997119,"previous_guid":"C15EB528FA164007BCA8F3695D0CB09C","section":"","section_color":null,"section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"am2dt\",\"text\":\"Inside of this subfolder will be a second folder named ‘check_classification,’ containing color-labelled versions of the classified files. These colorized classified images are handy for visualization of the results and qualitative validation of model performance across the dataset.       \",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":56,\"length\":20}],\"entityRanges\":[],\"data\":{}},{\"key\":\"floor\",\"text\":\"\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}},{\"key\":\"3806f\",\"text\":\"pthcheckclassification=[pth10x,'classification_',nm,'check_classification'];\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[{\"style\":\"bold\",\"offset\":0,\"length\":76}],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":97509,"case_id":0,"critical_ids":"","duration":0,"original_id":0,"number":"35","cases":[],"critical":null}],"template_id":0,"title":"CODA (part 3): deep learning tissue structures labeling | HuBMAP | JHU-TMC","title_html":"CODA (part 3): deep learning tissue structures labeling | HuBMAP | JHU-TMC","type_id":1,"units":[{"id":1,"type_id":3,"name":"µL","can_manage":0,"read_only":0},{"id":2,"type_id":3,"name":"mL","can_manage":0,"read_only":0},{"id":3,"type_id":3,"name":"L","can_manage":0,"read_only":0},{"id":4,"type_id":3,"name":"µg","can_manage":0,"read_only":0},{"id":5,"type_id":3,"name":"mg","can_manage":0,"read_only":0},{"id":6,"type_id":3,"name":"g","can_manage":0,"read_only":0},{"id":7,"type_id":3,"name":"kg","can_manage":0,"read_only":0},{"id":8,"type_id":3,"name":"ng","can_manage":0,"read_only":0},{"id":9,"type_id":3,"name":"Hz","can_manage":0,"read_only":0},{"id":10,"type_id":24,"name":"°C","can_manage":0,"read_only":0},{"id":11,"type_id":24,"name":"°К","can_manage":0,"read_only":0},{"id":12,"type_id":24,"name":"°F","can_manage":0,"read_only":0},{"id":13,"type_id":25,"name":"Mass Percent","can_manage":0,"read_only":0},{"id":14,"type_id":25,"name":"% volume","can_manage":0,"read_only":0},{"id":15,"type_id":25,"name":"Mass / % volume","can_manage":0,"read_only":0},{"id":16,"type_id":25,"name":"Parts per Million (PPM)","can_manage":0,"read_only":0},{"id":17,"type_id":25,"name":"Parts per Billion (PPB)","can_manage":0,"read_only":0},{"id":18,"type_id":25,"name":"Parts per Trillion (PPT)","can_manage":0,"read_only":0},{"id":19,"type_id":25,"name":"Mole Fraction","can_manage":0,"read_only":0},{"id":20,"type_id":25,"name":"Mole Percent","can_manage":0,"read_only":0},{"id":21,"type_id":25,"name":"Molarity (M)","can_manage":0,"read_only":1},{"id":22,"type_id":25,"name":"Molarity (M)","can_manage":0,"read_only":0},{"id":23,"type_id":25,"name":"Genome copies per ml","can_manage":0,"read_only":0},{"id":24,"type_id":3,"name":"μV","can_manage":0,"read_only":0},{"id":25,"type_id":3,"name":"ms","can_manage":0,"read_only":0},{"id":26,"type_id":3,"name":"pg","can_manage":0,"read_only":0},{"id":27,"type_id":25,"name":"Molarity dilutions","can_manage":0,"read_only":0},{"id":28,"type_id":25,"name":"millimolar (mM)","can_manage":0,"read_only":0},{"id":29,"type_id":25,"name":"micromolar (µM)","can_manage":0,"read_only":0},{"id":30,"type_id":25,"name":"nanomolar (nM)","can_manage":0,"read_only":0},{"id":31,"type_id":25,"name":"picomolar (pM)","can_manage":0,"read_only":0},{"id":32,"type_id":24,"name":"Room temperature","can_manage":0,"read_only":0},{"id":33,"type_id":30,"name":"rpm","can_manage":0,"read_only":0},{"id":34,"type_id":30,"name":"x g","can_manage":0,"read_only":0},{"id":165,"type_id":24,"name":"On ice","can_manage":0,"read_only":0},{"id":200,"type_id":32,"name":"cm","can_manage":0,"read_only":0},{"id":201,"type_id":32,"name":"mm","can_manage":0,"read_only":0},{"id":202,"type_id":32,"name":"µm","can_manage":0,"read_only":0},{"id":203,"type_id":32,"name":"nm","can_manage":0,"read_only":0},{"id":204,"type_id":25,"name":"mg/mL","can_manage":0,"read_only":0},{"id":205,"type_id":25,"name":"µg/µL","can_manage":0,"read_only":0},{"id":206,"type_id":25,"name":"% (v/v)","can_manage":0,"read_only":0},{"id":207,"type_id":3,"name":"V","can_manage":0,"read_only":0},{"id":1324,"type_id":30,"name":"rcf","can_manage":0,"read_only":0},{"id":1359,"type_id":35,"name":"Bar","can_manage":0,"read_only":0},{"id":1360,"type_id":35,"name":"Pa","can_manage":0,"read_only":0}],"uri":"coda-part-3-deep-learning-tissue-structures-labeli-dbgd2js6","url":"https://www.protocols.io/view/coda-part-3-deep-learning-tissue-structures-labeli-dbgd2js6","version_class":97509,"version_data":{"id":0,"code":"dbgd2js6","version_class":97509,"parent_id":null,"parent_uri":null,"is_same_owner":false,"is_parent_public":false,"has_pending_merge_request":false,"has_approved_merge_request":false,"merge_request":null},"version_id":0,"version_uri":"coda-part-3-deep-learning-tissue-structures-labeli-81wgbz1x3gpk/v1","versions":[{"id":97509,"title":"CODA (part 3): deep learning tissue structures labeling | HuBMAP | JHU-TMC","title_html":"CODA (part 3): deep learning tissue structures labeling | HuBMAP | JHU-TMC","image":{"source":"https://www.protocols.io/img/default_protocol.png","webp_source":null,"placeholder":"https://www.protocols.io/img/default_protocol.png","webp_placeholder":null},"doi":"dx.doi.org/10.17504/protocols.io.81wgbz1x3gpk/v1","uri":"coda-part-3-deep-learning-tissue-structures-labeli-dbgd2js6","published_on":1712006469,"modified_on":1712006469,"version_class":97509,"version_id":0,"version_code":"dbgd2js6","version_uri":"coda-part-3-deep-learning-tissue-structures-labeli-81wgbz1x3gpk/v1","created_on":1711656986,"categories":null,"type_id":1,"creator":{"name":"Kyu Sang Han","affiliation":"Johns Hopkins University","affiliation_url":"","username":"kyu-sang-han","link":"","image":{"source":"https://content.protocols.io/files/p6x4b7aex.jpg","placeholder":"https://content.protocols.io/files/p6x4b7aex.jpg","webp_source":"https://content.protocols.io/files/p6x3b7aex.webp"}},"stats":{"number_of_comments":0,"last_comment_time":0}}],"warning":""}