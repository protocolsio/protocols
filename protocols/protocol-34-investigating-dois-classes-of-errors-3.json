{"id":49366,"title":"Protocol: \"Investigating DOIs classes of errors\" V.2","title_html":"<p>Protocol: &quot;Investigating DOIs classes of errors&quot; V.2<\/p>","image":{"source":"https:\/\/www.protocols.io\/img\/default_protocol.png","placeholder":"https:\/\/www.protocols.io\/img\/default_protocol.png"},"doi":"dx.doi.org\/10.17504\/protocols.io.bufwntpe","doi_status":2,"uri":"protocol-34-investigating-dois-classes-of-errors-3-bufwntpe","type_id":1,"template_id":5,"published_on":1619554164,"parent_protocols":[],"parent_collections":[],"cited_protocols":[],"version_id":2,"version_data":{"id":"2","code":"bufwntpe","parent_id":49085,"parent_uri":"investigating-dois-39-classes-of-errors-bt65nrg6","is_same_owner":true,"has_pending_merge_request":false,"has_approved_merge_request":true},"created_on":1619172367,"modified_on":null,"categories":null,"public":1,"is_unlisted":0,"creator":{"name":"Arcangelo Massari","affiliation":null,"affiliations":[],"username":"m4vle152w1s4ple1","note":null,"link":null,"image":{"source":"\/img\/avatars\/010.png","placeholder":"\/img\/avatars\/010.png"},"badges":[{"id":2,"image":{"source":"\/img\/badges\/bronze.svg","placeholder":"\/img\/badges\/bronze.svg"},"name":"Author"}],"verified":0,"is_verified_user":false,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},"journal":null,"journal_name":null,"journal_link":null,"article_citation":null,"has_versions":0,"link":null,"total_collections":0,"number_of_steps":10,"authors":[{"name":"Ricarda Boente","affiliation":"University of Bologna","affiliations":[],"username":"m4vle152w1s4vle1","note":null,"link":null,"image":{"source":"\/img\/avatars\/005.png","placeholder":"\/img\/avatars\/005.png"},"badges":[],"verified":1,"is_verified_user":true,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},{"name":"Deniz Tural","affiliation":"University of Bologna","affiliations":[],"username":"m4vle152x1v4qle1","note":null,"link":null,"image":{"source":"\/img\/avatars\/008.png","placeholder":"\/img\/avatars\/008.png"},"badges":[],"verified":1,"is_verified_user":true,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},{"name":"Cristian Santini","affiliation":"University of Bologna","affiliations":[],"username":"m4vle152x1u4yle1","note":null,"link":null,"image":{"source":"\/img\/avatars\/001.png","placeholder":"\/img\/avatars\/001.png"},"badges":[],"verified":1,"is_verified_user":true,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},{"name":"Arcangelo Massari","affiliation":"University of Bologna","affiliations":[],"username":"m4vle152w1s4ple1","note":null,"link":null,"image":{"source":"\/img\/avatars\/010.png","placeholder":"\/img\/avatars\/010.png"},"badges":[],"verified":1,"is_verified_user":true,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false}],"versions":[],"groups":[{"id":22817,"uri":"open-science-20202021","title":"Open Science 2020\/2021","image":{"source":"https:\/\/www.protocols.io\/img\/group_placeholder.png","placeholder":"https:\/\/www.protocols.io\/img\/group_placeholder.png"},"tech_support":{"email":null,"phone":null,"hide_contact":0,"use_email":0,"url":null},"is_member":1,"request":{"id":22817,"uri":"open-science-20202021","title":"Open Science 2020\/2021","image":{"source":"https:\/\/www.protocols.io\/img\/group_placeholder.png","placeholder":"https:\/\/www.protocols.io\/img\/group_placeholder.png"},"tech_support":{"email":null,"phone":null,"hide_contact":0,"use_email":0,"url":null},"is_member":1,"description":null,"research_interests":null,"website":null,"location":null,"affiliation":null,"status":{"is_visible":true,"access_level":0},"stats":{"files":[],"total_members":0,"total_followers":0,"total_child_groups":0,"total_parent_groups":0,"has_collaborations":0},"user_status":{"is_member":true,"is_confirmed":true,"is_invited":false,"is_owner":false,"is_admin":false,"is_following":false},"join_link":null,"token":null,"owner":{"name":" ","affiliation":null,"affiliations":[],"username":null,"note":null,"link":null,"image":{"source":null,"placeholder":null},"badges":[],"verified":0,"is_verified_user":false,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},"is_protocol_requested":0,"is_group_requested":0,"is_my":false,"is_request":false,"is_confirmed":1,"is_declined":0,"requester":{"name":" ","affiliation":null,"affiliation_url":null,"username":null,"link":null},"protocol":{"id":0,"title":"Protocol: \"Investigating DOIs classes of errors\" V.2","title_html":"Protocol: &#34;Investigating DOIs classes of errors&#34; V.2","image":{"source":null,"placeholder":null},"doi":null,"doi_status":0,"uri":"protocol-34-investigating-dois-classes-of-errors-3-bufwntpe","type_id":1,"template_id":0,"published_on":null,"stats":{"number_of_views":0,"number_of_steps":0,"number_of_bookmarks":0,"number_of_comments":0,"number_of_exports":0,"number_of_runs":0,"number_of_votes":0,"is_voted":0},"parent_protocols":[],"parent_collections":[],"cited_protocols":[]},"created_on":1618332389,"resolve_on":0,"resolved_user":{"name":" ","affiliation":null,"affiliations":[],"username":null,"note":null,"link":null,"image":{"source":null,"placeholder":null},"badges":[],"verified":0,"is_verified_user":false,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},"shared":false}}],"is_owner":1,"has_subprotocols":0,"is_subprotocol":0,"is_bookmarked":0,"can_claim_authorship":0,"can_accept_authorship":0,"can_be_copied":1,"can_remove_fork":1,"fork_id":null,"url":"https:\/\/www.protocols.io\/view\/protocol-34-investigating-dois-classes-of-errors-3-bufwntpe","forks_count":{"private":0,"public":0},"access":{"can_view":1,"can_remove":0,"can_add":0,"can_edit":0,"can_publish":0,"can_get_doi":0,"can_share":1,"can_move":1,"can_move_outside":1,"can_transfer":1,"can_download":1,"is_locked":0},"guid":"010B57F50B5B480F8287588126509A2C","state_version_id":3396,"steps":[{"id":1166289,"guid":"77B85121681A4FB9A97184843141FC47","previous_id":null,"previous_guid":null,"modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"E9C8EDAB5CC646B19C9192422F6689A6","order_id":1,"type_id":6,"title":"Section","source":{"title":"DATA IMPORT"}},{"id":1054724,"guid":"6A79940B1B7C49F89C4328F45110AD73","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\"><span>We import a CSV containing invalid DOI-to-DOI citations. The CSV is provided on public license by Peroni, Silvio. (2021). Citations to invalid DOI-identified entities obtained from processing DOI-to-DOI citations to add in COCI (Version 1.0) [Data set]. <\/span><span style = \"font-style:italic;\">Zenodo<\/span><span>. <\/span><\/div><div class = \"text-block\"><a href=\"http:\/\/doi.org\/10.5281\/zenodo.4625300\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">http:\/\/doi.org\/10.5281\/zenodo.4625300<\/span><\/a><\/div><div class = \"text-block\">. <\/div><div class = \"text-block\">The CSV is organized as follows: the first column contains valid citing DOIs and the second contains invalid cited DOIs.<\/div><\/div>"}},{"id":1054725,"guid":"AD3AB2009AE711EBB6547342859BDF69","order_id":2,"type_id":9,"title":"dataset","source":{"name":"Citations to invalid DOIs obtained from Crossref","link":"https:\/\/zenodo.org\/record\/4625300\/files\/invalid_dois.csv"}},{"id":1054726,"guid":"53C2D0742B6B413DA15BF167F490860D","order_id":3,"type_id":26,"title":"notes","source":{"id":0,"parent_id":0,"uri":"","title":"","body":"<div class = \"text-blocks\"><table border><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.14778\/1920841.1920954<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.5555\/646836.708343\t<\/td><\/tr><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.5406\/ethnomusicology.59.2.0202\t<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.2307\/20184517\t<\/td><\/tr><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.1161\/01.cir.63.6.1391\t<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.1161\/circ.37.4.509\t<\/td><\/tr><\/table><\/div>","created_on":0,"changed_on":0,"creator":{"name":" ","affiliation":null,"affiliations":[],"username":"","note":null,"link":null,"image":{"source":"","placeholder":""},"badges":[],"verified":0,"is_verified_user":false,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},"comments":[]}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#A492FF","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1166291,"guid":"E25D242134F44BE7AD5F1A87DC8B9F87","previous_id":1166289,"previous_guid":"77B85121681A4FB9A97184843141FC47","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"2112967A81C144B2819E38C10A30B104","order_id":1,"type_id":6,"title":"Section","source":{"title":"ERROR ANALYSIS"}},{"id":1054724,"guid":"9CA9579E04A641E088CA76DF55798308","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Taking as a reference the DOI error's taxonomy proposed in \"Errors in DOI indexing by bibliometric databases\" (<\/div><div class = \"text-block\"><a href=\"https:\/\/doi.org\/10.1007\/s11192-014-1503-4\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">Franceschini et al. 2015<\/span><\/a><\/div><div class = \"text-block\">), there are two main classes of errors: author errors, made by authors when creating the list of cited articles for their publication, and database mapping errors, related to a data-entry error. This protocol deals only with the second kind of error, which can be further divided between prefix errors, suffix errors, and other-type errors, as proposed in \"DOI errors and possible solutions for Web of Science\" (<\/div><div class = \"text-block\"><a href=\"https:\/\/doi.org\/10.1007\/s11192-019-03162-4\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">Xu et al., 2019<\/span><\/a><\/div><div class = \"text-block\">). In order to solve our problem, we manually isolated from a subset of 100 DOIs recurrent strings at the beginning and at the end with corrupted DOI prefix and suffix respectively. In addition, we found other types of errors, like double underscores, double periods, XML tags, spaces, and forward slashes that could be removed at the end of the data cleaning process. <\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#94EBFF","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1166292,"guid":"B9CB1D26C53C45D7A648C80E7F5D3780","previous_id":1166323,"previous_guid":"B2126B80A42C11EB9F862D175D1030F2","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"832D84B3B6204A33B5021BF344FF912C","order_id":1,"type_id":6,"title":"Section","source":{"title":"DATA CLEANING PROCEDURE"}},{"id":1054724,"guid":"5161C96A9B8F46078B889EE672FBF8AA","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Here we describe the steps through which we carried out the cleaning procedure of factually invalid DOIs. <\/div><div class = \"text-block\">The workflow of our procedure is organized as follows:<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/files\/de5jbjqap.jpg\" \/><\/div><div class = \"text-block\">We created a Python software for handling the whole procedure. The source code is publicly available on ISC license at <\/div><div class = \"text-block\"><a href=\"http:\/\/doi.org\/10.5281\/zenodo.4723984\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">http:\/\/doi.org\/10.5281\/zenodo.4723984<\/span><\/a><\/div><div class = \"text-block\">. <\/div><div class = \"text-block\"><span>For our data cleaning system, we devised two class objects: one called <\/span><span style = \"font-weight:bold;\">class<\/span><span style = \"font-weight:bold;font-weight:bold;\"> <\/span><span style = \"font-weight:bold;\">Clean_DOIs()<\/span><span>, with all the methods required to carry our cleaning\/validation procedure, and <\/span><span style = \"font-weight:bold;\">class Support()<\/span><span>, with all the methods required to process and dump CSV as well as carry HTTP requests. In this protocol, we describe the use of the different methods that can be imported from our classes. If you want to reproduce the procedure described in the next step, once you have verified to have Python 3.x installed and the required libraries, you can clone our Github repository and launch the <\/span><span style = \"font-style:italic;\">tutorial.py <\/span><span>file in a terminal inside the folder or you can execute the commands listed in the following sub-sections.<\/span><\/div><\/div>"}},{"id":1054725,"guid":"713D8F86D0E44EDAB7D8AB3B2B42813E","order_id":2,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/files\/de5jbjqap.jpg\" \/><\/div>"}},{"id":1054726,"guid":"5F1858B0A50611EB873D85B4C91630DC","order_id":3,"type_id":15,"title":"command","source":{"id":8744,"name":"python tutorial.py","command_name":"Launch tutorial.py","command":null,"os_name":"","os_version":null}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#84CE84","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1166293,"guid":"049A5C391C62497BBF61D1BC1C121511","previous_id":1166883,"previous_guid":"B59188A0A50711EB873D85B4C91630DC","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"6B4171C0FB844CA1A5789887CA698E47","order_id":1,"type_id":6,"title":"Section","source":{"title":"DATA CLEANING PROCEDURE"}},{"id":1054724,"guid":"0FADFC0648E14B7B9B36DC290ED1B775","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\"><span>Our procedure first checks for each cited DOI if it is factually invalid or it has become valid in the meanwhile. For this purpose, we use the function <\/span><span style = \"font-weight:bold;\">check_dois_validity()<\/span><span style = \"font-weight:bold;font-weight:bold;\">,<\/span><span style = \"font-weight:bold;\"> <\/span><span>from our <\/span><span style = \"font-weight:bold;\">class Clean_DOIs()<\/span><span>, which takes in input a list of dictionaries like the one described above and does a GET request to the DOI Proxy with the cited DOI (<\/span><\/div><div class = \"text-block\"><a href=\"https:\/\/www.doi.org\/factsheets\/DOIProxy.html\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">https:\/\/www.doi.org\/factsheets\/DOIProxy.html<\/span><\/a><\/div><div class = \"text-block\"><span>) of each row of the CSV: if the status code corresponding to that specific DOI is different from 1, it means that it is not valid; otherwise, that DOI has become valid in the meanwhile. The function outputs an enriched version of the list of dictionaries in input, with two additional fields: <\/span><span style = \"font-style:italic;\">\"Valid_DOI\"<\/span><span>, which stores a validated DOI, and <\/span><span style = \"font-style:italic;\">\"Already_valid\"<\/span><span>, which stores 1 if it has become valid in the meanwhile, 0 otherwise.<\/span><\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">def check_dois_validity(self, data:list) -> list:<\/div><div class = \"text-block\">        checked_dois = list()<\/div><div class = \"text-block\">        pbar = tqdm(total=len(data))<\/div><div class = \"text-block\">        for row in data:<\/div><div class = \"text-block\">            invalid_dictionary = {<\/div><div class = \"text-block\">                \"Valid_citing_DOI\": row[\"Valid_citing_DOI\"],<\/div><div class = \"text-block\">                \"Invalid_cited_DOI\": row[\"Invalid_cited_DOI\"], <\/div><div class = \"text-block\">                \"Valid_DOI\": \"\",<\/div><div class = \"text-block\">                \"Already_valid\": 0<\/div><div class = \"text-block\">            }<\/div><div class = \"text-block\"><span>            handle = Support().handle_request(url=f\"<\/span><a href=\"https:\/\/doi.org\/api\/handles\/{row['Invalid_cited_DOI']}\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">https:\/\/doi.org\/api\/handles\/{row['Invalid_cited_DOI']}<\/span><\/a><span>\", cache_path=self.cache_path, error_log_dict=self.logs)<\/span><\/div><div class = \"text-block\">            if handle is not None:<\/div><div class = \"text-block\">                if handle[\"responseCode\"] == 1:<\/div><div class = \"text-block\">                    checked_dois.append(<\/div><div class = \"text-block\">                        {\"Valid_citing_DOI\": row[\"Valid_citing_DOI\"],<\/div><div class = \"text-block\">                        \"Invalid_cited_DOI\": row[\"Invalid_cited_DOI\"], <\/div><div class = \"text-block\">                        \"Valid_DOI\": row['Invalid_cited_DOI'],<\/div><div class = \"text-block\">                        \"Already_valid\": 1<\/div><div class = \"text-block\">                        })<\/div><div class = \"text-block\">                else:<\/div><div class = \"text-block\">                    checked_dois.append(invalid_dictionary)       <\/div><div class = \"text-block\">            else:<\/div><div class = \"text-block\">                checked_dois.append(invalid_dictionary)             <\/div><div class = \"text-block\">            pbar.update(1)<\/div><div class = \"text-block\">        pbar.close()<\/div><div class = \"text-block\">        return checked_dois<\/div><\/div><\/code><\/pre><\/div><div class = \"text-block\"><span>For performing the HTTP request, the function uses the <\/span><span style = \"font-weight:bold;\">handle_request()<\/span><span> method of the <\/span><span style = \"font-weight:bold;\">class Support()<\/span><span style = \"font-weight:bold;\">.<\/span><\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">def _requests_retry_session(<\/div><div class = \"text-block\">        self,<\/div><div class = \"text-block\">        tries=1,<\/div><div class = \"text-block\">        status_forcelist=(500, 502, 504, 520, 521),<\/div><div class = \"text-block\">        session=None<\/div><div class = \"text-block\">    ) -> Session:<\/div><div class = \"text-block\">        session = session or requests.Session()<\/div><div class = \"text-block\">        retry = Retry(<\/div><div class = \"text-block\">            total=tries,<\/div><div class = \"text-block\">            read=tries,<\/div><div class = \"text-block\">            connect=tries,<\/div><div class = \"text-block\">            status_forcelist=status_forcelist,<\/div><div class = \"text-block\">        )<\/div><div class = \"text-block\">        adapter = HTTPAdapter(max_retries=retry)<\/div><div class = \"text-block\"><span>        session.mount('<\/span><a href=\"http:\/\/',\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">http:\/\/',<\/span><\/a><span> adapter)<\/span><\/div><div class = \"text-block\"><span>        session.mount('<\/span><a href=\"https:\/\/',\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">https:\/\/',<\/span><\/a><span> adapter)<\/span><\/div><div class = \"text-block\">        return session<\/div><div class = \"text-block\">def handle_request(self, url:str, cache_path:str=\"\", error_log_dict:dict=dict()):<\/div><div class = \"text-block\">        if cache_path != \"\":<\/div><div class = \"text-block\">            requests_cache.install_cache(cache_path)<\/div><div class = \"text-block\">        try:<\/div><div class = \"text-block\">            data = self._requests_retry_session().get(url, timeout=10)<\/div><div class = \"text-block\">            if data.status_code == 200:<\/div><div class = \"text-block\">                return data.json()<\/div><div class = \"text-block\">            else:<\/div><div class = \"text-block\">                error_log_dict[url] = data.status_code<\/div><div class = \"text-block\">        except Exception as e:<\/div><div class = \"text-block\">            error_log_dict[url] = str(e)<\/div><\/div><\/code><\/pre><\/div><div class = \"text-block\"><span>In our procedure we applied our <\/span><span style = \"font-weight:bold;\">check_dois_validity() <\/span><span>function to our <\/span><span style = \"font-weight:bold;\"><data><\/span><span> and we store the results in a <\/span><span style = \"font-weight:bold;\"><checked_dois><\/span><span> variable:<\/span><\/div><div class = \"text-block\"><span>This is how the <\/span><span style = \"font-weight:bold;\"><checked_dois><\/span><span> variable appears:<\/span><\/div><\/div>"}},{"id":1054725,"guid":"CDEB1310A76611EBB340838B39CCBF73","order_id":2,"type_id":15,"title":"command","source":{"id":8750,"name":">>> checked_dois=clean_dois.check_dois_validity(data=data)","command_name":"","command":null,"os_name":null,"os_version":null}},{"id":1054726,"guid":"A9772741AD4140E0A8387D95FE055637","order_id":3,"type_id":17,"title":"result","source":{"body":"<div class = \"text-blocks\"><div class = \"text-block\">[{\"Valid_citing_DOI\": \"10.1007\/s11771-020-4410-2\", \"Invalid_cited_DOI\": \"10.13745\/j.esf.2016.02.011\", \"Valid_DOI\": \"10.13745\/j.esf.2016.02.011\", Already_valid\": 1},<\/div><div class = \"text-block\">...]<\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#84CE84","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1166294,"guid":"E8E9AD0E09B943408E41374AB4E08359","previous_id":1166293,"previous_guid":"049A5C391C62497BBF61D1BC1C121511","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"D44BAC331C0247A1B1A538ABDF4A655B","order_id":1,"type_id":6,"title":"Section","source":{"title":"DATA CLEANING PROCEDURE"}},{"id":1054724,"guid":"49637762CA5D4BC3BA53FD27A35FBFE9","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\"><span>We then pass the <\/span><span style = \"font-weight:bold;\"><checked_dois><\/span><span> executed by the previous function to another function called <\/span><span style = \"font-weight:bold;\">procedure()<\/span><span> aimed to clean the DOIs with the regular expressions described above and to verify the validity of the cleaned DOI.<\/span><\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">def clean_doi(self, doi:str) -> str:<\/div><div class = \"text-block\">        tmp_doi = doi.upper().replace(\" \", \"\")<\/div><div class = \"text-block\">        prefix_match = re.search(self.prefix_regex, tmp_doi)<\/div><div class = \"text-block\">        classes_of_errors = {<\/div><div class = \"text-block\">            \"prefix\": 0,<\/div><div class = \"text-block\">            \"suffix\": 0,<\/div><div class = \"text-block\">            \"other-type\": 0<\/div><div class = \"text-block\">        }<\/div><div class = \"text-block\">        if prefix_match:<\/div><div class = \"text-block\">            tmp_doi = prefix_match.group(1)<\/div><div class = \"text-block\">            classes_of_errors[\"prefix\"] += 1<\/div><div class = \"text-block\">        suffix_match = re.search(self.suffix_regex, tmp_doi)<\/div><div class = \"text-block\">        if suffix_match:<\/div><div class = \"text-block\">            tmp_doi = suffix_match.group(1)<\/div><div class = \"text-block\">            classes_of_errors[\"suffix\"] += 1<\/div><div class = \"text-block\">        new_doi = re.sub(\"\\\\\\\\\", \"\", tmp_doi)<\/div><div class = \"text-block\">        new_doi = re.sub(\"__\", \"_\", tmp_doi)<\/div><div class = \"text-block\">        new_doi = re.sub(\"\\\\.\\\\.\", \".\", tmp_doi)<\/div><div class = \"text-block\">        new_doi = re.sub(\"<.*?>.*?\", \"\", tmp_doi)<\/div><div class = \"text-block\">        new_doi = re.sub(\"<.*?\/>\", \"\", tmp_doi)<\/div><div class = \"text-block\">        if new_doi != tmp_doi:<\/div><div class = \"text-block\">            classes_of_errors[\"other-type\"] += 1<\/div><div class = \"text-block\">        return new_doi, classes_of_errors<\/div><div class = \"text-block\">def procedure(self, data:list) -> list:<\/div><div class = \"text-block\">        output = list()<\/div><div class = \"text-block\">        pbar = tqdm(total=len(data))<\/div><div class = \"text-block\">        for row in data:<\/div><div class = \"text-block\">            invalid_doi = row[\"Invalid_cited_DOI\"]<\/div><div class = \"text-block\">            invalid_dictionary = {<\/div><div class = \"text-block\">                \"Valid_citing_DOI\": row[\"Valid_citing_DOI\"],<\/div><div class = \"text-block\">                \"Invalid_cited_DOI\": row[\"Invalid_cited_DOI\"],<\/div><div class = \"text-block\">                \"Valid_DOI\": row[\"Valid_DOI\"],<\/div><div class = \"text-block\">                \"Already_valid\": row[\"Already_valid\"],<\/div><div class = \"text-block\">                \"Prefix_error\": 0,<\/div><div class = \"text-block\">                \"Suffix_error\": 0,<\/div><div class = \"text-block\">                \"Other-type_error\": 0<\/div><div class = \"text-block\">            }<\/div><div class = \"text-block\">            if row[\"Already_valid\"] != 1:<\/div><div class = \"text-block\">                new_doi, classes_of_errors = self.clean_doi(row[\"Invalid_cited_DOI\"])<\/div><div class = \"text-block\">                valid_dictionary = {<\/div><div class = \"text-block\">                    \"Valid_citing_DOI\": row[\"Valid_citing_DOI\"],<\/div><div class = \"text-block\">                    \"Invalid_cited_DOI\": row[\"Invalid_cited_DOI\"],<\/div><div class = \"text-block\">                    \"Valid_DOI\": new_doi,<\/div><div class = \"text-block\">                    \"Already_valid\": row[\"Already_valid\"],<\/div><div class = \"text-block\">                    \"Prefix_error\": classes_of_errors[\"prefix\"],<\/div><div class = \"text-block\">                    \"Suffix_error\": classes_of_errors[\"suffix\"],<\/div><div class = \"text-block\">                    \"Other-type_error\": classes_of_errors[\"other-type\"]<\/div><div class = \"text-block\">                }<\/div><div class = \"text-block\">                if new_doi != row[\"Invalid_cited_DOI\"]:<\/div><div class = \"text-block\"><span>                    handle = Support().handle_request(url=f\"<\/span><a href=\"https:\/\/doi.org\/api\/handles\/{new_doi}\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">https:\/\/doi.org\/api\/handles\/{new_doi}<\/span><\/a><span>\", cache_path=self.cache_path, error_log_dict=self.logs)<\/span><\/div><div class = \"text-block\">                    if handle is not None:<\/div><div class = \"text-block\">                        output.append(valid_dictionary)<\/div><div class = \"text-block\">                    else:<\/div><div class = \"text-block\">                        output.append(invalid_dictionary)<\/div><div class = \"text-block\">                else:<\/div><div class = \"text-block\">                    output.append(invalid_dictionary)<\/div><div class = \"text-block\">            else:<\/div><div class = \"text-block\">                output.append(invalid_dictionary)<\/div><div class = \"text-block\">            pbar.update(1)<\/div><div class = \"text-block\">        pbar.close()<\/div><div class = \"text-block\">        return output<\/div><\/div><\/code><\/pre><\/div><div class = \"text-block\"><span>In our data cleaning procedure we store the output of the <\/span><span style = \"font-weight:bold;\">procedure() <\/span><span>function in the <\/span><span style = \"font-weight:bold;\"><output> <\/span><span>variable:<\/span><\/div><div class = \"text-block\"><span>For each cited DOI, the function <\/span><span style = \"font-weight:bold;\">procedure() <\/span><span>performs five actions:<\/span><\/div><div class = \"text-block\">1) it removes white spaces in the string<\/div><div class = \"text-block\">2) it applies the prefix regular expression to catch eventual unwanted characters that precede a DOI. If there's a match, the regular expression removes the unwanted characters and the DOI is replaced with the cleaned one.<\/div><div class = \"text-block\">3) it applies the suffix regular expressions as a list of alternative unwanted patterns that may occur at the end of the string. If there's a match, the regular expression removes the unwanted characters and the DOI is replaced with the cleaned one.<\/div><div class = \"text-block\">4) finally, it removes eventual unwanted characters like double slashes, double points, xml tags and backward slashes.<\/div><div class = \"text-block\"><span>5) Finally the algorithm checks if the cited DOI after the cleaning procedure is different from the one in <\/span><span style = \"font-weight:bold;\"><checked_dois> <\/span><span>and it also checks if it is returned as valid by the DOI Handle API. If it is different and is validated by the DOI API, the algorithm stores the cleaned DOI in the \"<\/span><span style = \"font-style:italic;\">Valid_DOI\"  <\/span><span>field of the dictionary; if it is not different, the dictionary will store no new DOI.<\/span><\/div><div class = \"text-block\"><span>By applying <\/span><span style = \"font-weight:bold;\">procedure() <\/span><span>to our <\/span><span style = \"font-weight:bold;\"><checked_dois><\/span><span> we obtain a list of dictionaries containing 7 fields: the four already present in the input list (\"<\/span><span style = \"font-style:italic;\">Valid_citing_DOI\"<\/span><span style = \"font-weight:bold;font-style:italic;font-style:italic;\">,<\/span><span style = \"font-weight:bold;font-style:italic;\"> <\/span><span style = \"font-style:italic;\">\"Invalid_cited_DOI\"<\/span><span>, <\/span><span style = \"font-style:italic;\">\"Valid_DOI\", <\/span><span style = \"font-style:italic;font-style:italic;\">\"<\/span><span style = \"font-style:italic;\">Already_Valid\"<\/span><span>) and, in addition, <\/span><span style = \"font-style:italic;\">\"prefix_error\"<\/span><span>, <\/span><span style = \"font-style:italic;\">\"suffix_error\"<\/span><span>, <\/span><span style = \"font-style:italic;\">\"other-type<\/span><span style = \"font-weight:bold;font-style:italic;\">\"<\/span><span style = \"font-weight:bold;\"> <\/span><span>fields, which contain, for each cleaned DOI the number of errors that were cleaned. This is how the <\/span><span style = \"font-weight:bold;\"><output><\/span><span> variable looks like:<\/span><\/div><\/div>"}},{"id":1054725,"guid":"61909EF0A76711EBB340838B39CCBF73","order_id":2,"type_id":15,"title":"command","source":{"id":8752,"name":">>> output = clean_dois.procedure(data=checked_dois)","command_name":"","command":null,"os_name":null,"os_version":null}},{"id":1054726,"guid":"43E64212B4AB4C25BA54370E8C90DD7D","order_id":3,"type_id":17,"title":"result","source":{"body":"<div class = \"text-blocks\"><div class = \"text-block\">[{\"Valid_citing_DOI\": \"10.1007\/s40617-018-00299-1\", \"Invalid_cited_DOI\": \"10.1901\/jaba.2012.45-657\", \"Valid_DOI\": \"10.1901\/JABA.2012.45-657\", Already_valid\": 1, \"prefix_error\": 0, \"suffix_error\" 0:, \"other-type\": 0 }, <\/div><div class = \"text-block\">{\"Valid_citing_DOI\": \"10.1074\/jbc.m508416200\", \"Invalid_cited_DOI\": \"10.1059\/0003-4819-100-4-483\", \"Valid_DOI\": \"\", Already_valid\": 0, \"prefix_error\": 0, \"suffix_error\" 0:, \"other-type\": 0 }, <\/div><div class = \"text-block\">{\"Valid_citing_DOI\": \"10.1177\/2054358119836124\", \"Invalid_cited_DOI\": \"10.1016\/j.amepre.2015.07.017.\", \"Valid_DOI\": \"10.1016\/J.AMEPRE.2015.07.017\", Already_valid\": 0, \"prefix_error\": 0, \"suffix_error\" 1:, \"other-type\": 0 },<\/div><div class = \"text-block\">...]<\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#84CE84","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1166297,"guid":"8191B870CC60492097AB0B79E7511027","previous_id":1166331,"previous_guid":"0A095310A43411EB9F862D175D1030F2","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"7FFE35AAB4C7483F8E81C92285C746A3","order_id":1,"type_id":6,"title":"Section","source":{"title":"STATISTICS AND VISUALIZATION"}},{"id":1054724,"guid":"B20DB885BC074EC4AE67BBAD2DB01800","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Finally, a visualization was produced starting from the output file. For this purpose, d3.js v6.7.0, an open-source Javascript library for manipulating data-driven documents, was used. In particular, a barchart was created that compares the total number of DOIs with the number of valid DOIs after cleaning, the number of those that were already valid and the number of those that presented the various types of errors, i.e. errors of prefix, suffix and other-type. The barchart can be sorted in ascending or descending order and you can hover the mouse over the bars to view the exact represented value. It is possible to interact with the visualization at the following address: <\/div><div class = \"text-block\"><a href=\"https:\/\/open-sci.github.io\/2020-2021-grasshoppers-code\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">https:\/\/open-sci.github.io\/2020-2021-grasshoppers-code\/<\/span><\/a><\/div><div class = \"text-block\">. <\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#FFED92","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1166322,"guid":"51BBCAB0A42C11EB9F862D175D1030F2","previous_id":1166291,"previous_guid":"E25D242134F44BE7AD5F1A87DC8B9F87","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"F68AADFDC5B24E409A57873A603D4895","order_id":1,"type_id":6,"title":"Section","source":{"title":"ERROR ANALYSIS"}},{"id":1054724,"guid":"8ED836BD5C30433E8DC215FDC0D121EA","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\"><span>For cleaning <\/span><span style = \"font-weight:bold;\">prefix-type errors<\/span><span>, we took a modified version of the regular expression from (<\/span><\/div><div class = \"text-block\"><a href=\"https:\/\/doi.org\/10.1007\/s11192-019-03162-4\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">Xu et al., 2019<\/span><\/a><\/div><div class = \"text-block\">) in order to remove unwanted characters at the beginning of a DOI. The regular expression for matching prefix-type errors is the following:<\/div><\/div>"}},{"id":1054725,"guid":"1D438CDA683B49E09D8C8462BE986016","order_id":2,"type_id":26,"title":"notes","source":{"id":0,"parent_id":0,"uri":"","title":"","body":"<div class = \"text-blocks\"><div class = \"text-block\">\"(.*?)(?:\\.)?(?:HTTP:\\\/\\\/DX\\.D[0|O]I\\.[0|O]RG\\\/|HTTPS:\\\/\\\/D[0|O]I\\.[0|O]RG\\\/)(.*)\"<\/div><\/div>","created_on":0,"changed_on":0,"creator":{"name":" ","affiliation":null,"affiliations":[],"username":"","note":null,"link":null,"image":{"source":"","placeholder":""},"badges":[],"verified":0,"is_verified_user":false,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},"comments":[]}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#94EBFF","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1166323,"guid":"B2126B80A42C11EB9F862D175D1030F2","previous_id":1166322,"previous_guid":"51BBCAB0A42C11EB9F862D175D1030F2","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"A1C65D59999043EAB6FF477AEECBB887","order_id":1,"type_id":6,"title":"Section","source":{"title":"ERROR ANALYSIS"}},{"id":1054724,"guid":"8CE2D6D3D42B4995869FFFEAF0016FBC","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\"><span>For capturing <\/span><span style = \"font-weight:bold;\">suffix-type errors<\/span><span>, we enriched the approach provided by (<\/span><\/div><div class = \"text-block\"><a href=\"https:\/\/doi.org\/10.1007\/s11192-019-03162-4\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">Xu et al., 2019<\/span><\/a><\/div><div class = \"text-block\">) and we devised a set of 17 alternative suffix regular expressions. The regular expression are the following:<\/div><div class = \"text-block\">All the suffix regular expressions can be combined in a single regular expression by using alternation within a non-capturing group. This is how the regular expression for suffix-type errors looks like:<\/div><\/div>"}},{"id":1054725,"guid":"D6A1F3FB74F748C6B5A88AFC5A9CDA1A","order_id":2,"type_id":26,"title":"notes","source":{"id":0,"parent_id":0,"uri":"","title":"","body":"<div class = \"text-blocks\"><div class = \"text-block\">1) \"(.*?)(?:\\\/-\\\/DCSUPPLEMENTAL)$\"<\/div><div class = \"text-block\">2) \"(.*?)(?:SUPPINF[0|O](\\.)?)$\"<\/div><div class = \"text-block\">3) \"(.*?)(?:[\\.|\\(|,|;]?PMID:\\d+.*?)$\"<\/div><div class = \"text-block\">4) \"(.*?)(?:[\\.|\\(|,|;]?PMCID:PMC\\d+.*?)$\"<\/div><div class = \"text-block\">5) \"(.*?)(?:[\\(|\\[]EPUBAHEADOFPRINT[\\)\\]])$\"<\/div><div class = \"text-block\">6) \"(.*?)(?:[\\.|\\(|,|;]?ARTICLEPUBLISHEDONLINE.*?\\d{4})$\"<\/div><div class = \"text-block\">7) \"(.*?)(?:[\\.|\\(|,|;]*HTTP:\\\/\\\/.*?)$\"<\/div><div class = \"text-block\">8) \"(.*?)(?:\\\/(META|ABSTRACT|FULL|EPDF|PDF|SUMMARY)([>|\\)](LAST)?ACCESSED\\d+)?)$\"<\/div><div class = \"text-block\">9) \"(.*?)(?:[>|)](LAST)?ACCESSED\\d+)$\"<\/div><div class = \"text-block\">10) \"(.*?)(?:[\\.|(|,|;]?[A-Z]*\\.?SAGEPUB.*)$?\"<\/div><div class = \"text-block\">11) \"(.*?)(?:\\.{5}.*?)$\"<\/div><div class = \"text-block\">12) \"(.*?)(?:[\\.|,|<|&|(|;])$\"<\/div><div class = \"text-block\">13) \"(.*?)(?:[\\.|(|,|;]10.\\d{4}\\\/.*?)$\"<\/div><div class = \"text-block\">14) \"(.*?)(?:\\[DOI\\].*?)$\"<\/div><div class = \"text-block\">15) \"(.*?)(?:\\(\\d{4}\\)?)$\"<\/div><div class = \"text-block\">16) \"(.*?)(?:\\?.*?=.*?)$\"<\/div><div class = \"text-block\">17) \"(.*?)(?:#.*?)$\"<\/div><\/div>","created_on":0,"changed_on":0,"creator":{"name":" ","affiliation":null,"affiliations":[],"username":"","note":null,"link":null,"image":{"source":"","placeholder":""},"badges":[],"verified":0,"is_verified_user":false,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},"comments":[]}},{"id":1054726,"guid":"74C0E03248024D128725BB14A133FB43","order_id":3,"type_id":26,"title":"notes","source":{"id":0,"parent_id":0,"uri":"","title":"","body":"<div class = \"text-blocks\"><div class = \"text-block\">\"(.*?)(?:\\\/-\\\/DCSUPPLEMENTAL|SUPPINF[0|O](\\.)?|[\\.|\\(|,|;]?PMID:\\d+.*?|[\\.|\\(|,|;]?PMCID:PMC\\d+.*?|[\\(|\\[]EPUBAHEADOFPRINT[\\)\\]]|[\\.|\\(|,|;]?ARTICLEPUBLISHEDONLINE.*?\\d{4}|[\\.|\\(|,|;]*HTTP:\\\/\\\/.*?|\\\/(META|ABSTRACT|FULL|EPDF|PDF|SUMMARY)([>|\\)](LAST)?ACCESSED\\d+)?|[>|\\)](LAST)?ACCESSED\\d+|[\\.|\\(|,|;]?[A-Z]*\\.?SAGEPUB.*?|\\.{5}.*?|[\\.|,|<|&|\\(|;]+|[\\.|\\(|,|;]10.\\d{4}\\\/.*?|\\[DOI\\].*?|\\(\\d{4}\\)?|\\?.*?=.*?|#.*?)$\"<\/div><\/div>","created_on":0,"changed_on":0,"creator":{"name":" ","affiliation":null,"affiliations":[],"username":"","note":null,"link":null,"image":{"source":"","placeholder":""},"badges":[],"verified":0,"is_verified_user":false,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},"comments":[]}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#94EBFF","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1166331,"guid":"0A095310A43411EB9F862D175D1030F2","previous_id":1166294,"previous_guid":"E8E9AD0E09B943408E41374AB4E08359","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"2B6D72178192400B94EC0784133481F8","order_id":1,"type_id":6,"title":"Section","source":{"title":"DATA CLEANING PROCEDURE"}},{"id":1054724,"guid":"484FDD2AD2A247878C2CCFFD670CBB5D","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\"><span>At the end of our procedure we dump our <\/span><span style = \"font-weight:bold;\"><output> <\/span><span>in a csv file through the <\/span><span style = \"font-weight:bold;\">dump_csv()<\/span><span> method of the class <\/span><span style = \"font-weight:bold;\">Support()<\/span><span style = \"font-weight:bold;\">:<\/span><\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">def dump_csv(data:list, path:str):<\/div><div class = \"text-block\">        print(f\"[Support:INFO Writing csv at path {path}]\")<\/div><div class = \"text-block\">        with open(path, 'w', newline='', encoding='utf8')  as output_file:<\/div><div class = \"text-block\">            keys = data[0].keys()<\/div><div class = \"text-block\">            dict_writer = csv.DictWriter(output_file, keys)<\/div><div class = \"text-block\">            dict_writer.writeheader()<\/div><div class = \"text-block\">            dict_writer.writerows(data)<\/div><\/div><\/code><\/pre><\/div><div class = \"text-block\">This is how the method is used in our data cleaning procedure:<\/div><div class = \"text-block\">The output of the function is then stored in a CSV file, organized in 7 fields as the dictionary mentioned above:<\/div><table border><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.1007\/s40617-018-00299-1<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.1901\/jaba.2012.45-657<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.1901\/JABA.2012.45-657<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">1<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">0<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">0<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">0<\/td><\/tr><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.1074\/jbc.m508416200<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.1059\/0003-4819-100-4-483<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\"><\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">0<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">0<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">0<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">0<\/td><\/tr><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.1177\/2054358119836124<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.1016\/j.amepre.2015.07.017.<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.1016\/J.AMEPRE.2015.07.017<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">0<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">0<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">1<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">0<\/td><\/tr><\/table><div class = \"text-block\">A sample of the output data is available in our code release (<\/div><div class = \"text-block\"><a href=\"http:\/\/doi.org\/10.5281\/zenodo.4723984\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">http:\/\/doi.org\/10.5281\/zenodo.4723984<\/span><\/a><\/div><div class = \"text-block\">). <\/div><div class = \"text-block\">Further information about the possible uses of research data generated by this project, and the support provided by the authors for reuse, are available in the DMP provided by the authors at <\/div><div class = \"text-block\"><a href=\"https:\/\/doi.org\/10.5281\/zenodo.4665853\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">https:\/\/doi.org\/10.5281\/zenodo.4665853<\/span><\/a><\/div><div class = \"text-block\"><span style = \":UNDERLINE;\">.<\/span><\/div><\/div>"}},{"id":1054725,"guid":"7F4599F0A76711EBB340838B39CCBF73","order_id":2,"type_id":15,"title":"command","source":{"id":8753,"name":">>> Support().dump_csv(data=output, path=\".\/output.csv\")","command_name":"","command":null,"os_name":null,"os_version":null}},{"id":1054726,"guid":"1FF910BC854141CE9C143E6E34FED83C","order_id":3,"type_id":1,"title":"description","source":{"description":"<table border><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.1007\/s40617-018-00299-1<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.1901\/jaba.2012.45-657<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.1901\/JABA.2012.45-657<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">1<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">0<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">0<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">0<\/td><\/tr><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.1074\/jbc.m508416200<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.1059\/0003-4819-100-4-483<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\"><\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">0<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">0<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">0<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">0<\/td><\/tr><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.1177\/2054358119836124<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.1016\/j.amepre.2015.07.017.<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">10.1016\/J.AMEPRE.2015.07.017<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">0<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">0<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">1<\/td><td rowspan = \"\" colspan = \"\" style =\"display : table-cell;\">0<\/td><\/tr><\/table>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#84CE84","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1166883,"guid":"B59188A0A50711EB873D85B4C91630DC","previous_id":1166292,"previous_guid":"B9CB1D26C53C45D7A648C80E7F5D3780","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"F2416A0D192A484992F5BE535D1D4944","order_id":1,"type_id":6,"title":"Section","source":{"title":"DATA CLEANING PROCEDURE"}},{"id":1054724,"guid":"9418F3A38A3246E684407D6E64DF4D9F","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\"><span>First, with the function <\/span><span style = \"font-weight:bold;\">process_csv_input()<\/span><span> from our <\/span><span style = \"font-weight:bold;\">class<\/span><span style = \"font-weight:bold;font-weight:bold;\"> <\/span><span style = \"font-weight:bold;\">Support()<\/span><span>  we import our data in CSV format and we store it in a <\/span><span style = \"font-style:italic;\">DictReader<\/span><span>, an<\/span><span style = \"font-weight:bold;\"> <\/span><span>object that maps the information in each row to a dictionary whose keys are given by the optional fieldnames parameter.<\/span><\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">def process_csv_input(path:str) -> list:<\/div><div class = \"text-block\">        print(f\"[Support:INFO Proccessing csv at path {path}]\")<\/div><div class = \"text-block\">        with open(path, 'r', encoding='utf-8') as csvfile:<\/div><div class = \"text-block\">            reader = csv.DictReader(csvfile)<\/div><div class = \"text-block\">            return list(reader)<\/div><\/div><\/code><\/pre><\/div><div class = \"text-block\"><span>On our procedure, we perform this method on our input csv and we store it as a <\/span><span style = \"font-weight:bold;\"><data><\/span><span> variable. You can reproduce the experiment by launching:<\/span><\/div><div class = \"text-block\"><span>After this procedure, our <\/span><span style = \"font-weight:bold;\"><data><\/span><span> variable will consist of a list of dictionaries as shown below:<\/span><\/div><\/div>"}},{"id":1054725,"guid":"813AF6C0A76611EBB340838B39CCBF73","order_id":2,"type_id":15,"title":"command","source":{"id":8749,"name":"python3\n>>> import csv\n>>> from support import Support\n>>> from clean_dois import Clean_DOIs\n>>> data = Support().process_csv_input(path=\".\/dataset\/invalid_dois.csv\")","command_name":"","command":null,"os_name":null,"os_version":null}},{"id":1054726,"guid":"A9F4E138AB534815B8BDC5C0E58BAAD6","order_id":3,"type_id":17,"title":"result","source":{"body":"<div class = \"text-blocks\"><div class = \"text-block\">[{\"Valid_citing_DOI\": \"10.14778\/1920841.1920954\", \"Invalid_cited_DOI\": \"10.5555\/646836.708343\"}, {\"Valid_citing_DOI\": \"10.5406\/ethnomusicology.59.2.0202\", \"Invalid_cited_DOI\": \"10.2307\/20184517\"}, <\/div><div class = \"text-block\">...]<\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#84CE84","section_duration":0,"critical":null,"critical_id":null,"duration":0}],"document":"","materials":[],"description":"<div class = \"text-blocks\"><div class = \"text-block\">The purpose of this protocol is to provide an automated process to repair invalid DOIs that have been collected by the OpenCitations Index Of Crossref Open DOI-To-DOI References (COCI) while processing data provided by Crossref.<\/div><div class = \"text-block\"><span>The data needed for this work is <\/span><a href=\"http:\/\/doi.org\/10.5281\/zenodo.4625300\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">provided by COCI as a CSV<\/span><\/a><span> containing pairs of valid citing DOIs and invalid cited DOIs. With the goal to determine an automated process, we first classified the errors that characterize the wrong DOIs in the list. Our starting hypothesis is that there are two main classes of errors: factual errors, such as wrong characters, and DOIs that are not yet valid at the time of processing. The first class can be furtherly divided into three classes: errors due to irrelevant strings added to the beginning (prefix-type errors) or at the end (suffix-type errors) of the correct DOI, and errors due to unwanted characters in the middle (other-type errors). Once the classes of errors are addressed, we propose automatic processes to obtain correct DOIs from wrong ones. These processes involve the use of the information returned from <\/span><a href=\"https:\/\/www.doi.org\/factsheets\/DOIProxy.html\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">DOI API<\/span><\/a><span>, as well as rule-based methods, including regular expressions. to correct invalid DOIs.<\/span><\/div><div class = \"text-block\">The application of this methodology produces a CSV dataset containing all the pairs of citing and cited DOIs in the original dataset, each one enriched by 5 fields: \"Already_Valid\", which tells if the cited DOI was already valid before cleaning, \"New_DOI\", which contain a clean, valid DOI (if our procedure was able to produce one), and \"prefix_error\", \"suffix_error\" and \"other-type_error\" fields, which contain, for each cleaned DOI the number of errors that were cleaned.<\/div><\/div>","changed_on":1619554164}