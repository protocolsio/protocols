{"id":44181,"title":"Reproducibility for Thistlethwaite et al. 2020","title_html":"<p>Reproducibility for Thistlethwaite et al. 2020<\/p>","image":{"source":"https:\/\/s3.amazonaws.com\/protocols-files\/public\/aff7b00e7745383ae11e3af6080e1953f199d3d515fcb352a9ce52f476b677c2\/ch5dbfuzx.png","placeholder":"https:\/\/s3.amazonaws.com\/protocols-files\/public\/aff7b00e7745383ae11e3af6080e1953f199d3d515fcb352a9ce52f476b677c2\/ch5dbfuzx.png"},"doi":"dx.doi.org\/10.17504\/protocols.io.bpdvmi66","doi_status":2,"uri":"reproducibility-for-thistlethwaite-et-al-2020-bpdvmi66","type_id":1,"template_id":5,"published_on":1607660549,"parent_protocols":[],"parent_collections":[],"cited_protocols":[],"version_id":3,"version_data":{"id":"3","code":"bpdvmi66","parent_id":41951,"parent_uri":"reproducibility-for-thistlethwaite-et-al-2020-bk77kzrn","is_same_owner":true,"has_pending_merge_request":false,"has_approved_merge_request":true},"created_on":1604439269,"modified_on":null,"categories":null,"public":1,"is_unlisted":0,"creator":{"name":"Lillian R. Thistlethwaite","affiliation":"Baylor College of Medicine","affiliations":[{"affiliation":"Baylor College of Medicine","url":"http:\/\/genboree.org\/site\/bioinformatics_research_laboratory","is_default":1}],"username":"lillian-thistlethwaite","note":null,"link":null,"image":{"source":"https:\/\/s3.amazonaws.com\/protocols-files\/public\/aff7b00e7745383ae11e3af6080e1953f199d3d515fcb352a9ce52f476b677c2\/ch47bfuzx.jpeg","placeholder":"https:\/\/s3.amazonaws.com\/protocols-files\/public\/aff7b00e7745383ae11e3af6080e1953f199d3d515fcb352a9ce52f476b677c2\/ch47bfuzx.jpeg"},"badges":[{"id":2,"image":{"source":"\/img\/badges\/bronze.svg","placeholder":"\/img\/badges\/bronze.svg"},"name":"Author"},{"id":6,"image":{"source":"\/img\/badges\/accelerator.svg","placeholder":"\/img\/badges\/accelerator.svg"},"name":"Science accelerator"}],"verified":0,"is_verified_user":false,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},"journal":null,"journal_name":null,"journal_link":null,"article_citation":null,"has_versions":0,"link":null,"total_collections":0,"number_of_steps":37,"authors":[{"name":"Lillian Thistlethwaite","affiliation":"Baylor College of Medicine","affiliations":[],"username":"lillian-thistlethwaite","note":null,"link":null,"image":{"source":"https:\/\/s3.amazonaws.com\/protocols-files\/public\/aff7b00e7745383ae11e3af6080e1953f199d3d515fcb352a9ce52f476b677c2\/ch47bfuzx.jpeg","placeholder":"https:\/\/s3.amazonaws.com\/protocols-files\/public\/aff7b00e7745383ae11e3af6080e1953f199d3d515fcb352a9ce52f476b677c2\/ch47bfuzx.jpeg"},"badges":[],"verified":1,"is_verified_user":true,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},{"name":"xiqi.li2 ","affiliation":"Baylor College of Medicine","affiliations":[],"username":"m4ule1z1z1x4qle1","note":null,"link":null,"image":{"source":"\/img\/avatars\/008.png","placeholder":"\/img\/avatars\/008.png"},"badges":[],"verified":1,"is_verified_user":true,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},{"name":"Varduhipetrosyan ","affiliation":"Baylor College of Medicine","affiliations":[],"username":"w2y26443v213","note":null,"link":null,"image":{"source":"\/img\/avatars\/012.png","placeholder":"\/img\/avatars\/012.png"},"badges":[],"verified":1,"is_verified_user":true,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false}],"versions":[],"groups":[],"is_owner":1,"has_subprotocols":0,"is_subprotocol":0,"is_bookmarked":0,"can_claim_authorship":0,"can_accept_authorship":0,"can_be_copied":1,"can_remove_fork":1,"fork_id":null,"url":"https:\/\/www.protocols.io\/view\/reproducibility-for-thistlethwaite-et-al-2020-bpdvmi66","forks_count":{"private":0,"public":0},"access":{"can_view":1,"can_remove":0,"can_add":0,"can_edit":0,"can_publish":0,"can_get_doi":0,"can_share":1,"can_move":1,"can_move_outside":1,"can_transfer":1,"can_download":1,"is_locked":0},"guid":"2E85BB77A1C84CF58B4391C7251D0A9A","state_version_id":0,"steps":[{"id":1068540,"guid":"9960BF53BF634DD896E5664D9AAA76C4","previous_id":null,"previous_guid":null,"modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"D7E41D218CED4CF2889F6FE3D2B8D09C","order_id":1,"type_id":6,"title":"Section","source":{"title":"Prepare dataset"}},{"id":1054724,"guid":"B36FD709138B49C8A3447EDA0B93E89D","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">The CTD R package version 1.0.0 was used.<\/div><\/div>"}},{"id":1054725,"guid":"74112850E6FC11EABB2DB7383E25C608","order_id":2,"type_id":15,"title":"command","source":{"id":8114,"name":"require(CTD)","command_name":"Load the CTD R package","command":null,"os_name":null,"os_version":null}},{"id":1054726,"guid":"7EB4D9F0E6FC11EABB2DB7383E25C608","order_id":3,"type_id":15,"title":"command","source":{"id":8115,"name":"data(Miller2015)","command_name":"Load the Miller et al 2015 dataset","command":null,"os_name":null,"os_version":null}},{"id":1054727,"guid":"B807AFC0E6FC11EABB2DB7383E25C608","order_id":4,"type_id":15,"title":"command","source":{"id":8116,"name":"data_mx.og = as.matrix(Miller2015[,grep(\"IEM_\", colnames(Miller2015))])","command_name":"Remove metabolite annotation columns from dataset","command":"One sample per column, one metabolite per row.","os_name":null,"os_version":null}},{"id":1054728,"guid":"4AFD4C90E6FD11EABB2DB7383E25C608","order_id":5,"type_id":15,"title":"command","source":{"id":8117,"name":"cohorts = list()\ndiags = data_mx.og[1,]\ncohorts$mcc = names(diags[which(diags==\"3-methylcrotonyl CoA carboxylase\")])\ncohorts$arg = names(diags[which(diags==\"Argininemia\")])\ncohorts$cit = names(diags[which(diags==\"Citrullinemia\")])\ncohorts$cob = names(diags[which(diags==\"Cobalamin biosynthesis\")])\ncohorts$ga = names(diags[which(diags==\"Glutaric Aciduria\")])\ncohorts$gamt = names(diags[which(diags==\"Guanidinoacetate methyltransferase\")])\ncohorts$msud = names(diags[which(diags==\"Maple syrup urine disease\")])\ncohorts$mma = names(diags[which(diags==\"Methylmalonic aciduria\")])\ncohorts$otc = names(diags[which(diags==\"Ornithine transcarbamoylase\")])\ncohorts$pa = names(diags[which(diags==\"Propionic aciduria\")])\ncohorts$pku = names(diags[which(diags==\"Phenylketonuria\")])\ncohorts$tmhle = names(diags[which(diags==\"Trimethyllysine hydroxylase epsilon\")])\ncohorts$ref = names(diags[which(diags==\"No biochemical genetic diagnosis\")])","command_name":"Create diagnosis-patient mappings","command":"Create a list object that maps patient identifiers to their respective diagnostic class.","os_name":null,"os_version":null}},{"id":1054729,"guid":"594EEB00E6FD11EABB2DB7383E25C608","order_id":6,"type_id":15,"title":"command","source":{"id":8118,"name":"data_mx.og = data_mx.og[-c(1, grep(\"x -\", rownames(data_mx.og))),]","command_name":"Remove diagnosis row and x-compounds from data_mx.og","command":"Remove diagnosis row from data_mx.og","os_name":null,"os_version":null}},{"id":1054730,"guid":"81DA6770E6FD11EABB2DB7383E25C608","order_id":7,"type_id":15,"title":"command","source":{"id":8119,"name":"data_mx.og = apply(data_mx.og, c(1,2), as.numeric)","command_name":"Convert data_mx.og to numeric matrix.","command":"All elements should be numeric, not character.","os_name":null,"os_version":null}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#A492FF","section_duration":1,"critical":null,"critical_id":null,"duration":1},{"id":1068541,"guid":"9E38D307945547E0A55D3877A1CED9A2","previous_id":1068540,"previous_guid":"9960BF53BF634DD896E5664D9AAA76C4","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"EF4B06AFA7164E9BB1829535FF234919","order_id":1,"type_id":6,"title":"Section","source":{"title":"Fig 1: Plot individual metabolomics profiles onto biochemical pathway maps."}},{"id":1054724,"guid":"893E76A52C08476A839CE5E2FB58336B","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">The CTDext R package version 1.0.0 was used. The CTDext R package holds many pre-computed files necessary to reproduce some results from Thistlethwaite et al. 2020, as well as includes some additional pathway visualization and plotting features.<\/div><div class = \"text-block\">The CTDext R package can be downloaded using the devtools::install_github() function as follows:<\/div><div class = \"text-block\">install_github(\"BRL-BCM\/CTDext\")<\/div><\/div>"}},{"id":1054725,"guid":"9B1C29D0E6FD11EABB2DB7383E25C608","order_id":2,"type_id":15,"title":"command","source":{"id":8120,"name":"require(CTDext)","command_name":"Load the CTDext R package","command":null,"os_name":null,"os_version":null}},{"id":1054726,"guid":"A9B57FA0E6FD11EABB2DB7383E25C608","order_id":3,"type_id":15,"title":"command","source":{"id":8121,"name":"dir.create(\".\/pathwayVis\", showWarnings = FALSE)","command_name":"Create an output directory","command":"","os_name":null,"os_version":null}},{"id":1054727,"guid":"F2B9F910E6FD11EABB2DB7383E25C608","order_id":4,"type_id":15,"title":"command","source":{"id":8122,"name":"pathway.ListMaps_metabolon()","command_name":"Return a list of pathway maps curated by Metabolon's Metabolync.","command":"Return a list of pathway maps curated by Metabolon's Metabolync.","os_name":null,"os_version":null}},{"id":1054728,"guid":"354FB800E6FE11EABB2DB7383E25C608","order_id":5,"type_id":15,"title":"command","source":{"id":8123,"name":"plot.pathwayMap(\"allPathways\", \"IEM_1023\", data_mx.og[,\"IEM_1023\"], 2, 1, out.path=\".\/pathwayVis\", SVG = FALSE)\n# Display pathway map\nrequire(png)\nrequire(grid)\nimg <- readPNG('.\/pathwayVis\/allPathways-IEM_1023.png')\noptions(repr.plot.width=15, repr.plot.height=15)\ngrid::grid.raster(img)","command_name":"Generate pathway map with patient perturbation data superimposed on \"all Pathway\" map","command":null,"os_name":null,"os_version":null}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#94EBFF","section_duration":60,"critical":null,"critical_id":null,"duration":60},{"id":1068542,"guid":"C33FC95061874C5780204AE283DC28F5","previous_id":1068541,"previous_guid":"9E38D307945547E0A55D3877A1CED9A2","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"CA24EB12B119410B8A8CC717E7127443","order_id":1,"type_id":6,"title":"Section","source":{"title":"Tuning parameters used in this analysis"}},{"id":1054724,"guid":"953B1E5E650447FFBE0E6074F4EB3AB4","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\"><div class = \"justify\" style = \"text-align:left\">Before we start the analysis, we need to discuss some tuning parameters.<\/div><\/div><div class = \"text-block\"><div class = \"justify\" style = \"text-align:left\"><span style = \"font-weight:bold;\">Tuning parameters (defaults)<\/span><\/div><\/div><div class = \"text-block\"><ul style = \"list-style-type:disc;\"><li style = \"counter-reset:ol0;list-style-type:disc;\"><span style = \"font-weight:bold;text-align:left;\">p0:<\/span><span style = \"text-align:left;\"> the probability uniformly distributed to all metabolites. default is 0.1.<\/span><\/li><li style = \"counter-reset:ol0;list-style-type:disc;\"><span style = \"font-weight:bold;text-align:left;\">p1: <\/span><span style = \"text-align:left;\">the probability distributed preferentially based on edge weights and connectedness patterns in a network, G.default is 0.9.<\/span><\/li><li style = \"counter-reset:ol0;list-style-type:disc;\"><span style = \"font-weight:bold;text-align:left;\">thresholdDiff:<\/span><span style = \"text-align:left;\"> the probability at which the probability diffusion algorithm truncates. default = 0.01.<\/span><\/li><li style = \"counter-reset:ol0;list-style-type:disc;\"><span style = \"font-weight:bold;text-align:left;\">kmx: <\/span><span style = \"text-align:left;\">the number of top-perturbed (up or down) metabolites considered in the network-based interpretation. default in this analysis = 15.<\/span><\/li><\/ul><\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#84CE84","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1068543,"guid":"539048E95D854CE3A653D386B718E7DA","previous_id":1068542,"previous_guid":"C33FC95061874C5780204AE283DC28F5","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"9B11A74D4E6E4E7B958B3430AEE72029","order_id":1,"type_id":6,"title":"Section","source":{"title":"Figure 3: Sensitivity and Specificity of CTD between 3 Network Learning Paradigms"}},{"id":1054724,"guid":"79013C44CE234F7C891CA8080F11721F","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\"><span style = \"font-weight:bold;\">How to Replicate Figure 3<\/span><\/div><div class = \"text-block\">In this result, we calculate the ROC-AUCs for all 5 CTD-defined diagnostic models. We also plot CTD scores across diagnostic categories as barplots to show the sensitivity and specificity of the models under three different network learning paradigms:<\/div><div class = \"text-block\"><span style = \"font-weight:bold;\">i)   <\/span><span>latent embedding + network pruning (\"ind\")<\/span><\/div><div class = \"text-block\"><span style = \"font-weight:bold;\">ii)  <\/span><span>latent embedding + no network pruning (\"noPruning\")<\/span><\/div><div class = \"text-block\"><span style = \"font-weight:bold;\">iii) <\/span><span>no latent embedding or network pruning (\"noLatent\")<\/span><\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#FFED92","section_duration":920,"critical":null,"critical_id":null,"duration":0},{"id":1068544,"guid":"70D47B0DA38C4EB792294491B5851B9D","previous_id":1068543,"previous_guid":"539048E95D854CE3A653D386B718E7DA","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"7D59E211654848658EA8FC4204F96D2E","order_id":1,"type_id":6,"title":"Section","source":{"title":"Figure 3: Sensitivity and Specificity of CTD between 3 Network Learning Paradigms"}},{"id":1054724,"guid":"91A2E58473B74486BC1934EC867BACDD","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">The computational work in this step is required for downstream steps. In this analysis step, we estimate the probability and significance of patient-specific metabolite perturbations against different disease-specific network contexts using CTD.<\/div><div class = \"text-block\">The CTDext package provides precomputed node rankings derived from all 5 disease networks in Thistlethwaite et al. 2020 in order to save time. <\/div><div class = \"text-block\"><span>You can find out <\/span><span style = \"font-weight:bold;\">how to precompute node rankings <\/span><span>under a different Protocol: Precompute Node Rankings (DOI: <\/span><\/div><div class = \"text-block\"><a href=\"https:\/\/dx.doi.org\/10.17504\/protocols.io.bkecktaw\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">dx.doi.org\/10.17504\/protocols.io.bkecktaw<\/span><\/a><\/div><div class = \"text-block\">).<\/div><div class = \"text-block\"><span>You can find out <\/span><span style = \"font-weight:bold;\">how to learn partial correlation disease-specific networks <\/span><span>under a different Protocol: Learn Partial Correlation Disease-Specific Networks (DOI: <\/span><\/div><div class = \"text-block\"><a href=\"https:\/\/dx.doi.org\/10.17504\/protocols.io.bk7xkzpn\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">dx.doi.org\/10.17504\/protocols.io.bk7xkzpn<\/span><\/a><\/div><div class = \"text-block\">).<\/div><div class = \"text-block\">R package versioning:<\/div><div class = \"text-block\"><ul style = \"list-style-type:disc;\"><li style = \"counter-reset:ol0;list-style-type:disc;\">CTD v 1.0.0<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">CTDext v 1.0.0<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">R.utils v 2.9.2<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">pROC v 1.16.2<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">ggplot2 v 3.3.2<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">gridExtra v 2.3.0<\/li><\/ul><\/div><\/div>"}},{"id":1054725,"guid":"354FB6D0E95511EAA3434F176A4D61AA","order_id":2,"type_id":15,"title":"command","source":{"id":8124,"name":"require(R.utils)\np0=0.1\np1=0.9\nthresholdDiff=0.01\nkmx=15\np=list()\nfor (type in c(\"ind\", \"noPruning\", \"noLatent\")) {\n  dir.create(sprintf(\".\/loocv\/loocv_%s_runCTD\/\",type), recursive = TRUE, showWarnings = FALSE)\n  for (model in c(\"cit\", \"msud\", \"mma\", \"pa\", \"pku\")) {\n    for (fold in 1:length(which(cohorts[[model]] %in% colnames(Miller2015)))) {\n      # load corresponding networks.\n      if (type==\"noPruning\") {\n        ig = loadToEnv(system.file(sprintf('networks\/ind_foldNets\/bg_%s_fold%s.RData',model,fold), package='CTDext'))[['ig']]\n        # latent embedding + no network pruning\n      } else if (type==\"noLatent\") {\n        ig = loadToEnv(system.file(sprintf('networks\/noLatent_foldNets\/bg_%s_noLatent_fold%s.RData',model,fold), package='CTDext'))[['ig']]\n        # no latent embedding + no network pruning\n      } else {\n        # latent embedding + network pruning\n        ig = loadToEnv(system.file(sprintf('networks\/ind_foldNets\/bg_%s_fold%s.RData',model,fold), package='CTDext'))[['ig_pruned']]\n      }\n      adj_mat = as.matrix(get.adjacency(ig, attr=\"weight\"))\n      G = vector(mode=\"list\", length=length(V(ig)$name))\n      names(G) = V(ig)$name\n      \n      # load precomputed node ranks that were derived from the loaded graph\n      ranks = loadToEnv(system.file(sprintf(\"ranks\/%s_ranks\/%s%s-ranks.RData\", type, toupper(model), fold), package='CTDext'))[[\"permutationByStartNode\"]]\n      ranks = lapply(ranks, function(i) tolower(i))\n      \n      # p.value matrix derived from z-score\n      data_mx = data_mx.og[which(rownames(data_mx.og) %in% V(ig)$name), ]\n      data_mx = data_mx[,which(colnames(data_mx) %in% unlist(cohorts))] # choose which samples to include\n      data.pvals = apply(data_mx, c(1,2), function(i) 2*pnorm(abs(i), lower.tail = FALSE))\n      data.pvals = t(data.pvals)\n      \n      df = data.frame(ptID=character(), S=character(), lenS=numeric(), optT=numeric(),\n                      fishers=numeric(), I0=numeric(), IA=numeric(), d=numeric(), stringsAsFactors = FALSE)\n      r=1\n      ptBSbyK = list()\n      for (p in 1:ncol(data_mx)) {\n        ptID = colnames(data_mx)[p]\n        print(sprintf(\"Model: %s-fold%d, Type: %s. Patient %d\/%d...\", model, fold, type, p, ncol(data_mx)))\n        if (ptID %in% unlist(cohorts)) {\n          diag = names(cohorts)[which(unlist(lapply(cohorts, function(i) ptID %in% i)))]\n          # using single-node diffusion\n          S = data_mx[order(abs(data_mx[,p]), decreasing = TRUE),p][1:kmx]\n          ptBSbyK = mle.getPtBSbyK(names(S), ranks, num.misses = log2(length(G)))\n          res = mle.getEncodingLength(ptBSbyK, data.pvals, ptID, G)\n          for (k in 1:kmx) {\n            df[r, \"ptID\"] = colnames(data_mx)[p]\n            df[r, \"diag\"] = diag # diagnosis\n            df[r, \"S\"] = paste(names(S)[1:k], collapse=\"\/\") # node names (metabolites)\n            df[r, \"lenS\"] = k # length of diffussion path\n            df[r, \"optT\"] = res[k, \"opt.T\"]\n            df[r, \"fishers\"] = res[k, \"fishers.Info\"]\n            df[r, \"I0\"] = res[k, \"IS.null\"]\n            df[r, \"IA\"] = res[k, \"IS.alt\"]\n            df[r, \"d\"] = res[k, \"d.score\"]\n            r = r + 1\n          }\n        }\n      }\n      save(ptBSbyK, df, file=sprintf(\".\/loocv\/loocv_%s_runCTD\/model_%s_%s_fold%d_kmx%d.RData\", type, model, type, fold, kmx))\n    }\n  }\n}","command_name":"Single-node encoding","command":"The following cell expanded the diffusion-based encoding followed by decoding process to all samples in data_mx.og for 5 disease models and 3 types of networks. The output dataframes will be saved as RData files. This processmay take a few minutes.","os_name":null,"os_version":null}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#FFED92","section_duration":920,"critical":null,"critical_id":null,"duration":900},{"id":1068545,"guid":"7A33F844DB2B4872B33EDFDDAEC51444","previous_id":1068544,"previous_guid":"70D47B0DA38C4EB792294491B5851B9D","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"89BEED0B96E048738B991CFD0DBEFEAD","order_id":1,"type_id":6,"title":"Section","source":{"title":"Figure 3: Sensitivity and Specificity of CTD between 3 Network Learning Paradigms"}},{"id":1054724,"guid":"ADA491E44BB2444396F279FE3396B28A","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Now, we can visualize the results that generates Figure 3.<\/div><\/div>"}},{"id":1054725,"guid":"55CB9A00E95511EAA3434F176A4D61AA","order_id":2,"type_id":15,"title":"command","source":{"id":8125,"name":"require(pROC)\nrequire(ggplot2)\nkmx=15\np2=list()\nfor (model in c(\"cit\", \"msud\", \"mma\", \"pa\", \"pku\")) {\n  for (type in c(\"ind\", \"noPruning\", \"noLatent\")) {\n    df_all = data.frame(fold=numeric(), pt=numeric(), bits=numeric(), diag=character(), stringsAsFactors = FALSE)\n    for (fold in 1:length(which(cohorts[[model]] %in% colnames(Miller2015)))) {\n      load(sprintf(\".\/loocv\/loocv_%s_runCTD\/model_%s_%s_fold%d_kmx%d.RData\", type, model, type, fold, kmx))\n      pts = unique(df$ptID)\n      df = df[which(df$ptID %in% pts),]\n      df_best = data.frame(pt=numeric(), ptID=character(), bits=numeric(), diag=character(), stringsAsFactors = FALSE)\n      for (pt in 1:length(pts)) {\n        pt_data = df[which(df$ptID==pts[pt]),]\n        ptID = unique(df[which(df$ptID==pts[pt]), \"ptID\"])\n        if (pt_data[1,\"diag\"]==model) {\n          df_best[pt, \"pt\"] = which(cohorts[[model]]==ptID)\n        }\n        df_best[pt, \"ptID\"] = ptID\n        df_best[pt, \"bits\"] = max(df[which(df$ptID==pts[pt]), \"d\"])-log2(nrow(pt_data)) # p adjust for kmx\n        df_best[pt, \"diag\"] = unique(pt_data[,\"diag\"])\n      }\n      df_best$bits[which(df_best$bits<0)] = 0\n      df_best$fold = rep(fold, nrow(df_best))\n      df_all = rbind(df_all, df_best)\n    }\n    df_all = df_all[which(df_all$ptID %in% colnames(Miller2015)),]\n    df_all$bits = -log2(p.adjust(2^-(df_all$bits), method=\"fdr\"))# p adjust for samples number\n    \n    # Visualize LOOCV signal and compare to off-target diseased test patients\n    dff = df_all\n    dff$loocv = rep(0, nrow(dff))\n    dff$loocv[which(dff$pt==dff$fold)] = 1\n    dff = dff[-intersect(which(dff$loocv==0), which(dff$diag==model)), ]\n    b_bits = cbind(unique(dff$ptID), sapply(unique(dff$ptID), function(i) mean(dff[which(dff$ptID==i),\"bits\"])))\n    dff = dff[-which(duplicated(dff$ptID)),]\n    dff$diag[which(dff$diag==\"ref\")] = \"z.ref\"\n    dff = dff[order(dff$ptID),]\n    b_bits = b_bits[order(b_bits[,1]),]\n    dff$bits = as.numeric(b_bits[,2])\n    save(dff,file = sprintf(\".\/loocv\/loocv_%s_runCTD\/best_bits_%s_%s_loocv.RData\", type, model, type))\n    # Get diagnostic labels\n    d = dff$diag\n    d[which(d!=model)] = 0\n    d[which(d==model)] = 1\n    d = as.numeric(d)\n    auc = roc(d, dff$bits,quiet = TRUE)\n    \n    p2[[type]][[model]] = ggplot(dff, aes(x=diag, y=bits, fill=diag)) + \n      geom_boxplot(size=0.5) + \n      geom_hline(yintercept=-log2(0.05)) +\n      theme(text = element_text(size=15),\n            axis.title.x = element_blank(),\n            axis.text.x = element_text(angle = 30, hjust = 1,size = 15),\n            legend.position = \"none\") +\n      labs(title=sprintf(\"%s (%s)\", model, type),subtitle = sprintf(\"AUC=%.2f\",auc$auc))\n    \n    print(sprintf(\"AUC (Model: %s Type: %s) = %.3f\", toupper(model), type, auc$auc))\n  }\n}","command_name":"Calculate the ROC-AUCs.","command":null,"os_name":null,"os_version":null}},{"id":1054726,"guid":"46D5A540E95511EAA3434F176A4D61AA","order_id":3,"type_id":15,"title":"command","source":{"id":8126,"name":"# Visualize barplots and AUC\nrequire(gridExtra)\noptions(repr.plot.width=15, repr.plot.height=15)\ng=unlist(p2,recursive = FALSE)\nprint(grid.arrange(g[[1]],g[[6]],g[[11]],\n             g[[2]],g[[7]],g[[12]],\n             g[[3]],g[[8]],g[[13]],\n             g[[4]],g[[9]],g[[14]],\n             g[[5]],g[[10]],g[[15]],\n             ncol = 3))","command_name":"Barplots of CTD signal across disease cohorts and network contexts.","command":"This code chunk generates Figure 3. In the following cell, you should see that patients showed strong significance when interpreted agaisnt the correct disase-specific network and little to no significance when interpreted with incorrect disease-specific networks. Latent variable embedding is associated with higher model sensetivity, whereas network pruning is associated with higher model specificity.","os_name":null,"os_version":null}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#FFED92","section_duration":920,"critical":null,"critical_id":null,"duration":20},{"id":1068546,"guid":"F6F292BB8BD946B18D14B5207C7A5EC5","previous_id":1068545,"previous_guid":"7A33F844DB2B4872B33EDFDDAEC51444","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"32FCE8E9AFFB4589B713529C7CDB6EB0","order_id":1,"type_id":6,"title":"Section","source":{"title":"Figure S1: Highly connected patient-specific modules called by CTD."}},{"id":1054724,"guid":"DB28C9C6241A47F9BD6C0EAD4A2FBC1B","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\"><span style = \"font-weight:bold;\">How to Replicate Figure S1<\/span><\/div><div class = \"text-block\"><span>In this result, we interpreted disease signatures from selected <\/span><span style = \"font-weight:bold;\">individual <\/span><span>patients representing each disease category. We also visualize selected patient's most connected modules in the relevant disease-specific network context.<\/span><\/div><div class = \"text-block\">R package versioning:<\/div><div class = \"text-block\"><ul style = \"list-style-type:disc;\"><li style = \"counter-reset:ol0;list-style-type:disc;\">CTD v 1.0.0<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">CTDext v 1.0.0<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">R.utils v 2.9.2<\/li><\/ul><\/div><\/div>"}},{"id":1054725,"guid":"A4519250E95611EAA3434F176A4D61AA","order_id":2,"type_id":15,"title":"command","source":{"id":8127,"name":"# Create an output directory\ndir.create(\".\/loocv\/blowouts\", recursive = TRUE, showWarnings = FALSE)\nrequire(R.utils)\n# set global variables\np0 = 0.1 \np1 = 0.9\nthresholdDiff = 0.01\nkmx=15 # Setting kmx=15 will select top 15 perturbed metabolites\nptIDs = c(\"IEM_1017\",\"IEM_1058\",\"IEM_1051\",\"IEM_1093\",\"IEM_1105\")\np.igraph=list()\nfor (ptID in ptIDs){\n  getDiag=sapply(cohorts,function(x) which(x==ptID))\n  model=names(getDiag[sapply(getDiag,length)>0])\n  fold=getDiag[sapply(getDiag,length)>0] \n  # load latent-embedding, pruned network that is learnt from the rest of the patients diagnosed with the same disease.\n  ig = loadToEnv(system.file(sprintf('networks\/ind_foldNets\/bg_%s_fold%s.RData',model,fold), package='CTDext'))[['ig_pruned']]\n  # get \"ig\" derived adjacency matrix\n  G = vector(mode=\"list\", length=length(V(ig)$name))\n  names(G) = V(ig)$name\n  adj_mat = as.matrix(get.adjacency(ig, attr=\"weight\"))\n  data_mx = data_mx.og[which(rownames(data_mx.og) %in% V(ig)$name), ]\n  # p.value derived from z-score\n  data.pvals = sapply(data_mx[,ptID], function(i) 2*pnorm(abs(i), lower.tail = FALSE))\n  data.pvals = t(data.pvals)\n  rownames(data.pvals)=ptID\n  \n  # using single-node diffusion\n  S = data_mx[order(abs(data_mx[,ptID]), decreasing = TRUE),ptID][1:kmx] # top kmx perturbed metabolites in ptID's profile\n  print(sprintf(\"%s: Single-node ranking...\",ptID))\n  ranks = list()\n  for (i in 1:length(S)) {\n    ind = which(names(G)==names(S)[i])\n    ranks[[i]] = singleNode.getNodeRanksN(ind, G, p1, thresholdDiff, adj_mat, names(S), num.misses = log2(length(G))) # get node ranks\n  }\n  names(ranks) = names(S)\n  ptBSbyK = mle.getPtBSbyK(names(S), ranks) # encode nodes\n  res = mle.getEncodingLength(ptBSbyK, data.pvals, ptID, G) # get encoding length\n  mets = unique(c(names(S), names(ptBSbyK[[which.max(res[,\"d.score\"])]]))) # best co-perturbed metabolite set is the most compressed subset of nodes\n  p.mets=2^-(res[which.max(res[,\"d.score\"]),\"d.score\"]-log2(nrow(res))) # p value of this \"modular perturbation\"\n  print(mets)\n  print(p.mets)\n  \n  # generate igraph for disease-relevant metabolites of the selected patient\n  e = delete.vertices(ig, v=V(ig)$name[-which(V(ig)$name %in% mets)])\n  reds = intersect(V(e)$name[which(V(e)$name %in% names(S))], names(S[which(S>0)]))\n  blues = intersect(V(e)$name[which(V(e)$name %in% names(S))], names(S[which(S<0)]))\n  V(e)$color = rep(\"\", length(V(e)$name))\n  V(e)$color[which(V(e)$name %in% reds)] = \"red\" # red indicates positive z-score\n  V(e)$color[which(V(e)$name %in% blues)] = \"light blue\" # blue indicates negative z-score\n  V(e)$color[-which(V(e)$name %in% names(S))] = \"grey\" # grey verteces are highly connect to \"mets\"\n  cc = cluster_walktrap(e) #find densely connected subgraphs, also called communities in a graph via random walks. \n  weights = ifelse(crossing(cc, e), 1, 5)\n  layout = layout_with_fr(e, weights=weights)\n  p.igraph[[ptID]]=list(model=model,e=e,layout=layout)\n}","command_name":"Estimate probabilities of selected individual patient's metabolite perturbations in disease contexts.","command":"Now, we are ready to estimate probabilities of individual patient's metabolite perturbations in disease contexts. We choose to highlight one patient per diagnostic category: \n\nCitrullinemia: Patient IEM_1017\nMaple syrup urine disease: IEM_1058\nMethylmalonic aciduria: IEM_1051\nPropionic aciduria: IEM_1093\nPhenylketonuria: IEM_1105","os_name":null,"os_version":null}},{"id":1054726,"guid":"C8B250D0E95611EAA3434F176A4D61AA","order_id":3,"type_id":15,"title":"command","source":{"id":8128,"name":"options(repr.plot.width=15, repr.plot.height=15)\npar(mfrow = c(2,2))\nfor (ptID in ptIDs){\n  p=p.igraph[[ptID]]\n  png(sprintf(\".\/loocv\/blowouts\/%s_%s_module.png\", p$model, ptID))\n  plot.igraph(p$e, layout=p$layout, edge.width=50*abs(E(e)$weight),vertex.label.cex=2,vertex.label.color=\"black\",main=sprintf(\"%s: %s\",toupper(p$model),ptID))\n  dev.off()\n  plot.igraph(p$e, layout=p$layout, edge.width=50*abs(E(e)$weight),vertex.label.cex=2,vertex.label.color=\"black\")\n  title(main=sprintf(\"%s: %s\",toupper(p$model),ptID),cex.main=3)\n}","command_name":"Plot the igraph object for the most connected metabolite perturbations of the selected patients","command":null,"os_name":null,"os_version":null}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#EA9F6C","section_duration":93,"critical":null,"critical_id":null,"duration":93},{"id":1068547,"guid":"EBD2007B9700420CB431C237906FF519","previous_id":1068546,"previous_guid":"F6F292BB8BD946B18D14B5207C7A5EC5","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"5F6EF3F8176A4DA4A2F5B7449F0B1767","order_id":1,"type_id":6,"title":"Section","source":{"title":"Power analysis"}},{"id":1054724,"guid":"2B32D514E720457C9FA9B0EF8E3F6481","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\"><span style = \"font-weight:bold;\">How to Replicate Figure 4.<\/span><\/div><div class = \"text-block\">In this result, we performed a power analysis on three simulated networks of size 50, with varying levels of connectedness.<\/div><div class = \"text-block\">Network 1: 10% connected<\/div><div class = \"text-block\">Network 2: 30% connected<\/div><div class = \"text-block\">Network 3: 60% connected<\/div><div class = \"text-block\">The simulation is broken up into 4 steps: <\/div><div class = \"text-block\">1. Build networks.<\/div><div class = \"text-block\">2. Get number of edges connecting subsets of size 5.<\/div><div class = \"text-block\">3. Use CTD to get subset probabilities by enumerating over all >2 million outcomes of choose(50, 5). This enumeration will allow you to establish a ground truth p-values by determining the distribution of probabilities assigned by CTD over all subset outcomes of size 5 in each of the three 50 node networks.<\/div><div class = \"text-block\">4. For 2,500 node subsets, select equally amongst the number of edges between node subsets to assure that you get a variable level of connected subsets. Then, draw 2,000 permutations to establish a permutation-based p-value estimate.<\/div><div class = \"text-block\">R package versioning:<\/div><div class = \"text-block\"><ul style = \"list-style-type:disc;\"><li style = \"counter-reset:ol0;list-style-type:disc;\">CTD v 1.0.0<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">CTDext v 1.0.0<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">igraph v 1.2.5<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">R.utils v 2.9.2<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">gmp v 0.6.0<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">ggplot2 v 3.3.2<\/li><\/ul><\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#E57785","section_duration":54900,"critical":null,"critical_id":null,"duration":0},{"id":1068548,"guid":"CA0F9A9C0B4C458AA7F7E27359691873","previous_id":1068547,"previous_guid":"EBD2007B9700420CB431C237906FF519","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"F8C3BFF319E543C3AC1905314C570833","order_id":1,"type_id":6,"title":"Section","source":{"title":"Power analysis"}},{"id":1054724,"guid":"48902AA8AB964C108BD53046FC82966B","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Build simulation networks: Build 3 undirected networks with 50 nodes and assign edge weights of 1 with a varying level of connectedness between them.<\/div><\/div>"}},{"id":1054725,"guid":"DA9A51E0E95511EAA3434F176A4D61AA","order_id":2,"type_id":15,"title":"command","source":{"id":8129,"name":"net1 = matrix(0, nrow=50, ncol=50)\nnet2 = matrix(0, nrow=50, ncol=50)\nnet3 = matrix(0, nrow=50, ncol=50)\n\nnet1[sample(1:nrow(net1), 0.20*nrow(net1), replace = FALSE), sample(1:nrow(net1), 0.20*nrow(net1), replace = FALSE)] = 1\nnet2[sample(1:nrow(net2), 0.40*nrow(net2), replace = FALSE), sample(1:nrow(net2), 0.40*nrow(net2), replace = FALSE)] = 1\nnet3[sample(1:nrow(net3), 0.60*nrow(net3), replace = FALSE), sample(1:nrow(net3), 0.60*nrow(net3), replace = FALSE)] = 1\n\ndiag(net1) = 0\ndiag(net2) = 0\ndiag(net3) = 0\n\ncolnames(net1) = sprintf(\"%s\", 1:ncol(net1))\ncolnames(net2) = sprintf(\"%s\", 1:ncol(net2))\ncolnames(net3) = sprintf(\"%s\", 1:ncol(net3))\n\nig_net1 = graph.adjacency(net1, mode=\"undirected\", weighted=TRUE, add.colnames = \"name\")\nig_net2 = graph.adjacency(net2, mode=\"undirected\", weighted=TRUE, add.colnames = \"name\")\nig_net3 = graph.adjacency(net3, mode=\"undirected\", weighted=TRUE, add.colnames = \"name\")\n\nprint(\"Level of connectedness achieved for each network:\")\nprint(sprintf(\"Network 1 = %.2f\", length(E(ig_net1)$weight)\/(50*49\/2)))\nprint(sprintf(\"Network 2 = %.2f\", length(E(ig_net2)$weight)\/(50*49\/2)))\nprint(sprintf(\"Network 3 = %.2f\", length(E(ig_net3)$weight)\/(50*49\/2)))\n\nsave.image(\"nets_setup.RData\")","command_name":"Build simulation networks","command":"Since the simulation networks are generated by random edges, we provide the nets_setup.RData in the CTDext R package (an extension R package to the CTD R package) for perfect replication of this result.","os_name":null,"os_version":null}},{"id":1054726,"guid":"E0F50F30E95511EAA3434F176A4D61AA","order_id":3,"type_id":15,"title":"command","source":{"id":8130,"name":"load(system.file(\"networks\/nets_setup.RData\", package=\"CTDext\"))","command_name":"Load nets_setup.RData from CTDext","command":"As an alternative to building your own networks as in the \"Build simulation networks\" script, you can load the networks we used in our simulation through the CTDext R package.","os_name":null,"os_version":null}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#E57785","section_duration":54900,"critical":null,"critical_id":null,"duration":1},{"id":1068549,"guid":"64FBCB419B49430C9AA6098A99721DA1","previous_id":1068548,"previous_guid":"CA0F9A9C0B4C458AA7F7E27359691873","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"C223543E85C44180A5DFA9AA037E2BF1","order_id":1,"type_id":6,"title":"Section","source":{"title":"Power analysis"}},{"id":1054724,"guid":"4A618DF33C79496DAE556D8301680B9C","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Establish ground truth: Count the number of modules of size 5 with parameter r number of edges between them. <\/div><div class = \"text-block\">Note: We run 10,000 subsets at a time on a computing cluster, a form of parallelization, which significantly speeds up this step compared to enumerating using serial code. The parallel implementation is pasted below, following by a PBS job scheduler launcher script, and a wrapper script which automatically launches the PBS scripts.<\/div><div class = \"text-block\">Each job running 10,000 subsets took about 1-1.5 minutes, and 100 jobs were running at a given time. It took about 5-7 minutes to run all 212 jobs. Collating the job output .RData files into one .RData files took another 5 minutes.<\/div><\/div>"}},{"id":1054725,"guid":"40DD3BF0EBB511EAB4636B013B5A0081","order_id":2,"type_id":15,"title":"command","source":{"id":8131,"name":"args = commandArgs(trailingOnly=TRUE)\nitt = as.numeric(args[1])\nprint(itt)\n\nstart = 1+10000*(itt-1)\neend = start+9999\n\nrequire(igraph)\nload(\"nets_setup.RData\")\nsubsets_k = combn(50, 5)\nif (eend>ncol(subsets_k)) {\n  eend = ncol(subsets_k)\n}\n\ndff_nets = data.frame(network=character(30000), it=numeric(30000), num.edges = numeric(30000), stringsAsFactors = FALSE)\nr = 1\nfor (it in start:eend) {\n  if (it %% 1000 == 0) {\n    print(it)\n    save.image(sprintf(\"simulation_%d.RData\", itt))\n  }\n  net1_subset_it = induced_subgraph(ig_net1, v=subsets_k[,it])\n  net2_subset_it = induced_subgraph(ig_net2, v=subsets_k[,it])\n  net3_subset_it = induced_subgraph(ig_net3, v=subsets_k[,it])\n\n  dff_nets[r, \"network\"] = \"net1\"\n  dff_nets[r, \"it\"] = it\n  dff_nets[r, \"num.edges\"] = length(E(net1_subset_it))\n  r = r + 1\n  dff_nets[r, \"network\"] = \"net2\"\n  dff_nets[r, \"it\"] = it\n  dff_nets[r, \"num.edges\"] = length(E(net2_subset_it))\n  r = r + 1\n  dff_nets[r, \"network\"] = \"net3\"\n  dff_nets[r, \"it\"] = it\n  dff_nets[r, \"num.edges\"] = length(E(net3_subset_it))\n  r = r + 1\n}\nsave.image(sprintf(\"simulation_%d.RData\", itt))","command_name":"Get number of edges for all subsets in each of the 3 networks","command":"Using number of edges as a heuristic for connectedness (which CTD also estimates using network flow\/diffusion) will allow us to draw equally from several different levels of connectedness when we go to estimate power. It's important to test the power of CTD at a full range of connectedness levels, because CTD is most powerful when estimating probabilities of highly connected subsets, and less powerful for sparsely connected subsets. See Figure 4 in Thistlethwaite et al (2020) for details.","os_name":null,"os_version":null}},{"id":1054726,"guid":"EF7BBAA0EBB611EAB4636B013B5A0081","order_id":3,"type_id":15,"title":"command","source":{"id":8132,"name":"# Request 1 processors on 1 node\n#PBS -l nodes=1:ppn=1\n#Request 1 hour of walltime\n#PBS -l walltime=1:00:00\n#Request that regular output and terminal output go to the same file\n#PBS -j oe\n#PBS -m abe\nmodule load R\/3.3\ncd metabolomics\/9thCommitteeMeeting\/conservativeness\nitt=${itt}\nRscript get_numedges.r $itt > num_edges:$itt.out\nrm num_edges:$itt.out","command_name":"PBS job launcher for num_edges enumeration.","command":null,"os_name":null,"os_version":null}},{"id":1054727,"guid":"A9BBA150EBB711EAB4636B013B5A0081","order_id":4,"type_id":15,"title":"command","source":{"id":8133,"name":"totalN = ceiling(ncol(combn(50, 5))\/10000)\nfor (n in 1:totalN) {\n  str = sprintf(\"qsub -v it=%d num_edges.pbs\", n)\n  system(str, wait=FALSE)\n  system(\"sleep 0.2\")\n}","command_name":"Wrapper script for num_edges.pbs","command":"You can launch this wrapper script like this:\n\nRscript wrapper_num_edges.r","os_name":null,"os_version":null}},{"id":1054728,"guid":"5CFAFFB0EBB611EAB4636B013B5A0081","order_id":5,"type_id":15,"title":"command","source":{"id":8134,"name":"require(igraph)\n# collate enumerated subsets into one R object\nsubsets_k = combn(50, 5)\nsize_df = 3*ncol(subsets_k)\ndfff_nets = data.frame(network=character(size_df), it=numeric(size_df), num.edges = numeric(size_df), stringsAsFactors = FALSE)\nnum_jobs = ceiling(ncol(subsets_k)\/10000)\nfor (n in 1:num_jobs) {\n  print(n)\n  load(sprintf(\"simulation_%d.RData\", n))\n  begin_ind = 1+(n-1)*30000\n  end_ind = begin_ind+30000\n  dfff_nets[begin_ind:end_ind,] = dff_nets\n}\ndff_net1 = dfff_nets[which(dfff_nets$network==\"net1\"),]\ndff_net2 = dfff_nets[which(dfff_nets$network==\"net2\"),]\ndff_net3 = dfff_nets[which(dfff_nets$network==\"net3\"),]\nsave.image(file=\"simulation_collated.RData\")","command_name":"Collate num_edge simulation results","command":"Once all 212 PBS jobs have finished, this means all subsets of size 5 have been enumerated over. Now we can collate those 212 simulation_*.RData files into a single simulated_collated.RData file.","os_name":null,"os_version":null}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#E57785","section_duration":54900,"critical":null,"critical_id":null,"duration":600},{"id":1068550,"guid":"1B9FF30D8A0B43FDBDD1C15C72E6E7D6","previous_id":1068549,"previous_guid":"64FBCB419B49430C9AA6098A99721DA1","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"BE58A8A5FDD748668E1361EF00F5A969","order_id":1,"type_id":6,"title":"Section","source":{"title":"Power analysis"}},{"id":1054724,"guid":"481CE41FEEA048728C93EB7C8CE95E46","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Run CTD on all possible node sets of size 5 for each network, collect p-values for each encoding algorithm (single-node). <\/div><div class = \"text-block\">Note: We use the same approach to enumeration as we did in Step 6.2, where we launch individual jobs on a cluster that performs the CTD probability estimation for 10,000 subsets at a time. For over 2 million subsets of size 5 in a network of size 50, this amounted to 212 jobs per network. For 3 networks, this amounted to 212*3= 636 jobs.<\/div><div class = \"text-block\">Each job took a variable amount of time, depending on how connected the 10,000 subsets being processed were and how efficient the cluster node was at the time. Job execution times ranged from 32 minutes to ~6.5 hours, and 100 jobs were running at any given time. 636 jobs were launched in total (212 jobs for 3 networks), resulting in an approximate execution time of about ~21 hours.<\/div><\/div>"}},{"id":1054725,"guid":"770588F0EBB911EAB4636B013B5A0081","order_id":2,"type_id":15,"title":"command","source":{"id":8135,"name":"args = commandArgs(trailingOnly=TRUE)\nnetwork = args[1]\nchunk = as.numeric(args[2])\n\nrequire(CTD)\nrequire(R.utils)\nload(\"nets_setup.RData\")\np0=0.1\np1=0.9\nthresholdDiff=0.01\nkmx=k=5\nsize_df = 10000\nsubsets_k = combn(50, 5)\n\ndff_res = data.frame(network=character(size_df), encoder=character(size_df), it=numeric(size_df), \n                     idx.ig=character(size_df), d.score=numeric(size_df), stringsAsFactors = FALSE)\nr = 1\n\nstart_it = 1+size_df*(chunk-1)\nend_it = start_it + (size_df-1)\nif (end_it > ncol(subsets_k)) {\n  end_it = ncol(subsets_k)\n}\nprint(sprintf(\"Start.it = %d, End.it = %d\", start_it, end_it))\n\nrequire(gmp)\nstart.time = Sys.time()\nfor (it in start_it:end_it) {\n  print(it)\n  if (it %% 1000 == 0) { save.image(sprintf(\"sn_enumerate_%s_%d.RData\", network, chunk)) }\n  sig.nodes = subsets_k[,it]\n  \n  # Single-node encoding\n  if (network==\"net1\") {ig=ig_net1} else if(network==\"net2\"){ig=ig_net2} else {ig=ig_net3}\n  adj_mat = get.adjacency(ig, attr=\"weight\")\n  G = vector(mode=\"list\", length=length(V(ig)$name))\n  names(G) = V(ig)$name\n  ranks = list()\n  for (i in 1:length(sig.nodes)) {\n    ind = which(names(G)==sig.nodes[i])\n    ranks[[i]] = singleNode.getNodeRanksN(ind, G, p1, thresholdDiff, adj_mat, S=sig.nodes, log2(length(G)))\n  }\n  names(ranks) = sig.nodes\n  ptBSbyK = mle.getPtBSbyK(as.character(sig.nodes), ranks)\n  res = mle.getEncodingLength(ptBSbyK, NULL, NULL, G)\n  dff_res[r, \"network\"] = network\n  dff_res[r, \"encoder\"] = \"single-node\"\n  dff_res[r, \"it\"] = it\n  dff_res[r, \"idx.ig\"] = paste(which(V(ig)$name %in% sig.nodes), sep=\"-\", collapse=\"-\")\n  dff_res[r, \"d.score\"] = res[k,\"d.score\"]\n  r = r + 1\n}\nend.time = Sys.time()\n\nprint(sprintf(\"Elapsed time = %.2f seconds.\", end.time - start.time))\n\nsave(dff_res, file=sprintf(\"sn_enumerate_%s_%d.RData\", network, chunk))","command_name":"Get the CTD probability for 10,000 subsets at a time.","command":null,"os_name":null,"os_version":null}},{"id":1054726,"guid":"961632A0EBD511EAB4636B013B5A0081","order_id":3,"type_id":15,"title":"command","source":{"id":8136,"name":"# Request 1 processors on 1 node\n#PBS -l nodes=1:ppn=1\n#Request x number of hours of walltime\n#PBS -l walltime=15:00:00\n#Request that regular output and terminal output go to the same file\n#PBS -j oe\n#PBS -m abe\nmodule load R\/3.3\ncd metabolomics\/9thCommitteeMeeting\/conservativeness\n\nnet=${net}\nchunk=${chunk}\nRscript sn_enumerate_gt.r $net $chunk > sn_enum:$net-$chunk.out\nrm sn_enum:$net-$chunk.out","command_name":"PBS script for sn_enumerate_gt.r","command":null,"os_name":null,"os_version":null}},{"id":1054727,"guid":"D89AB380EBD511EAB4636B013B5A0081","order_id":4,"type_id":15,"title":"command","source":{"id":8137,"name":"totalN = ceiling(ncol(combn(50, 5))\/10000)\nfor (net in c(\"net1\", \"net2\", \"net3\")) {\n  for (chunk in 1:totalN) {\n    str = sprintf(\"qsub -v net=%s,chunk=%d sn_enum.pbs\", net, chunk)\n    system(str, wait=FALSE)\n    system(\"sleep 0.2\")\n  }\n}","command_name":"Wrapper script for sn_enum.pbs","command":null,"os_name":null,"os_version":null}},{"id":1054728,"guid":"4493FF60EBD611EAB4636B013B5A0081","order_id":5,"type_id":15,"title":"command","source":{"id":8138,"name":"# Collate Single-node enumerations\nsubsets_k = combn(50,5)\nfor (net in c(\"net1\", \"net2\", \"net3\")) {\n  dfff_res = data.frame(network=character(), encoder=character(), it=numeric(), \n                       idx.ig=character(), d.score=numeric(), stringsAsFactors = FALSE)\n  ff = list.files(\"sn_enum\", pattern=sprintf(\"sn_enumerate_%s\", net))\n  for (f in ff) {\n    load(sprintf(\"sn_enum\/%s\", f))\n    dfff_res = rbind(dfff_res, dff_res)\n    print(dim(dfff_res))\n  }\n  dfff_res = dfff_res[-which(dfff_res$it==0),]\n  dim(dfff_res)\n  if (nrow(dfff_res)==ncol(subsets_k)) {\n    save(dfff_res, file=sprintf(\"sn_enumerate_%s.RData\", net))\n  }\n}","command_name":"Collate sn_enumerate_*.RData files into one per network","command":null,"os_name":null,"os_version":null}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#E57785","section_duration":54900,"critical":null,"critical_id":null,"duration":75600},{"id":1068551,"guid":"76CC7540ED504574AE784998C8D7B220","previous_id":1068550,"previous_guid":"1B9FF30D8A0B43FDBDD1C15C72E6E7D6","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"A6FB1E91A6BF49C09272F3F4AEDDED3C","order_id":1,"type_id":6,"title":"Section","source":{"title":"Power analysis"}},{"id":1054724,"guid":"C762C2BF2A444CABA7EBB8D8244CB99B","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Get permutation-based pvalues for 2,500 node sets you calculated a CTD upper bounds estimate for.<\/div><\/div>"}},{"id":1054725,"guid":"4C94B200EC7A11EAB4636B013B5A0081","order_id":2,"type_id":15,"title":"command","source":{"id":8139,"name":"for (net in c(\"net1\", \"net2\", \"net3\")) {\n  load(\"simulation_collated.RData\")\n  if (net==\"net1\"){numedges_df=dff_net1} else if(net==\"net2\"){numedges_df=dff_net2} else {numedges_df=dff_net3}\n  # Sample 25000 outcomes, sample equally between the 11 num.edges categories\n  ind.ne0 = sample(which(numedges_df$num.edges==0), 250)\n  ind.ne1 = sample(which(numedges_df$num.edges==1), 250)\n  ind.ne2 = sample(which(numedges_df$num.edges==2), 250)\n  ind.ne3 = sample(which(numedges_df$num.edges==3), 250)\n  ind.ne4 = sample(which(numedges_df$num.edges==4), 250)\n  ind.ne5 = sample(which(numedges_df$num.edges==5), 250)\n  ind.ne6 = sample(which(numedges_df$num.edges==6), 250)\n  ind.ne7 = sample(which(numedges_df$num.edges==7), 250)\n  ind.ne8 = sample(which(numedges_df$num.edges==8), 250)\n  if (sum(numedges_df$num.edges==9)>=250) {\n    ind.ne9 = sample(which(numedges_df$num.edges==9), 250)\n  }\n  if (sum(numedges_df$num.edges==10)>=250) {\n    ind.ne10 = sample(which(numedges_df$num.edges==10), 250)\n  } else { ind.ne10 = c() }\n  ind = c(ind.ne0, ind.ne1, ind.ne2, ind.ne3, ind.ne4, ind.ne5, ind.ne6, ind.ne7, ind.ne8, ind.ne9, ind.ne10)\n\n  # Figure 4a\n  load(sprintf(\"sn_enumerate_%s.RData\", net))\n  dff_net_sim = data.frame(network=character(), encoder=character(), it=numeric(), idx.ig=character(), \n                           num.edges=numeric(), ctd.pval=numeric(), perm.pval=numeric(), stringsAsFactors = FALSE)\n  r = 1\n  for (i in 1:length(ind)) {\n    ii = ind[i]\n    if (i%% 100==0) { print(i) }\n    dff_net_sim[r, \"network\"] = net\n    dff_net_sim[r, \"encoder\"] = \"single-node\"\n    dff_net_sim[r, \"it\"] = dfff_res[ii, \"it\"]\n    dff_net_sim[r, \"idx.ig\"] = dfff_res[ii, \"idx.ig\"]\n    dff_net_sim[r, \"ctd.pval\"] = 2^-dfff_res[ii,\"d.score\"]\n    perms_df = dfff_res[sample(1:nrow(dfff_res), 2000), \"d.score\"]\n    dff_net_sim[r, \"perm.pval\"] = (1+length(which(perms_df>=dfff_res[ii,\"d.score\"])))\/2001\n    dff_net_sim[r, \"true.pval\"] = length(which(dfff_res[,\"d.score\"]>=dfff_res[ii,\"d.score\"]))\/nrow(dfff_res)\n    r = r + 1\n  }\n  dff_net_sim$ctd.pval[which(dff_net_sim$ctd.pval>1)] = 1\n  \n  # Figure 4b\n  dff = data.frame(network=character(), pval.thresh=numeric(), alpha=numeric(), power=numeric(), spec=numeric(), estimate_type=character(), encoding_type=character(), stringsAsFactors = FALSE)\n  for (ctd.pval.thresh in seq(0, 1, 0.01)) {\n    dff_stats_thresh = dff_net_sim[which(dff_net_sim$ctd.pval<=ctd.pval.thresh),]\n    prob_alpha = c()\n    spec_alpha = c()\n    r = 1\n    for (alpha in 0.05) {\n      # CTD-bounds pval\n      tp = length(intersect(which(dff_stats_thresh$true.pval<=alpha), \n                            which(dff_stats_thresh$ctd.pval<=alpha)))\n      fn = length(intersect(which(dff_stats_thresh$true.pval<=alpha), \n                            which(dff_stats_thresh$ctd.pval>alpha)))\n      tn = length(intersect(which(dff_stats_thresh$true.pval>alpha), \n                            which(dff_stats_thresh$ctd.pval>alpha)))\n      fp = length(intersect(which(dff_stats_thresh$true.pval>alpha), \n                            which(dff_stats_thresh$ctd.pval<=alpha)))\n      print(sprintf(\"Sum TP\/FN\/FP\/TN = %d, should be %d.\", tp+fn+fp+tn, nrow(dff_stats_thresh)))\n      prob_alpha[r] = tp\/(tp+fn)\n      spec_alpha[r] = 1-(tn\/(tn+fp))\n      r = r + 1\n    }\n    dff = rbind(dff, data.frame(pval.thresh=rep(ctd.pval.thresh, length(prob_alpha)), \n                                network=net,\n                                alpha=0.05, \n                                power=prob_alpha, \n                                spec = spec_alpha,\n                                estimate_type=rep(\"ctd-upper-bounds\", length(prob_alpha)),\n                                encoding_type=rep(\"single-node\", length(prob_alpha))))\n  }\n  save(dff_net_sim, dff, ind, file=sprintf(\"power_%s_sn.RData\", net))\n}","command_name":"Permutation-based p-values, estimate CTD's power.","command":null,"os_name":null,"os_version":null}},{"id":1054726,"guid":"7AE896D0EC7A11EAB4636B013B5A0081","order_id":3,"type_id":15,"title":"command","source":{"id":8140,"name":"require(R.utils)\nrequire(ggplot2)\nn1 = loadToEnv(\"power_net1_sn.RData\")[[\"dff\"]]\nn2 = loadToEnv(\"power_net2_sn.RData\")[[\"dff\"]]\nn3 = loadToEnv(\"power_net3_sn.RData\")[[\"dff\"]]\nsn_nets = rbind(n1, n2, n3)\nsn_nets$est_type = sprintf(\"%s-%s\", sn_nets$estimate_type, sn_nets$network)\nsvg(\"singleNode_power_v5.svg\")\nggplot(sn_nets, aes(x=pval.thresh, y=power, colour=est_type)) + geom_point(size=2) + geom_line() +\n  ggtitle(\"Simulation: Power of CTD Upper-Bounds\\nEstimates (Single-Node) by Threshold\") + \n  theme(axis.text.y = element_text(size=12), axis.text.x = element_text(size=12)) + xlab(\"CTD p-value threshold\")\ndev.off()\n\n\ndff = data.frame(CTD=-log2(dff_net_sim$ctd.pval), Permutation=-log2(dff_net_sim$perm.pval), True=-log2(dff_net_sim$true.pval))\ndelta_h = dff$Permutation-dff$CTD\nstdev_power = sd(delta_h)\nmn_power = mean(delta_h)\nmax(delta_h)\nmn_power\nmn_power + 2.03*stdev_power\/sqrt(nrow(dff)-1)\nmn_power - 2.03*stdev_power\/sqrt(nrow(dff)-1)\ndff$True = 2^-dff$True\ndff$CTD = 2^-dff$CTD\ndff$Permutation = 2^-dff$Permutation\ndff$True[which(dff$True>1)] = 1\ndff$CTD[which(dff$CTD>1)] = 1\ndff$Permutation[which(dff$Permutation>1)] = 1\nsvg(\"singleNode_conservative_v5.svg\")\nggplot(dff) + xlim(0, 1) + ylim(0, 1) +\n  geom_point(aes(x=True, y=CTD, color=\"CTD\")) + \n  geom_point(aes(x=True, y=Permutation, color=\"Permutation\")) + \n  ggtitle(\"Simulation: CTD Upper-Bounds Estimates\\n(Single-Node) vs. Permutation-based P-values\") + \n  xlab(\"True P-value (bits)\") + ylab(\"Estimated P-value (bits)\") +\n  theme(axis.text.y = element_text(size=12), axis.text.x = element_text(size=12))\ndev.off()","command_name":"Visualize CTD's power","command":null,"os_name":null,"os_version":null}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#E57785","section_duration":54900,"critical":null,"critical_id":null,"duration":300},{"id":1068552,"guid":"745926527797431C89ED7EB4E504C410","previous_id":1068551,"previous_guid":"76CC7540ED504574AE784998C8D7B220","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"CABFED7A5C6D4262A18CB62CF4582195","order_id":1,"type_id":6,"title":"Section","source":{"title":"Table 5: CTD as a feature selection method"}},{"id":1054724,"guid":"FDBB63E6B3E546DA91F925561CE2A830","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\"><span style = \"font-weight:bold;\">How to Replicate Table 5<\/span><\/div><div class = \"text-block\">In this result, we used CTD as a feature selection method and a covariate in 5 different disease-specific Partial Least Square (PLS) regression models.<\/div><div class = \"text-block\">Here we compare CTD as a feature selection method to a basic top z-score feature selection method, and the FSFCN algorithm using three different network clustering algorithms: the Greedy Modularity Optimization, InfoMap, and WalkTrap.<\/div><div class = \"text-block\">R package versioning:<\/div><div class = \"text-block\"><ul style = \"list-style-type:disc;\"><li style = \"counter-reset:ol0;list-style-type:disc;\">CTD v 1.0.0<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">CTDext v 1.0.0<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">igraph v 1.2.5<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">pls v 2.7.3<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">pROC v 1.16.2<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">caret v 6.0.86<\/li><\/ul><\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#EA94FF","section_duration":1224,"critical":null,"critical_id":null,"duration":0},{"id":1068553,"guid":"3BEE535B04C844B0B159380D67CB1EB8","previous_id":1068552,"previous_guid":"745926527797431C89ED7EB4E504C410","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"EF2655D94068406C884F1E5801F82AA5","order_id":1,"type_id":6,"title":"Section","source":{"title":"Table 5: CTD as a feature selection method"}},{"id":1054724,"guid":"456D37E61DE247608762595817251D23","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Define the FCFSN algorithm.<\/div><\/div>"}},{"id":1054725,"guid":"3BB457D0E95811EAA3434F176A4D61AA","order_id":2,"type_id":15,"title":"command","source":{"id":8141,"name":"require(entropy)\nwhichRtoSelect = function(data_mx, classes) {\n  rs = c()\n  for (f in 1:nrow(data_mx)) {\n    y2d = discretize2d(data_mx[f,], classes, ceiling(1+log2(ncol(data_mx))), ceiling(1+log2(ncol(data_mx))))\n    rs = c(rs, mi.empirical(y2d))\n  }\n  return(quantile(rs, 0.95))\n}\nprunedIGraph = function(data_mx, classes, R) {\n  ig_pruned = make_empty_graph(directed=FALSE)\n  fr = c()\n  for (f in 1:nrow(data_mx)) {\n    y2d = discretize2d(data_mx[f,], classes, ceiling(1+log2(ncol(data_mx))), ceiling(1+log2(ncol(data_mx))))\n    if(mi.empirical(y2d) > R) {\n      fr = c(fr, rownames(data_mx)[f])\n    }\n  }\n  ig_pruned = add.vertices(ig_pruned, nv=length(fr), attr=list(name=fr))\n  \n  \n  L = data.frame(fi=character(), fj=character(), s=numeric(), stringsAsFactors = FALSE)\n  data_mx_fr = data_mx[which(rownames(data_mx) %in% fr),]\n  it = 1\n  for (fi in 1:length(fr)) {\n    for (fj in fi:length(fr)) {\n      if (fi!=fj) {\n        L[it,\"fi\"] = rownames(data_mx_fr)[fi]\n        L[it,\"fj\"] = rownames(data_mx_fr)[fj]\n        L[it,\"s\"] = cor(data_mx_fr[fi,], data_mx_fr[fj,], method=\"spearman\")\n        it = it + 1\n      }\n    }\n  }\n  L = L[order(abs(L$s), decreasing = TRUE),]\n  \n  it = 1\n  disconnected = TRUE\n  while (disconnected) {\n    ig_pruned = add.edges(ig_pruned, e=c(L[it,\"fi\"], L[it, \"fj\"]), attr = list(weight=L[it,\"s\"]))\n    it = it + 1\n    disconnected = (!is.connected(ig_pruned))\n  }\n  \n  return(ig_pruned)\n}\nfsfcn = function(ig_pruned, data_mx, classes, clusters) {\n  S = c()\n  for (c in 1:length(clusters)) {\n    ig_cluster = induced_subgraph(ig_pruned, v=which(V(ig_pruned)$name %in% clusters[[c]]))\n    data_mx_sub = data_mx[which(rownames(data_mx) %in% clusters[[c]]),]\n    while (length(V(ig_cluster)$name)>0) {\n      if (length(V(ig_cluster)$name)==1) {\n        f_mx = V(ig_cluster)$name[1]\n        data_mx_sub = as.matrix(data_mx_sub)\n      } else {\n        mi = c()\n        for (f in 1:nrow(data_mx_sub)) {\n          y2d = discretize2d(data_mx_sub[f,], classes, 10, 10)\n          mi[f] = mi.empirical(y2d)\n        }\n        f_mx = rownames(data_mx_sub)[which.max(mi)]\n      }\n      f_n = names(unlist(ego(ig_cluster, 1, nodes=f_mx)))\n      ig_cluster = delete.vertices(ig_cluster, v=which(V(ig_cluster)$name %in% c(f_mx, f_n)))\n      data_mx_sub = data_mx_sub[-which(rownames(data_mx_sub) %in% c(f_mx, f_n)),]\n      S = c(S, f_mx)\n      print(sprintf(\"Size S = %d, Size ig_cluster = %d\", length(S), length(V(ig_cluster)$name)))\n    }\n  }\n  return(S)\n}","command_name":"The FCFSN algorithm","command":"Three functions to implement the FCFSN algorithm published in:\n\nSavic M, Kurbalija V, Ivanovic M, Bosnic Z. A Feature Selection Method Based on Feature Correlation Networks. In: Ouhammou Y, Ivanovic M, Abell\u00f3 A, Bellatreche L, editors. Model and Data Engineering. Springer, Cham: Lecture Notes in Computer Science; 2017. p. 248-61.","os_name":null,"os_version":null}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#EA94FF","section_duration":1224,"critical":null,"critical_id":null,"duration":1},{"id":1068554,"guid":"27DAF51123804C179348C091CBC5EF4D","previous_id":1068553,"previous_guid":"3BEE535B04C844B0B159380D67CB1EB8","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"01991AE85D9840DD95754BF80809D3D4","order_id":1,"type_id":6,"title":"Section","source":{"title":"Table 5: CTD as a feature selection method"}},{"id":1054724,"guid":"70CFA41AFC9342B295ABE92EEB6F4B6F","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Apply and compare CTD as a feature selection method.<\/div><\/div>"}},{"id":1054725,"guid":"64F9D570E95811EAA3434F176A4D61AA","order_id":2,"type_id":15,"title":"command","source":{"id":8142,"name":"rm(list=setdiff(ls(),c(\"data_mx.og\",\"cohorts\", \"whichRtoSelect\", \"prunedIGraph\", \"fsfcn\")))\nmodule_select=list()\nfill.rate = as.numeric(Miller2015$`Times identifed in all 200 samples`[-1])\/200\ndata_mx = data_mx.og[which(fill.rate>0.80), ]\ndata_mx = data_mx[-grep(\"x - \", rownames(data_mx)),]\nfor (model in c(\"cit\", \"msud\", \"mma\", \"pa\", \"pku\")) {\n  # Top Z-score feature selection: Metabolites with an absolute value mean z-score > 2 will be selected.\n  df_mn = apply(data_mx[,which(colnames(data_mx) %in% cohorts[[model]])], 1, function(i) mean(na.omit(i)))\n  module_select[[\"Zscore\"]][[model]] = names(df_mn[which(abs(df_mn)>2)])\n  \n  # CTD feature selection\n  # Iterate through all patients with a known diagnosis to find most connected metabolites in their \n  # z-scored perturbations >2 or <-2\n  mdst = c()\n  df_ctd = data.frame(ptID=character(), mets=character(), m=numeric(), stringsAsFactors = FALSE)\n  for (fold in 1:length(cohorts[[model]])) {\n    load(system.file(sprintf('networks\/ind_foldNets\/bg_%s_fold%s.RData',model,fold), package='CTDext'))\n    adjacency_matrix = as.matrix(get.adjacency(ig_pruned, attr=\"weight\"))\n    G = vector(mode=\"list\", length=length(V(ig_pruned)$name))\n    names(G) = V(ig_pruned)$name\n    ranks = loadToEnv(system.file(sprintf('ranks\/ind_ranks\/%s%d-ranks.RData',toupper(model), fold), package='CTDext'))[[\"permutationByStartNode\"]]\n    ranks = lapply(ranks, tolower)\n    # The patient-who-was-left-out-of-this-network-fold's perturbations will be scored by CTD.\n    ptID = cohorts[[model]][fold]\n    diag = names(cohorts)[which(unlist(lapply(cohorts, function(i) ptID %in% i)))]\n    S = data_mx[order(abs(data_mx[,ptID]), decreasing = TRUE),ptID]\n    S = S[which(abs(S)>2)]\n    S = S[which(names(S) %in% names(G))]\n    ptBSbyK = mle.getPtBSbyK(names(S), ranks, num.misses = log2(length(G)))\n    res = mle.getEncodingLength(ptBSbyK, NULL, ptID, G)\n    df_ctd[fold, \"ptID\"] = cohorts[[model]][fold]\n    df_ctd[fold, \"mets\"] = paste(names(which(ptBSbyK[[which.max(res[,\"d.score\"])]]==1)), collapse=\"@\")\n    df_ctd[fold, \"m\"] = res[which.max(res[,\"d.score\"]), \"d.score\"]-log2(nrow(res))\n    mdst = c(mdst, names(which(ptBSbyK[[which.max(res[,\"d.score\"])]]==1)))\n  }\n  # CTD will select metabolites that are present in at least 50% of patients' optimally connected subsets\n  module_select[[\"CTD\"]][[model]] = names(table(mdst)[table(mdst)>(length(cohorts[[model]])\/2)])\n  \n  # FSFCN algorithm\n  diag_data = data_mx[,which(colnames(data_mx) %in% c(cohorts[[model]], cohorts$ref))]\n  diags = colnames(diag_data)\n  diags[-which(diags %in% cohorts[[model]])] = 0\n  diags[which(diags %in% cohorts[[model]])] = 1\n  diags = as.numeric(diags)\n  R = whichRtoSelect(diag_data, diags)\n  ig_pruned = prunedIGraph(diag_data, diags, R=R)\n  # InfoMap: FSFCN\n  cc = cluster_infomap(ig_pruned, e.weights = abs(E(ig_pruned)$weight), v.weights = NULL, nb.trials = 10, modularity = FALSE)\n  module_select[[\"FSFCN-InfoMap\"]][[model]] = fsfcn(ig_pruned, diag_data, diags, communities(cc))\n  # Walktrap: FSFCN\n  cc = cluster_walktrap(ig_pruned)\n  module_select[[\"FSFCN-WalkTrap\"]][[model]] = fsfcn(ig_pruned, diag_data, diags, communities(cc))\n  # GMO: FSFCN\n  E(ig_pruned)$weight = abs(E(ig_pruned)$weight)\n  cc = cluster_fast_greedy(ig_pruned)\n  module_select[[\"FSFCN-GMO\"]][[model]] = fsfcn(ig_pruned, diag_data, diags, communities(cc))\n}","command_name":"Apply CTD as a feature selection method.","command":"Other feature selection methods are also run to compare CTD to:\n\n1. Top z-score method\n2. FCFSN with Greedy Modularity Optimization \n3. FCFSN with InfoMap\n4. FCFSN with WalkTrap","os_name":null,"os_version":null}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#EA94FF","section_duration":1224,"critical":null,"critical_id":null,"duration":22},{"id":1068555,"guid":"7DC5C82C0C4A48B183C992B953766D1A","previous_id":1068554,"previous_guid":"27DAF51123804C179348C091CBC5EF4D","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"CFE0C1D706FB414483FE692CE02FAC0F","order_id":1,"type_id":6,"title":"Section","source":{"title":"Table 5: CTD as a feature selection method"}},{"id":1054724,"guid":"0D6636B5F67B4BBE9AD414B573C9139B","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Estimate and plot the variable importance of every feature selected in each feature selection method.<\/div><\/div>"}},{"id":1054725,"guid":"872F0160E95811EAA3434F176A4D61AA","order_id":2,"type_id":15,"title":"command","source":{"id":8143,"name":"# CTD disease specific PLS models call \"yes\" or \"no\" based on CTD-derived significance \n# of patient's top metabolite perturbations.\nrm(list=setdiff(ls(),c(\"data_mx.og\",\"cohorts\", \"data_mx\",\"module_select\")))\nrequire(pls)\nrequire(pROC)\nrequire(caret) # for varImp function\ndir.create('.\/pls', showWarnings = FALSE)\nfsmethods=c(\"Zscore\", \"CTD\", \"FSFCN-GMO\", \"FSFCN-InfoMap\", \"FSFCN-WalkTrap\")\ndf_varImp2=list()\ndff_model=list()\nfor (model in c(\"cit\", \"msud\", \"mma\", \"pa\", \"pku\")) {\n  # Get CTD LOOCV signal \n  load(sprintf(\".\/loocv\/loocv_ind_runCTD\/best_bits_%s_ind_loocv.RData\", model))\n  data_mx2 = data_mx[, dff$ptID]\n  # add CTD score as covariate\n  data_mx2 = rbind(dff$bits, data_mx2)\n  rownames(data_mx2)[1] = \"CTD.covariate\"\n  data_mx2 = t(apply(data_mx2, 1, scale))\n  colnames(data_mx2) = dff$ptID\n  # Get diagnostic labels\n  diag = dff$diag\n  diag[which(diag != model)] = 0\n  diag[which(diag == model)] = 1\n  data_mx2 = rbind(as.numeric(diag), data_mx2)\n  rownames(data_mx2)[1] = \"diag\"\n  data_mx2 = apply(data_mx2, c(1,2), as.numeric)\n  \n  # compute variant importance of CTD score as a covariate in pls regression model\n  df2_fsmethod=list()\n  varImp=list()\n  varimp=list()\n  dff_model[[model]]=list()\n  for (fsmethod in fsmethods){\n    df2_fsmethod[[fsmethod]] = data_mx2[which(rownames(data_mx2) %in% c(\"CTD.covariate\", \"diag\", module_select[[fsmethod]][[model]])),]\n    varImp[[fsmethod]] = vector(\"list\", length=ncol(data_mx2))\n    for (it in 1:ncol(data_mx2)){\n      isTrain = c(1:ncol(data_mx2))[-it]\n      model_res = plsr(diag~., data = as.data.frame(t(df2_fsmethod[[fsmethod]][,isTrain])))\n      varImp[[fsmethod]][[it]] = varImp(model_res)\n      tst_data = df2_fsmethod[[fsmethod]][-1,it]\n      model_tst =  predict(model_res, ncomp=model_res$ncomp, newdata=as.data.frame(t(tst_data)))\n      dff_model[[model]][[fsmethod]][it] = model_tst\n    }\n    varimp[[fsmethod]]=apply(as.data.frame(varImp[[fsmethod]]),1,mean)\n    names(varimp[[fsmethod]])=gsub(\"\\\\`\", \"\", names(varimp[[fsmethod]]))\n  }\n  \n  for (fsmethod in fsmethods){\n    percentile = 1 - length(which(varimp[[fsmethod]]>=varimp[[fsmethod]][[\"CTD.covariate\"]]))\/length(varimp[[fsmethod]])\n    mets_who_beat = names(which(varimp[[fsmethod]]>varimp[[fsmethod]][[\"CTD.covariate\"]]))\n    print(sprintf(\"%s: Model %s placed CTD.covariate in %f-th percentile, rank was %d\/%d. Mets who beat were %s\", model, fsmethod, percentile, length(mets_who_beat)+1, length(varimp[[fsmethod]]), paste(mets_who_beat, collapse=\", \")))\n  }\n  \n  df_varImp2[[model]] = data.frame(metabolite=names(Reduce(c,varimp)),\n                                   varimp=Reduce(c,varimp),\n                                   model=Reduce(c,sapply(names(varimp), function(x) rep(x,length(varimp[[x]])))))\n}","command_name":"Variable importance calculation.","command":"May take a few minutes.","os_name":null,"os_version":null}},{"id":1054726,"guid":"A627C700E95811EAA3434F176A4D61AA","order_id":3,"type_id":15,"title":"command","source":{"id":8144,"name":"rm(list=setdiff(ls(),c(\"data_mx.og\",\"cohorts\",\"fsmethods\",\"dff_model\",\"df_varImp2\")))\np=list()\nfor (model in c(\"cit\", \"msud\", \"mma\", \"pa\", \"pku\")){\n  p[[model]]=ggplot(df_varImp2[[model]], aes(x=metabolite, y=varimp, group=model, colour=model)) +\n    geom_point(size=5) +\n    geom_line(size=2) +\n    theme(text = element_text(size=25), axis.text.x = element_text(angle = 45, hjust = 1)) +\n    ggtitle(sprintf(\"Variable Importance for %s\", toupper(model)))\n}\np","command_name":"Plot variable importance","command":null,"os_name":null,"os_version":null}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#EA94FF","section_duration":1224,"critical":null,"critical_id":null,"duration":1200},{"id":1068556,"guid":"8E9FB6CB3F72422B863656C5EA0C8F56","previous_id":1068555,"previous_guid":"7DC5C82C0C4A48B183C992B953766D1A","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"BF6DC93613CD48DC9078084C2D9E70D3","order_id":1,"type_id":6,"title":"Section","source":{"title":"Table 5: CTD as a feature selection method"}},{"id":1054724,"guid":"F9988224DB764E649CA57B2DBCAF058A","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Calculate the area under the curve (AUC) for each partial least sqaures (PLS) regression model.<\/div><\/div>"}},{"id":1054725,"guid":"C69A5B60E95811EAA3434F176A4D61AA","order_id":2,"type_id":15,"title":"command","source":{"id":8145,"name":"# calculate AUC\npls_auc=list()\npls_auc2=list()\nfor (model in c(\"cit\", \"msud\", \"mma\", \"pa\", \"pku\")) {\n  print(\"\")\n  print(sprintf(\"For %s model...\", toupper(model)))\n\n  # Get diagnostic labels\n  load(sprintf(\".\/loocv\/loocv_ind_runCTD\/best_bits_%s_ind_loocv.RData\", model))\n  diag = dff$diag\n  diag[which(diag != model)] = 0\n  diag[which(diag == model)] = 1\n  \n  # Calculate AUC using pROC, since you cannot calculate directly with TP, TN, FP, FN\n  for (fsmethod in fsmethods){\n    pls_auc[[fsmethod]]=roc(diag, dff_model[[model]][[fsmethod]], quiet = TRUE)\n    print(sprintf(\"PLS regression by %s selected features + CTD.covariate AUC = %.3f\", fsmethod, pls_auc[[fsmethod]]$auc))\n    pls_auc2[[fsmethod]] = coords(pls_auc[[fsmethod]], \"best\", ret=c(\"threshold\", \"specificity\", \"accuracy\", \"precision\", \"recall\"))\n  }\n  ctd_auc = roc(diag, dff$bits, quiet = TRUE)\n  print(sprintf(\"PLS regression by CTD.covariate only AUC = %.3f\", pls_auc[[fsmethod]]$auc))\n  ctd_auc2 = coords(ctd_auc, \"best\", ret=c(\"threshold\", \"specificity\", \"accuracy\", \"precision\", \"recall\"))\n  print(pls_auc2)\n  print(ctd_auc2)\n}","command_name":"Calculate the AUC for PLS.","command":null,"os_name":null,"os_version":null}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#EA94FF","section_duration":1224,"critical":null,"critical_id":null,"duration":1},{"id":1068557,"guid":"F3F4D5671C06403EBF4061924011868D","previous_id":1068556,"previous_guid":"8E9FB6CB3F72422B863656C5EA0C8F56","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"ACFE162D4EE9428A9567E8691064C393","order_id":1,"type_id":6,"title":"Section","source":{"title":"TCGA: topological pathway enrichment analysis"}},{"id":1054724,"guid":"1C8351ED33604DC48B629DFB657CF980","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Topological Pathway Enrichment Analysis for Breast Cancer Subtypes <\/div><div class = \"text-block\">TCGA data was downloaded as shared through the UCSC via the Xena browser: <\/div><div class = \"text-block\">HiSeqV2:<\/div><div class = \"text-block\"><a href=\"https:\/\/xenabrowser.net\/datapages\/?dataset=TCGA.BRCA.sampleMap%2FHiSeqV2&host=https%3A%2F%2Ftcga.xenahubs.net&removeHub=https%3A%2F%2Fxena.treehouse.gi.ucsc.edu%3A443\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">https:\/\/xenabrowser.net\/datapages\/?dataset=TCGA.BRCA.sampleMap%2FHiSeqV2&host=https%3A%2F%2Ftcga.xenahubs.net&removeHub=https%3A%2F%2Fxena.treehouse.gi.ucsc.edu%3A443<\/span><\/a><\/div><div class = \"text-block\">BRCA_clinicalMatrix:<\/div><div class = \"text-block\"><a href=\"https:\/\/xenabrowser.net\/datapages\/?dataset=TCGA.BRCA.sampleMap%2FBRCA_clinicalMatrix&host=https%3A%2F%2Ftcga.xenahubs.net&removeHub=https%3A%2F%2Fxena.treehouse.gi.ucsc.edu%3A443\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">https:\/\/xenabrowser.net\/datapages\/?dataset=TCGA.BRCA.sampleMap%2FBRCA_clinicalMatrix&host=https%3A%2F%2Ftcga.xenahubs.net&removeHub=https%3A%2F%2Fxena.treehouse.gi.ucsc.edu%3A443<\/span><\/a><\/div><div class = \"text-block\">Using the clinicalMatrix, we can select samples from HiSeqV2 that are breast cancer samples and identify the specific subtype of breast cancer for each sample.<\/div><div class = \"text-block\"><span style = \"font-weight:bold;\">An important note<\/span><span>: Since CePa, SPIA and PRS use permutation testing to estimate p-values, we noticed slightly different p-value estimates between runs. The same general results are reproduced across runs, but p-values outputted by these methods will differ slightly.<\/span><\/div><div class = \"text-block\">R package versioning:<\/div><div class = \"text-block\"><ul style = \"list-style-type:disc;\"><li style = \"counter-reset:ol0;list-style-type:disc;\">CTD v 1.0.0<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">CTDext v 1.0.0<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">graphics (in base R version 4.0.2)<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">dplyr v 1.0.2<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">DESeq2 v 1.28.1<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">graphite v 1.34.0<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">igraph v 1.2.5<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">graph v 1.66.0<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">CePa v 0.7.0<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">huge v 1.3.4.1<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">org.Hs.eg.db v 3.11.4<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">EnrichmentBrowser v 2.18.0<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">ToPASeq v 1.22.0<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">SPIA v 2.40.0<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">DEGraph v 1.40.0<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">fgsea v 1.14.0<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">reshape2 v 1.4.4<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">ggplot2 v 3.3.2<\/li><\/ul><\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#A492FF","section_duration":59100,"critical":null,"critical_id":null,"duration":60},{"id":1068558,"guid":"EBD9A9401776435CB6B0C6936E8D5C7F","previous_id":1068557,"previous_guid":"F3F4D5671C06403EBF4061924011868D","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"EBDE7FC7892D49AA8D476D51838C8817","order_id":1,"type_id":6,"title":"Section","source":{"title":"TCGA: topological pathway enrichment analysis"}},{"id":1054724,"guid":"9C72BC231DCE49C486250ED488D4939F","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Normalize TGCA Breast Cancer and Normal Samples with the DESeq2 R package. Secondly, load the pathway knowledge using the graphite R package and build a pathway catalogue R object. <\/div><\/div>"}},{"id":1054725,"guid":"3EB46270ECBB11EA8D17D1E06244DC3A","order_id":2,"type_id":15,"title":"command","source":{"id":8146,"name":"require(graphics)\nrequire(dplyr)\nrequire(DESeq2)\nBRCA.RNA = read.table(\"HiSeqV2\",header = TRUE) \nrownames(BRCA.RNA) = BRCA.RNA$sample\nBRCA.RNA$sample = NULL\nBRCA.RNA =  (2^BRCA.RNA) - 1\ncolnames(BRCA.RNA) = gsub(x = colnames(BRCA.RNA), pattern = \"\\\\.\", replacement = \"-\") \nBRCA.table.clinic = read.table(\"BRCA_clinicalMatrix\", header = TRUE, sep = \"\\t\", row.names = NULL)\nsubtype = BRCA.table.clinic[,c(\"sampleID\",\"PAM50Call_RNAseq\")]\nsubtype = subtype[!subtype$PAM50Call_RNAseq == \"\",]\nsample_subtypes = as.character(subtype$sampleID)\nnormal_samples = BRCA.RNA[,grep(\"-11\",colnames(BRCA.RNA))]\nnormal_samples_df = as.data.frame(colnames(normal_samples))\nnormal_samples$genes = rownames(normal_samples)\ncolnames(normal_samples_df) = \"sampleID\"\nnormal_samples_df$group = \"normal\"\n#114 normal samples \nBRCA.RNA.tumor = BRCA.RNA[,-grep(\"-11\",colnames(BRCA.RNA))]\n#remove the metastatic samples \nBRCA.RNA.tumor = BRCA.RNA.tumor[,-grep(\"-06\",colnames(BRCA.RNA.tumor))]\n#Remove the normal-like samples \nsubtype = subtype[!subtype$PAM50Call_RNAseq == \"Normal\", ]\ngroups = subtype\ncolnames(groups)[2] = \"group\"\ngroups  = rbind(groups,normal_samples_df)\ngroups = groups[!duplicated(groups$sampleID),]\nrownames(groups) = groups$sampleID\ngroups$sampleID = NULL\nrna_subtype = intersect(colnames(BRCA.RNA),rownames(groups))\nBRCA.RNA.keep = BRCA.RNA[,rna_subtype]\ngroups = groups[rna_subtype,,drop = FALSE]\n#DeSeq normalization\nBRCA.RNA.keep_round = round(BRCA.RNA.keep,digits = 0)\n#Remove genes with no expression \nBRCA.RNA.keep_round = BRCA.RNA.keep_round[rowSums(BRCA.RNA.keep_round) > 0, ]\n#Remove genes with no variance \nrequire(caret)\nnzv <- nearZeroVar(t(BRCA.RNA.keep_round), saveMetrics= TRUE)\nnzv = rownames(nzv[nzv$nzv == \"TRUE\",])\nBRCA.RNA.keep_round = BRCA.RNA.keep_round[!rownames(BRCA.RNA.keep_round) %in% nzv,]\nnames_counts_all = rownames(BRCA.RNA.keep_round)\nBRCA.RNA.keep_round = sapply(BRCA.RNA.keep_round, as.integer)\nrownames(BRCA.RNA.keep_round) = names_counts_all\ngroups$group = as.character(groups$group)\ngroups$group = as.factor(groups$group)\nrownames(groups)\nwrite.table(BRCA.RNA.keep_round,\"BRCA.RNA.keep_round.txt\", sep = \"\\t\")\nwrite.table(groups,\"groups.txt\", sep = \"\\t\")\nrequire(BiocParallel)\nregister(MulticoreParam(6))\ndds_groups=  DESeqDataSetFromMatrix(countData = BRCA.RNA.keep_round,\n                                    colData = groups,\n                                    design= ~ group  )\ndds_groups <- estimateSizeFactors(dds_groups)\nnormalized_counts_groups = counts(dds_groups,normalized = TRUE)\nnormalized_counts_groups = as.data.frame(normalized_counts_groups)\nsubtype = BRCA.table.clinic[,c(\"sampleID\",\"PAM50Call_RNAseq\")]\nsubtype = subtype[!subtype$PAM50Call_RNAseq == \"\",]\nsample_subtypes = as.character(subtype$sampleID)\nwrite.table(normalized_counts_groups,\"normal_BRCA_DESeq.txt\", sep = \"\\t\")\nwrite.table(groups,\"sample_ID_group.txt\")\nlumA_id = as.character(subtype$sampleID[which(subtype$PAM50Call_RNAseq==\"LumA\")])\nlumB_id = as.character(subtype$sampleID[which(subtype$PAM50Call_RNAseq==\"LumB\")])\nher2_id = as.character(subtype$sampleID[which(subtype$PAM50Call_RNAseq==\"Her2\")])\nnormal_like_id = as.character(subtype$sampleID[which(subtype$PAM50Call_RNAseq==\"Normal\")])\nbasal_id = as.character(subtype$sampleID[which(subtype$PAM50Call_RNAseq==\"Basal\")])\nwrite.table(lumA_id,\"lumA_id.txt\",sep = \"\\t\")\nwrite.table(lumB_id,\"lumB_id.txt\",sep = \"\\t\")\nwrite.table(her2_id,\"her2_id.txt\",sep = \"\\t\")\nwrite.table(normal_like_id,\"normal_like_id.txt\",sep = \"\\t\")\nwrite.table(basal_id,\"basal_id.txt\",sep = \"\\t\")","command_name":"Normalize TCGA breast cancer data","command":null,"os_name":null,"os_version":null}},{"id":1054726,"guid":"39EB6F10ECC311EA8D17D1E06244DC3A","order_id":3,"type_id":15,"title":"command","source":{"id":8147,"name":"require(graphite)\nrequire(igraph)\nrequire(graph)\nrequire(CePa)\n# Load pathways using the graphite package (compatible with most methods)\npwys = pathways(\"hsapiens\",\"kegg\")\n# Make a pathway catalogue (PC) object for the KEGG pathway knowledgebase (compatiable with CePa)\npathList = list()\ninteractionList = data.frame(interaction.id=numeric(), input=character(), output=character(), stringsAsFactors = FALSE)\nit = 1\nfor (n in 1:length(pwys)) {\n  print(n)\n  it.ids = c()\n  pwy_graphNEL = pathwayGraph(pwys[[n]])\n  ig = igraph.from.graphNEL(pwy_graphNEL)\n  e_list = get.edgelist(ig)\n  if (nrow(e_list)>0) {\n    for (r in 1:nrow(e_list)) {\n      interactionList[it, \"interaction.id\"] = it\n      it.ids = c(it.ids, it)\n      interactionList[it, \"input\"] = e_list[r,1]\n      interactionList[it, \"output\"] = e_list[r,2]\n      it = it + 1\n    }\n    pathList[[names(pwys)[n]]] = it.ids\n  }\n}\n# Get ENTREZ ID mappings to Gene SYMBOLS\nrequire(org.Hs.eg.db)\nmap_df = as.data.frame(mapIds(org.Hs.eg.db, rownames(normalized_counts_groups), 'ENTREZID', 'SYMBOL'))\ncolnames(map_df) = \"entrez_id\"\nmap_df$gene = rownames(map_df)\nmapping = data.frame(node.id=sprintf(\"ENTREZID:%s\", map_df$entrez_id), symbol=map_df$gene, stringsAsFactors = FALSE)\npc = set.pathway.catalogue(pathList, interactionList, mapping, min.node=5, max.node=5000, min.gene=5, max.gene=5000)\n# optional save state for easy reload\nsave(pc, file=\"kegg_pc.RData\")\n# Keep only pathways from graphite package also found in the KEGG Pathway Catalogue used for CePa.\npwys = pwys[which(names(pwys) %in% names(pc$pathList))]","command_name":"Load pathways using graphite and pathway catalogue formats","command":"graphite is an R package that works with several of the topological pathway enrichment methods we compare CTD to (SPIA, DEGraph, ORA, GSEA).\n\nCePa requires a different format for communicating pathway knowledge: a pathway catalogue object, which is a list object that contains specific values: pathList, interactionList.\n\nWe copy information from graphite's pathway knowledge pulled from KEGG, to build a pathway catalogue object compatible with CePa in this code snippet.","os_name":null,"os_version":null}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#A492FF","section_duration":59100,"critical":null,"critical_id":null,"duration":2040},{"id":1068559,"guid":"E72CECA1A79B4FA79ABC56903B5C28DE","previous_id":1068558,"previous_guid":"EBD9A9401776435CB6B0C6936E8D5C7F","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"DD6B20DB15C44F9B964FC9C4C0944DC2","order_id":1,"type_id":6,"title":"Section","source":{"title":"TCGA: topological pathway enrichment analysis"}},{"id":1054724,"guid":"0FE50962CBC44671B22640C7D1B9083D","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">CTD for each subtype<\/div><\/div>"}},{"id":1054725,"guid":"1E938230ED5811EA8A6D83C1F0C82F98","order_id":2,"type_id":15,"title":"command","source":{"id":8148,"name":"require(CTD)\nrequire(huge)\nrequire(org.Hs.eg.db)\ndf_ctd = data.frame(subtype=character(), pathway=character(), ctd.pval=numeric(), stringsAsFactors = FALSE)\nr = 1\nfor (subtype_to_test in c(\"lumA\", \"lumB\", \"her2\", \"basal\")) {\n  #Ids\n  subtype_id = read.table(sprintf(\"%s_id.txt\",subtype_to_test), sep=\"\\t\", header=TRUE, check.names=FALSE)\n  subtype_id = as.character(subtype_id$x)\n  subtype_id = gsub(\"\\\\-\",\".\",subtype_id)\n  subtype_id = subtype_id[-grep(\"\\\\.06\",subtype_id)]\n  print(\"IDs loaded\")\n  #R load the data set with the subtype samples and normal samples only\n  subtype_normal = as.data.frame(read.table(\"normal_BRCA_DESeq.txt\", header=TRUE, stringsAsFactors = FALSE))\n  subtype_normal = subtype_normal[, c(grep(\"\\\\.11\", colnames(subtype_normal)), which(colnames(subtype_normal) %in% subtype_id))]\n  subtype_normal = apply(subtype_normal, c(1,2), as.numeric)\n  subtype_normal = subtype_normal[rowSums(subtype_normal) > 0,]\n  # map ENTREZ IDs to Gene SYMBOL, because various pathway packages use ENTREZ IDs and our dataset uses Gene SYMBOLs\n  map_df = as.data.frame(mapIds(org.Hs.eg.db, rownames(subtype_normal), 'ENTREZID', 'SYMBOL'))\n  colnames(map_df) = \"entrez_id\"\n  map_df$gene = rownames(map_df)\n  subtype_normal = subtype_normal[-which(is.na(map_df$entrez_id)),]\n  map_df = map_df[-which(is.na(map_df$entrez_id)),]\n  subtype_normal = subtype_normal[sort(rownames(subtype_normal)),]\n  map_df = map_df[sort(map_df$gene),]\n  # Rename Gene SYMBOL rownames in our TCGA dataset to their respective ENTREZ IDs\n  subtype_normal_entrez = subtype_normal\n  rownames(subtype_normal_entrez) = map_df$entrez_id\n  rownames(subtype_normal_entrez) = sprintf(\"ENTREZID:%s\", rownames(subtype_normal_entrez))\n  subtype_normal_entrez = apply(subtype_normal_entrez, c(1,2), as.numeric)\n  subtype_normal_entrez = subtype_normal_entrez[rowSums(subtype_normal_entrez)>0, ]\n  # Indicator variable to identify the cancer vs normal samples \n  phenoData = colnames(subtype_normal)\n  phenoData[grep(\".01\",phenoData)] = 1\n  phenoData[grep(\".11\",phenoData)] = 0\n  # Use the deAna function to perform differential expression between subtype cases and controls\n  # Define differentially expressed (DE) genes between the two conditions\n  # ...Using ENTREZ IDs\n  subtype_normal_entrez_de = deAna(as.matrix(subtype_normal_entrez),grp = phenoData,  de.method=\"limma\")\n  subtype_normal_entrez_de_fc = subtype_normal_entrez_de$FC\n  all = rownames(subtype_normal_entrez_de)\n  names(subtype_normal_entrez_de_fc) = all\n  # CTD starts here.\n  subtype_normal_entrez2 = log2(subtype_normal_entrez+1)\n  dif.genes = names(which(abs(subtype_normal_entrez_de_fc)>quantile(abs(subtype_normal_entrez_de_fc), 0.95)))\n  paths.hsa = names(pwys)\n  for (pathway in 1:length(paths.hsa)) {\n    print(sprintf(\"Pathway %d\/%d...\", pathway, length(paths.hsa)))\n    pwy_graphNEL = pathwayGraph(pwys[[pathway]])\n    ig = igraph.from.graphNEL(pwy_graphNEL)\n    tmp = t(subtype_normal_entrez2[which(rownames(subtype_normal_entrez2) %in% V(ig)$name),])\n    if (ncol(tmp)>0) {\n      rrr = apply(tmp, 2, sd)\n      if (length(which(rrr==0))>0) {tmp = tmp[,-which(rrr==0)]}\n      tmp_ref = t(subtype_normal_entrez2[which(rownames(subtype_normal_entrez2) %in% V(ig)$name), grep(\".11\", colnames(subtype_normal_entrez2))])\n      rrr = apply(tmp_ref, 2, sd)\n      if (length(which(rrr==0))>0) {tmp_ref = tmp_ref[,-which(rrr==0)]}\n      # Disease+reference interaction network\n      inv_covmatt = huge(tmp, method=\"glasso\", lambda=0.1)\n      inv_covmat = as.matrix(inv_covmatt$icov[[1]])\n      diag(inv_covmat) = 0;\n      colnames(inv_covmat) = colnames(tmp)\n      ig = graph.adjacency(as.matrix(inv_covmat), mode=\"undirected\", weighted=TRUE, add.colnames='name')\n      V(ig)$name = colnames(inv_covmat)\n      # Reference only network\n      inv_covmatt_ref = huge(tmp_ref, method=\"glasso\", lambda=0.1)\n      inv_covmat_ref = as.matrix(inv_covmatt_ref$icov[[1]])\n      diag(inv_covmat_ref) = 0;\n      colnames(inv_covmat_ref) = colnames(tmp_ref)\n      ig_ref = graph.adjacency(as.matrix(inv_covmat_ref), mode=\"undirected\", weighted=TRUE, add.colnames='name')\n      V(ig_ref)$name = colnames(inv_covmat_ref)\n      if (length(E(ig)$weight)>0) {\n        ig_pruned = graph.naivePruning(ig, ig_ref)\n        adj_mat = as.matrix(get.adjacency(ig_pruned, attr=\"weight\"))\n        G = vector(mode=\"list\", length=length(V(ig_pruned)$name))\n        names(G) = V(ig_pruned)$name\n        if (length(dif.genes[which(dif.genes %in% V(ig_pruned)$name)])>0) {\n          for (n in 1:length(dif.genes[which(dif.genes %in% V(ig_pruned)$name)])) {\n            ind = which(names(G)==dif.genes[which(dif.genes %in% V(ig_pruned)$name)][n])\n            ranks[[n]] = singleNode.getNodeRanksN(ind, G, p1=0.9, thresholdDiff=0.01, adj_mat, S=dif.genes[which(dif.genes %in% V(ig_pruned)$name)])\n          }\n          names(ranks) = dif.genes[which(dif.genes %in% V(ig_pruned)$name)]\n          ptBSbyK = mle.getPtBSbyK(dif.genes[which(dif.genes %in% V(ig_pruned)$name)], ranks)\n          res = mle.getEncodingLength(ptBSbyK, NULL, NULL, G)\n          df_ctd[r, \"subtype\"] = subtype_to_test\n          df_ctd[r, \"pathway\"] = paths.hsa[pathway]\n          df_ctd[r, \"ctd.pval\"] = 2^-(max(res$d.score)-log2(length(dif.genes[which(dif.genes %in% V(ig)$name)])))\n          r = r + 1\n        } else {\n          df_ctd[r, \"subtype\"] = subtype_to_test\n          df_ctd[r, \"pathway\"] = paths.hsa[pathway]\n          df_ctd[r, \"ctd.pval\"] = 1\n          r = r + 1\n        }\n      } else {\n        df_ctd[r, \"subtype\"] = subtype_to_test\n        df_ctd[r, \"pathway\"] = paths.hsa[pathway]\n        df_ctd[r, \"ctd.pval\"] = 1\n        r = r + 1\n      }\n    } else {\n      df_ctd[r, \"subtype\"] = subtype_to_test\n      df_ctd[r, \"pathway\"] = paths.hsa[pathway]\n      df_ctd[r, \"ctd.pval\"] = 1\n      r = r + 1\n    }\n  }\n  df_ctd[which(df_ctd$ctd.pval>1), \"ctd.pval\"] = 1\n  print(\"ctd done\")\n}\nsave(df_ctd, file=\"ctd_tbpe.RData\")","command_name":"CTD as a topological-based pathway enrichment method","command":"Subtypes: \n\"lumA\" : Luminal A\n\"lumB\": Luminal B\n\"her2\": HER2\n\"basal\": Basal","os_name":null,"os_version":null}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#A492FF","section_duration":59100,"critical":null,"critical_id":null,"duration":14400},{"id":1068560,"guid":"D47092FCE70D4DA0B840F4B1EEB48DA7","previous_id":1068559,"previous_guid":"E72CECA1A79B4FA79ABC56903B5C28DE","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"19C78004A83C4A8CADF556E13906083A","order_id":1,"type_id":6,"title":"Section","source":{"title":"TCGA: topological pathway enrichment analysis"}},{"id":1054724,"guid":"5B84BF51BA8148B39C6976278A43A157","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">CePa for each subtype<\/div><\/div>"}},{"id":1054725,"guid":"8214B230ED5C11EA8A6D83C1F0C82F98","order_id":2,"type_id":15,"title":"command","source":{"id":8149,"name":"require(CePa)\nrequire(EnrichmentBrowser)\nload(\"kegg_pc.RData\")\ndf_cepa = data.frame(subtype=character(), pathway=character(), cepa.pval=numeric(), stringsAsFactors = FALSE)\nfor (subtype_to_test in c(\"lumA\", \"lumB\", \"her2\", \"basal\")) {\n  #Ids\n  subtype_id = read.table(sprintf(\"%s_id.txt\",subtype_to_test), sep=\"\\t\", header=TRUE, check.names=FALSE)\n  subtype_id = as.character(subtype_id$x)\n  subtype_id = gsub(\"\\\\-\",\".\",subtype_id)\n  if (length(grep(\"\\\\.06\",subtype_id))>0) { subtype_id = subtype_id[-grep(\"\\\\.06\",subtype_id)] }\n  print(sprintf(\"IDs loaded for subtype %s\", subtype_to_test))\n  #R load the data set with the subtype samples and normal samples only\n  subtype_normal = as.data.frame(read.table(\"normal_BRCA_DESeq.txt\", header=TRUE, stringsAsFactors = FALSE))\n  subtype_normal = subtype_normal[, c(grep(\"\\\\.11\", colnames(subtype_normal)), which(colnames(subtype_normal) %in% subtype_id))]\n  subtype_normal = apply(subtype_normal, c(1,2), as.numeric)\n  subtype_normal = subtype_normal[rowSums(subtype_normal) > 0,]\n  # Indicator variable to identify the cancer vs normal samples \n  phenoData = colnames(subtype_normal)\n  phenoData[grep(\".01\",phenoData)] = 1\n  phenoData[grep(\".11\",phenoData)] = 0\n  # Use the deAna function to perform differential expression between subtype cases and controls\n  # Define differentially expressed (DE) genes between the two conditions\n  # ...Using Gene SYMBOLS\n  subtype_normal_de = deAna(as.matrix(subtype_normal),grp = phenoData,  de.method=\"limma\")\n  subtype_normal_de_fc = subtype_normal_de$FC\n  all = rownames(subtype_normal_de)\n  names(subtype_normal_de_fc) = all\n  ## CePa starts here.\n  phenoData_cepa = sampleLabel(phenoData,treatment = \"1\",control = \"0\")\n  dif.genes = names(which(abs(subtype_normal_de_fc)>quantile(abs(subtype_normal_de_fc), 0.95)))\n  cepa_df = cepa.all(dif = dif.genes, bk = names(subtype_normal_de_fc), pc=pc)\n  dff = data.frame(subtype=character(), pathway=character(), cepa.pval=numeric(), stringsAsFactors = FALSE)\n  dff[1:length(cepa_df), \"subtype\"] = subtype_to_test\n  dff[1:length(cepa_df), \"pathway\"] = names(pc$pathList)\n  dff[1:length(cepa_df), \"cepa.pval\"] = unlist(lapply(cepa_df, function(i) i$betweenness$p.value))\n  df_cepa = rbind(df_cepa, dff)\n  print(\"cepa done\")\n}\nsave(df_cepa, file=\"cepa_tbpe.RData\")","command_name":"CePa","command":"Subtypes: \n\"lumA\" : Luminal A\n\"lumB\": Luminal B\n\"her2\": HER2\n\"basal\": Basal","os_name":null,"os_version":null}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#A492FF","section_duration":59100,"critical":null,"critical_id":null,"duration":3000},{"id":1068561,"guid":"12C91FAE219144EAADCEF36DCE06C3A7","previous_id":1068560,"previous_guid":"D47092FCE70D4DA0B840F4B1EEB48DA7","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"3F905A1940F248558B7132C6591EF51A","order_id":1,"type_id":6,"title":"Section","source":{"title":"TCGA: topological pathway enrichment analysis"}},{"id":1054724,"guid":"D9AA36C7E77A4155B8AFC999AB54B47D","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">PRS for each subtype.<\/div><div class = \"text-block\">If you are unhappy with the amount of time it takes PRS to run, set the nperm parameter to 100 instead of 1000. This will only allow a minimum p-value of 0.01, whereas 1000 permutations can estimate p-values at the resolution of 0.001.<\/div><\/div>"}},{"id":1054725,"guid":"050F3490ED8411EA8A6D83C1F0C82F98","order_id":2,"type_id":15,"title":"command","source":{"id":8150,"name":"require(ToPASeq)\nrequire(org.Hs.eg.db)\nrequire(EnrichmentBrowser)\ndf_prs = data.frame(subtype=character(), pathway=character(), prs.pval=numeric(), stringsAsFactors = FALSE)\nr = 1\nfor (subtype_to_test in c(\"lumA\", \"lumB\", \"her2\", \"basal\")) {\n  #Ids\n  subtype_id = read.table(sprintf(\"%s_id.txt\",subtype_to_test), sep=\"\\t\", header=TRUE, check.names=FALSE)\n  subtype_id = as.character(subtype_id$x)\n  subtype_id = gsub(\"\\\\-\",\".\",subtype_id)\n  if (length(grep(\"\\\\.06\",subtype_id))>0) { subtype_id = subtype_id[-grep(\"\\\\.06\",subtype_id)] }\n  print(sprintf(\"IDs loaded for subtype %s\", subtype_to_test))\n  #R load the data set with the subtype samples and normal samples only\n  subtype_normal = as.data.frame(read.table(\"normal_BRCA_DESeq.txt\", header=TRUE, stringsAsFactors = FALSE))\n  subtype_normal = subtype_normal[, c(grep(\"\\\\.11\", colnames(subtype_normal)), which(colnames(subtype_normal) %in% subtype_id))]\n  subtype_normal = apply(subtype_normal, c(1,2), as.numeric)\n  subtype_normal = subtype_normal[rowSums(subtype_normal) > 0,]\n  # map ENTREZ IDs to Gene SYMBOL, because various pathway packages use ENTREZ IDs and our dataset uses Gene SYMBOLs\n  map_df = as.data.frame(mapIds(org.Hs.eg.db, rownames(subtype_normal), 'ENTREZID', 'SYMBOL'))\n  colnames(map_df) = \"entrez_id\"\n  map_df$gene = rownames(map_df)\n  subtype_normal = subtype_normal[-which(is.na(map_df$entrez_id)),]\n  map_df = map_df[-which(is.na(map_df$entrez_id)),]\n  subtype_normal = subtype_normal[sort(rownames(subtype_normal)),]\n  map_df = map_df[sort(map_df$gene),]\n  # Rename Gene SYMBOL rownames in our TCGA dataset to their respective ENTREZ IDs\n  subtype_normal_entrez = subtype_normal\n  rownames(subtype_normal_entrez) = map_df$entrez_id\n  rownames(subtype_normal_entrez) = sprintf(\"ENTREZID:%s\", rownames(subtype_normal_entrez))\n  subtype_normal_entrez = apply(subtype_normal_entrez, c(1,2), as.numeric)\n  subtype_normal_entrez = subtype_normal_entrez[rowSums(subtype_normal_entrez) > 0, ]\n  # Indicator variable to identify the cancer vs normal samples \n  phenoData = colnames(subtype_normal)\n  phenoData[grep(\".01\",phenoData)] = 1\n  phenoData[grep(\".11\",phenoData)] = 0\n  # Use the deAna function to perform differential expression between subtype cases and controls\n  # Define differentially expressed (DE) genes between the two conditions\n  # ...Using ENTREZ IDs\n  subtype_normal_entrez_de = deAna(as.matrix(subtype_normal_entrez),grp = phenoData,  de.method=\"limma\")\n  subtype_normal_entrez_de_fc = subtype_normal_entrez_de$FC\n  all = rownames(subtype_normal_entrez_de)\n  names(subtype_normal_entrez_de_fc) = all\n  ## PRS starts here.\n  for (n in 1:length(pwys)) {\n    print(sprintf(\"%d \/ %d...\", n, length(pwys)))\n    df_prs[r,\"subtype\"] = subtype_to_test\n    df_prs[r,\"pathway\"] = names(pwys)[n]\n    prs_df = try(prs(de = subtype_normal_entrez_de_fc,all =  all, pwys = pwys[n], nperm=1000))\n    if (class(prs_df)==\"try-error\" || nrow(prs_df)==0) {\n      df_prs[r,\"prs.pval\"] = NA\n    } else {\n      df_prs[r,\"prs.pval\"] = prs_df$p.value\n    }\n    r = r + 1\n  }\n  print(\"prs done\")\n}\nsave(df_prs, file=\"prs_tbpe.RData\")","command_name":"PRS","command":"Subtypes: \n\"lumA\" : Luminal A\n\"lumB\": Luminal B\n\"her2\": HER2\n\"basal\": Basal","os_name":null,"os_version":null}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#A492FF","section_duration":59100,"critical":null,"critical_id":null,"duration":36000},{"id":1068562,"guid":"14EFA2E6C0B44926901DE624C6B15954","previous_id":1068561,"previous_guid":"12C91FAE219144EAADCEF36DCE06C3A7","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"1D47E187ADAC49E2982C2E89A299863C","order_id":1,"type_id":6,"title":"Section","source":{"title":"TCGA: topological pathway enrichment analysis"}},{"id":1054724,"guid":"084DA6620BAC4F9EB9F9E9924DC00EAC","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">SPIA for each subtype<\/div><\/div>"}},{"id":1054725,"guid":"FCFED800ED8311EA8A6D83C1F0C82F98","order_id":2,"type_id":15,"title":"command","source":{"id":8151,"name":"require(SPIA)\nrequire(org.Hs.eg.db)\nrequire(EnrichmentBrowser)\nprepareSPIA(pwys, \"baseKEGG\")\ndf_spia = data.frame(subtype=character(), pathway=character(), spia.pval=numeric(), stringsAsFactors = FALSE)\nfor (subtype_to_test in c(\"lumA\", \"lumB\", \"her2\", \"basal\")) {\n  #Ids\n  subtype_id = read.table(sprintf(\"%s_id.txt\",subtype_to_test), sep=\"\\t\", header=TRUE, check.names=FALSE)\n  subtype_id = as.character(subtype_id$x)\n  subtype_id = gsub(\"\\\\-\",\".\",subtype_id)\n  if (length(grep(\"\\\\.06\",subtype_id))>0) { subtype_id = subtype_id[-grep(\"\\\\.06\",subtype_id)] }\n  print(\"IDs loaded\")\n  #R load the data set with the subtype samples and normal samples only\n  subtype_normal = as.data.frame(read.table(\"normal_BRCA_DESeq.txt\", header=TRUE, stringsAsFactors = FALSE))\n  subtype_normal = subtype_normal[, c(grep(\"\\\\.11\", colnames(subtype_normal)), which(colnames(subtype_normal) %in% subtype_id))]\n  subtype_normal = apply(subtype_normal, c(1,2), as.numeric)\n  subtype_normal = subtype_normal[rowSums(subtype_normal) > 0,]\n  # map ENTREZ IDs to Gene SYMBOL, because various pathway packages use ENTREZ IDs and our dataset uses Gene SYMBOLs\n  map_df = as.data.frame(mapIds(org.Hs.eg.db, rownames(subtype_normal), 'ENTREZID', 'SYMBOL'))\n  colnames(map_df) = \"entrez_id\"\n  map_df$gene = rownames(map_df)\n  subtype_normal = subtype_normal[-which(is.na(map_df$entrez_id)),]\n  map_df = map_df[-which(is.na(map_df$entrez_id)),]\n  subtype_normal = subtype_normal[sort(rownames(subtype_normal)),]\n  map_df = map_df[sort(map_df$gene),]\n  # Rename Gene SYMBOL rownames in our TCGA dataset to their respective ENTREZ IDs\n  subtype_normal_entrez = subtype_normal\n  rownames(subtype_normal_entrez) = map_df$entrez_id\n  rownames(subtype_normal_entrez) = sprintf(\"ENTREZID:%s\", rownames(subtype_normal_entrez))\n  subtype_normal_entrez = apply(subtype_normal_entrez, c(1,2), as.numeric)\n  subtype_normal_entrez = subtype_normal_entrez[rowSums(subtype_normal_entrez) > 0, ]\n  # Indicator variable to identify the cancer vs normal samples \n  phenoData = colnames(subtype_normal)\n  phenoData[grep(\".01\",phenoData)] = 1\n  phenoData[grep(\".11\",phenoData)] = 0\n  # Use the deAna function to perform differential expression between subtype cases and controls\n  # Define differentially expressed (DE) genes between the two conditions\n  # ...Using ENTREZ IDs\n  subtype_normal_entrez_de = deAna(as.matrix(subtype_normal_entrez),grp = phenoData,  de.method=\"limma\")\n  subtype_normal_entrez_de_fc = subtype_normal_entrez_de$FC\n  all = rownames(subtype_normal_entrez_de)\n  names(subtype_normal_entrez_de_fc) = all\n  ## SPIA starts here.\n  spia_df = runSPIA(de=subtype_normal_entrez_de_fc, names(subtype_normal_entrez_de_fc), pathwaySetName=\"baseKEGG\", combine=\"fisher\")\n  spia_df = spia_df[,c(\"Name\", \"pG\")]\n  colnames(spia_df) = c(\"pathway\", \"spia.pval\")\n  spia_df[1:length(spia_df), \"subtype\"] = subtype_to_test\n  df_spia = rbind(df_spia, spia_df)\n  print(\"spia done\")\n}\nsave(df_spia, file=\"spia_tbpe.RData\")","command_name":"SPIA","command":"Subtypes: \n\"lumA\" : Luminal A\n\"lumB\": Luminal B\n\"her2\": HER2\n\"basal\": Basal","os_name":null,"os_version":null}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#A492FF","section_duration":59100,"critical":null,"critical_id":null,"duration":2700},{"id":1068563,"guid":"0322A3812DC34101BE26574E8B6FB053","previous_id":1068562,"previous_guid":"14EFA2E6C0B44926901DE624C6B15954","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"E94CF2DA735840EAB7B3CF666ADDB386","order_id":1,"type_id":6,"title":"Section","source":{"title":"TCGA: topological pathway enrichment analysis"}},{"id":1054724,"guid":"94D8E341D4CC4F1A94DD08680DAFE123","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">DEGraph for each subtype<\/div><\/div>"}},{"id":1054725,"guid":"F47309E0ED8311EA8A6D83C1F0C82F98","order_id":2,"type_id":15,"title":"command","source":{"id":8152,"name":"stat.fishersMethod.r = function(x) {\n  return (pchisq(-2 * sum(log(x)),df=2*length(x),lower.tail=FALSE))\n}\nrequire(DEGraph)\nrequire(org.Hs.eg.db)\ndf_degraph = data.frame(subtype=character(), pathway=character(), degraph.pval=numeric(), stringsAsFactors = FALSE)\nr = 1\nfor (subtype_to_test in c(\"lumA\", \"lumB\", \"her2\", \"basal\")) {\n  #Ids\n  subtype_id = read.table(sprintf(\"%s_id.txt\",subtype_to_test), sep=\"\\t\", header=TRUE, check.names=FALSE)\n  subtype_id = as.character(subtype_id$x)\n  subtype_id = gsub(\"\\\\-\",\".\",subtype_id)\n  if (length(grep(\"\\\\.06\",subtype_id))>0) { subtype_id = subtype_id[-grep(\"\\\\.06\",subtype_id)] }\n  print(sprintf(\"IDs loaded for subtype %s\", subtype_to_test))\n  #R load the data set with the subtype samples and normal samples only\n  subtype_normal = as.data.frame(read.table(\"normal_BRCA_DESeq.txt\", header=TRUE, stringsAsFactors = FALSE))\n  subtype_normal = subtype_normal[, c(grep(\"\\\\.11\", colnames(subtype_normal)), which(colnames(subtype_normal) %in% subtype_id))]\n  subtype_normal = apply(subtype_normal, c(1,2), as.numeric)\n  subtype_normal = subtype_normal[rowSums(subtype_normal) > 0,]\n  # map ENTREZ IDs to Gene SYMBOL, because various pathway packages use ENTREZ IDs and our dataset uses Gene SYMBOLs\n  map_df = as.data.frame(mapIds(org.Hs.eg.db, rownames(subtype_normal), 'ENTREZID', 'SYMBOL'))\n  colnames(map_df) = \"entrez_id\"\n  map_df$gene = rownames(map_df)\n  subtype_normal = subtype_normal[-which(is.na(map_df$entrez_id)),]\n  map_df = map_df[-which(is.na(map_df$entrez_id)),]\n  subtype_normal = subtype_normal[sort(rownames(subtype_normal)),]\n  map_df = map_df[sort(map_df$gene),]\n  # Rename Gene SYMBOL rownames in our TCGA dataset to their respective ENTREZ IDs\n  subtype_normal_entrez = subtype_normal\n  rownames(subtype_normal_entrez) = map_df$entrez_id\n  rownames(subtype_normal_entrez) = sprintf(\"ENTREZID:%s\", rownames(subtype_normal_entrez))\n  subtype_normal_entrez = apply(subtype_normal_entrez, c(1,2), as.numeric)\n  subtype_normal_entrez = subtype_normal_entrez[rowSums(subtype_normal_entrez) > 0, ]\n  # Indicator variable to identify the cancer vs normal samples \n  phenoData = colnames(subtype_normal)\n  phenoData[grep(\".01\",phenoData)] = 1\n  phenoData[grep(\".11\",phenoData)] = 0\n  # DEGraph starts here\n  for (n in 1:length(names(pwys))) {\n    print(sprintf(\"%d \/ %d...\", n, length(names(pwys))))\n    pwy_graphNEL = pathwayGraph(pwys[[n]])\n    res = try(testOneGraph(pwy_graphNEL, subtype_normal_entrez[which(rownames(subtype_normal_entrez) %in% nodes(pwy_graphNEL)), ], \n                           as.numeric(phenoData), useInteractionSigns=FALSE))\n    if (class(res)!=\"try-error\") {\n      df_degraph[r,\"subtype\"] = subtype_to_test\n      df_degraph[r,\"pathway\"] = names(pwys)[n]\n      df_degraph[r,\"degraph.pval\"] = stat.fishersMethod(as.numeric(lapply(res, function(i) i$p.value[2])))\n      r = r + 1\n    }\n  }\n  print(\"degraph done\")\n}\nsave(df_degraph, file=\"degraph_tbpe.RData\")","command_name":"DEGraph","command":"Subtypes: \n\"lumA\" : Luminal A\n\"lumB\": Luminal B\n\"her2\": HER2\n\"basal\": Basal","os_name":null,"os_version":null}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#A492FF","section_duration":59100,"critical":null,"critical_id":null,"duration":300},{"id":1068564,"guid":"36A8A7A0F12549D09C07E1D79B288F68","previous_id":1068563,"previous_guid":"0322A3812DC34101BE26574E8B6FB053","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"C8271A004FB9414AA78FEC69FE5724D8","order_id":1,"type_id":6,"title":"Section","source":{"title":"TCGA: topological pathway enrichment analysis"}},{"id":1054724,"guid":"71A778E753CD4AE6A713C31C07279ED6","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">ORA for each subtype<\/div><\/div>"}},{"id":1054725,"guid":"4ECBEC60ED8211EA8A6D83C1F0C82F98","order_id":2,"type_id":15,"title":"command","source":{"id":8153,"name":"require(org.Hs.eg.db)\nrequire(EnrichmentBrowser)\ndf_ora = data.frame(pathway=character(), ora.pval=numeric(), subtype=character(), stringsAsFactors = FALSE)\nfor (subtype_to_test in c(\"lumA\", \"lumB\", \"her2\", \"basal\")) {\n  #Ids\n  subtype_id = read.table(sprintf(\"%s_id.txt\",subtype_to_test), sep=\"\\t\", header=TRUE, check.names=FALSE)\n  subtype_id = as.character(subtype_id$x)\n  subtype_id = gsub(\"\\\\-\",\".\",subtype_id)\n  if (length(grep(\"\\\\.06\",subtype_id))>0) {   subtype_id = subtype_id[-grep(\"\\\\.06\",subtype_id)] }\n  print(sprintf(\"IDs loaded for subtype %s\", subtype_to_test))\n  #R load the data set with the subtype samples and normal samples only\n  subtype_normal = as.data.frame(read.table(\"normal_BRCA_DESeq.txt\", header=TRUE, stringsAsFactors = FALSE))\n  subtype_normal = subtype_normal[, c(grep(\"\\\\.11\", colnames(subtype_normal)), which(colnames(subtype_normal) %in% subtype_id))]\n  subtype_normal = apply(subtype_normal, c(1,2), as.numeric)\n  subtype_normal = subtype_normal[rowSums(subtype_normal) > 0,]\n  # map ENTREZ IDs to Gene SYMBOL, because various pathway packages use ENTREZ IDs and our dataset uses Gene SYMBOLs\n  map_df = as.data.frame(mapIds(org.Hs.eg.db, rownames(subtype_normal), 'ENTREZID', 'SYMBOL'))\n  colnames(map_df) = \"entrez_id\"\n  map_df$gene = rownames(map_df)\n  subtype_normal = subtype_normal[-which(is.na(map_df$entrez_id)),]\n  map_df = map_df[-which(is.na(map_df$entrez_id)),]\n  subtype_normal = subtype_normal[sort(rownames(subtype_normal)),]\n  map_df = map_df[sort(map_df$gene),]\n  # Rename Gene SYMBOL rownames in our TCGA dataset to their respective ENTREZ IDs\n  subtype_normal_entrez = subtype_normal\n  rownames(subtype_normal_entrez) = map_df$entrez_id\n  rownames(subtype_normal_entrez) = sprintf(\"ENTREZID:%s\", rownames(subtype_normal_entrez))\n  subtype_normal_entrez = apply(subtype_normal_entrez, c(1,2), as.numeric)\n  subtype_normal_entrez = subtype_normal_entrez[rowSums(subtype_normal_entrez) > 0, ]\n  # Indicator variable to identify the cancer vs normal samples \n  phenoData = colnames(subtype_normal)\n  phenoData[grep(\".01\",phenoData)] = 1\n  phenoData[grep(\".11\",phenoData)] = 0\n  # Use the deAna function to perform differential expression between subtype cases and controls\n  # Define differentially expressed (DE) genes between the two conditions\n  # ...Using ENTREZ IDs\n  subtype_normal_entrez_de = deAna(as.matrix(subtype_normal_entrez),grp = phenoData,  de.method=\"limma\")\n  subtype_normal_entrez_de_fc = subtype_normal_entrez_de$FC\n  all = rownames(subtype_normal_entrez_de)\n  names(subtype_normal_entrez_de_fc) = all\n  ## ORA starts here\n  dif.genes = names(which(abs(subtype_normal_entrez_de_fc)>quantile(abs(subtype_normal_entrez_de_fc), 0.95)))\n  population = intersect(names(subtype_normal_entrez_de_fc), pc$mapping$node.id)\n  paths.hsa = names(pwys)\n  ora_df = data.frame(pathway=character(), ora.pval=numeric(), hits=integer(), size=integer(), stringsAsFactors = FALSE)\n  for (pathway in 1:length(paths.hsa)) {\n    pwy_graphNEL = pathwayGraph(pwys[[pathway]])\n    ig = igraph.from.graphNEL(pwy_graphNEL)\n    pathway.compounds = V(ig)$name\n    pathCompIDs = pathway.compounds[which(pathway.compounds %in% population)]\n    # q (sample successes), m (population successes), n (population failures), k (sample size)\n    sampleSuccesses = length(which(dif.genes %in% pathCompIDs))\n    populationSuccesses = length(intersect(pathCompIDs, population))\n    N = length(population)\n    populationFailures=N-populationSuccesses\n    numDraws=length(dif.genes)\n    ora_df[pathway, \"pathway\"] = paths.hsa[pathway]\n    ora_df[pathway, \"ora.pval\"] = phyper(q=sampleSuccesses-1, m=populationSuccesses, n=populationFailures, k=numDraws, lower.tail=FALSE)\n    ora_df[pathway, \"hits\"] = sampleSuccesses\n    ora_df[pathway, \"size\"] = populationSuccesses\n  }\n  ora_df = ora_df[,c(\"pathway\", \"ora.pval\")]\n  ora_df$subtype = rep(subtype_to_test, nrow(ora_df))\n  df_ora = rbind(df_ora, ora_df)\n  print(\"ora done\")\n}\nsave(df_ora, file=\"ora_sbpe.RData\")","command_name":"ORA","command":"Subtypes: \n\"lumA\" : Luminal A\n\"lumB\": Luminal B\n\"her2\": HER2\n\"basal\": Basal","os_name":null,"os_version":null}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#A492FF","section_duration":59100,"critical":null,"critical_id":null,"duration":300},{"id":1068565,"guid":"1ECA946E7CF94125BA2ABF31102137C7","previous_id":1068564,"previous_guid":"36A8A7A0F12549D09C07E1D79B288F68","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"B40A68D0424542FB8644D51EB3B94ECC","order_id":1,"type_id":6,"title":"Section","source":{"title":"TCGA: topological pathway enrichment analysis"}},{"id":1054724,"guid":"23A11A636F9049B6BEDA05829D0D42BC","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">GSEA for each subtype<\/div><\/div>"}},{"id":1054725,"guid":"941FB9E0ED8211EA8A6D83C1F0C82F98","order_id":2,"type_id":15,"title":"command","source":{"id":8154,"name":"require(fgsea)\nrequire(org.Hs.eg.db)\nrequire(EnrichmentBrowser)\ndf_gsea = data.frame(subtype=character(), pathway=character(), gsea.pval=numeric(), stringsAsFactors = FALSE)\nfor (subtype_to_test in c(\"lumA\", \"lumB\", \"her2\", \"basal\")) {\n  #Ids\n  subtype_id = read.table(sprintf(\"%s_id.txt\",subtype_to_test), sep=\"\\t\", header=TRUE, check.names=FALSE)\n  subtype_id = as.character(subtype_id$x)\n  subtype_id = gsub(\"\\\\-\",\".\",subtype_id)\n  if (length(grep(\"\\\\.06\",subtype_id))>0) { subtype_id = subtype_id[-grep(\"\\\\.06\",subtype_id)] }\n  print(sprintf(\"IDs loaded for subtype %s\", subtype_to_test))\n  #R load the data set with the subtype samples and normal samples only\n  subtype_normal = as.data.frame(read.table(\"normal_BRCA_DESeq.txt\", header=TRUE, stringsAsFactors = FALSE))\n  subtype_normal = subtype_normal[, c(grep(\"\\\\.11\", colnames(subtype_normal)), which(colnames(subtype_normal) %in% subtype_id))]\n  subtype_normal = apply(subtype_normal, c(1,2), as.numeric)\n  subtype_normal = subtype_normal[rowSums(subtype_normal) > 0,]\n  # map ENTREZ IDs to Gene SYMBOL, because various pathway packages use ENTREZ IDs and our dataset uses Gene SYMBOLs\n  map_df = as.data.frame(mapIds(org.Hs.eg.db, rownames(subtype_normal), 'ENTREZID', 'SYMBOL'))\n  colnames(map_df) = \"entrez_id\"\n  map_df$gene = rownames(map_df)\n  subtype_normal = subtype_normal[-which(is.na(map_df$entrez_id)),]\n  map_df = map_df[-which(is.na(map_df$entrez_id)),]\n  subtype_normal = subtype_normal[sort(rownames(subtype_normal)),]\n  map_df = map_df[sort(map_df$gene),]\n  # Rename Gene SYMBOL rownames in our TCGA dataset to their respective ENTREZ IDs\n  subtype_normal_entrez = subtype_normal\n  rownames(subtype_normal_entrez) = map_df$entrez_id\n  rownames(subtype_normal_entrez) = sprintf(\"ENTREZID:%s\", rownames(subtype_normal_entrez))\n  subtype_normal_entrez = apply(subtype_normal_entrez, c(1,2), as.numeric)\n  subtype_normal_entrez = subtype_normal_entrez[rowSums(subtype_normal_entrez) > 0, ]\n  # Indicator variable to identify the cancer vs normal samples \n  phenoData = colnames(subtype_normal)\n  phenoData[grep(\".01\",phenoData)] = 1\n  phenoData[grep(\".11\",phenoData)] = 0\n  # Define differentially expressed (DE) genes between the two conditions\n  # ...Using ENTREZ IDs\n  subtype_normal_entrez_de = deAna(as.matrix(subtype_normal_entrez),grp = phenoData,  de.method=\"limma\")\n  subtype_normal_entrez_de_fc = subtype_normal_entrez_de$FC\n  all = rownames(subtype_normal_entrez_de)\n  names(subtype_normal_entrez_de_fc) = all\n  ## GSEA starts here.\n  gsea_df = data.frame(pathway=character(), gsea.pval=numeric(), stringsAsFactors = FALSE)\n  pathways = list()\n  for (i in 1:length(pwys)) {\n    pwy_graphNEL = pathwayGraph(pwys[[i]])\n    ig = igraph.from.graphNEL(pwy_graphNEL)\n    pathways[[names(pwys)[i]]] = V(ig)$name\n  }\n  ranks = subtype_normal_entrez_de_fc\n  res = fgsea(pathways, ranks, nperm=1000)\n  gsea_df[1:nrow(res), \"pathway\"] = res$pathway\n  gsea_df[1:nrow(res), \"gsea.pval\"] = res$pval\n  gsea_df$subtype = rep(subtype_to_test, nrow(gsea_df))\n  df_gsea = rbind(df_gsea, gsea_df)\n  print(\"gsea done\")\n}\nsave(df_gsea, file=\"gsea_tbpe.RData\")","command_name":"GSEA","command":"Subtypes: \n\"lumA\" : Luminal A\n\"lumB\": Luminal B\n\"her2\": HER2\n\"basal\": Basal","os_name":null,"os_version":null}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#A492FF","section_duration":59100,"critical":null,"critical_id":null,"duration":300},{"id":1068566,"guid":"C4D4C59A0F694F4DB119295772AFCC32","previous_id":1068565,"previous_guid":"1ECA946E7CF94125BA2ABF31102137C7","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"4430E167BD3A44F7A08E181AC7F8DF6E","order_id":1,"type_id":6,"title":"Section","source":{"title":"TCGA: topological pathway enrichment analysis"}},{"id":1054724,"guid":"B448186798B846E29CD17B34FA76EC38","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Combine all pathway enrichment method's result by subtype<\/div><\/div>"}},{"id":1054725,"guid":"60397400ED8611EA8A6D83C1F0C82F98","order_id":2,"type_id":15,"title":"command","source":{"id":8155,"name":"#Combine all pathway enrichment results into one data frame, df_all\nrequire(dplyr)\nfor (subtype_to_test in c(\"lumA\", \"lumB\", \"her2\", \"basal\")) {\n  load(\"ctd_tbpe.RData\")\n  load(\"cepa_tbpe.RData\")\n  load(\"spia_tbpe.RData\")\n  load(\"degraph_tbpe.RData\")\n  load(\"prs_tbpe.RData\")\n  load(\"ora_sbpe.RData\")\n  load(\"gsea_sbpe.RData\")\n  df_ctd = df_ctd[which(df_ctd$subtype==subtype_to_test), c(\"pathway\", \"ctd.pval\")]\n  df_cepa = df_cepa[which(df_cepa$subtype==subtype_to_test), c(\"pathway\", \"cepaORA.pval\")]\n  df_spia = df_spia[which(df_spia$subtype==subtype_to_test), c(\"pathway\", \"spia.pval\")]\n  df_prs = df_prs[which(df_prs$subtype==subtype_to_test), c(\"pathway\", \"prs.pval\")]\n  df_degraph = df_degraph[which(df_degraph$subtype==subtype_to_test), c(\"pathway\", \"degraph.pval\")]\n  df_ora = df_ora[which(df_ora$subtype==subtype_to_test), c(\"pathway\", \"ora.pval\")]\n  df_gsea = df_gsea[which(df_gsea$subtype==subtype_to_test), c(\"pathway\", \"gsea.pval\")]\n  \n  df_all = left_join(left_join(left_join(left_join(left_join(left_join(df_prs,df_cepa,by = \"pathway\"), \n                                                             df_spia, by=\"pathway\"), \n                                                   df_ora, by=\"pathway\"), \n                                         df_gsea, by=\"pathway\"), \n                               df_ctd, by=\"pathway\"), df_degraph, by=\"pathway\")\n  # FDR correct p-values based on number of pathways tested\n  df_all$prs.pval = p.adjust(df_all$prs.pval, method=\"fdr\")\n  df_all$cepaORA.pval = p.adjust(df_all$cepaORA.pval, method=\"fdr\")\n  df_all$spia.pval = p.adjust(df_all$spia.pval, method=\"fdr\")\n  df_all$ora.pval = p.adjust(df_all$ora.pval, method=\"fdr\")\n  df_all$gsea.pval = p.adjust(df_all$gsea.pval, method=\"fdr\")\n  df_all$ctd.pval = p.adjust(df_all$ctd.pval, method=\"fdr\")\n  df_all$degraph.pval = p.adjust(df_all$degraph.pval, method=\"fdr\")\n  df_all = df_all[order(df_all$pathway), ]\n  save(df_all, file=sprintf(\"topo_%s.RData\",subtype_to_test))\n}","command_name":"Combine pathway enrichment results by subtype","command":"Subtypes: \n\"lumA\" : Luminal A\n\"lumB\": Luminal B\n\"her2\": HER2\n\"basal\": Basal","os_name":null,"os_version":null}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#A492FF","section_duration":59100,"critical":null,"critical_id":null,"duration":1},{"id":1068567,"guid":"CB51A9EABA334E0FB4BDF20406710AD9","previous_id":1068566,"previous_guid":"C4D4C59A0F694F4DB119295772AFCC32","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"83FE89E9717246F690492EDF1383017C","order_id":1,"type_id":6,"title":"Section","source":{"title":"TCGA: topological pathway enrichment analysis"}},{"id":1054724,"guid":"3061A11A2B9E442ABA6BE7F17E8A5F9D","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\"> Generate Figure 5<\/div><\/div>"}},{"id":1054725,"guid":"22D9B0F0EE1411EA8A6D83C1F0C82F98","order_id":2,"type_id":15,"title":"command","source":{"id":8156,"name":"require(reshape2)\nrequire(ggplot2)\ndff_all = data.frame(ranks=numeric(), pathway=character(), method=character(), subtype=character(), stringsAsFactors = FALSE)\nfor (subtype_to_test in c(\"lumA\", \"lumB\", \"her2\", \"basal\")) {\n  load(sprintf(\"topo_%s.RData\", subtype_to_test))\n  rankPos.gsea = df_all$pathway[order(df_all$gsea.pval, decreasing = FALSE)]\n  rankPos.ora = df_all$pathway[order(df_all$ora.pval, decreasing = FALSE)]\n  rankPos.ctd = df_all$pathway[order(df_all$ctd.pval, decreasing = FALSE)]\n  rankPos.spia = df_all$pathway[order(df_all$spia.pval, decreasing = FALSE)]\n  rankPos.cepa = df_all$pathway[order(df_all$cepaORA.pval, decreasing = FALSE)]\n  rankPos.prs = df_all$pathway[order(df_all$prs.pval, decreasing = FALSE)]\n  rankPos.degraph = df_all$pathway[order(df_all$degraph.pval, decreasing = FALSE)]\n  df_all$gsea.ranks = sapply(df_all$pathway, function(i) which(rankPos.gsea==i))\n  df_all$ora.ranks = sapply(df_all$pathway, function(i) which(rankPos.ora==i))\n  df_all$ctd.ranks = sapply(df_all$pathway, function(i) which(rankPos.ctd==i))\n  df_all$spia.ranks = sapply(df_all$pathway, function(i) which(rankPos.spia==i))\n  df_all$cepa.ranks = sapply(df_all$pathway, function(i) which(rankPos.cepa==i))\n  df_all$prs.ranks = sapply(df_all$pathway, function(i) which(rankPos.prs==i))\n  df_all$degraph.ranks = sapply(df_all$pathway, function(i) which(rankPos.degraph==i))\n  dff = data.frame(ranks=c(df_all$gsea.ranks, df_all$ora.ranks, df_all$ctd.ranks, df_all$spia.ranks,\n                           df_all$cepa.ranks, df_all$prs.ranks, df_all$degraph.ranks),\n                   pvalue=c(round(df_all[,\"gsea.pval\"], 2), round(df_all[,\"ora.pval\"], 2), round(df_all[,\"ctd.pval\"], 2),\n                            round(df_all[,\"spia.pval\"], 2), round(df_all[,\"cepaORA.pval\"], 2), round(df_all[,\"prs.pval\"], 2),\n                            round(df_all[,\"degraph.pval\"], 2)),\n                   pathway=rep(df_all$pathway, 7),\n                   method=c(rep(\"GSEA\", length(df_all$gsea.ranks)), rep(\"ORA\", length(df_all$ora.ranks)), \n                            rep(\"CTD\", length(df_all$ctd.ranks)), rep(\"SPIA\", length(df_all$spia.ranks)),\n                            rep(\"CePa\", length(df_all$cepa.ranks)), rep(\"PRS\", length(df_all$prs.ranks)), \n                            rep(\"DEGraph\", length(df_all$degraph.ranks))),\n                   subtype=rep(subtype_to_test, 7*nrow(df_all)))\n  dff_all = rbind(dff_all, dff)\n}\nind.pos = c(\"PI3K-Akt signaling pathway\", \"Pathways in cancer\", \"TGF-beta signaling pathway\", \"Breast cancer\", \"Estrogen signaling pathway\",\n        \"MAPK signaling pathway\", \"JAK-STAT signaling pathway\", \"Wnt signaling pathway\")\nind.neg = c(\"Alzheimer disease\", \"Cushing syndrome\", \"Inflammatory bowel disease (IBD)\", \n            \"Inositol phosphate metabolism\", \"Morphine addiction\", \"Olfactory transduction\",\n            \"Pertussis\", \"Porphyrin and chlorophyll metabolism\")\nind = c(ind.pos, ind.neg)\ndff_all = dff_all[which(dff_all$pathway %in% ind),]\n# Which methods called which pathways significant (FDR p-value < 0.05)?\ndff_all[which(dff_all$pvalue<0.15),]\n# Plot ranks\ndff_all$subtype = factor(dff_all$subtype, levels=c(\"lumA\", \"lumB\", \"her2\", \"basal\"))\nsvg(\"fig5_pathway_enrichment.svg\")\nggplot(dff_all) + geom_bar(aes(x=method, y=ranks, fill=subtype), stat=\"identity\") + \n  facet_wrap(~pathway) + ggtitle(\"Comparison of Pathway Enrichment Methods\") + ylim(c(0,1000))\ndev.off()","command_name":"Generate Figure 5","command":null,"os_name":null,"os_version":null}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#A492FF","section_duration":59100,"critical":null,"critical_id":null,"duration":1},{"id":1068568,"guid":"A55EB102DEFE443F8F60CA67EA5E3769","previous_id":1068567,"previous_guid":"CB51A9EABA334E0FB4BDF20406710AD9","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"B95F46FFFEA64F4E839131A845F8319B","order_id":1,"type_id":6,"title":"Section","source":{"title":"Set-based pathway enrichment methods for metabolomics"}},{"id":1054724,"guid":"DA43C46FE54B42528389765A83E2B7B0","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Two set-based pathway enrichment methods are applied to the metabolomics data from Miller et al 2015, for 5 diagnostic categories (citrullinemia, maple syrup urine disease, methylmalonic aciduria, propionic aciduria, phenylketonuria).<\/div><div class = \"text-block\">R package versioning:<\/div><div class = \"text-block\"><ul style = \"list-style-type:disc;\"><li style = \"counter-reset:ol0;list-style-type:disc;\">CTD v 1.0.0<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">CTDext v 1.0.0<\/li><\/ul><\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#94EBFF","section_duration":117,"critical":null,"critical_id":null,"duration":0},{"id":1068569,"guid":"3B159EB98FCA4157B6351F66006705A8","previous_id":1068568,"previous_guid":"A55EB102DEFE443F8F60CA67EA5E3769","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"9E132D66D4C5419D8984528CAE9638D0","order_id":1,"type_id":6,"title":"Section","source":{"title":"Set-based pathway enrichment methods for metabolomics"}},{"id":1054724,"guid":"1EC04BAF23E6484AA1910FB93FD33316","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Over-representation analysis (ORA)<\/div><\/div>"}},{"id":1054725,"guid":"D9863080E95A11EAA3434F176A4D61AA","order_id":2,"type_id":15,"title":"command","source":{"id":8157,"name":"# CIT patients: selected IEM_1017 for visualization\nstat.getORA_Metabolon(data_mx.og[,\"IEM_1017\"], threshold = 2, type = \"zscore\")\n# MSUD patients: Selected IEM_1058 for visualization\nstat.getORA_Metabolon(data_mx.og[,\"IEM_1058\"], threshold = 2, type = \"zscore\")\n# MMA patients: Selected IEM_1051 for visualization\nstat.getORA_Metabolon(data_mx.og[,\"IEM_1051\"], threshold = 2, type = \"zscore\")\n# PA patients: Selected IEM_1093 for visualization\nstat.getORA_Metabolon(data_mx.og[,\"IEM_1093\"], threshold = 2, type = \"zscore\")\n# PKU patients: selected IEM_1105 for visualization\nstat.getORA_Metabolon(data_mx.og[,\"IEM_1105\"], threshold = 2, type = \"zscore\")","command_name":"Over-representation analysis (ORA)","command":null,"os_name":null,"os_version":null}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#94EBFF","section_duration":117,"critical":null,"critical_id":null,"duration":3},{"id":1068570,"guid":"CA12497A77C748DCBD7C448B36E23FF6","previous_id":1068569,"previous_guid":"3B159EB98FCA4157B6351F66006705A8","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"040D76AF1411490E86DE3142A4D532DD","order_id":1,"type_id":6,"title":"Section","source":{"title":"Set-based pathway enrichment methods for metabolomics"}},{"id":1054724,"guid":"81C925B4C5E3462BAD69D5F7202E00F3","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Metabolite set enrichment analysis (MSEA)<\/div><\/div>"}},{"id":1054725,"guid":"26319210E98011EAA3434F176A4D61AA","order_id":2,"type_id":15,"title":"command","source":{"id":8158,"name":"fill.rate = as.numeric(Miller2015$`Times identifed in all 200 samples`[-1])\/200\n# CIT\ndata_mx = data_mx.og[which(fill.rate>0.80),which(colnames(data_mx.og) %in% c(cohorts$cit, cohorts$ref))]\ndata_mx = data_mx[-grep(\"x -\", rownames(data_mx)),]\ndiag.ind = colnames(data_mx)\ndiag.ind[-which(diag.ind %in% cohorts$cit)] = 0\ndiag.ind[which(diag.ind %in% cohorts$cit)] = 1\ndiag.ind = as.numeric(diag.ind)\ncit_msea = stat.getMSEA_Metabolon(data_mx, diag.ind, pathway_knowledgebase = \"Metabolon\")\ncit_msea = cit_msea[which(cit_msea$`NOM\\npval`<0.05),c(\"Pathway\", \"Size\", \"NES\", \"NOM\\npval\", \"FDR\\nqval\")]\ncit_msea[order(cit_msea$`NOM\\npval`, decreasing = FALSE), ]\n\n# MSUD \ndata_mx = data_mx.og[which(fill.rate>0.80),which(colnames(data_mx.og) %in% c(cohorts$msud, cohorts$ref))]\ndata_mx = data_mx[-grep(\"x -\", rownames(data_mx)),]\ndiag.ind = colnames(data_mx)\ndiag.ind[-which(diag.ind %in% cohorts$msud)] = 0\ndiag.ind[which(diag.ind %in% cohorts$msud)] = 1\ndiag.ind = as.numeric(diag.ind)\nmsud_msea = stat.getMSEA_Metabolon(data_mx, diag.ind, pathway_knowledgebase = \"Metabolon\")\nmsud_msea = msud_msea[which(msud_msea$`NOM\\npval`<0.05),c(\"Pathway\", \"Size\", \"NES\", \"NOM\\npval\", \"FDR\\nqval\")]\nmsud_msea[order(msud_msea$`NOM\\npval`, decreasing = FALSE), ]\n\n# MMA \ndata_mx = data_mx.og[which(fill.rate>0.80),which(colnames(data_mx.og) %in% c(cohorts$mma, cohorts$ref))]\ndata_mx = data_mx[-grep(\"x -\", rownames(data_mx)),]\ndiag.ind = colnames(data_mx)\ndiag.ind[-which(diag.ind %in% cohorts$mma)] = 0\ndiag.ind[which(diag.ind %in% cohorts$mma)] = 1\ndiag.ind = as.numeric(diag.ind)\nmma_msea = stat.getMSEA_Metabolon(data_mx, diag.ind, pathway_knowledgebase = \"Metabolon\")\nmma_msea = mma_msea[which(mma_msea$`NOM\\npval`<0.05),c(\"Pathway\", \"Size\", \"NES\", \"NOM\\npval\", \"FDR\\nqval\")]\nmma_msea[order(mma_msea$`NOM\\npval`, decreasing = FALSE), ]\n\n# PA \ndata_mx = data_mx.og[which(fill.rate>0.80),which(colnames(data_mx.og) %in% c(cohorts$pa, cohorts$ref))]\ndata_mx = data_mx[-grep(\"x -\", rownames(data_mx)),]\ndiag.ind = colnames(data_mx)\ndiag.ind[-which(diag.ind %in% cohorts$pa)] = 0\ndiag.ind[which(diag.ind %in% cohorts$pa)] = 1\ndiag.ind = as.numeric(diag.ind)\npa_msea = stat.getMSEA_Metabolon(data_mx, diag.ind, pathway_knowledgebase = \"Metabolon\")\npa_msea = pa_msea[which(pa_msea$`NOM\\npval`<0.05),c(\"Pathway\", \"Size\", \"NES\", \"NOM\\npval\", \"FDR\\nqval\")]\npa_msea[order(pa_msea$`NOM\\npval`, decreasing = FALSE), ]\n\n# PKU \ndata_mx = data_mx.og[which(fill.rate>0.80),which(colnames(data_mx.og) %in% c(cohorts$pku, cohorts$ref))]\ndata_mx = data_mx[-grep(\"x -\", rownames(data_mx)),]\ndiag.ind = colnames(data_mx)\ndiag.ind[-which(diag.ind %in% cohorts$pku)] = 0\ndiag.ind[which(diag.ind %in% cohorts$pku)] = 1\ndiag.ind = as.numeric(diag.ind)\npku_msea = stat.getMSEA_Metabolon(data_mx, diag.ind, pathway_knowledgebase = \"Metabolon\")\npku_msea = pku_msea[which(pku_msea$`NOM\\npval`<0.05),c(\"Pathway\", \"Size\", \"NES\", \"NOM\\npval\", \"FDR\\nqval\")]\npku_msea[order(pku_msea$`NOM\\npval`, decreasing = FALSE), ]","command_name":"Metabolite set enrichment analysis (MSEA)","command":"Several things can affect the pathway enrichment results returned by metabolite set enrichment analysis (MSEA). These include\n\n1. The GMT pathway knowledgebase you use can differ in the coverage of metabolites profiled by untargeted metabolomics. Make sure the knowledgebase you're using has the highest percentage of metabolites that can map back to your patient profiling data.\n\n2. The fill rate threshold you select for your profiling data. If you include metabolite data that was highly imputed, your results may show pathways that include the metabolites associated with imputed values, depending on your imputation strategy. We have found that using a fill rate threshold outputs more disease relevant pathways using MSEA compared to including all metabolites. In our use of MSEA, we use an 80% fill rate threshold when deciding which metabolites to keep in our dataset.","os_name":null,"os_version":null}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#94EBFF","section_duration":117,"critical":null,"critical_id":null,"duration":114},{"id":1068571,"guid":"6A260E701BAF4051A834A03BC80543F7","previous_id":1068570,"previous_guid":"CA12497A77C748DCBD7C448B36E23FF6","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"BFDA242FF14D40AE89062FAF64C8FE3C","order_id":1,"type_id":6,"title":"Section","source":{"title":"Figure 7: Node set probability is based on network context."}},{"id":1054724,"guid":"584377096AFA4BF28BAF969780906D25","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">In this result, we show that the probability assigned to a node set varies significantly based on the network's specificity. For example, the top 5 perturbed metabolites in patients with citrullinemia are assigned the highest probability in the Citrullinemia disease context, compared to the top 5 metabolites perturbed in methylmalonic aciduria or phenylketonuria.<\/div><div class = \"text-block\"><span style = \"font-weight:bold;\">Note, because surrogate profiles (generated by data.surrogateProfiles()) are generated using random draws from the standard normal distribution, results will vary when you run the code in this section, but the same general trends will be consistent.<\/span><\/div><div class = \"text-block\">R package versioning:<\/div><div class = \"text-block\"><ul style = \"list-style-type:disc;\"><li style = \"counter-reset:ol0;list-style-type:disc;\">CTD v 1.0.0<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">CTDext v 1.0.0<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">huge v 1.3.4.1<\/li><li style = \"counter-reset:ol0;list-style-type:disc;\">ggplot2 v 3.3.2<\/li><\/ul><\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#84CE84","section_duration":3800,"critical":null,"critical_id":null,"duration":0},{"id":1068572,"guid":"8E75115C5BEC41819C59D618C5109FE8","previous_id":1068571,"previous_guid":"6A260E701BAF4051A834A03BC80543F7","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"20D21AA088EF4D078277D65E574FA66B","order_id":1,"type_id":6,"title":"Section","source":{"title":"Figure 7: Node set probability is based on network context."}},{"id":1054724,"guid":"EF8035E8B5CE416FB3C0910BAF9372B8","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Separate data into cohorts<\/div><\/div>"}},{"id":1054725,"guid":"990FFF10EA7F11EAA3434F176A4D61AA","order_id":2,"type_id":15,"title":"command","source":{"id":8159,"name":"fill.rate = as.numeric(Miller2015$`Times identifed in all 200 samples`[-1])\/200\ndata_mx = data_mx.og[which(fill.rate>0.80),]\ndata_mx = data_mx[-grep(\"x -\", rownames(data_mx)),]\ncit_data = data_mx[,which(diags==\"Citrullinemia\")]\nmma_data = data_mx[,which(diags==\"Methylmalonic aciduria\")]\npku_data = data_mx[,which(diags==\"Phenylketonuria\")]\nref_data = data_mx[,which(diags==\"No biochemical genetic diagnosis\")]\n# Sort metabolite perturbations by mean z-score across all reference profiles.\ncit_tmp = apply(abs(cit_data), 1, function(i) mean(na.omit(i)))\ncit_tmp = cit_tmp[order(abs(cit_tmp), decreasing = TRUE)]\nmma_tmp = apply(abs(mma_data), 1, function(i) mean(na.omit(i)))\nmma_tmp = mma_tmp[order(abs(mma_tmp), decreasing = TRUE)]\npku_tmp = apply(abs(pku_data), 1, function(i) mean(na.omit(i)))\npku_tmp = pku_tmp[order(abs(pku_tmp), decreasing = TRUE)]\nref_tmp = apply(abs(ref_data), 1, function(i) mean(na.omit(i)))\nref_tmp = pku_tmp[order(abs(ref_tmp), decreasing = TRUE)]\n# Add surrogate disease and surrogate reference profiles based on 1 standard deviation around profiles from real patients to improve rank of matrix when learning Gaussian Markov Random Field network on data.\ncit_data1 = data.surrogateProfiles(cit_data[,-1], 1, ref_data = ref_data)\ncit_data2 = data.surrogateProfiles(cit_data[,-2], 1, ref_data = ref_data)\ncit_data3 = data.surrogateProfiles(cit_data[,-3], 1, ref_data = ref_data)\ncit_data4 = data.surrogateProfiles(cit_data[,-4], 1, ref_data = ref_data)\ncit_data5 = data.surrogateProfiles(cit_data[,-5], 1, ref_data = ref_data)\ncit_data6 = data.surrogateProfiles(cit_data[,-6], 1, ref_data = ref_data)\ncit_data7 = data.surrogateProfiles(cit_data[,-7], 1, ref_data = ref_data)\ncit_data8 = data.surrogateProfiles(cit_data[,-8], 1, ref_data = ref_data)\ncit_data9 = data.surrogateProfiles(cit_data[,-9], 1, ref_data = ref_data)\ncit_data = data.surrogateProfiles(cit_data, 1, ref_data = ref_data)\ndim(cit_data)\nmma_data1 = data.surrogateProfiles(mma_data[,-1], 1, ref_data = ref_data)\nmma_data2 = data.surrogateProfiles(mma_data[,-2], 1, ref_data = ref_data)\nmma_data3 = data.surrogateProfiles(mma_data[,-3], 1, ref_data = ref_data)\nmma_data4 = data.surrogateProfiles(mma_data[,-4], 1, ref_data = ref_data)\nmma_data5 = data.surrogateProfiles(mma_data[,-5], 1, ref_data = ref_data)\nmma_data6 = data.surrogateProfiles(mma_data[,-6], 1, ref_data = ref_data)\nmma_data7 = data.surrogateProfiles(mma_data[,-7], 1, ref_data = ref_data)\nmma_data8 = data.surrogateProfiles(mma_data[,-8], 1, ref_data = ref_data)\nmma_data9 = data.surrogateProfiles(mma_data[,-9], 1, ref_data = ref_data)\nmma_data = data.surrogateProfiles(mma_data, 1, ref_data = ref_data)\ndim(mma_data)\npku_data1 = data.surrogateProfiles(pku_data[,-1], 1, ref_data = ref_data)\npku_data2 = data.surrogateProfiles(pku_data[,-2], 1, ref_data = ref_data)\npku_data3 = data.surrogateProfiles(pku_data[,-3], 1, ref_data = ref_data)\npku_data4 = data.surrogateProfiles(pku_data[,-4], 1, ref_data = ref_data)\npku_data5 = data.surrogateProfiles(pku_data[,-5], 1, ref_data = ref_data)\npku_data6 = data.surrogateProfiles(pku_data[,-6], 1, ref_data = ref_data)\npku_data7 = data.surrogateProfiles(pku_data[,-7], 1, ref_data = ref_data)\npku_data8 = data.surrogateProfiles(pku_data[,-8], 1, ref_data = ref_data)\npku_data = data.surrogateProfiles(pku_data, 1, ref_data = ref_data)\ndim(pku_data)\nref_data = data.surrogateProfiles(ref_data, 1, ref_data = ref_data)\ndim(ref_data)","command_name":"LOOCV data matrix construction by disease","command":"Build data matrices with surrogate disease and control profiles using a leave one out cross validation data paradigm. Do this for three disease states, separately:\n\n1. Citrullinemia\n2. Methylmalonic aciduria\n3. Phenylketonuria","os_name":null,"os_version":null}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#84CE84","section_duration":3800,"critical":null,"critical_id":null,"duration":17},{"id":1068573,"guid":"633E64A3FA8B4606B5BF7F065B6D2312","previous_id":1068572,"previous_guid":"8E75115C5BEC41819C59D618C5109FE8","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"A91344A6AE6D4DF9931A70460468BCD3","order_id":1,"type_id":6,"title":"Section","source":{"title":"Figure 7: Node set probability is based on network context."}},{"id":1054724,"guid":"25E0D4583EF841DE98F290DA97EFA10B","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Learn disease-specific network folds.<\/div><\/div>"}},{"id":1054725,"guid":"26BD6000EA8011EAA3434F176A4D61AA","order_id":2,"type_id":15,"title":"command","source":{"id":8160,"name":"# Learn a Gaussian Markov Random Field model using the Graphical LASSO in the R package \"huge\". \n# Use a regularization parameter of 0.25 for all graphs.\nrequire(huge)\n# cit graph\ncit_ig = huge(t(cit_data), method=\"glasso\", lambda = 0.25)\ncit_ig1 = huge(t(cit_data1), method=\"glasso\", lambda = 0.25)\ncit_ig2 = huge(t(cit_data2), method=\"glasso\", lambda = 0.25)\ncit_ig3 = huge(t(cit_data3), method=\"glasso\", lambda = 0.25)\ncit_ig4 = huge(t(cit_data4), method=\"glasso\", lambda = 0.25)\ncit_ig5 = huge(t(cit_data5), method=\"glasso\", lambda = 0.25)\ncit_ig6 = huge(t(cit_data6), method=\"glasso\", lambda = 0.25)\ncit_ig7 = huge(t(cit_data7), method=\"glasso\", lambda = 0.25)\ncit_ig8 = huge(t(cit_data8), method=\"glasso\", lambda = 0.25)\ncit_ig9 = huge(t(cit_data9), method=\"glasso\", lambda = 0.25)\nplot(cit_ig)\n# mma graph\nmma_ig = huge(t(mma_data), method=\"glasso\", lambda = 0.25)\nmma_ig1 = huge(t(mma_data1), method=\"glasso\", lambda = 0.25)\nmma_ig2 = huge(t(mma_data2), method=\"glasso\", lambda = 0.25)\nmma_ig3 = huge(t(mma_data3), method=\"glasso\", lambda = 0.25)\nmma_ig4 = huge(t(mma_data4), method=\"glasso\", lambda = 0.25)\nmma_ig5 = huge(t(mma_data5), method=\"glasso\", lambda = 0.25)\nmma_ig6 = huge(t(mma_data6), method=\"glasso\", lambda = 0.25)\nmma_ig7 = huge(t(mma_data7), method=\"glasso\", lambda = 0.25)\nmma_ig8 = huge(t(mma_data8), method=\"glasso\", lambda = 0.25)\nmma_ig9 = huge(t(mma_data9), method=\"glasso\", lambda = 0.25)\nplot(mma_ig)\n# pku graph\npku_ig = huge(t(pku_data), method=\"glasso\", lambda = 0.25)\npku_ig1 = huge(t(pku_data1), method=\"glasso\", lambda = 0.25)\npku_ig2 = huge(t(pku_data2), method=\"glasso\", lambda = 0.25)\npku_ig3 = huge(t(pku_data3), method=\"glasso\", lambda = 0.25)\npku_ig4 = huge(t(pku_data4), method=\"glasso\", lambda = 0.25)\npku_ig5 = huge(t(pku_data5), method=\"glasso\", lambda = 0.25)\npku_ig6 = huge(t(pku_data6), method=\"glasso\", lambda = 0.25)\npku_ig7 = huge(t(pku_data7), method=\"glasso\", lambda = 0.25)\npku_ig8 = huge(t(pku_data8), method=\"glasso\", lambda = 0.25)\nplot(pku_ig)\n\nref_ig = huge(t(ref_data), method=\"glasso\", lambda=0.25)\nplot(ref_ig)\n\n# Get the adjacency matrices, set the diagonal edges (self-edges) to 0, as we are not interested in\n# \"selfed\" edge weights.\ncit_ig = as.matrix(cit_ig$icov[[1]])\ncit_ig1 = as.matrix(cit_ig1$icov[[1]])\ncit_ig2 = as.matrix(cit_ig2$icov[[1]])\ncit_ig3 = as.matrix(cit_ig3$icov[[1]])\ncit_ig4 = as.matrix(cit_ig4$icov[[1]])\ncit_ig5 = as.matrix(cit_ig5$icov[[1]])\ncit_ig6 = as.matrix(cit_ig6$icov[[1]])\ncit_ig7 = as.matrix(cit_ig7$icov[[1]])\ncit_ig8 = as.matrix(cit_ig8$icov[[1]])\ncit_ig9 = as.matrix(cit_ig9$icov[[1]])\nmma_ig = as.matrix(mma_ig$icov[[1]])\nmma_ig1 = as.matrix(mma_ig1$icov[[1]])\nmma_ig2 = as.matrix(mma_ig2$icov[[1]])\nmma_ig3 = as.matrix(mma_ig3$icov[[1]])\nmma_ig4 = as.matrix(mma_ig4$icov[[1]])\nmma_ig5 = as.matrix(mma_ig5$icov[[1]])\nmma_ig6 = as.matrix(mma_ig6$icov[[1]])\nmma_ig7 = as.matrix(mma_ig7$icov[[1]])\nmma_ig8 = as.matrix(mma_ig8$icov[[1]])\nmma_ig9 = as.matrix(mma_ig9$icov[[1]])\npku_ig = as.matrix(pku_ig$icov[[1]])\npku_ig1 = as.matrix(pku_ig1$icov[[1]])\npku_ig2 = as.matrix(pku_ig2$icov[[1]])\npku_ig3 = as.matrix(pku_ig3$icov[[1]])\npku_ig4 = as.matrix(pku_ig4$icov[[1]])\npku_ig5 = as.matrix(pku_ig5$icov[[1]])\npku_ig6 = as.matrix(pku_ig6$icov[[1]])\npku_ig7 = as.matrix(pku_ig7$icov[[1]])\npku_ig8 = as.matrix(pku_ig8$icov[[1]])\nref_ig = as.matrix(ref_ig$icov[[1]])\ndiag(cit_ig) = 0\ndiag(cit_ig1) = 0\ndiag(cit_ig2) = 0\ndiag(cit_ig3) = 0\ndiag(cit_ig4) = 0\ndiag(cit_ig5) = 0\ndiag(cit_ig6) = 0\ndiag(cit_ig7) = 0\ndiag(cit_ig8) = 0\ndiag(cit_ig9) = 0\ndiag(mma_ig) = 0\ndiag(mma_ig1) = 0\ndiag(mma_ig2) = 0\ndiag(mma_ig3) = 0\ndiag(mma_ig4) = 0\ndiag(mma_ig5) = 0\ndiag(mma_ig6) = 0\ndiag(mma_ig7) = 0\ndiag(mma_ig8) = 0\ndiag(mma_ig9) = 0\ndiag(pku_ig) = 0\ndiag(pku_ig1) = 0\ndiag(pku_ig2) = 0\ndiag(pku_ig3) = 0\ndiag(pku_ig4) = 0\ndiag(pku_ig5) = 0\ndiag(pku_ig6) = 0\ndiag(pku_ig7) = 0\ndiag(pku_ig8) = 0\ndiag(ref_ig) = 0\ncolnames(cit_ig) = rownames(cit_data)\ncolnames(cit_ig1) = rownames(cit_data1)\ncolnames(cit_ig2) = rownames(cit_data2)\ncolnames(cit_ig3) = rownames(cit_data3)\ncolnames(cit_ig4) = rownames(cit_data4)\ncolnames(cit_ig5) = rownames(cit_data5)\ncolnames(cit_ig6) = rownames(cit_data6)\ncolnames(cit_ig7) = rownames(cit_data7)\ncolnames(cit_ig8) = rownames(cit_data8)\ncolnames(cit_ig9) = rownames(cit_data9)\ncolnames(mma_ig) = rownames(mma_data)\ncolnames(mma_ig1) = rownames(mma_data1)\ncolnames(mma_ig2) = rownames(mma_data2)\ncolnames(mma_ig3) = rownames(mma_data3)\ncolnames(mma_ig4) = rownames(mma_data4)\ncolnames(mma_ig5) = rownames(mma_data5)\ncolnames(mma_ig6) = rownames(mma_data6)\ncolnames(mma_ig7) = rownames(mma_data7)\ncolnames(mma_ig8) = rownames(mma_data8)\ncolnames(mma_ig9) = rownames(mma_data9)\ncolnames(pku_ig) = rownames(pku_data)\ncolnames(pku_ig1) = rownames(pku_data1)\ncolnames(pku_ig2) = rownames(pku_data2)\ncolnames(pku_ig3) = rownames(pku_data3)\ncolnames(pku_ig4) = rownames(pku_data4)\ncolnames(pku_ig5) = rownames(pku_data5)\ncolnames(pku_ig6) = rownames(pku_data6)\ncolnames(pku_ig7) = rownames(pku_data7)\ncolnames(pku_ig8) = rownames(pku_data8)\ncolnames(ref_ig) = rownames(ref_data)\n# Convert adjacency matrices to igraph objects for all three graphs.\nig_cit1 = graph.adjacency(cit_ig1, mode=\"undirected\", weighted=TRUE, add.colnames = \"name\")\nig_cit2 = graph.adjacency(cit_ig2, mode=\"undirected\", weighted=TRUE, add.colnames = \"name\")\nig_cit3 = graph.adjacency(cit_ig3, mode=\"undirected\", weighted=TRUE, add.colnames = \"name\")\nig_cit4 = graph.adjacency(cit_ig4, mode=\"undirected\", weighted=TRUE, add.colnames = \"name\")\nig_cit5 = graph.adjacency(cit_ig5, mode=\"undirected\", weighted=TRUE, add.colnames = \"name\")\nig_cit6 = graph.adjacency(cit_ig6, mode=\"undirected\", weighted=TRUE, add.colnames = \"name\")\nig_cit7 = graph.adjacency(cit_ig7, mode=\"undirected\", weighted=TRUE, add.colnames = \"name\")\nig_cit8 = graph.adjacency(cit_ig8, mode=\"undirected\", weighted=TRUE, add.colnames = \"name\")\nig_cit9 = graph.adjacency(cit_ig9, mode=\"undirected\", weighted=TRUE, add.colnames = \"name\")\nig_cit = graph.adjacency(cit_ig, mode=\"undirected\", weighted=TRUE, add.colnames = \"name\")\nig_cit\nig_mma1 = graph.adjacency(mma_ig1, mode=\"undirected\", weighted=TRUE, add.colnames = \"name\")\nig_mma2 = graph.adjacency(mma_ig2, mode=\"undirected\", weighted=TRUE, add.colnames = \"name\")\nig_mma3 = graph.adjacency(mma_ig3, mode=\"undirected\", weighted=TRUE, add.colnames = \"name\")\nig_mma4 = graph.adjacency(mma_ig4, mode=\"undirected\", weighted=TRUE, add.colnames = \"name\")\nig_mma5 = graph.adjacency(mma_ig5, mode=\"undirected\", weighted=TRUE, add.colnames = \"name\")\nig_mma6 = graph.adjacency(mma_ig6, mode=\"undirected\", weighted=TRUE, add.colnames = \"name\")\nig_mma7 = graph.adjacency(mma_ig7, mode=\"undirected\", weighted=TRUE, add.colnames = \"name\")\nig_mma8 = graph.adjacency(mma_ig8, mode=\"undirected\", weighted=TRUE, add.colnames = \"name\")\nig_mma9 = graph.adjacency(mma_ig9, mode=\"undirected\", weighted=TRUE, add.colnames = \"name\")\nig_mma = graph.adjacency(mma_ig, mode=\"undirected\", weighted=TRUE, add.colnames = \"name\")\nig_mma\nig_pku1 = graph.adjacency(pku_ig1, mode=\"undirected\", weighted=TRUE, add.colnames = \"name\")\nig_pku2 = graph.adjacency(pku_ig2, mode=\"undirected\", weighted=TRUE, add.colnames = \"name\")\nig_pku3 = graph.adjacency(pku_ig3, mode=\"undirected\", weighted=TRUE, add.colnames = \"name\")\nig_pku4 = graph.adjacency(pku_ig4, mode=\"undirected\", weighted=TRUE, add.colnames = \"name\")\nig_pku5 = graph.adjacency(pku_ig5, mode=\"undirected\", weighted=TRUE, add.colnames = \"name\")\nig_pku6 = graph.adjacency(pku_ig6, mode=\"undirected\", weighted=TRUE, add.colnames = \"name\")\nig_pku7 = graph.adjacency(pku_ig7, mode=\"undirected\", weighted=TRUE, add.colnames = \"name\")\nig_pku8 = graph.adjacency(pku_ig8, mode=\"undirected\", weighted=TRUE, add.colnames = \"name\")\nig_pku = graph.adjacency(pku_ig, mode=\"undirected\", weighted=TRUE, add.colnames = \"name\")\nig_pku\n\nig_ref = graph.adjacency(ref_ig, mode=\"undirected\", weighted=TRUE, add.colnames = \"name\")\nig_ref\n# Create a random graph based on permuting node labels of the learned reference graph.\nig_rand = ig_ref\nV(ig_rand)$name = V(ig_ref)$name[sample(1:length(V(ig_ref)$name), length(V(ig_ref)$name), replace = FALSE)]\nig_rand","command_name":"Learn network folds","command":"We learn 1 network per patient left out. So if we have 9 Citrullinemia patients, we have 9 network folds, where each network fold corresponds to 1 Citrullinemia patient being left out of network learning. We repeat this for 9 methylmalonic aciduria patients, with 8 network folds, and 8 phenylketonuria patients, with 8 network folds. We also learn a \"reference only\" network, used in network pruning, and a \"random network\", which is a copy of the reference only network with node labels scrambled.","os_name":null,"os_version":null}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#84CE84","section_duration":3800,"critical":null,"critical_id":null,"duration":120},{"id":1068574,"guid":"E05927E0379B451585FD6EB0AE0E0BC0","previous_id":1068573,"previous_guid":"633E64A3FA8B4606B5BF7F065B6D2312","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"F2AD3F5DEBCA40BBA4E461F466E0324E","order_id":1,"type_id":6,"title":"Section","source":{"title":"Figure 7: Node set probability is based on network context."}},{"id":1054724,"guid":"658A1DA119D4498AB812163B32CEF38E","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Prune disease+control network folds to output disease-specific network folds.<\/div><\/div>"}},{"id":1054725,"guid":"45420710EA8011EAA3434F176A4D61AA","order_id":2,"type_id":15,"title":"command","source":{"id":8161,"name":"# Naive pruning method: Prune edges in disease networks that are associated with significant modules in reference network.\nig_cit_naive = graph.naivePruning(ig_cit, ig_ref)\nig_cit1_naive = graph.naivePruning(ig_cit1, ig_ref)\nig_cit2_naive = graph.naivePruning(ig_cit2, ig_ref)\nig_cit3_naive = graph.naivePruning(ig_cit3, ig_ref)\nig_cit4_naive = graph.naivePruning(ig_cit4, ig_ref)\nig_cit5_naive = graph.naivePruning(ig_cit5, ig_ref)\nig_cit6_naive = graph.naivePruning(ig_cit6, ig_ref)\nig_cit7_naive = graph.naivePruning(ig_cit7, ig_ref)\nig_cit8_naive = graph.naivePruning(ig_cit8, ig_ref)\nig_cit9_naive = graph.naivePruning(ig_cit9, ig_ref)\n\nig_mma_naive = graph.naivePruning(ig_mma, ig_ref)\nig_mma1_naive = graph.naivePruning(ig_mma1, ig_ref)\nig_mma2_naive = graph.naivePruning(ig_mma2, ig_ref)\nig_mma3_naive = graph.naivePruning(ig_mma3, ig_ref)\nig_mma4_naive = graph.naivePruning(ig_mma4, ig_ref)\nig_mma5_naive = graph.naivePruning(ig_mma5, ig_ref)\nig_mma6_naive = graph.naivePruning(ig_mma6, ig_ref)\nig_mma7_naive = graph.naivePruning(ig_mma7, ig_ref)\nig_mma8_naive = graph.naivePruning(ig_mma8, ig_ref)\nig_mma9_naive = graph.naivePruning(ig_mma9, ig_ref)\n\nig_pku_naive = graph.naivePruning(ig_pku, ig_ref)\nig_pku1_naive = graph.naivePruning(ig_pku1, ig_ref)\nig_pku2_naive = graph.naivePruning(ig_pku2, ig_ref)\nig_pku3_naive = graph.naivePruning(ig_pku3, ig_ref)\nig_pku4_naive = graph.naivePruning(ig_pku4, ig_ref)\nig_pku5_naive = graph.naivePruning(ig_pku5, ig_ref)\nig_pku6_naive = graph.naivePruning(ig_pku6, ig_ref)\nig_pku7_naive = graph.naivePruning(ig_pku7, ig_ref)\nig_pku8_naive = graph.naivePruning(ig_pku8, ig_ref)\n\nig_rand_naive = graph.naivePruning(ig_rand, ig_ref)","command_name":"Prune network folds","command":null,"os_name":null,"os_version":null}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#84CE84","section_duration":3800,"critical":null,"critical_id":null,"duration":1500},{"id":1068575,"guid":"C247A7A529294092991D521E6A1AF67A","previous_id":1068574,"previous_guid":"E05927E0379B451585FD6EB0AE0E0BC0","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"5FD2BE592007489BA21F3F325F62217A","order_id":1,"type_id":6,"title":"Section","source":{"title":"Figure 7: Node set probability is based on network context."}},{"id":1054724,"guid":"AD8E15CC1FA54400AC94559D71677EB5","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">This is the main driver script for this experiment. Now that we have all disease-specific network folds learned, we can calculate the probabilities of the top 5 perturbed metabolites for each disease state (citrullinemia, methylmalonic aciduria, phenylketonuria) in each network context.<\/div><\/div>"}},{"id":1054725,"guid":"2A80C1E0EA8611EAA3434F176A4D61AA","order_id":2,"type_id":15,"title":"command","source":{"id":8162,"name":"p1=0.9\nthresholdDiff=0.01\ndocit = TRUE\ndomma = TRUE\ndopku = TRUE\nres = data.frame(subset_size=numeric(), graph_name=character(), \n                 IA_top_cit=numeric(), IA_top_mma=numeric(), IA_top_pku=numeric(),\n                 IA_top_ref=numeric(), IA_top_rand=numeric(), stringsAsFactors = FALSE)\nr_row = 1\nfor (subset_size in c(5,10,15,20)) {\n  # Set the top K metabolite perturbations based on each cohort dataset. K = subset_size in the for loop.\n  # Top K metabolites from cit cohort\n  met_set1 = tolower(names(head(cit_tmp, n=subset_size)))\n  # Top K metabolites from mma cohort\n  met_set2 = tolower(names(head(mma_tmp, n=subset_size)))\n  # Top K metabolites from pku cohort\n  met_set3 = tolower(names(head(pku_tmp, n=subset_size)))\n  # Top K metabolties from reference cohort\n  met_set4 = tolower(names(head(ref_tmp, n=subset_size)))\n  # K random metabolites\n  met_set5 = tolower(sample(V(ig_rand)$name, size=subset_size, replace = FALSE))\n  \n  if (docit) {\n    # ig_cit: More global parameters\n    G = vector(mode=\"list\", length=length(V(ig_cit_naive)$name))\n    names(G) = V(ig_cit_naive)$name\n    adj_mat = as.matrix(get.adjacency(ig_cit_naive, attr=\"weight\"))\n    # Use single node encoding to get node ranks\n    ranks1 = list()\n    for (n in 1:length(met_set1)) {\n      ind = which(names(G)==met_set1[n])\n      ranks1[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set1, num.misses = log2(length(G)))\n    }\n    names(ranks1) = met_set1\n    ranks2 = list()\n    for (n in 1:length(met_set2)) {\n      ind = which(names(G)==met_set2[n])\n      ranks2[[n]] = singleNode.getNodeRanksN(n=ind, G=G,  p1, thresholdDiff, adj_mat, S=met_set2, num.misses = log2(length(G)))\n    }\n    names(ranks2) = met_set2\n    ranks3 = list()\n    for (n in 1:length(met_set3)) {\n      ind = which(names(G)==met_set3[n])\n      ranks3[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set3, num.misses = log2(length(G)))\n    }\n    names(ranks3) = met_set3\n    ranks4 = list()\n    for (n in 1:length(met_set4)) {\n      ind = which(names(G)==met_set4[n])\n      ranks4[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set4, num.misses = log2(length(G)))\n    }\n    names(ranks4) = met_set4\n    ranks5 = list()\n    for (n in 1:length(met_set5)) {\n      ind = which(names(G)==met_set5[n])\n      ranks5[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set5, num.misses = log2(length(G)))\n    }\n    names(ranks5) = met_set5\n    # Get bitstrings from node ranks\n    set1_cit_bs = mle.getPtBSbyK(met_set1, ranks1)\n    set2_cit_bs = mle.getPtBSbyK(met_set2, ranks2)\n    set3_cit_bs = mle.getPtBSbyK(met_set3, ranks3)\n    set4_cit_bs = mle.getPtBSbyK(met_set4, ranks4)\n    set5_cit_bs = mle.getPtBSbyK(met_set5, ranks5)\n    # Then use the bitstrings to convert into encoding length.\n    set1_res = mle.getEncodingLength(set1_cit_bs, NULL, \"set1\", G)[length(met_set1),]\n    set2_res = mle.getEncodingLength(set2_cit_bs, NULL, \"set2\", G)[length(met_set2),]\n    set3_res = mle.getEncodingLength(set3_cit_bs, NULL, \"set3\", G)[length(met_set3),]\n    set4_res = mle.getEncodingLength(set4_cit_bs, NULL, \"set4\", G)[length(met_set4),]\n    set5_res = mle.getEncodingLength(set5_cit_bs, NULL, \"set5\", G)[length(met_set5),]\n    print(set1_res) # look at IS.alt column.\n    print(set2_res) # look at IS.alt column.\n    print(set3_res) # look at IS.alt column.\n    print(set4_res) # look at IS.alt column.\n    print(set5_res) # look at IS.alt column.\n    res[r_row, \"subset_size\"] = subset_size\n    res[r_row, \"graph_name\"] = \"cit\"\n    res[r_row, \"IA_top_cit\"] = set1_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_mma\"] = set2_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_pku\"] = set3_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_ref\"] = set4_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_rand\"] = set5_res[,\"IS.alt\"]\n    r_row = r_row + 1\n    \n    # ig_cit1: More global parameters\n    G = vector(mode=\"list\", length=length(V(ig_cit1_naive)$name))\n    names(G) = V(ig_cit1_naive)$name\n    adj_mat = as.matrix(get.adjacency(ig_cit1_naive, attr=\"weight\"))\n    # Use single node encoding to get node ranks.\n    ranks1 = list()\n    for (n in 1:length(met_set1)) {\n      ind = which(names(G)==met_set1[n])\n      ranks1[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set1, num.misses = log2(length(G)))\n    }\n    names(ranks1) = met_set1\n    ranks2 = list()\n    for (n in 1:length(met_set2)) {\n      ind = which(names(G)==met_set2[n])\n      ranks2[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set2, num.misses = log2(length(G)))\n    }\n    names(ranks2) = met_set2\n    ranks3 = list()\n    for (n in 1:length(met_set3)) {\n      ind = which(names(G)==met_set3[n])\n      ranks3[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set3, num.misses = log2(length(G)))\n    }\n    names(ranks3) = met_set3\n    ranks4 = list()\n    for (n in 1:length(met_set4)) {\n      ind = which(names(G)==met_set4[n])\n      ranks4[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set4, num.misses = log2(length(G)))\n    }\n    names(ranks4) = met_set4\n    ranks5 = list()\n    for (n in 1:length(met_set5)) {\n      ind = which(names(G)==met_set5[n])\n      ranks5[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set5, num.misses = log2(length(G)))\n    }\n    names(ranks5) = met_set5\n    # Then use the node permutations to outputted to convert them into bitstrings.\n    set1_cit_bs = mle.getPtBSbyK(met_set1, ranks1)\n    set2_cit_bs = mle.getPtBSbyK(met_set2, ranks2)\n    set3_cit_bs = mle.getPtBSbyK(met_set3, ranks3)\n    set4_cit_bs = mle.getPtBSbyK(met_set4, ranks4)\n    set5_cit_bs = mle.getPtBSbyK(met_set5, ranks5)\n    # Then use the bitstrings to convert into encoding length.\n    set1_res = mle.getEncodingLength(set1_cit_bs, NULL, \"set1\", G)[length(met_set1),]\n    set2_res = mle.getEncodingLength(set2_cit_bs, NULL, \"set2\", G)[length(met_set2),]\n    set3_res = mle.getEncodingLength(set3_cit_bs, NULL, \"set3\", G)[length(met_set3),]\n    set4_res = mle.getEncodingLength(set4_cit_bs, NULL, \"set4\", G)[length(met_set4),]\n    set5_res = mle.getEncodingLength(set5_cit_bs, NULL, \"set5\", G)[length(met_set5),]\n    print(set1_res) # look at IS.alt column.\n    print(set2_res) # look at IS.alt column.\n    print(set3_res) # look at IS.alt column.\n    print(set4_res) # look at IS.alt column.\n    print(set5_res) # look at IS.alt column.\n    res[r_row, \"subset_size\"] = subset_size\n    res[r_row, \"graph_name\"] = \"cit1\"\n    res[r_row, \"IA_top_cit\"] = set1_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_mma\"] = set2_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_pku\"] = set3_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_ref\"] = set4_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_rand\"] = set5_res[,\"IS.alt\"]\n    r_row = r_row + 1\n    \n    # ig_cit2: More global parameters\n    G = vector(mode=\"list\", length=length(V(ig_cit2_naive)$name))\n    names(G) = V(ig_cit2_naive)$name\n    adj_mat = as.matrix(get.adjacency(ig_cit2_naive, attr=\"weight\"))\n    # Use single node encoding to get node ranks.\n    ranks1 = list()\n    for (n in 1:length(met_set1)) {\n      ind = which(names(G)==met_set1[n])\n      ranks1[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set1, num.misses = log2(length(G)))\n    }\n    names(ranks1) = met_set1\n    ranks2 = list()\n    for (n in 1:length(met_set2)) {\n      ind = which(names(G)==met_set2[n])\n      ranks2[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set2, num.misses = log2(length(G)))\n    }\n    names(ranks2) = met_set2\n    ranks3 = list()\n    for (n in 1:length(met_set3)) {\n      ind = which(names(G)==met_set3[n])\n      ranks3[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set3, num.misses = log2(length(G)))\n    }\n    names(ranks3) = met_set3\n    ranks4 = list()\n    for (n in 1:length(met_set4)) {\n      ind = which(names(G)==met_set4[n])\n      ranks4[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set4, num.misses = log2(length(G)))\n    }\n    names(ranks4) = met_set4\n    ranks5 = list()\n    for (n in 1:length(met_set5)) {\n      ind = which(names(G)==met_set5[n])\n      ranks5[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set5, num.misses = log2(length(G)))\n    }\n    names(ranks5) = met_set5\n    # Then use the node permutations to outputted to convert them into bitstrings.\n    set1_cit_bs = mle.getPtBSbyK(met_set1, ranks1)\n    set2_cit_bs = mle.getPtBSbyK(met_set2, ranks2)\n    set3_cit_bs = mle.getPtBSbyK(met_set3, ranks3)\n    set4_cit_bs = mle.getPtBSbyK(met_set4, ranks4)\n    set5_cit_bs = mle.getPtBSbyK(met_set5, ranks5)\n    # Then use the bitstrings to convert into encoding length.\n    set1_res = mle.getEncodingLength(set1_cit_bs, NULL, \"set1\", G)[length(met_set1),]\n    set2_res = mle.getEncodingLength(set2_cit_bs, NULL, \"set2\", G)[length(met_set2),]\n    set3_res = mle.getEncodingLength(set3_cit_bs, NULL, \"set3\", G)[length(met_set3),]\n    set4_res = mle.getEncodingLength(set4_cit_bs, NULL, \"set4\", G)[length(met_set4),]\n    set5_res = mle.getEncodingLength(set5_cit_bs, NULL, \"set5\", G)[length(met_set5),]\n    print(set1_res) # look at IS.alt column.\n    print(set2_res) # look at IS.alt column.\n    print(set3_res) # look at IS.alt column.\n    print(set4_res) # look at IS.alt column.\n    print(set5_res) # look at IS.alt column.\n    res[r_row, \"subset_size\"] = subset_size\n    res[r_row, \"graph_name\"] = \"cit2\"\n    res[r_row, \"IA_top_cit\"] = set1_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_mma\"] = set2_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_pku\"] = set3_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_ref\"] = set4_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_rand\"] = set5_res[,\"IS.alt\"]\n    r_row = r_row + 1\n    \n    # ig_cit3: More global parameters\n    G = vector(mode=\"list\", length=length(V(ig_cit3_naive)$name))\n    names(G) = V(ig_cit3_naive)$name\n    adj_mat = as.matrix(get.adjacency(ig_cit3_naive, attr=\"weight\"))\n    # Use single node encoding to get node ranks.\n    ranks1 = list()\n    for (n in 1:length(met_set1)) {\n      ind = which(names(G)==met_set1[n])\n      ranks1[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set1, num.misses = log2(length(G)))\n    }\n    names(ranks1) = met_set1\n    ranks2 = list()\n    for (n in 1:length(met_set2)) {\n      ind = which(names(G)==met_set2[n])\n      ranks2[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set2, num.misses = log2(length(G)))\n    }\n    names(ranks2) = met_set2\n    ranks3 = list()\n    for (n in 1:length(met_set3)) {\n      ind = which(names(G)==met_set3[n])\n      ranks3[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set3, num.misses = log2(length(G)))\n    }\n    names(ranks3) = met_set3\n    ranks4 = list()\n    for (n in 1:length(met_set4)) {\n      ind = which(names(G)==met_set4[n])\n      ranks4[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set4, num.misses = log2(length(G)))\n    }\n    names(ranks4) = met_set4\n    ranks5 = list()\n    for (n in 1:length(met_set5)) {\n      ind = which(names(G)==met_set5[n])\n      ranks5[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set5, num.misses = log2(length(G)))\n    }\n    names(ranks5) = met_set5\n    # Then use the node permutations to outputted to convert them into bitstrings.\n    set1_cit_bs = mle.getPtBSbyK(met_set1, ranks1)\n    set2_cit_bs = mle.getPtBSbyK(met_set2, ranks2)\n    set3_cit_bs = mle.getPtBSbyK(met_set3, ranks3)\n    set4_cit_bs = mle.getPtBSbyK(met_set4, ranks4)\n    set5_cit_bs = mle.getPtBSbyK(met_set5, ranks5)\n    # Then use the bitstrings to convert into encoding length.\n    set1_res = mle.getEncodingLength(set1_cit_bs, NULL, \"set1\", G)[length(met_set1),]\n    set2_res = mle.getEncodingLength(set2_cit_bs, NULL, \"set2\", G)[length(met_set2),]\n    set3_res = mle.getEncodingLength(set3_cit_bs, NULL, \"set3\", G)[length(met_set3),]\n    set4_res = mle.getEncodingLength(set4_cit_bs, NULL, \"set4\", G)[length(met_set4),]\n    set5_res = mle.getEncodingLength(set5_cit_bs, NULL, \"set5\", G)[length(met_set5),]\n    print(set1_res) # look at IS.alt column.\n    print(set2_res) # look at IS.alt column.\n    print(set3_res) # look at IS.alt column.\n    print(set4_res) # look at IS.alt column.\n    print(set5_res) # look at IS.alt column.\n    res[r_row, \"subset_size\"] = subset_size\n    res[r_row, \"graph_name\"] = \"cit3\"\n    res[r_row, \"IA_top_cit\"] = set1_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_mma\"] = set2_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_pku\"] = set3_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_ref\"] = set4_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_rand\"] = set5_res[,\"IS.alt\"]\n    r_row = r_row + 1\n    \n    # ig_cit4: More global parameters\n    G = vector(mode=\"list\", length=length(V(ig_cit4_naive)$name))\n    names(G) = V(ig_cit4_naive)$name\n    adj_mat = as.matrix(get.adjacency(ig_cit4_naive, attr=\"weight\"))\n    # Use single node encoding to get node ranks.\n    ranks1 = list()\n    for (n in 1:length(met_set1)) {\n      ind = which(names(G)==met_set1[n])\n      ranks1[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set1, num.misses = log2(length(G)))\n    }\n    names(ranks1) = met_set1\n    ranks2 = list()\n    for (n in 1:length(met_set2)) {\n      ind = which(names(G)==met_set2[n])\n      ranks2[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set2, num.misses = log2(length(G)))\n    }\n    names(ranks2) = met_set2\n    ranks3 = list()\n    for (n in 1:length(met_set3)) {\n      ind = which(names(G)==met_set3[n])\n      ranks3[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set3, num.misses = log2(length(G)))\n    }\n    names(ranks3) = met_set3\n    ranks4 = list()\n    for (n in 1:length(met_set4)) {\n      ind = which(names(G)==met_set4[n])\n      ranks4[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set4, num.misses = log2(length(G)))\n    }\n    names(ranks4) = met_set4\n    ranks5 = list()\n    for (n in 1:length(met_set5)) {\n      ind = which(names(G)==met_set5[n])\n      ranks5[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set5, num.misses = log2(length(G)))\n    }\n    names(ranks5) = met_set5\n    # Then use the node permutations to outputted to convert them into bitstrings.\n    set1_cit_bs = mle.getPtBSbyK(met_set1, ranks1)\n    set2_cit_bs = mle.getPtBSbyK(met_set2, ranks2)\n    set3_cit_bs = mle.getPtBSbyK(met_set3, ranks3)\n    set4_cit_bs = mle.getPtBSbyK(met_set4, ranks4)\n    set5_cit_bs = mle.getPtBSbyK(met_set5, ranks5)\n    # Then use the bitstrings to convert into encoding length.\n    set1_res = mle.getEncodingLength(set1_cit_bs, NULL, \"set1\", G)[length(met_set1),]\n    set2_res = mle.getEncodingLength(set2_cit_bs, NULL, \"set2\", G)[length(met_set2),]\n    set3_res = mle.getEncodingLength(set3_cit_bs, NULL, \"set3\", G)[length(met_set3),]\n    set4_res = mle.getEncodingLength(set4_cit_bs, NULL, \"set4\", G)[length(met_set4),]\n    set5_res = mle.getEncodingLength(set5_cit_bs, NULL, \"set5\", G)[length(met_set5),]\n    print(set1_res) # look at IS.alt column.\n    print(set2_res) # look at IS.alt column.\n    print(set3_res) # look at IS.alt column.\n    print(set4_res) # look at IS.alt column.\n    print(set5_res) # look at IS.alt column.\n    res[r_row, \"subset_size\"] = subset_size\n    res[r_row, \"graph_name\"] = \"cit4\"\n    res[r_row, \"IA_top_cit\"] = set1_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_mma\"] = set2_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_pku\"] = set3_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_ref\"] = set4_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_rand\"] = set5_res[,\"IS.alt\"]\n    r_row = r_row + 1\n    \n    # ig_cit5: More global parameters\n    G = vector(mode=\"list\", length=length(V(ig_cit5_naive)$name))\n    names(G) = V(ig_cit5_naive)$name\n    adj_mat = as.matrix(get.adjacency(ig_cit5_naive, attr=\"weight\"))\n    # Use single node encoding to get node ranks.\n    ranks1 = list()\n    for (n in 1:length(met_set1)) {\n      ind = which(names(G)==met_set1[n])\n      ranks1[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set1, num.misses = log2(length(G)))\n    }\n    names(ranks1) = met_set1\n    ranks2 = list()\n    for (n in 1:length(met_set2)) {\n      ind = which(names(G)==met_set2[n])\n      ranks2[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set2, num.misses = log2(length(G)))\n    }\n    names(ranks2) = met_set2\n    ranks3 = list()\n    for (n in 1:length(met_set3)) {\n      ind = which(names(G)==met_set3[n])\n      ranks3[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set3, num.misses = log2(length(G)))\n    }\n    names(ranks3) = met_set3\n    ranks4 = list()\n    for (n in 1:length(met_set4)) {\n      ind = which(names(G)==met_set4[n])\n      ranks4[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set4, num.misses = log2(length(G)))\n    }\n    names(ranks4) = met_set4\n    ranks5 = list()\n    for (n in 1:length(met_set5)) {\n      ind = which(names(G)==met_set5[n])\n      ranks5[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set5, num.misses = log2(length(G)))\n    }\n    names(ranks5) = met_set5\n    # Then use the node permutations to outputted to convert them into bitstrings.\n    set1_cit_bs = mle.getPtBSbyK(met_set1, ranks1)\n    set2_cit_bs = mle.getPtBSbyK(met_set2, ranks2)\n    set3_cit_bs = mle.getPtBSbyK(met_set3, ranks3)\n    set4_cit_bs = mle.getPtBSbyK(met_set4, ranks4)\n    set5_cit_bs = mle.getPtBSbyK(met_set5, ranks5)\n    # Then use the bitstrings to convert into encoding length.\n    set1_res = mle.getEncodingLength(set1_cit_bs, NULL, \"set1\", G)[length(met_set1),]\n    set2_res = mle.getEncodingLength(set2_cit_bs, NULL, \"set2\", G)[length(met_set2),]\n    set3_res = mle.getEncodingLength(set3_cit_bs, NULL, \"set3\", G)[length(met_set3),]\n    set4_res = mle.getEncodingLength(set4_cit_bs, NULL, \"set4\", G)[length(met_set4),]\n    set5_res = mle.getEncodingLength(set5_cit_bs, NULL, \"set5\", G)[length(met_set5),]\n    print(set1_res) # look at IS.alt column.\n    print(set2_res) # look at IS.alt column.\n    print(set3_res) # look at IS.alt column.\n    print(set4_res) # look at IS.alt column.\n    print(set5_res) # look at IS.alt column.\n    res[r_row, \"subset_size\"] = subset_size\n    res[r_row, \"graph_name\"] = \"cit5\"\n    res[r_row, \"IA_top_cit\"] = set1_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_mma\"] = set2_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_pku\"] = set3_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_ref\"] = set4_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_rand\"] = set5_res[,\"IS.alt\"]\n    r_row = r_row + 1\n    \n    # ig_cit6: More global parameters\n    G = vector(mode=\"list\", length=length(V(ig_cit6_naive)$name))\n    names(G) = V(ig_cit6_naive)$name\n    adj_mat = as.matrix(get.adjacency(ig_cit6_naive, attr=\"weight\"))\n    # Use single node encoding to get node ranks.\n    ranks1 = list()\n    for (n in 1:length(met_set1)) {\n      ind = which(names(G)==met_set1[n])\n      ranks1[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set1, num.misses = log2(length(G)))\n    }\n    names(ranks1) = met_set1\n    ranks2 = list()\n    for (n in 1:length(met_set2)) {\n      ind = which(names(G)==met_set2[n])\n      ranks2[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set2, num.misses = log2(length(G)))\n    }\n    names(ranks2) = met_set2\n    ranks3 = list()\n    for (n in 1:length(met_set3)) {\n      ind = which(names(G)==met_set3[n])\n      ranks3[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set3, num.misses = log2(length(G)))\n    }\n    names(ranks3) = met_set3\n    ranks4 = list()\n    for (n in 1:length(met_set4)) {\n      ind = which(names(G)==met_set4[n])\n      ranks4[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set4, num.misses = log2(length(G)))\n    }\n    names(ranks4) = met_set4\n    ranks5 = list()\n    for (n in 1:length(met_set5)) {\n      ind = which(names(G)==met_set5[n])\n      ranks5[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set5, num.misses = log2(length(G)))\n    }\n    names(ranks5) = met_set5\n    # Then use the node permutations to outputted to convert them into bitstrings.\n    set1_cit_bs = mle.getPtBSbyK(met_set1, ranks1)\n    set2_cit_bs = mle.getPtBSbyK(met_set2, ranks2)\n    set3_cit_bs = mle.getPtBSbyK(met_set3, ranks3)\n    set4_cit_bs = mle.getPtBSbyK(met_set4, ranks4)\n    set5_cit_bs = mle.getPtBSbyK(met_set5, ranks5)\n    # Then use the bitstrings to convert into encoding length.\n    set1_res = mle.getEncodingLength(set1_cit_bs, NULL, \"set1\", G)[length(met_set1),]\n    set2_res = mle.getEncodingLength(set2_cit_bs, NULL, \"set2\", G)[length(met_set2),]\n    set3_res = mle.getEncodingLength(set3_cit_bs, NULL, \"set3\", G)[length(met_set3),]\n    set4_res = mle.getEncodingLength(set4_cit_bs, NULL, \"set4\", G)[length(met_set4),]\n    set5_res = mle.getEncodingLength(set5_cit_bs, NULL, \"set5\", G)[length(met_set5),]\n    print(set1_res) # look at IS.alt column.\n    print(set2_res) # look at IS.alt column.\n    print(set3_res) # look at IS.alt column.\n    print(set4_res) # look at IS.alt column.\n    print(set5_res) # look at IS.alt column.\n    res[r_row, \"subset_size\"] = subset_size\n    res[r_row, \"graph_name\"] = \"cit6\"\n    res[r_row, \"IA_top_cit\"] = set1_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_mma\"] = set2_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_pku\"] = set3_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_ref\"] = set4_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_rand\"] = set5_res[,\"IS.alt\"]\n    r_row = r_row + 1\n    \n    # ig_cit7: More global parameters\n    G = vector(mode=\"list\", length=length(V(ig_cit7_naive)$name))\n    names(G) = V(ig_cit7_naive)$name\n    adj_mat = as.matrix(get.adjacency(ig_cit7_naive, attr=\"weight\"))\n    # Use single node encoding to get node ranks.\n    ranks1 = list()\n    for (n in 1:length(met_set1)) {\n      ind = which(names(G)==met_set1[n])\n      ranks1[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set1, num.misses = log2(length(G)))\n    }\n    names(ranks1) = met_set1\n    ranks2 = list()\n    for (n in 1:length(met_set2)) {\n      ind = which(names(G)==met_set2[n])\n      ranks2[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set2, num.misses = log2(length(G)))\n    }\n    names(ranks2) = met_set2\n    ranks3 = list()\n    for (n in 1:length(met_set3)) {\n      ind = which(names(G)==met_set3[n])\n      ranks3[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set3, num.misses = log2(length(G)))\n    }\n    names(ranks3) = met_set3\n    ranks4 = list()\n    for (n in 1:length(met_set4)) {\n      ind = which(names(G)==met_set4[n])\n      ranks4[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set4, num.misses = log2(length(G)))\n    }\n    names(ranks4) = met_set4\n    ranks5 = list()\n    for (n in 1:length(met_set5)) {\n      ind = which(names(G)==met_set5[n])\n      ranks5[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set5, num.misses = log2(length(G)))\n    }\n    names(ranks5) = met_set5\n    # Then use the node permutations to outputted to convert them into bitstrings.\n    set1_cit_bs = mle.getPtBSbyK(met_set1, ranks1)\n    set2_cit_bs = mle.getPtBSbyK(met_set2, ranks2)\n    set3_cit_bs = mle.getPtBSbyK(met_set3, ranks3)\n    set4_cit_bs = mle.getPtBSbyK(met_set4, ranks4)\n    set5_cit_bs = mle.getPtBSbyK(met_set5, ranks5)\n    # Then use the bitstrings to convert into encoding length.\n    set1_res = mle.getEncodingLength(set1_cit_bs, NULL, \"set1\", G)[length(met_set1),]\n    set2_res = mle.getEncodingLength(set2_cit_bs, NULL, \"set2\", G)[length(met_set2),]\n    set3_res = mle.getEncodingLength(set3_cit_bs, NULL, \"set3\", G)[length(met_set3),]\n    set4_res = mle.getEncodingLength(set4_cit_bs, NULL, \"set4\", G)[length(met_set4),]\n    set5_res = mle.getEncodingLength(set5_cit_bs, NULL, \"set5\", G)[length(met_set5),]\n    print(set1_res) # look at IS.alt column.\n    print(set2_res) # look at IS.alt column.\n    print(set3_res) # look at IS.alt column.\n    print(set4_res) # look at IS.alt column.\n    print(set5_res) # look at IS.alt column.\n    res[r_row, \"subset_size\"] = subset_size\n    res[r_row, \"graph_name\"] = \"cit7\"\n    res[r_row, \"IA_top_cit\"] = set1_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_mma\"] = set2_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_pku\"] = set3_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_ref\"] = set4_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_rand\"] = set5_res[,\"IS.alt\"]\n    r_row = r_row + 1\n    \n    # ig_cit8: More global parameters\n    G = vector(mode=\"list\", length=length(V(ig_cit8_naive)$name))\n    names(G) = V(ig_cit8_naive)$name\n    adj_mat = as.matrix(get.adjacency(ig_cit8_naive, attr=\"weight\"))\n    # Use single node encoding to get node ranks.\n    ranks1 = list()\n    for (n in 1:length(met_set1)) {\n      ind = which(names(G)==met_set1[n])\n      ranks1[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set1, num.misses = log2(length(G)))\n    }\n    names(ranks1) = met_set1\n    ranks2 = list()\n    for (n in 1:length(met_set2)) {\n      ind = which(names(G)==met_set2[n])\n      ranks2[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set2, num.misses = log2(length(G)))\n    }\n    names(ranks2) = met_set2\n    ranks3 = list()\n    for (n in 1:length(met_set3)) {\n      ind = which(names(G)==met_set3[n])\n      ranks3[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set3, num.misses = log2(length(G)))\n    }\n    names(ranks3) = met_set3\n    ranks4 = list()\n    for (n in 1:length(met_set4)) {\n      ind = which(names(G)==met_set4[n])\n      ranks4[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set4, num.misses = log2(length(G)))\n    }\n    names(ranks4) = met_set4\n    ranks5 = list()\n    for (n in 1:length(met_set5)) {\n      ind = which(names(G)==met_set5[n])\n      ranks5[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set5, num.misses = log2(length(G)))\n    }\n    names(ranks5) = met_set5\n    # Then use the node permutations to outputted to convert them into bitstrings.\n    set1_cit_bs = mle.getPtBSbyK(met_set1, ranks1)\n    set2_cit_bs = mle.getPtBSbyK(met_set2, ranks2)\n    set3_cit_bs = mle.getPtBSbyK(met_set3, ranks3)\n    set4_cit_bs = mle.getPtBSbyK(met_set4, ranks4)\n    set5_cit_bs = mle.getPtBSbyK(met_set5, ranks5)\n    # Then use the bitstrings to convert into encoding length.\n    set1_res = mle.getEncodingLength(set1_cit_bs, NULL, \"set1\", G)[length(met_set1),]\n    set2_res = mle.getEncodingLength(set2_cit_bs, NULL, \"set2\", G)[length(met_set2),]\n    set3_res = mle.getEncodingLength(set3_cit_bs, NULL, \"set3\", G)[length(met_set3),]\n    set4_res = mle.getEncodingLength(set4_cit_bs, NULL, \"set4\", G)[length(met_set4),]\n    set5_res = mle.getEncodingLength(set5_cit_bs, NULL, \"set5\", G)[length(met_set5),]\n    print(set1_res) # look at IS.alt column.\n    print(set2_res) # look at IS.alt column.\n    print(set3_res) # look at IS.alt column.\n    print(set4_res) # look at IS.alt column.\n    print(set5_res) # look at IS.alt column.\n    res[r_row, \"subset_size\"] = subset_size\n    res[r_row, \"graph_name\"] = \"cit8\"\n    res[r_row, \"IA_top_cit\"] = set1_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_mma\"] = set2_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_pku\"] = set3_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_ref\"] = set4_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_rand\"] = set5_res[,\"IS.alt\"]\n    r_row = r_row + 1\n    \n    # ig_cit9: More global parameters\n    G = vector(mode=\"list\", length=length(V(ig_cit9_naive)$name))\n    names(G) = V(ig_cit9_naive)$name\n    adj_mat = as.matrix(get.adjacency(ig_cit9_naive, attr=\"weight\"))\n    # Use single node encoding to get node ranks.\n    ranks1 = list()\n    for (n in 1:length(met_set1)) {\n      ind = which(names(G)==met_set1[n])\n      ranks1[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set1, num.misses = log2(length(G)))\n    }\n    names(ranks1) = met_set1\n    ranks2 = list()\n    for (n in 1:length(met_set2)) {\n      ind = which(names(G)==met_set2[n])\n      ranks2[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set2, num.misses = log2(length(G)))\n    }\n    names(ranks2) = met_set2\n    ranks3 = list()\n    for (n in 1:length(met_set3)) {\n      ind = which(names(G)==met_set3[n])\n      ranks3[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set3, num.misses = log2(length(G)))\n    }\n    names(ranks3) = met_set3\n    ranks4 = list()\n    for (n in 1:length(met_set4)) {\n      ind = which(names(G)==met_set4[n])\n      ranks4[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set4, num.misses = log2(length(G)))\n    }\n    names(ranks4) = met_set4\n    ranks5 = list()\n    for (n in 1:length(met_set5)) {\n      ind = which(names(G)==met_set5[n])\n      ranks5[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set5, num.misses = log2(length(G)))\n    }\n    names(ranks5) = met_set5\n    # Then use the node permutations to outputted to convert them into bitstrings.\n    set1_cit_bs = mle.getPtBSbyK(met_set1, ranks1)\n    set2_cit_bs = mle.getPtBSbyK(met_set2, ranks2)\n    set3_cit_bs = mle.getPtBSbyK(met_set3, ranks3)\n    set4_cit_bs = mle.getPtBSbyK(met_set4, ranks4)\n    set5_cit_bs = mle.getPtBSbyK(met_set5, ranks5)\n    # Then use the bitstrings to convert into encoding length.\n    set1_res = mle.getEncodingLength(set1_cit_bs, NULL, \"set1\", G)[length(met_set1),]\n    set2_res = mle.getEncodingLength(set2_cit_bs, NULL, \"set2\", G)[length(met_set2),]\n    set3_res = mle.getEncodingLength(set3_cit_bs, NULL, \"set3\", G)[length(met_set3),]\n    set4_res = mle.getEncodingLength(set4_cit_bs, NULL, \"set4\", G)[length(met_set4),]\n    set5_res = mle.getEncodingLength(set5_cit_bs, NULL, \"set5\", G)[length(met_set5),]\n    print(set1_res) # look at IS.alt column.\n    print(set2_res) # look at IS.alt column.\n    print(set3_res) # look at IS.alt column.\n    print(set4_res) # look at IS.alt column.\n    print(set5_res) # look at IS.alt column.\n    res[r_row, \"subset_size\"] = subset_size\n    res[r_row, \"graph_name\"] = \"cit9\"\n    res[r_row, \"IA_top_cit\"] = set1_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_mma\"] = set2_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_pku\"] = set3_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_ref\"] = set4_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_rand\"] = set5_res[,\"IS.alt\"]\n    r_row = r_row + 1\n  }\n  \n  if (domma) {\n    # ig_mma: Re-set global parameters for mma network.\n    G = vector(mode=\"list\", length=length(V(ig_mma_naive)$name))\n    names(G) = V(ig_mma_naive)$name\n    adj_mat = as.matrix(get.adjacency(ig_mma_naive, attr=\"weight\"))\n    # Use single node encoding to get node ranks\n    ranks1 = list()\n    for (n in 1:length(met_set1)) {\n      ind = which(names(G)==met_set1[n])\n      ranks1[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set1, num.misses = log2(length(G)))\n    }\n    names(ranks1) = met_set1\n    ranks2 = list()\n    for (n in 1:length(met_set2)) {\n      ind = which(names(G)==met_set2[n])\n      ranks2[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set2, num.misses = log2(length(G)))\n    }\n    names(ranks2) = met_set2\n    ranks3 = list()\n    for (n in 1:length(met_set3)) {\n      ind = which(names(G)==met_set3[n])\n      ranks3[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set3, num.misses = log2(length(G)))\n    }\n    names(ranks3) = met_set3\n    ranks4 = list()\n    for (n in 1:length(met_set4)) {\n      ind = which(names(G)==met_set4[n])\n      ranks4[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set4, num.misses = log2(length(G)))\n    }\n    names(ranks4) = met_set4\n    ranks5 = list()\n    for (n in 1:length(met_set5)) {\n      ind = which(names(G)==met_set5[n])\n      ranks5[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set5, num.misses = log2(length(G)))\n    }\n    names(ranks5) = met_set5\n    # Then use the node permutations to outputted to convert them into bitstrings.\n    set1_mma_bs = mle.getPtBSbyK(met_set1, ranks1)\n    set2_mma_bs = mle.getPtBSbyK(met_set2, ranks2)\n    set3_mma_bs = mle.getPtBSbyK(met_set3, ranks3)\n    set4_mma_bs = mle.getPtBSbyK(met_set4, ranks4)\n    set5_mma_bs = mle.getPtBSbyK(met_set5, ranks5)\n    # Then use the bitstrings to convert into encoding length.\n    set1_res = mle.getEncodingLength(set1_mma_bs, NULL, \"set1\", G)[length(met_set1),]\n    set2_res = mle.getEncodingLength(set2_mma_bs, NULL, \"set2\", G)[length(met_set2),]\n    set3_res = mle.getEncodingLength(set3_mma_bs, NULL, \"set3\", G)[length(met_set3),]\n    set4_res = mle.getEncodingLength(set4_mma_bs, NULL, \"set4\", G)[length(met_set4),]\n    set5_res = mle.getEncodingLength(set5_mma_bs, NULL, \"set5\", G)[length(met_set5),]\n    print(set1_res) # look at IS.alt column.\n    print(set2_res) # look at IS.alt column.\n    print(set3_res) # look at IS.alt column.\n    print(set4_res) # look at IS.alt column.\n    print(set5_res) # look at IS.alt column.\n    res[r_row, \"subset_size\"] = subset_size\n    res[r_row, \"graph_name\"] = \"mma\"\n    res[r_row, \"IA_top_cit\"] = set1_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_mma\"] = set2_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_pku\"] = set3_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_ref\"] = set4_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_rand\"] = set5_res[,\"IS.alt\"]\n    r_row = r_row + 1\n    \n    # ig_mma1: Re-set global parameters for mma network.\n    G = vector(mode=\"list\", length=length(V(ig_mma1_naive)$name))\n    names(G) = V(ig_mma1_naive)$name\n    adj_mat = as.matrix(get.adjacency(ig_mma1_naive, attr=\"weight\"))\n    # Use single node encoding to get node ranks\n    ranks1 = list()\n    for (n in 1:length(met_set1)) {\n      ind = which(names(G)==met_set1[n])\n      ranks1[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set1, num.misses = log2(length(G)))\n    }\n    names(ranks1) = met_set1\n    ranks2 = list()\n    for (n in 1:length(met_set2)) {\n      ind = which(names(G)==met_set2[n])\n      ranks2[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set2, num.misses = log2(length(G)))\n    }\n    names(ranks2) = met_set2\n    ranks3 = list()\n    for (n in 1:length(met_set3)) {\n      ind = which(names(G)==met_set3[n])\n      ranks3[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set3, num.misses = log2(length(G)))\n    }\n    names(ranks3) = met_set3\n    ranks4 = list()\n    for (n in 1:length(met_set4)) {\n      ind = which(names(G)==met_set4[n])\n      ranks4[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set4, num.misses = log2(length(G)))\n    }\n    names(ranks4) = met_set4\n    ranks5 = list()\n    for (n in 1:length(met_set5)) {\n      ind = which(names(G)==met_set5[n])\n      ranks5[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set5, num.misses = log2(length(G)))\n    }\n    names(ranks5) = met_set5\n    # Then use the node permutations to outputted to convert them into bitstrings.\n    set1_mma_bs = mle.getPtBSbyK(met_set1, ranks1)\n    set2_mma_bs = mle.getPtBSbyK(met_set2, ranks2)\n    set3_mma_bs = mle.getPtBSbyK(met_set3, ranks3)\n    set4_mma_bs = mle.getPtBSbyK(met_set4, ranks4)\n    set5_mma_bs = mle.getPtBSbyK(met_set5, ranks5)\n    # Then use the bitstrings to convert into encoding length.\n    set1_res = mle.getEncodingLength(set1_mma_bs, NULL, \"set1\", G)[length(met_set1),]\n    set2_res = mle.getEncodingLength(set2_mma_bs, NULL, \"set2\", G)[length(met_set2),]\n    set3_res = mle.getEncodingLength(set3_mma_bs, NULL, \"set3\", G)[length(met_set3),]\n    set4_res = mle.getEncodingLength(set4_mma_bs, NULL, \"set4\", G)[length(met_set4),]\n    set5_res = mle.getEncodingLength(set5_mma_bs, NULL, \"set5\", G)[length(met_set5),]\n    print(set1_res) # look at IS.alt column.\n    print(set2_res) # look at IS.alt column.\n    print(set3_res) # look at IS.alt column.\n    print(set4_res) # look at IS.alt column.\n    print(set5_res) # look at IS.alt column.\n    res[r_row, \"subset_size\"] = subset_size\n    res[r_row, \"graph_name\"] = \"mma1\"\n    res[r_row, \"IA_top_cit\"] = set1_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_mma\"] = set2_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_pku\"] = set3_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_ref\"] = set4_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_rand\"] = set5_res[,\"IS.alt\"]\n    r_row = r_row + 1\n    \n    # ig_mma2: Re-set global parameters for mma network.\n    G = vector(mode=\"list\", length=length(V(ig_mma2_naive)$name))\n    names(G) = V(ig_mma2_naive)$name\n    adj_mat = as.matrix(get.adjacency(ig_mma2_naive, attr=\"weight\"))\n    # Use single node encoding to get node ranks\n    ranks1 = list()\n    for (n in 1:length(met_set1)) {\n      ind = which(names(G)==met_set1[n])\n      ranks1[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set1, num.misses = log2(length(G)))\n    }\n    names(ranks1) = met_set1\n    ranks2 = list()\n    for (n in 1:length(met_set2)) {\n      ind = which(names(G)==met_set2[n])\n      ranks2[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set2, num.misses = log2(length(G)))\n    }\n    names(ranks2) = met_set2\n    ranks3 = list()\n    for (n in 1:length(met_set3)) {\n      ind = which(names(G)==met_set3[n])\n      ranks3[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set3, num.misses = log2(length(G)))\n    }\n    names(ranks3) = met_set3\n    ranks4 = list()\n    for (n in 1:length(met_set4)) {\n      ind = which(names(G)==met_set4[n])\n      ranks4[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set4, num.misses = log2(length(G)))\n    }\n    names(ranks4) = met_set4\n    ranks5 = list()\n    for (n in 1:length(met_set5)) {\n      ind = which(names(G)==met_set5[n])\n      ranks5[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set5, num.misses = log2(length(G)))\n    }\n    names(ranks5) = met_set5\n    # Then use the node permutations to outputted to convert them into bitstrings.\n    set1_mma_bs = mle.getPtBSbyK(met_set1, ranks1)\n    set2_mma_bs = mle.getPtBSbyK(met_set2, ranks2)\n    set3_mma_bs = mle.getPtBSbyK(met_set3, ranks3)\n    set4_mma_bs = mle.getPtBSbyK(met_set4, ranks4)\n    set5_mma_bs = mle.getPtBSbyK(met_set5, ranks5)\n    # Then use the bitstrings to convert into encoding length.\n    set1_res = mle.getEncodingLength(set1_mma_bs, NULL, \"set1\", G)[length(met_set1),]\n    set2_res = mle.getEncodingLength(set2_mma_bs, NULL, \"set2\", G)[length(met_set2),]\n    set3_res = mle.getEncodingLength(set3_mma_bs, NULL, \"set3\", G)[length(met_set3),]\n    set4_res = mle.getEncodingLength(set4_mma_bs, NULL, \"set4\", G)[length(met_set4),]\n    set5_res = mle.getEncodingLength(set5_mma_bs, NULL, \"set5\", G)[length(met_set5),]\n    print(set1_res) # look at IS.alt column.\n    print(set2_res) # look at IS.alt column.\n    print(set3_res) # look at IS.alt column.\n    print(set4_res) # look at IS.alt column.\n    print(set5_res) # look at IS.alt column.\n    res[r_row, \"subset_size\"] = subset_size\n    res[r_row, \"graph_name\"] = \"mma2\"\n    res[r_row, \"IA_top_cit\"] = set1_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_mma\"] = set2_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_pku\"] = set3_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_ref\"] = set4_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_rand\"] = set5_res[,\"IS.alt\"]\n    r_row = r_row + 1\n    \n    # ig_mma3: Re-set global parameters for mma network.\n    G = vector(mode=\"list\", length=length(V(ig_mma3_naive)$name))\n    names(G) = V(ig_mma3_naive)$name\n    adj_mat = as.matrix(get.adjacency(ig_mma3_naive, attr=\"weight\"))\n    # Use single node encoding to get node ranks\n    ranks1 = list()\n    for (n in 1:length(met_set1)) {\n      ind = which(names(G)==met_set1[n])\n      ranks1[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set1, num.misses = log2(length(G)))\n    }\n    names(ranks1) = met_set1\n    ranks2 = list()\n    for (n in 1:length(met_set2)) {\n      ind = which(names(G)==met_set2[n])\n      ranks2[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set2, num.misses = log2(length(G)))\n    }\n    names(ranks2) = met_set2\n    ranks3 = list()\n    for (n in 1:length(met_set3)) {\n      ind = which(names(G)==met_set3[n])\n      ranks3[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set3, num.misses = log2(length(G)))\n    }\n    names(ranks3) = met_set3\n    ranks4 = list()\n    for (n in 1:length(met_set4)) {\n      ind = which(names(G)==met_set4[n])\n      ranks4[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set4, num.misses = log2(length(G)))\n    }\n    names(ranks4) = met_set4\n    ranks5 = list()\n    for (n in 1:length(met_set5)) {\n      ind = which(names(G)==met_set5[n])\n      ranks5[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set5, num.misses = log2(length(G)))\n    }\n    names(ranks5) = met_set5\n    # Then use the node permutations to outputted to convert them into bitstrings.\n    set1_mma_bs = mle.getPtBSbyK(met_set1, ranks1)\n    set2_mma_bs = mle.getPtBSbyK(met_set2, ranks2)\n    set3_mma_bs = mle.getPtBSbyK(met_set3, ranks3)\n    set4_mma_bs = mle.getPtBSbyK(met_set4, ranks4)\n    set5_mma_bs = mle.getPtBSbyK(met_set5, ranks5)\n    # Then use the bitstrings to convert into encoding length.\n    set1_res = mle.getEncodingLength(set1_mma_bs, NULL, \"set1\", G)[length(met_set1),]\n    set2_res = mle.getEncodingLength(set2_mma_bs, NULL, \"set2\", G)[length(met_set2),]\n    set3_res = mle.getEncodingLength(set3_mma_bs, NULL, \"set3\", G)[length(met_set3),]\n    set4_res = mle.getEncodingLength(set4_mma_bs, NULL, \"set4\", G)[length(met_set4),]\n    set5_res = mle.getEncodingLength(set5_mma_bs, NULL, \"set5\", G)[length(met_set5),]\n    print(set1_res) # look at IS.alt column.\n    print(set2_res) # look at IS.alt column.\n    print(set3_res) # look at IS.alt column.\n    print(set4_res) # look at IS.alt column.\n    print(set5_res) # look at IS.alt column.\n    res[r_row, \"subset_size\"] = subset_size\n    res[r_row, \"graph_name\"] = \"mma3\"\n    res[r_row, \"IA_top_cit\"] = set1_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_mma\"] = set2_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_pku\"] = set3_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_ref\"] = set4_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_rand\"] = set5_res[,\"IS.alt\"]\n    r_row = r_row + 1\n    \n    # ig_mma4: Re-set global parameters for mma network.\n    G = vector(mode=\"list\", length=length(V(ig_mma4_naive)$name))\n    names(G) = V(ig_mma4_naive)$name\n    adj_mat = as.matrix(get.adjacency(ig_mma4_naive, attr=\"weight\"))\n    # Use single node encoding to get node ranks\n    ranks1 = list()\n    for (n in 1:length(met_set1)) {\n      ind = which(names(G)==met_set1[n])\n      ranks1[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set1, num.misses = log2(length(G)))\n    }\n    names(ranks1) = met_set1\n    ranks2 = list()\n    for (n in 1:length(met_set2)) {\n      ind = which(names(G)==met_set2[n])\n      ranks2[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set2, num.misses = log2(length(G)))\n    }\n    names(ranks2) = met_set2\n    ranks3 = list()\n    for (n in 1:length(met_set3)) {\n      ind = which(names(G)==met_set3[n])\n      ranks3[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set3, num.misses = log2(length(G)))\n    }\n    names(ranks3) = met_set3\n    ranks4 = list()\n    for (n in 1:length(met_set4)) {\n      ind = which(names(G)==met_set4[n])\n      ranks4[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set4, num.misses = log2(length(G)))\n    }\n    names(ranks4) = met_set4\n    ranks5 = list()\n    for (n in 1:length(met_set5)) {\n      ind = which(names(G)==met_set5[n])\n      ranks5[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set5, num.misses = log2(length(G)))\n    }\n    names(ranks5) = met_set5\n    # Then use the node permutations to outputted to convert them into bitstrings.\n    set1_mma_bs = mle.getPtBSbyK(met_set1, ranks1)\n    set2_mma_bs = mle.getPtBSbyK(met_set2, ranks2)\n    set3_mma_bs = mle.getPtBSbyK(met_set3, ranks3)\n    set4_mma_bs = mle.getPtBSbyK(met_set4, ranks4)\n    set5_mma_bs = mle.getPtBSbyK(met_set5, ranks5)\n    # Then use the bitstrings to convert into encoding length.\n    set1_res = mle.getEncodingLength(set1_mma_bs, NULL, \"set1\", G)[length(met_set1),]\n    set2_res = mle.getEncodingLength(set2_mma_bs, NULL, \"set2\", G)[length(met_set2),]\n    set3_res = mle.getEncodingLength(set3_mma_bs, NULL, \"set3\", G)[length(met_set3),]\n    set4_res = mle.getEncodingLength(set4_mma_bs, NULL, \"set4\", G)[length(met_set4),]\n    set5_res = mle.getEncodingLength(set5_mma_bs, NULL, \"set5\", G)[length(met_set5),]\n    print(set1_res) # look at IS.alt column.\n    print(set2_res) # look at IS.alt column.\n    print(set3_res) # look at IS.alt column.\n    print(set4_res) # look at IS.alt column.\n    print(set5_res) # look at IS.alt column.\n    res[r_row, \"subset_size\"] = subset_size\n    res[r_row, \"graph_name\"] = \"mma4\"\n    res[r_row, \"IA_top_cit\"] = set1_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_mma\"] = set2_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_pku\"] = set3_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_ref\"] = set4_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_rand\"] = set5_res[,\"IS.alt\"]\n    r_row = r_row + 1\n    \n    # ig_mma5: Re-set global parameters for mma network.\n    G = vector(mode=\"list\", length=length(V(ig_mma5_naive)$name))\n    names(G) = V(ig_mma5_naive)$name\n    adj_mat = as.matrix(get.adjacency(ig_mma5_naive, attr=\"weight\"))\n    # Use single node encoding to get node ranks\n    ranks1 = list()\n    for (n in 1:length(met_set1)) {\n      ind = which(names(G)==met_set1[n])\n      ranks1[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set1, num.misses = log2(length(G)))\n    }\n    names(ranks1) = met_set1\n    ranks2 = list()\n    for (n in 1:length(met_set2)) {\n      ind = which(names(G)==met_set2[n])\n      ranks2[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set2, num.misses = log2(length(G)))\n    }\n    names(ranks2) = met_set2\n    ranks3 = list()\n    for (n in 1:length(met_set3)) {\n      ind = which(names(G)==met_set3[n])\n      ranks3[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set3, num.misses = log2(length(G)))\n    }\n    names(ranks3) = met_set3\n    ranks4 = list()\n    for (n in 1:length(met_set4)) {\n      ind = which(names(G)==met_set4[n])\n      ranks4[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set4, num.misses = log2(length(G)))\n    }\n    names(ranks4) = met_set4\n    ranks5 = list()\n    for (n in 1:length(met_set5)) {\n      ind = which(names(G)==met_set5[n])\n      ranks5[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set5, num.misses = log2(length(G)))\n    }\n    names(ranks5) = met_set5\n    # Then use the node permutations to outputted to convert them into bitstrings.\n    set1_mma_bs = mle.getPtBSbyK(met_set1, ranks1)\n    set2_mma_bs = mle.getPtBSbyK(met_set2, ranks2)\n    set3_mma_bs = mle.getPtBSbyK(met_set3, ranks3)\n    set4_mma_bs = mle.getPtBSbyK(met_set4, ranks4)\n    set5_mma_bs = mle.getPtBSbyK(met_set5, ranks5)\n    # Then use the bitstrings to convert into encoding length.\n    set1_res = mle.getEncodingLength(set1_mma_bs, NULL, \"set1\", G)[length(met_set1),]\n    set2_res = mle.getEncodingLength(set2_mma_bs, NULL, \"set2\", G)[length(met_set2),]\n    set3_res = mle.getEncodingLength(set3_mma_bs, NULL, \"set3\", G)[length(met_set3),]\n    set4_res = mle.getEncodingLength(set4_mma_bs, NULL, \"set4\", G)[length(met_set4),]\n    set5_res = mle.getEncodingLength(set5_mma_bs, NULL, \"set5\", G)[length(met_set5),]\n    print(set1_res) # look at IS.alt column.\n    print(set2_res) # look at IS.alt column.\n    print(set3_res) # look at IS.alt column.\n    print(set4_res) # look at IS.alt column.\n    print(set5_res) # look at IS.alt column.\n    res[r_row, \"subset_size\"] = subset_size\n    res[r_row, \"graph_name\"] = \"mma5\"\n    res[r_row, \"IA_top_cit\"] = set1_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_mma\"] = set2_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_pku\"] = set3_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_ref\"] = set4_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_rand\"] = set5_res[,\"IS.alt\"]\n    r_row = r_row + 1\n    \n    # ig_mma6: Re-set global parameters for mma network.\n    G = vector(mode=\"list\", length=length(V(ig_mma6_naive)$name))\n    names(G) = V(ig_mma6_naive)$name\n    adj_mat = as.matrix(get.adjacency(ig_mma6_naive, attr=\"weight\"))\n    # Use single node encoding to get node ranks\n    ranks1 = list()\n    for (n in 1:length(met_set1)) {\n      ind = which(names(G)==met_set1[n])\n      ranks1[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set1, num.misses = log2(length(G)))\n    }\n    names(ranks1) = met_set1\n    ranks2 = list()\n    for (n in 1:length(met_set2)) {\n      ind = which(names(G)==met_set2[n])\n      ranks2[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set2, num.misses = log2(length(G)))\n    }\n    names(ranks2) = met_set2\n    ranks3 = list()\n    for (n in 1:length(met_set3)) {\n      ind = which(names(G)==met_set3[n])\n      ranks3[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set3, num.misses = log2(length(G)))\n    }\n    names(ranks3) = met_set3\n    ranks4 = list()\n    for (n in 1:length(met_set4)) {\n      ind = which(names(G)==met_set4[n])\n      ranks4[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set4, num.misses = log2(length(G)))\n    }\n    names(ranks4) = met_set4\n    ranks5 = list()\n    for (n in 1:length(met_set5)) {\n      ind = which(names(G)==met_set5[n])\n      ranks5[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set5, num.misses = log2(length(G)))\n    }\n    names(ranks5) = met_set5\n    # Then use the node permutations to outputted to convert them into bitstrings.\n    set1_mma_bs = mle.getPtBSbyK(met_set1, ranks1)\n    set2_mma_bs = mle.getPtBSbyK(met_set2, ranks2)\n    set3_mma_bs = mle.getPtBSbyK(met_set3, ranks3)\n    set4_mma_bs = mle.getPtBSbyK(met_set4, ranks4)\n    set5_mma_bs = mle.getPtBSbyK(met_set5, ranks5)\n    # Then use the bitstrings to convert into encoding length.\n    set1_res = mle.getEncodingLength(set1_mma_bs, NULL, \"set1\", G)[length(met_set1),]\n    set2_res = mle.getEncodingLength(set2_mma_bs, NULL, \"set2\", G)[length(met_set2),]\n    set3_res = mle.getEncodingLength(set3_mma_bs, NULL, \"set3\", G)[length(met_set3),]\n    set4_res = mle.getEncodingLength(set4_mma_bs, NULL, \"set4\", G)[length(met_set4),]\n    set5_res = mle.getEncodingLength(set5_mma_bs, NULL, \"set5\", G)[length(met_set5),]\n    print(set1_res) # look at IS.alt column.\n    print(set2_res) # look at IS.alt column.\n    print(set3_res) # look at IS.alt column.\n    print(set4_res) # look at IS.alt column.\n    print(set5_res) # look at IS.alt column.\n    res[r_row, \"subset_size\"] = subset_size\n    res[r_row, \"graph_name\"] = \"mma6\"\n    res[r_row, \"IA_top_cit\"] = set1_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_mma\"] = set2_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_pku\"] = set3_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_ref\"] = set4_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_rand\"] = set5_res[,\"IS.alt\"]\n    r_row = r_row + 1\n    \n    # ig_mma7: Re-set global parameters for mma network.\n    G = vector(mode=\"list\", length=length(V(ig_mma7_naive)$name))\n    names(G) = V(ig_mma7_naive)$name\n    adj_mat = as.matrix(get.adjacency(ig_mma7_naive, attr=\"weight\"))\n    # Use single node encoding to get node ranks\n    ranks1 = list()\n    for (n in 1:length(met_set1)) {\n      ind = which(names(G)==met_set1[n])\n      ranks1[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set1, num.misses = log2(length(G)))\n    }\n    names(ranks1) = met_set1\n    ranks2 = list()\n    for (n in 1:length(met_set2)) {\n      ind = which(names(G)==met_set2[n])\n      ranks2[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set2, num.misses = log2(length(G)))\n    }\n    names(ranks2) = met_set2\n    ranks3 = list()\n    for (n in 1:length(met_set3)) {\n      ind = which(names(G)==met_set3[n])\n      ranks3[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set3, num.misses = log2(length(G)))\n    }\n    names(ranks3) = met_set3\n    ranks4 = list()\n    for (n in 1:length(met_set4)) {\n      ind = which(names(G)==met_set4[n])\n      ranks4[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set4, num.misses = log2(length(G)))\n    }\n    names(ranks4) = met_set4\n    ranks5 = list()\n    for (n in 1:length(met_set5)) {\n      ind = which(names(G)==met_set5[n])\n      ranks5[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set5, num.misses = log2(length(G)))\n    }\n    names(ranks5) = met_set5\n    # Then use the node permutations to outputted to convert them into bitstrings.\n    set1_mma_bs = mle.getPtBSbyK(met_set1, ranks1)\n    set2_mma_bs = mle.getPtBSbyK(met_set2, ranks2)\n    set3_mma_bs = mle.getPtBSbyK(met_set3, ranks3)\n    set4_mma_bs = mle.getPtBSbyK(met_set4, ranks4)\n    set5_mma_bs = mle.getPtBSbyK(met_set5, ranks5)\n    # Then use the bitstrings to convert into encoding length.\n    set1_res = mle.getEncodingLength(set1_mma_bs, NULL, \"set1\", G)[length(met_set1),]\n    set2_res = mle.getEncodingLength(set2_mma_bs, NULL, \"set2\", G)[length(met_set2),]\n    set3_res = mle.getEncodingLength(set3_mma_bs, NULL, \"set3\", G)[length(met_set3),]\n    set4_res = mle.getEncodingLength(set4_mma_bs, NULL, \"set4\", G)[length(met_set4),]\n    set5_res = mle.getEncodingLength(set5_mma_bs, NULL, \"set5\", G)[length(met_set5),]\n    print(set1_res) # look at IS.alt column.\n    print(set2_res) # look at IS.alt column.\n    print(set3_res) # look at IS.alt column.\n    print(set4_res) # look at IS.alt column.\n    print(set5_res) # look at IS.alt column.\n    res[r_row, \"subset_size\"] = subset_size\n    res[r_row, \"graph_name\"] = \"mma7\"\n    res[r_row, \"IA_top_cit\"] = set1_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_mma\"] = set2_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_pku\"] = set3_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_ref\"] = set4_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_rand\"] = set5_res[,\"IS.alt\"]\n    r_row = r_row + 1\n    \n    # ig_mma8: Re-set global parameters for mma network.\n    G = vector(mode=\"list\", length=length(V(ig_mma8_naive)$name))\n    names(G) = V(ig_mma8_naive)$name\n    adj_mat = as.matrix(get.adjacency(ig_mma8_naive, attr=\"weight\"))\n    # Use single node encoding to get node ranks\n    ranks1 = list()\n    for (n in 1:length(met_set1)) {\n      ind = which(names(G)==met_set1[n])\n      ranks1[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set1, num.misses = log2(length(G)))\n    }\n    names(ranks1) = met_set1\n    ranks2 = list()\n    for (n in 1:length(met_set2)) {\n      ind = which(names(G)==met_set2[n])\n      ranks2[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set2, num.misses = log2(length(G)))\n    }\n    names(ranks2) = met_set2\n    ranks3 = list()\n    for (n in 1:length(met_set3)) {\n      ind = which(names(G)==met_set3[n])\n      ranks3[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set3, num.misses = log2(length(G)))\n    }\n    names(ranks3) = met_set3\n    ranks4 = list()\n    for (n in 1:length(met_set4)) {\n      ind = which(names(G)==met_set4[n])\n      ranks4[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set4, num.misses = log2(length(G)))\n    }\n    names(ranks4) = met_set4\n    ranks5 = list()\n    for (n in 1:length(met_set5)) {\n      ind = which(names(G)==met_set5[n])\n      ranks5[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set5, num.misses = log2(length(G)))\n    }\n    names(ranks5) = met_set5\n    # Then use the node permutations to outputted to convert them into bitstrings.\n    set1_mma_bs = mle.getPtBSbyK(met_set1, ranks1)\n    set2_mma_bs = mle.getPtBSbyK(met_set2, ranks2)\n    set3_mma_bs = mle.getPtBSbyK(met_set3, ranks3)\n    set4_mma_bs = mle.getPtBSbyK(met_set4, ranks4)\n    set5_mma_bs = mle.getPtBSbyK(met_set5, ranks5)\n    # Then use the bitstrings to convert into encoding length.\n    set1_res = mle.getEncodingLength(set1_mma_bs, NULL, \"set1\", G)[length(met_set1),]\n    set2_res = mle.getEncodingLength(set2_mma_bs, NULL, \"set2\", G)[length(met_set2),]\n    set3_res = mle.getEncodingLength(set3_mma_bs, NULL, \"set3\", G)[length(met_set3),]\n    set4_res = mle.getEncodingLength(set4_mma_bs, NULL, \"set4\", G)[length(met_set4),]\n    set5_res = mle.getEncodingLength(set5_mma_bs, NULL, \"set5\", G)[length(met_set5),]\n    print(set1_res) # look at IS.alt column.\n    print(set2_res) # look at IS.alt column.\n    print(set3_res) # look at IS.alt column.\n    print(set4_res) # look at IS.alt column.\n    print(set5_res) # look at IS.alt column.\n    res[r_row, \"subset_size\"] = subset_size\n    res[r_row, \"graph_name\"] = \"mma8\"\n    res[r_row, \"IA_top_cit\"] = set1_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_mma\"] = set2_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_pku\"] = set3_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_ref\"] = set4_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_rand\"] = set5_res[,\"IS.alt\"]\n    r_row = r_row + 1\n    \n    # ig_mma9: Re-set global parameters for mma network.\n    G = vector(mode=\"list\", length=length(V(ig_mma9_naive)$name))\n    names(G) = V(ig_mma9_naive)$name\n    adj_mat = as.matrix(get.adjacency(ig_mma9_naive, attr=\"weight\"))\n    # Use single node encoding to get node ranks\n    ranks1 = list()\n    for (n in 1:length(met_set1)) {\n      ind = which(names(G)==met_set1[n])\n      ranks1[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set1, num.misses = log2(length(G)))\n    }\n    names(ranks1) = met_set1\n    ranks2 = list()\n    for (n in 1:length(met_set2)) {\n      ind = which(names(G)==met_set2[n])\n      ranks2[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set2, num.misses = log2(length(G)))\n    }\n    names(ranks2) = met_set2\n    ranks3 = list()\n    for (n in 1:length(met_set3)) {\n      ind = which(names(G)==met_set3[n])\n      ranks3[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set3, num.misses = log2(length(G)))\n    }\n    names(ranks3) = met_set3\n    ranks4 = list()\n    for (n in 1:length(met_set4)) {\n      ind = which(names(G)==met_set4[n])\n      ranks4[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set4, num.misses = log2(length(G)))\n    }\n    names(ranks4) = met_set4\n    ranks5 = list()\n    for (n in 1:length(met_set5)) {\n      ind = which(names(G)==met_set5[n])\n      ranks5[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set5, num.misses = log2(length(G)))\n    }\n    names(ranks5) = met_set5\n    # Then use the node permutations to outputted to convert them into bitstrings.\n    set1_mma_bs = mle.getPtBSbyK(met_set1, ranks1)\n    set2_mma_bs = mle.getPtBSbyK(met_set2, ranks2)\n    set3_mma_bs = mle.getPtBSbyK(met_set3, ranks3)\n    set4_mma_bs = mle.getPtBSbyK(met_set4, ranks4)\n    set5_mma_bs = mle.getPtBSbyK(met_set5, ranks5)\n    # Then use the bitstrings to convert into encoding length.\n    set1_res = mle.getEncodingLength(set1_mma_bs, NULL, \"set1\", G)[length(met_set1),]\n    set2_res = mle.getEncodingLength(set2_mma_bs, NULL, \"set2\", G)[length(met_set2),]\n    set3_res = mle.getEncodingLength(set3_mma_bs, NULL, \"set3\", G)[length(met_set3),]\n    set4_res = mle.getEncodingLength(set4_mma_bs, NULL, \"set4\", G)[length(met_set4),]\n    set5_res = mle.getEncodingLength(set5_mma_bs, NULL, \"set5\", G)[length(met_set5),]\n    print(set1_res) # look at IS.alt column.\n    print(set2_res) # look at IS.alt column.\n    print(set3_res) # look at IS.alt column.\n    print(set4_res) # look at IS.alt column.\n    print(set5_res) # look at IS.alt column.\n    res[r_row, \"subset_size\"] = subset_size\n    res[r_row, \"graph_name\"] = \"mma9\"\n    res[r_row, \"IA_top_cit\"] = set1_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_mma\"] = set2_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_pku\"] = set3_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_ref\"] = set4_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_rand\"] = set5_res[,\"IS.alt\"]\n    r_row = r_row + 1\n  }\n  \n  if (dopku) {\n    # ig_pku: Re-set global parameters for pku network.\n    G = vector(mode=\"list\", length=length(V(ig_pku_naive)$name))\n    names(G) = V(ig_pku_naive)$name\n    adj_mat = as.matrix(get.adjacency(ig_pku_naive, attr=\"weight\"))\n    # Use single node encoding to get node ranks\n    ranks1 = list()\n    for (n in 1:length(met_set1)) {\n      ind = which(names(G)==met_set1[n])\n      ranks1[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set1, num.misses = log2(length(G)))\n    }\n    names(ranks1) = met_set1\n    ranks2 = list()\n    for (n in 1:length(met_set2)) {\n      ind = which(names(G)==met_set2[n])\n      ranks2[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set2, num.misses = log2(length(G)))\n    }\n    names(ranks2) = met_set2\n    ranks3 = list()\n    for (n in 1:length(met_set3)) {\n      ind = which(names(G)==met_set3[n])\n      ranks3[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set3, num.misses = log2(length(G)))\n    }\n    names(ranks3) = met_set3\n    ranks4 = list()\n    for (n in 1:length(met_set4)) {\n      ind = which(names(G)==met_set4[n])\n      ranks4[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set4, num.misses = log2(length(G)))\n    }\n    names(ranks4) = met_set4\n    ranks5 = list()\n    for (n in 1:length(met_set5)) {\n      ind = which(names(G)==met_set5[n])\n      ranks5[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set5, num.misses = log2(length(G)))\n    }\n    names(ranks5) = met_set5\n    # Then use the node permutations to outputted to convert them into bitstrings.\n    set1_pku_bs = mle.getPtBSbyK(met_set1, ranks1)\n    set2_pku_bs = mle.getPtBSbyK(met_set2, ranks2)\n    set3_pku_bs = mle.getPtBSbyK(met_set3, ranks3)\n    set4_pku_bs = mle.getPtBSbyK(met_set4, ranks4)\n    set5_pku_bs = mle.getPtBSbyK(met_set5, ranks5)\n    # Then use the bitstrings to convert into encoding length.\n    set1_res = mle.getEncodingLength(set1_pku_bs, NULL, \"set1\", G)[length(met_set1),]\n    set2_res = mle.getEncodingLength(set2_pku_bs, NULL, \"set2\", G)[length(met_set2),]\n    set3_res = mle.getEncodingLength(set3_pku_bs, NULL, \"set3\", G)[length(met_set3),]\n    set4_res = mle.getEncodingLength(set4_pku_bs, NULL, \"set4\", G)[length(met_set4),]\n    set5_res = mle.getEncodingLength(set5_pku_bs, NULL, \"set5\", G)[length(met_set5),]\n    print(set1_res) # look at IS.alt column.\n    print(set2_res) # look at IS.alt column.\n    print(set3_res) # look at IS.alt column.\n    print(set4_res) # look at IS.alt column.\n    print(set5_res) # look at IS.alt column.\n    res[r_row, \"subset_size\"] = subset_size\n    res[r_row, \"graph_name\"] = \"pku\"\n    res[r_row, \"IA_top_cit\"] = set1_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_mma\"] = set2_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_pku\"] = set3_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_ref\"] = set4_res[,\"IS.alt\"]\n    res[r_row, \"IA_top_rand\"] = set5_res[,\"IS.alt\"]\n    r_row = r_row + 1\n    \n    # ig_pku1: Re-set global parameters for pku network.\n    G = vector(mode=\"list\", length=length(V(ig_pku1_naive)$name))\n    names(G) = V(ig_pku1_naive)$name\n    adj_mat = as.matrix(get.adjacency(ig_pku1_naive, attr=\"weight\"))\n    # Use single node encoding to get node ranks\n    ranks1 = list()\n    for (n in 1:length(met_set1)) {\n      ind = which(names(G)==met_set1[n])\n      ranks1[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set1, num.misses = log2(length(G)))\n    }\n    names(ranks1) = met_set1\n    ranks2 = list()\n    for (n in 1:length(met_set2)) {\n      ind = which(names(G)==met_set2[n])\n      ranks2[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set2, num.misses = log2(length(G)))\n    }\n    names(ranks2) = met_set2\n    ranks3 = list()\n    for (n in 1:length(met_set3)) {\n      ind = which(names(G)==met_set3[n])\n      ranks3[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set3, num.misses = log2(length(G)))\n    }\n    names(ranks3) = met_set3\n    ranks4 = list()\n    for (n in 1:length(met_set4)) {\n      ind = which(names(G)==met_set4[n])\n      ranks4[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set4, num.misses = log2(length(G)))\n    }\n    names(ranks4) = met_set4\n    ranks5 = list()\n    for (n in 1:length(met_set5)) {\n      ind = which(names(G)==met_set5[n])\n      ranks5[[n]] = singleNode.getNodeRanksN(n=ind, G=G, p1, thresholdDiff, adj_mat, S=met_set5, num.misses = log2(length(G)))\n    }\n    names(ranks5) = met_set5\n    # Then use the node permutations to outputted to convert them into bitstrings.\n    set1_pku_bs = mle.getPtBSbyK(met_set1, ranks1)\n    set2_pku_bs = mle.getPtBSbyK(met_set2, ranks2)\n    set3_pku_bs = mle.getPtBSbyK(met_set3, ranks3)\n    set4_pku_bs = mle.getPtBSbyK(met_set4, ranks4)\n    set5_pku_bs = mle.getPtBSbyK(met_set","command_name":"Probability based on network context main driver script","command":null,"os_name":null,"os_version":null}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#84CE84","section_duration":3800,"critical":null,"critical_id":null,"duration":2040},{"id":1068576,"guid":"EAD3E81856A849DE9F781948B248A58E","previous_id":1068575,"previous_guid":"C247A7A529294092991D521E6A1AF67A","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"B37D5D190E494960B5DEE57AA2DC09E5","order_id":1,"type_id":6,"title":"Section","source":{"title":"Figure 7: Node set probability is based on network context."}},{"id":1054724,"guid":"995D58067F3E4AA0BE78F82C27741E3E","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Plot the results.<\/div><\/div>"}},{"id":1054725,"guid":"FE713700EBB211EAA3434F176A4D61AA","order_id":2,"type_id":15,"title":"command","source":{"id":8163,"name":"require(ggplot2)\nbits_to_prob = function(bits) { return(2^-bits) }\nratio_cit_to_rand = log2(bits_to_prob(res$IA_top_cit) \/ bits_to_prob(res$IA_top_rand))\nratio_mma_to_rand = log2(bits_to_prob(res$IA_top_mma) \/ bits_to_prob(res$IA_top_rand))\nratio_pku_to_rand = log2(bits_to_prob(res$IA_top_pku) \/ bits_to_prob(res$IA_top_rand))\ndf = data.frame(subset_size = as.factor(rep(sprintf(\"K=%d\", res$subset_size), 3)),\n                graph = rep(res$graph_name, 3),\n                Log2.Ratio.to.Random = c(ratio_cit_to_rand, ratio_mma_to_rand, ratio_pku_to_rand),\n                Metabolite.Set = c(rep(\"TopCIT\", nrow(res)), rep(\"TopMMA\", nrow(res)), rep(\"TopPKU\", nrow(res))))\ndf$subset_size = factor(df$subset_size, levels=c(\"K=5\", \"K=10\", \"K=15\", \"K=20\"))\nlevels(df$subset_size)\n# CIT LOOCV plot\ndf_cit = df[grep(\"cit\", df$graph),]\nerr = df_cit[grep(\"cit[[:digit:]]\", df_cit$graph),]\nerror_bars = data.frame(k=numeric(), mn=numeric(), low = numeric(), high = numeric(), Metabolite.Set=character(), stringsAsFactors = FALSE)\nerror_bars[1, \"k\"] = 5\nerror_bars[1, \"mn\"] = mean(err[intersect(which(err$subset_size==\"K=5\"), which(err$Metabolite.Set==\"TopCIT\")), \"Log2.Ratio.to.Random\"])\nerror_bars[1, \"low\"] = min(err[intersect(which(err$subset_size==\"K=5\"), which(err$Metabolite.Set==\"TopCIT\")), \"Log2.Ratio.to.Random\"])\nerror_bars[1, \"high\"] = max(err[intersect(which(err$subset_size==\"K=5\"), which(err$Metabolite.Set==\"TopCIT\")), \"Log2.Ratio.to.Random\"])\nerror_bars[1, \"Metabolite.Set\"] = \"TopCIT\"\nerror_bars[2, \"k\"] = 5\nerror_bars[2, \"mn\"] = mean(err[intersect(which(err$subset_size==\"K=5\"), which(err$Metabolite.Set==\"TopMMA\")), \"Log2.Ratio.to.Random\"])\nerror_bars[2, \"low\"] = min(err[intersect(which(err$subset_size==\"K=5\"), which(err$Metabolite.Set==\"TopMMA\")), \"Log2.Ratio.to.Random\"])\nerror_bars[2, \"high\"] = max(err[intersect(which(err$subset_size==\"K=5\"), which(err$Metabolite.Set==\"TopMMA\")), \"Log2.Ratio.to.Random\"])\nerror_bars[2, \"Metabolite.Set\"] = \"TopMMA\"\nerror_bars[3, \"k\"] = 5\nerror_bars[3, \"mn\"] = mean(err[intersect(which(err$subset_size==\"K=5\"), which(err$Metabolite.Set==\"TopPKU\")), \"Log2.Ratio.to.Random\"])\nerror_bars[3, \"low\"] = min(err[intersect(which(err$subset_size==\"K=5\"), which(err$Metabolite.Set==\"TopPKU\")), \"Log2.Ratio.to.Random\"])\nerror_bars[3, \"high\"] = max(err[intersect(which(err$subset_size==\"K=5\"), which(err$Metabolite.Set==\"TopPKU\")), \"Log2.Ratio.to.Random\"])\nerror_bars[3, \"Metabolite.Set\"] = \"TopPKU\"\nerror_bars[4, \"k\"] = 10\nerror_bars[4, \"mn\"] = mean(err[intersect(which(err$subset_size==\"K=10\"), which(err$Metabolite.Set==\"TopCIT\")), \"Log2.Ratio.to.Random\"])\nerror_bars[4, \"low\"] = min(err[intersect(which(err$subset_size==\"K=10\"), which(err$Metabolite.Set==\"TopCIT\")), \"Log2.Ratio.to.Random\"])\nerror_bars[4, \"high\"] = max(err[intersect(which(err$subset_size==\"K=10\"), which(err$Metabolite.Set==\"TopCIT\")), \"Log2.Ratio.to.Random\"])\nerror_bars[4, \"Metabolite.Set\"] = \"TopCIT\"\nerror_bars[5, \"k\"] = 10\nerror_bars[5, \"mn\"] = mean(err[intersect(which(err$subset_size==\"K=10\"), which(err$Metabolite.Set==\"TopMMA\")), \"Log2.Ratio.to.Random\"])\nerror_bars[5, \"low\"] = min(err[intersect(which(err$subset_size==\"K=10\"), which(err$Metabolite.Set==\"TopMMA\")), \"Log2.Ratio.to.Random\"])\nerror_bars[5, \"high\"] = max(err[intersect(which(err$subset_size==\"K=10\"), which(err$Metabolite.Set==\"TopMMA\")), \"Log2.Ratio.to.Random\"])\nerror_bars[5, \"Metabolite.Set\"] = \"TopMMA\"\nerror_bars[6, \"k\"] = 10\nerror_bars[6, \"mn\"] = mean(err[intersect(which(err$subset_size==\"K=10\"), which(err$Metabolite.Set==\"TopPKU\")), \"Log2.Ratio.to.Random\"])\nerror_bars[6, \"low\"] = min(err[intersect(which(err$subset_size==\"K=10\"), which(err$Metabolite.Set==\"TopPKU\")), \"Log2.Ratio.to.Random\"])\nerror_bars[6, \"high\"] = max(err[intersect(which(err$subset_size==\"K=10\"), which(err$Metabolite.Set==\"TopPKU\")), \"Log2.Ratio.to.Random\"])\nerror_bars[6, \"Metabolite.Set\"] = \"TopPKU\"\nerror_bars[7, \"k\"] = 15\nerror_bars[7, \"mn\"] = mean(err[intersect(which(err$subset_size==\"K=15\"), which(err$Metabolite.Set==\"TopCIT\")), \"Log2.Ratio.to.Random\"])\nerror_bars[7, \"low\"] = min(err[intersect(which(err$subset_size==\"K=15\"), which(err$Metabolite.Set==\"TopCIT\")), \"Log2.Ratio.to.Random\"])\nerror_bars[7, \"high\"] = max(err[intersect(which(err$subset_size==\"K=15\"), which(err$Metabolite.Set==\"TopCIT\")), \"Log2.Ratio.to.Random\"])\nerror_bars[7, \"Metabolite.Set\"] = \"TopCIT\"\nerror_bars[8, \"k\"] = 15\nerror_bars[8, \"mn\"] = mean(err[intersect(which(err$subset_size==\"K=15\"), which(err$Metabolite.Set==\"TopMMA\")), \"Log2.Ratio.to.Random\"])\nerror_bars[8, \"low\"] = min(err[intersect(which(err$subset_size==\"K=15\"), which(err$Metabolite.Set==\"TopMMA\")), \"Log2.Ratio.to.Random\"])\nerror_bars[8, \"high\"] = max(err[intersect(which(err$subset_size==\"K=15\"), which(err$Metabolite.Set==\"TopMMA\")), \"Log2.Ratio.to.Random\"])\nerror_bars[8, \"Metabolite.Set\"] = \"TopMMA\"\nerror_bars[9, \"k\"] = 15\nerror_bars[9, \"mn\"] = mean(err[intersect(which(err$subset_size==\"K=15\"), which(err$Metabolite.Set==\"TopPKU\")), \"Log2.Ratio.to.Random\"])\nerror_bars[9, \"low\"] = min(err[intersect(which(err$subset_size==\"K=15\"), which(err$Metabolite.Set==\"TopPKU\")), \"Log2.Ratio.to.Random\"])\nerror_bars[9, \"high\"] = max(err[intersect(which(err$subset_size==\"K=15\"), which(err$Metabolite.Set==\"TopPKU\")), \"Log2.Ratio.to.Random\"])\nerror_bars[9, \"Metabolite.Set\"] = \"TopPKU\"\nerror_bars[10, \"k\"] = 20\nerror_bars[10, \"mn\"] = mean(err[intersect(which(err$subset_size==\"K=20\"), which(err$Metabolite.Set==\"TopCIT\")), \"Log2.Ratio.to.Random\"])\nerror_bars[10, \"low\"] = min(err[intersect(which(err$subset_size==\"K=20\"), which(err$Metabolite.Set==\"TopCIT\")), \"Log2.Ratio.to.Random\"])\nerror_bars[10, \"high\"] = max(err[intersect(which(err$subset_size==\"K=20\"), which(err$Metabolite.Set==\"TopCIT\")), \"Log2.Ratio.to.Random\"])\nerror_bars[10, \"Metabolite.Set\"] = \"TopCIT\"\nerror_bars[11, \"k\"] = 20\nerror_bars[11, \"mn\"] = mean(err[intersect(which(err$subset_size==\"K=20\"), which(err$Metabolite.Set==\"TopMMA\")), \"Log2.Ratio.to.Random\"])\nerror_bars[11, \"low\"] = min(err[intersect(which(err$subset_size==\"K=20\"), which(err$Metabolite.Set==\"TopMMA\")), \"Log2.Ratio.to.Random\"])\nerror_bars[11, \"high\"] = max(err[intersect(which(err$subset_size==\"K=20\"), which(err$Metabolite.Set==\"TopMMA\")), \"Log2.Ratio.to.Random\"])\nerror_bars[11, \"Metabolite.Set\"] = \"TopMMA\"\nerror_bars[12, \"k\"] = 20\nerror_bars[12, \"mn\"] = mean(err[intersect(which(err$subset_size==\"K=20\"), which(err$Metabolite.Set==\"TopPKU\")), \"Log2.Ratio.to.Random\"])\nerror_bars[12, \"low\"] = min(err[intersect(which(err$subset_size==\"K=20\"), which(err$Metabolite.Set==\"TopPKU\")), \"Log2.Ratio.to.Random\"])\nerror_bars[12, \"high\"] = max(err[intersect(which(err$subset_size==\"K=20\"), which(err$Metabolite.Set==\"TopPKU\")), \"Log2.Ratio.to.Random\"])\nerror_bars[12, \"Metabolite.Set\"] = \"TopPKU\"\nsvg(\"probbasedon_cit_LOOCV.svg\", width=5, height = 2, pointsize=12)\nggplot(error_bars, aes(x=Metabolite.Set, y=mn, fill=Metabolite.Set)) + geom_bar(stat=\"identity\", position = \"dodge\") + \n  geom_errorbar(aes(ymin=error_bars$low, ymax=error_bars$high), width=0.1) + theme_bw() + \n  ggtitle(\"Probability Assigned to Metabolites Sets\\nUsing an Citrullinemia-Specific Disease Network\") + facet_wrap(~k, nrow=1)\ndev.off()\n\n# MMA LOOCV plot\ndf_mma = df[grep(\"mma\", df$graph),]\nerr = df_mma[grep(\"mma[[:digit:]]\", df_mma$graph),]\nerror_bars = data.frame(k=numeric(), mn=numeric(), low = numeric(), high = numeric(), Metabolite.Set=character(), stringsAsFactors = FALSE)\nerror_bars[1, \"k\"] = 5\nerror_bars[1, \"mn\"] = mean(err[intersect(which(err$subset_size==\"K=5\"), which(err$Metabolite.Set==\"TopCIT\")), \"Log2.Ratio.to.Random\"])\nerror_bars[1, \"low\"] = min(err[intersect(which(err$subset_size==\"K=5\"), which(err$Metabolite.Set==\"TopCIT\")), \"Log2.Ratio.to.Random\"])\nerror_bars[1, \"high\"] = max(err[intersect(which(err$subset_size==\"K=5\"), which(err$Metabolite.Set==\"TopCIT\")), \"Log2.Ratio.to.Random\"])\nerror_bars[1, \"Metabolite.Set\"] = \"TopCIT\"\nerror_bars[2, \"k\"] = 5\nerror_bars[2, \"mn\"] = mean(err[intersect(which(err$subset_size==\"K=5\"), which(err$Metabolite.Set==\"TopMMA\")), \"Log2.Ratio.to.Random\"])\nerror_bars[2, \"low\"] = min(err[intersect(which(err$subset_size==\"K=5\"), which(err$Metabolite.Set==\"TopMMA\")), \"Log2.Ratio.to.Random\"])\nerror_bars[2, \"high\"] = max(err[intersect(which(err$subset_size==\"K=5\"), which(err$Metabolite.Set==\"TopMMA\")), \"Log2.Ratio.to.Random\"])\nerror_bars[2, \"Metabolite.Set\"] = \"TopMMA\"\nerror_bars[3, \"k\"] = 5\nerror_bars[3, \"mn\"] = mean(err[intersect(which(err$subset_size==\"K=5\"), which(err$Metabolite.Set==\"TopPKU\")), \"Log2.Ratio.to.Random\"])\nerror_bars[3, \"low\"] = min(err[intersect(which(err$subset_size==\"K=5\"), which(err$Metabolite.Set==\"TopPKU\")), \"Log2.Ratio.to.Random\"])\nerror_bars[3, \"high\"] = max(err[intersect(which(err$subset_size==\"K=5\"), which(err$Metabolite.Set==\"TopPKU\")), \"Log2.Ratio.to.Random\"])\nerror_bars[3, \"Metabolite.Set\"] = \"TopPKU\"\nerror_bars[4, \"k\"] = 10\nerror_bars[4, \"mn\"] = mean(err[intersect(which(err$subset_size==\"K=10\"), which(err$Metabolite.Set==\"TopCIT\")), \"Log2.Ratio.to.Random\"])\nerror_bars[4, \"low\"] = min(err[intersect(which(err$subset_size==\"K=10\"), which(err$Metabolite.Set==\"TopCIT\")), \"Log2.Ratio.to.Random\"])\nerror_bars[4, \"high\"] = max(err[intersect(which(err$subset_size==\"K=10\"), which(err$Metabolite.Set==\"TopCIT\")), \"Log2.Ratio.to.Random\"])\nerror_bars[4, \"Metabolite.Set\"] = \"TopCIT\"\nerror_bars[5, \"k\"] = 10\nerror_bars[5, \"mn\"] = mean(err[intersect(which(err$subset_size==\"K=10\"), which(err$Metabolite.Set==\"TopMMA\")), \"Log2.Ratio.to.Random\"])\nerror_bars[5, \"low\"] = min(err[intersect(which(err$subset_size==\"K=10\"), which(err$Metabolite.Set==\"TopMMA\")), \"Log2.Ratio.to.Random\"])\nerror_bars[5, \"high\"] = max(err[intersect(which(err$subset_size==\"K=10\"), which(err$Metabolite.Set==\"TopMMA\")), \"Log2.Ratio.to.Random\"])\nerror_bars[5, \"Metabolite.Set\"] = \"TopMMA\"\nerror_bars[6, \"k\"] = 10\nerror_bars[6, \"mn\"] = mean(err[intersect(which(err$subset_size==\"K=10\"), which(err$Metabolite.Set==\"TopPKU\")), \"Log2.Ratio.to.Random\"])\nerror_bars[6, \"low\"] = min(err[intersect(which(err$subset_size==\"K=10\"), which(err$Metabolite.Set==\"TopPKU\")), \"Log2.Ratio.to.Random\"])\nerror_bars[6, \"high\"] = max(err[intersect(which(err$subset_size==\"K=10\"), which(err$Metabolite.Set==\"TopPKU\")), \"Log2.Ratio.to.Random\"])\nerror_bars[6, \"Metabolite.Set\"] = \"TopPKU\"\nerror_bars[7, \"k\"] = 15\nerror_bars[7, \"mn\"] = mean(err[intersect(which(err$subset_size==\"K=15\"), which(err$Metabolite.Set==\"TopCIT\")), \"Log2.Ratio.to.Random\"])\nerror_bars[7, \"low\"] = min(err[intersect(which(err$subset_size==\"K=15\"), which(err$Metabolite.Set==\"TopCIT\")), \"Log2.Ratio.to.Random\"])\nerror_bars[7, \"high\"] = max(err[intersect(which(err$subset_size==\"K=15\"), which(err$Metabolite.Set==\"TopCIT\")), \"Log2.Ratio.to.Random\"])\nerror_bars[7, \"Metabolite.Set\"] = \"TopCIT\"\nerror_bars[8, \"k\"] = 15\nerror_bars[8, \"mn\"] = mean(err[intersect(which(err$subset_size==\"K=15\"), which(err$Metabolite.Set==\"TopMMA\")), \"Log2.Ratio.to.Random\"])\nerror_bars[8, \"low\"] = min(err[intersect(which(err$subset_size==\"K=15\"), which(err$Metabolite.Set==\"TopMMA\")), \"Log2.Ratio.to.Random\"])\nerror_bars[8, \"high\"] = max(err[intersect(which(err$subset_size==\"K=15\"), which(err$Metabolite.Set==\"TopMMA\")), \"Log2.Ratio.to.Random\"])\nerror_bars[8, \"Metabolite.Set\"] = \"TopMMA\"\nerror_bars[9, \"k\"] = 15\nerror_bars[9, \"mn\"] = mean(err[intersect(which(err$subset_size==\"K=15\"), which(err$Metabolite.Set==\"TopPKU\")), \"Log2.Ratio.to.Random\"])\nerror_bars[9, \"low\"] = min(err[intersect(which(err$subset_size==\"K=15\"), which(err$Metabolite.Set==\"TopPKU\")), \"Log2.Ratio.to.Random\"])\nerror_bars[9, \"high\"] = max(err[intersect(which(err$subset_size==\"K=15\"), which(err$Metabolite.Set==\"TopPKU\")), \"Log2.Ratio.to.Random\"])\nerror_bars[9, \"Metabolite.Set\"] = \"TopPKU\"\nerror_bars[10, \"k\"] = 20\nerror_bars[10, \"mn\"] = mean(err[intersect(which(err$subset_size==\"K=20\"), which(err$Metabolite.Set==\"TopCIT\")), \"Log2.Ratio.to.Random\"])\nerror_bars[10, \"low\"] = min(err[intersect(which(err$subset_size==\"K=20\"), which(err$Metabolite.Set==\"TopCIT\")), \"Log2.Ratio.to.Random\"])\nerror_bars[10, \"high\"] = max(err[intersect(which(err$subset_size==\"K=20\"), which(err$Metabolite.Set==\"TopCIT\")), \"Log2.Ratio.to.Random\"])\nerror_bars[10, \"Metabolite.Set\"] = \"TopCIT\"\nerror_bars[11, \"k\"] = 20\nerror_bars[11, \"mn\"] = mean(err[intersect(which(err$subset_size==\"K=20\"), which(err$Metabolite.Set==\"TopMMA\")), \"Log2.Ratio.to.Random\"])\nerror_bars[11, \"low\"] = min(err[intersect(which(err$subset_size==\"K=20\"), which(err$Metabolite.Set==\"TopMMA\")), \"Log2.Ratio.to.Random\"])\nerror_bars[11, \"high\"] = max(err[intersect(which(err$subset_size==\"K=20\"), which(err$Metabolite.Set==\"TopMMA\")), \"Log2.Ratio.to.Random\"])\nerror_bars[11, \"Metabolite.Set\"] = \"TopMMA\"\nerror_bars[12, \"k\"] = 20\nerror_bars[12, \"mn\"] = mean(err[intersect(which(err$subset_size==\"K=20\"), which(err$Metabolite.Set==\"TopPKU\")), \"Log2.Ratio.to.Random\"])\nerror_bars[12, \"low\"] = min(err[intersect(which(err$subset_size==\"K=20\"), which(err$Metabolite.Set==\"TopPKU\")), \"Log2.Ratio.to.Random\"])\nerror_bars[12, \"high\"] = max(err[intersect(which(err$subset_size==\"K=20\"), which(err$Metabolite.Set==\"TopPKU\")), \"Log2.Ratio.to.Random\"])\nerror_bars[12, \"Metabolite.Set\"] = \"TopPKU\"\nsvg(\"probbasedon_mma_LOOCV.svg\", width=5, height = 2, pointsize=12)\nggplot(error_bars, aes(x=Metabolite.Set, y=mn, fill=Metabolite.Set)) + geom_bar(stat=\"identity\", position = \"dodge\") + \n  geom_errorbar(aes(ymin=error_bars$low, ymax=error_bars$high), width=0.1) + theme_bw() + \n  ggtitle(\"Probability Assigned to Metabolites Sets\\nUsing an Guanidinoacetate Methyltransferase Deficiency-Specific Disease Network\") + facet_wrap(~k, nrow=1)\ndev.off()\n\n# PKU LOOCV plot\ndf_pku = df[grep(\"pku\", df$graph),]\nerr = df_pku[grep(\"pku[[:digit:]]\", df_pku$graph),]\nerror_bars = data.frame(k=numeric(), mn=numeric(), low = numeric(), high = numeric(), Metabolite.Set=character(), stringsAsFactors = FALSE)\nerror_bars[1, \"k\"] = 5\nerror_bars[1, \"mn\"] = mean(err[intersect(which(err$subset_size==\"K=5\"), which(err$Metabolite.Set==\"TopCIT\")), \"Log2.Ratio.to.Random\"])\nerror_bars[1, \"low\"] = min(err[intersect(which(err$subset_size==\"K=5\"), which(err$Metabolite.Set==\"TopCIT\")), \"Log2.Ratio.to.Random\"])\nerror_bars[1, \"high\"] = max(err[intersect(which(err$subset_size==\"K=5\"), which(err$Metabolite.Set==\"TopCIT\")), \"Log2.Ratio.to.Random\"])\nerror_bars[1, \"Metabolite.Set\"] = \"TopCIT\"\nerror_bars[2, \"k\"] = 5\nerror_bars[2, \"mn\"] = mean(err[intersect(which(err$subset_size==\"K=5\"), which(err$Metabolite.Set==\"TopMMA\")), \"Log2.Ratio.to.Random\"])\nerror_bars[2, \"low\"] = min(err[intersect(which(err$subset_size==\"K=5\"), which(err$Metabolite.Set==\"TopMMA\")), \"Log2.Ratio.to.Random\"])\nerror_bars[2, \"high\"] = max(err[intersect(which(err$subset_size==\"K=5\"), which(err$Metabolite.Set==\"TopMMA\")), \"Log2.Ratio.to.Random\"])\nerror_bars[2, \"Metabolite.Set\"] = \"TopMMA\"\nerror_bars[3, \"k\"] = 5\nerror_bars[3, \"mn\"] = mean(err[intersect(which(err$subset_size==\"K=5\"), which(err$Metabolite.Set==\"TopPKU\")), \"Log2.Ratio.to.Random\"])\nerror_bars[3, \"low\"] = min(err[intersect(which(err$subset_size==\"K=5\"), which(err$Metabolite.Set==\"TopPKU\")), \"Log2.Ratio.to.Random\"])\nerror_bars[3, \"high\"] = max(err[intersect(which(err$subset_size==\"K=5\"), which(err$Metabolite.Set==\"TopPKU\")), \"Log2.Ratio.to.Random\"])\nerror_bars[3, \"Metabolite.Set\"] = \"TopPKU\"\nerror_bars[4, \"k\"] = 10\nerror_bars[4, \"mn\"] = mean(err[intersect(which(err$subset_size==\"K=10\"), which(err$Metabolite.Set==\"TopCIT\")), \"Log2.Ratio.to.Random\"])\nerror_bars[4, \"low\"] = min(err[intersect(which(err$subset_size==\"K=10\"), which(err$Metabolite.Set==\"TopCIT\")), \"Log2.Ratio.to.Random\"])\nerror_bars[4, \"high\"] = max(err[intersect(which(err$subset_size==\"K=10\"), which(err$Metabolite.Set==\"TopCIT\")), \"Log2.Ratio.to.Random\"])\nerror_bars[4, \"Metabolite.Set\"] = \"TopCIT\"\nerror_bars[5, \"k\"] = 10\nerror_bars[5, \"mn\"] = mean(err[intersect(which(err$subset_size==\"K=10\"), which(err$Metabolite.Set==\"TopMMA\")), \"Log2.Ratio.to.Random\"])\nerror_bars[5, \"low\"] = min(err[intersect(which(err$subset_size==\"K=10\"), which(err$Metabolite.Set==\"TopMMA\")), \"Log2.Ratio.to.Random\"])\nerror_bars[5, \"high\"] = max(err[intersect(which(err$subset_size==\"K=10\"), which(err$Metabolite.Set==\"TopMMA\")), \"Log2.Ratio.to.Random\"])\nerror_bars[5, \"Metabolite.Set\"] = \"TopMMA\"\nerror_bars[6, \"k\"] = 10\nerror_bars[6, \"mn\"] = mean(err[intersect(which(err$subset_size==\"K=10\"), which(err$Metabolite.Set==\"TopPKU\")), \"Log2.Ratio.to.Random\"])\nerror_bars[6, \"low\"] = min(err[intersect(which(err$subset_size==\"K=10\"), which(err$Metabolite.Set==\"TopPKU\")), \"Log2.Ratio.to.Random\"])\nerror_bars[6, \"high\"] = max(err[intersect(which(err$subset_size==\"K=10\"), which(err$Metabolite.Set==\"TopPKU\")), \"Log2.Ratio.to.Random\"])\nerror_bars[6, \"Metabolite.Set\"] = \"TopPKU\"\nerror_bars[7, \"k\"] = 15\nerror_bars[7, \"mn\"] = mean(err[intersect(which(err$subset_size==\"K=15\"), which(err$Metabolite.Set==\"TopCIT\")), \"Log2.Ratio.to.Random\"])\nerror_bars[7, \"low\"] = min(err[intersect(which(err$subset_size==\"K=15\"), which(err$Metabolite.Set==\"TopCIT\")), \"Log2.Ratio.to.Random\"])\nerror_bars[7, \"high\"] = max(err[intersect(which(err$subset_size==\"K=15\"), which(err$Metabolite.Set==\"TopCIT\")), \"Log2.Ratio.to.Random\"])\nerror_bars[7, \"Metabolite.Set\"] = \"TopCIT\"\nerror_bars[8, \"k\"] = 15\nerror_bars[8, \"mn\"] = mean(err[intersect(which(err$subset_size==\"K=15\"), which(err$Metabolite.Set==\"TopMMA\")), \"Log2.Ratio.to.Random\"])\nerror_bars[8, \"low\"] = min(err[intersect(which(err$subset_size==\"K=15\"), which(err$Metabolite.Set==\"TopMMA\")), \"Log2.Ratio.to.Random\"])\nerror_bars[8, \"high\"] = max(err[intersect(which(err$subset_size==\"K=15\"), which(err$Metabolite.Set==\"TopMMA\")), \"Log2.Ratio.to.Random\"])\nerror_bars[8, \"Metabolite.Set\"] = \"TopMMA\"\nerror_bars[9, \"k\"] = 15\nerror_bars[9, \"mn\"] = mean(err[intersect(which(err$subset_size==\"K=15\"), which(err$Metabolite.Set==\"TopPKU\")), \"Log2.Ratio.to.Random\"])\nerror_bars[9, \"low\"] = min(err[intersect(which(err$subset_size==\"K=15\"), which(err$Metabolite.Set==\"TopPKU\")), \"Log2.Ratio.to.Random\"])\nerror_bars[9, \"high\"] = max(err[intersect(which(err$subset_size==\"K=15\"), which(err$Metabolite.Set==\"TopPKU\")), \"Log2.Ratio.to.Random\"])\nerror_bars[9, \"Metabolite.Set\"] = \"TopPKU\"\nerror_bars[10, \"k\"] = 20\nerror_bars[10, \"mn\"] = mean(err[intersect(which(err$subset_size==\"K=20\"), which(err$Metabolite.Set==\"TopCIT\")), \"Log2.Ratio.to.Random\"])\nerror_bars[10, \"low\"] = min(err[intersect(which(err$subset_size==\"K=20\"), which(err$Metabolite.Set==\"TopCIT\")), \"Log2.Ratio.to.Random\"])\nerror_bars[10, \"high\"] = max(err[intersect(which(err$subset_size==\"K=20\"), which(err$Metabolite.Set==\"TopCIT\")), \"Log2.Ratio.to.Random\"])\nerror_bars[10, \"Metabolite.Set\"] = \"TopCIT\"\nerror_bars[11, \"k\"] = 20\nerror_bars[11, \"mn\"] = mean(err[intersect(which(err$subset_size==\"K=20\"), which(err$Metabolite.Set==\"TopMMA\")), \"Log2.Ratio.to.Random\"])\nerror_bars[11, \"low\"] = min(err[intersect(which(err$subset_size==\"K=20\"), which(err$Metabolite.Set==\"TopMMA\")), \"Log2.Ratio.to.Random\"])\nerror_bars[11, \"high\"] = max(err[intersect(which(err$subset_size==\"K=20\"), which(err$Metabolite.Set==\"TopMMA\")), \"Log2.Ratio.to.Random\"])\nerror_bars[11, \"Metabolite.Set\"] = \"TopMMA\"\nerror_bars[12, \"k\"] = 20\nerror_bars[12, \"mn\"] = mean(err[intersect(which(err$subset_size==\"K=20\"), which(err$Metabolite.Set==\"TopPKU\")), \"Log2.Ratio.to.Random\"])\nerror_bars[12, \"low\"] = min(err[intersect(which(err$subset_size==\"K=20\"), which(err$Metabolite.Set==\"TopPKU\")), \"Log2.Ratio.to.Random\"])\nerror_bars[12, \"high\"] = max(err[intersect(which(err$subset_size==\"K=20\"), which(err$Metabolite.Set==\"TopPKU\")), \"Log2.Ratio.to.Random\"])\nerror_bars[12, \"Metabolite.Set\"] = \"TopPKU\"\nsvg(\"probbasedon_pku_LOOCV.svg\", width=5, height = 2, pointsize=12)\nggplot(error_bars, aes(x=Metabolite.Set, y=mn, fill=Metabolite.Set)) + geom_bar(stat=\"identity\", position = \"dodge\") + \n  geom_errorbar(aes(ymin=error_bars$low, ymax=error_bars$high), width=0.1) + theme_bw() + \n  ggtitle(\"Probability Assigned to Metabolites Sets\\nUsing an Phenylketonuria-Specific Disease Network\") + facet_wrap(~k, nrow=1)\ndev.off()","command_name":"Plot the results","command":null,"os_name":null,"os_version":null}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#84CE84","section_duration":3800,"critical":null,"critical_id":null,"duration":3}],"document":"","materials":[{"id":580452,"mol_weight":0,"name":"NONE","linfor":"","url":"http:\/\/N\/A","sku":"N\/A","cas_number":"","rrid":"N\/A","public":0,"vendor":{"name":"Contributed by users","affiliation":null,"affiliations":[],"username":null,"note":null,"link":"https:\/\/www.protocols.io","image":{"source":"https:\/\/www.protocols.io\/img\/vendors\/1.png","placeholder":"https:\/\/www.protocols.io\/img\/vendors\/1.png"},"badges":[],"verified":0,"is_verified_user":false,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false,"id":1},"can_edit":0,"stats":{"total_protocols":0}}],"description":"<div class = \"text-blocks\"><div class = \"text-block\">We consider the following algorithmic problem that arises in transcriptomics, metabolomics and other fields: given a weighted graph and a subset of its nodes, find subsets of perturbed variables that show significant connectedness within the graph. While solutions to this problem may be discovered by devising a variety of scoring functions, statistically rigorous discovery is obstructed by the high computational cost of permutation testing, required to establish p-values. In this work, we develop CTD, a novel information-theoretic method that evaluates the connectedness of perturbation signatures in a network context and assigns an upper bounds on their p-values without use of permutation testing. We apply CTD to interpret multi-metabolite perturbations due to inborn errors of metabolism and multi-gene perturbations associated with breast cancer in the context of disease-specific Gaussian Markov Random Field networks learned directly from respective molecular profiling data. <\/div><\/div>","changed_on":1607660549}