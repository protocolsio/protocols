{"id":41103,"title":"Structure-from-motion multi-view photogrammetry applied to linear-scan sediment cores images","title_html":"<p>Structure-from-motion multi-view photogrammetry applied to linear-scan sediment cores images<\/p>","image":{"source":"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj7bbbhyf.jpg","placeholder":"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj7bbbhyf.jpg"},"doi":null,"doi_status":0,"uri":"structure-from-motion-multi-view-photogrammetry-ap-bkdpks5n","type_id":1,"template_id":1,"published_on":1600007628,"parent_protocols":[],"parent_collections":[],"cited_protocols":[],"version_id":0,"version_data":{"id":"0","code":"bkdpks5n","parent_id":0,"parent_uri":null,"is_same_owner":false,"has_pending_merge_request":false,"has_approved_merge_request":false},"created_on":1598539898,"categories":null,"creator":{"name":"Kevin Jacq","affiliation":"Universit\u00e9 Rouen Normandie","affiliations":[{"affiliation":"Universit\u00e9 Rouen Normandie","url":"http:\/\/www.univ-rouen.fr\/","is_default":1},{"affiliation":"Centre national de la recherche scientifique","url":"http:\/\/www.cnrs.fr\/","is_default":0}],"username":"kevin-jacq","note":null,"link":null,"image":{"source":"\/img\/avatars\/010.png","placeholder":"\/img\/avatars\/010.png"},"badges":[{"id":2,"image":{"source":"\/img\/badges\/bronze.svg","placeholder":"\/img\/badges\/bronze.svg"},"name":"Author"}],"verified":0,"is_verified_user":false,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},"journal":null,"journal_name":null,"journal_link":null,"article_citation":null,"public":1,"has_versions":0,"link":null,"total_collections":0,"number_of_steps":21,"authors":[{"name":"Kevin Jacq","affiliation":"Universit\u00e9 Savoie Mont Blanc","affiliations":[],"username":"kevin-jacq","note":null,"link":null,"image":{"source":"\/img\/avatars\/010.png","placeholder":"\/img\/avatars\/010.png"},"badges":[],"verified":1,"is_verified_user":true,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},{"name":"William Rapuc","affiliation":"Universit\u00e9 Savoie Mont Blanc","affiliations":[],"username":"w2y274w2s213","note":null,"link":null,"image":{"source":"\/img\/avatars\/011.png","placeholder":"\/img\/avatars\/011.png"},"badges":[],"verified":0,"is_verified_user":false,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},{"name":"Claire Blanchet","affiliation":"Universit\u00e9 Savoie Mont Blanc","affiliations":[],"username":null,"note":null,"link":null,"image":{"source":null,"placeholder":null},"badges":[],"verified":0,"is_verified_user":false,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},{"name":"Estelle Ployon","affiliation":"Universit\u00e9 Grenoble Alpes","affiliations":[],"username":null,"note":null,"link":null,"image":{"source":null,"placeholder":null},"badges":[],"verified":0,"is_verified_user":false,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},{"name":"Cecile Pignol","affiliation":"Universit\u00e9 Savoie Mont Blanc","affiliations":[],"username":"cecile-pignol","note":null,"link":null,"image":{"source":"\/img\/avatars\/006.png","placeholder":"\/img\/avatars\/006.png"},"badges":[],"verified":1,"is_verified_user":true,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},{"name":"Didier Coquin","affiliation":"Universit\u00e9 Savoie Mont Blanc","affiliations":[],"username":null,"note":null,"link":null,"image":{"source":null,"placeholder":null},"badges":[],"verified":0,"is_verified_user":false,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},{"name":"Bernard Fanget","affiliation":"Universit\u00e9 Savoie Mont Blanc","affiliations":[],"username":null,"note":null,"link":null,"image":{"source":null,"placeholder":null},"badges":[],"verified":0,"is_verified_user":false,"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false}],"versions":[],"groups":[],"is_owner":1,"has_subprotocols":0,"is_subprotocol":0,"is_bookmarked":0,"can_claim_authorship":0,"can_accept_authorship":0,"can_be_copied":1,"can_remove_fork":1,"fork_id":null,"url":"https:\/\/www.protocols.io\/view\/structure-from-motion-multi-view-photogrammetry-ap-bkdpks5n","forks_count":{"private":0,"public":0},"access":{"can_view":1,"can_remove":1,"can_add":0,"can_edit":0,"can_publish":0,"can_get_doi":1,"can_share":1,"can_move":1,"can_move_outside":1,"can_transfer":1,"can_download":1,"is_locked":0},"guid":"CBA526B0E87411EA8EB74B98EEB0A341","state_version_id":596,"steps":[{"id":1030519,"guid":"5F3BCA90F50F11EA9888DBC50D398C25","previous_id":null,"previous_guid":null,"modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"E259F03D6FC94E25AD645B159C1BB020","order_id":1,"type_id":6,"title":"Section","source":{"title":"General description of the acquisition bench"}},{"id":1054724,"guid":"5B461F27E0274088BFDFD06A267D7C69","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj7ebbhyf.jpg\" \/><\/div><\/div>"}},{"id":1054725,"guid":"CF1D7CEAE34C441F93AA0ED91A4A02D6","order_id":2,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj7ebbhyf.jpg\" \/><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#A492FF","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1030532,"guid":"32EF0390F51311EA9888DBC50D398C25","previous_id":1030519,"previous_guid":"5F3BCA90F50F11EA9888DBC50D398C25","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"4346DAD8796F44CFA469BA822FE3BAC7","order_id":1,"type_id":6,"title":"Section","source":{"title":"General description of the acquisition bench"}},{"id":1054724,"guid":"FE816CBE9A1A4943B29579BB1F89FEBA","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj9ubbhyf.jpg\" \/><\/div><\/div>"}},{"id":1054725,"guid":"A9B6F3ADEFC743A78672834DBE5A602A","order_id":2,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj9ubbhyf.jpg\" \/><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#A492FF","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1030533,"guid":"01D838C0F51411EA9888DBC50D398C25","previous_id":1030532,"previous_guid":"32EF0390F51311EA9888DBC50D398C25","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"552A077B9A7E480EB9E767A7E0578F15","order_id":1,"type_id":6,"title":"Section","source":{"title":"Camera acquisition parameters and calibration"}},{"id":1054724,"guid":"BF4432C05D344EE7BE65F9B711866442","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><\/div>"}},{"id":1054725,"guid":"26A0A7DB54B74C87A6A4983C6C904322","order_id":2,"type_id":19,"title":"safety","source":{"body":"<div class = \"text-blocks\"><div class = \"text-block\">It is important that the parameters related to the camera (shutter speed, aperture, etc.) are fixed throughout the acquisition. The autofocus must also be disabled.<\/div><\/div>","link":""}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#94EBFF","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1030534,"guid":"654149B0F51411EA9888DBC50D398C25","previous_id":1030533,"previous_guid":"01D838C0F51411EA9888DBC50D398C25","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"DC1322F559004E8B9D021BA2051ABC00","order_id":1,"type_id":6,"title":"Section","source":{"title":"Camera acquisition parameters and calibration"}},{"id":1054724,"guid":"219FD59A88F84DBFB5D04A568774666A","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">With the chosen acquisition parameters, the camera must be calibrated in two steps:<\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#94EBFF","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1030605,"guid":"A4D0E2A0F51611EA9888DBC50D398C25","previous_id":1030534,"previous_guid":"654149B0F51411EA9888DBC50D398C25","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"3B458ED9B80D46D9885C279809161BFB","order_id":1,"type_id":6,"title":"Section","source":{"title":"Camera acquisition parameters and calibration"}},{"id":1054724,"guid":"02B5B1D30E6A4FEF822321A71B4751F4","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">The first is to perform a white balance, in order to obtain relevant colors according to the lighting, this is called radiometric correction.<\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#94EBFF","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1030616,"guid":"03A7E850F51711EA9888DBC50D398C25","previous_id":1030605,"previous_guid":"A4D0E2A0F51611EA9888DBC50D398C25","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"8D83FC1DD7314A1AAE648903A1A4E4C9","order_id":1,"type_id":6,"title":"Section","source":{"title":"Camera acquisition parameters and calibration"}},{"id":1054724,"guid":"272CEE5BDE0144B9A0D36DEEBEBFF269","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">The second consists in taking pictures of a checkerboard from several angles and over the entire surface acquired by the camera. This allows to correct the images for geometric distortions induced by the lens that imply that the pixels are not square.<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj7hbbhyf.jpg\" \/><\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj7jbbhyf.jpg\" \/><\/div><div class = \"text-block\">The Agisoft Lens software uses these checkerboard images to estimate the corrections to be applied to the images.<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj75bbhyf.png\" \/><\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj76bbhyf.png\" \/><\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj77bbhyf.png\" \/><\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj78bbhyf.png\" \/><\/div><\/div>"}},{"id":1054725,"guid":"D710579D30DA4D8DA1C6EB576E3B08A5","order_id":2,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj7hbbhyf.jpg\" \/><\/div>"}},{"id":1054726,"guid":"E866C34F95CC4010B8EBF25E101C5806","order_id":3,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj7jbbhyf.jpg\" \/><\/div>"}},{"id":1054727,"guid":"02D622CDAF6D415E9E4B95B58A11D464","order_id":4,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj75bbhyf.png\" \/><\/div>"}},{"id":1054728,"guid":"CE0B3D33518F4150A2AC9D0CC8FC3510","order_id":5,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj76bbhyf.png\" \/><\/div>"}},{"id":1054729,"guid":"4802638E15624DE98E318B9BE1F58747","order_id":6,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj77bbhyf.png\" \/><\/div>"}},{"id":1054730,"guid":"A2AF3655E0A146DD9F46637C195B7024","order_id":7,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj78bbhyf.png\" \/><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#94EBFF","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1030624,"guid":"B306ED50F51711EA9888DBC50D398C25","previous_id":1030616,"previous_guid":"03A7E850F51711EA9888DBC50D398C25","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"F283D7732D7246E8A2520B3A58856DFE","order_id":1,"type_id":6,"title":"Section","source":{"title":"Recommendations on coded markers and their georeferencing"}},{"id":1054724,"guid":"B14761C6F124457E8A56FF11116BED57","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">The method described in this protocol relies on markers placed on rulers along the sample to create a planar spatial reference (z=0).<\/div><div class = \"text-block\">The Agisoft Photoscan or Metashape software proposes a list of markers all different which will be automatically recognized by the software. <\/div><div class = \"text-block\">These markers must be placed in a regular way so as to be present on three successive images to allow a good registration of the images and at a size not exceeding 30 pixels for the central circle. In our case, the markers are 10 cm apart and have a diameter of 1 cm.<\/div><\/div>"}},{"id":1054725,"guid":"B6DBCAB114F44BF7A591C74E585BD378","order_id":2,"type_id":19,"title":"safety","source":{"body":"<div class = \"text-blocks\"><div class = \"text-block\">Markers should be printed on a material that does not get damaged and remains clean from sediment and water. They should also not be plastified as this will reflect light, and the algorithm will be distorted. For these reasons, we decided to use a mat adhesive paper.<\/div><\/div>","link":""}},{"id":1054726,"guid":"5F9C56C1017E48DBA0AEDDEB3451D2BD","order_id":3,"type_id":19,"title":"safety","source":{"body":"<div class = \"text-blocks\"><div class = \"text-block\">These targets should be cut in squares and not in circles, keeping in mind that the targets are circles on a white background.<\/div><\/div>","link":""}},{"id":1054727,"guid":"FDA9EA2A38344F77A7F4AB47C680AE9C","order_id":4,"type_id":19,"title":"safety","source":{"body":"<div class = \"text-blocks\"><div class = \"text-block\">If a marker is damaged, it will probably be necessary to replace it with a new one that must be different from the others.<\/div><\/div>","link":""}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#84CE84","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1030629,"guid":"5C1DF250F51B11EA9888DBC50D398C25","previous_id":1030624,"previous_guid":"B306ED50F51711EA9888DBC50D398C25","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"44914433869E4435B43D5F720DB9AF93","order_id":1,"type_id":6,"title":"Section","source":{"title":"Recommendations on coded markers and their georeferencing"}},{"id":1054724,"guid":"D5FBD71FD3464CCFAA1F148B31636780","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Each marker, defined by the software, is numbered and must be georeferenced to constrain the models with this landmark created with the rules and markers.<\/div><div class = \"text-block\">The georeferencing is performed by measuring the position of the marker's center relative to a point defined as the origin. In our case, the origin was chosen as one of the corners of the sedimentary core frame by the rulers.<\/div><div class = \"text-block\">The marker numbers and their positions are recorded in a csv file which will be used by the software.<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj74bbhyf.jpg\" \/><\/div><\/div>"}},{"id":1054725,"guid":"13682E0375484004985AD7958DA49763","order_id":2,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj74bbhyf.jpg\" \/><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#84CE84","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1030705,"guid":"64698EE0F53611EA9888DBC50D398C25","previous_id":1030744,"previous_guid":"E1D21670F54211EA9888DBC50D398C25","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"B8942AEA68984E9F950E06F491BBCC9E","order_id":1,"type_id":6,"title":"Section","source":{"title":"Creation of the orthoimage"}},{"id":1054724,"guid":"D020011EE95F4AE78716039D682985FD","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">1) Importing images<\/div><div class = \"text-block\">Select the images with the \"Add Photos\" icon in the Workspace tab or in Workflow > Add Photos...<\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#EA9F6C","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1030706,"guid":"0ACD1E90F53811EA9888DBC50D398C25","previous_id":1030705,"previous_guid":"64698EE0F53611EA9888DBC50D398C25","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"D98CBC522F2E451881F2602A95B1C21D","order_id":1,"type_id":6,"title":"Section","source":{"title":"Creation of the orthoimage"}},{"id":1054724,"guid":"24FC00D29ABF4CE99E0954FEE936B5EF","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">2) Corrections with camera settings<\/div><div class = \"text-block\">Now that the images have been loaded, they need to be corrected with the camera settings. You have to import them by going to Tools > Camera Calibration...<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj79bbhyf.png\" \/><\/div><div class = \"text-block\">Then load the parameters with the \"load\" icon. Set the calibration to be applied to all images by checking the box.<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj8abbhyf.png\" \/><\/div><\/div>"}},{"id":1054725,"guid":"D5B82EBF07834EF18E49479815FBB98A","order_id":2,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj79bbhyf.png\" \/><\/div>"}},{"id":1054726,"guid":"1FC17466133540D9A579AF207890ED1D","order_id":3,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj8abbhyf.png\" \/><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#EA9F6C","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1030707,"guid":"940A7B30F53811EA9888DBC50D398C25","previous_id":1030706,"previous_guid":"0ACD1E90F53811EA9888DBC50D398C25","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"4D683C9A534F4E5C9FA39CF477FE4E9F","order_id":1,"type_id":6,"title":"Section","source":{"title":"Creation of the orthoimage"}},{"id":1054724,"guid":"1A769F93A61F40B6A7F92D05C3A42EF6","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">3) Marker detection<\/div><div class = \"text-block\">Two methods can be used to detect and georeference the markers. One automatic and one semi-automatic.<\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#EA9F6C","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1030708,"guid":"D3299480F53911EA9888DBC50D398C25","previous_id":1030707,"previous_guid":"940A7B30F53811EA9888DBC50D398C25","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"22C5FBF12C094FA498B78EFE9262DACA","order_id":1,"type_id":6,"title":"Section","source":{"title":"Creation of the orthoimage"}},{"id":1054724,"guid":"77E52C2F37DC4810AFABC2052F99CCB6","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Automatic method:<\/div><div class = \"text-block\">A Python script has been developed to detect the markers and retrieve their positions in the csv file previously created in step 6.<\/div><div class = \"text-block\"><a href=\"https:\/\/github.com\/JacqKevin\/RGB_PhotoScanOrthorectification\" style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">It can be found on github<\/span><\/a><\/div><div class = \"text-block\">. <\/div><div class = \"text-block\">Load the script that will automatically detect the markers and associate them with their coordinates (x, y, z). To do this go to Tools > Run Script...<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj8bbbhyf.jpg\" \/><\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj8dbbhyf.jpg\" \/><\/div><\/div>"}},{"id":1054725,"guid":"BACA61EEB10747EA847E9F60515BCB50","order_id":2,"type_id":19,"title":"safety","source":{"body":"<div class = \"text-blocks\"><div class = \"text-block\">It is possible that this script must be corrected, because in the case of a change of version of the Agisoft software, the command tags may be different.<\/div><\/div>","link":""}},{"id":1054726,"guid":"4ED1CE65E0EB4597AFFDE0A6076B4121","order_id":3,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj8bbbhyf.jpg\" \/><\/div>"}},{"id":1054727,"guid":"207999EFA2EA4B88912003F570185860","order_id":4,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj8dbbhyf.jpg\" \/><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#EA9F6C","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1030709,"guid":"79ACD6A0F53A11EA9888DBC50D398C25","previous_id":1030708,"previous_guid":"D3299480F53911EA9888DBC50D398C25","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"F318A2EBF6A147A4B715F50B05EB0B29","order_id":1,"type_id":6,"title":"Section","source":{"title":"Creation of the orthoimage"}},{"id":1054724,"guid":"DB1043C789A5413181208E428BAAAE5F","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Semi-automatic method:<\/div><div class = \"text-block\">Markers can be detected in Tools > Markers > Detect markers...<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj8ebbhyf.png\" \/><\/div><div class = \"text-block\"> Then define the markers to be detected according to those that have been printed and placed on the rulers.<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj8ibbhyf.png\" \/><\/div><div class = \"text-block\"> After the markers have been detected, it is necessary to manually enter their positions in x,y, and z in meters.<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj8kbbhyf.png\" \/><\/div><\/div>"}},{"id":1054725,"guid":"CB72323176954401BE2921521AD0929A","order_id":2,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj8ebbhyf.png\" \/><\/div>"}},{"id":1054726,"guid":"E5A4785989154752BFA93EC5F5D20519","order_id":3,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj8ibbhyf.png\" \/><\/div>"}},{"id":1054727,"guid":"B53C434CF8A5484D98F081AF945BF688","order_id":4,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj8kbbhyf.png\" \/><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#EA9F6C","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1030710,"guid":"1E079E00F53C11EA9888DBC50D398C25","previous_id":1030709,"previous_guid":"79ACD6A0F53A11EA9888DBC50D398C25","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"FD1BBDE068694B03B440F19C38BCE86D","order_id":1,"type_id":6,"title":"Section","source":{"title":"Creation of the orthoimage"}},{"id":1054724,"guid":"5661CCAF3AA247D690317193D7372E29","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Now that everything has been calibrated and the markers defined, it is necessary to follow the order of the Workflow for the creation of the orthoimage.<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj8mbbhyf.png\" \/><\/div><div class = \"text-block\">The different stages of the model are visible in the Workspace tab (bottom left) by unrolling Chunk:<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj8xbbhyf.png\" \/><\/div><\/div>"}},{"id":1054725,"guid":"5D78275E61C743DDA19AEC5B1A29D644","order_id":2,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj8mbbhyf.png\" \/><\/div>"}},{"id":1054726,"guid":"9C16B3A832CF4ED29C9798E64A590F52","order_id":3,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj8xbbhyf.png\" \/><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#EA9F6C","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1030738,"guid":"58D776E0F53C11EA9888DBC50D398C25","previous_id":1030710,"previous_guid":"1E079E00F53C11EA9888DBC50D398C25","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"56AB9A34E2EA47BC9E541AA062E57DAE","order_id":1,"type_id":6,"title":"Section","source":{"title":"Creation of the orthoimage"}},{"id":1054724,"guid":"074E553ABF0F477D93D6C462BB9D24B7","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">4) Registration and assembly<\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#EA9F6C","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1030739,"guid":"C88CD900F53F11EA9888DBC50D398C25","previous_id":1030738,"previous_guid":"58D776E0F53C11EA9888DBC50D398C25","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"18E8778AF35645E6A6CFD65A989010DA","order_id":1,"type_id":6,"title":"Section","source":{"title":"Creation of the orthoimage"}},{"id":1054724,"guid":"1ABA461B47454B00B499AD42860CA3A4","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">The first step is the alignment of the images which estimates the analog pixels between them, the positions of the cameras and creates tie points that correspond to the connection points between the images.<\/div><div class = \"text-block\">Go to Workflow > Align Photos... then select settings.<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj8ubbhyf.png\" \/><\/div><div class = \"text-block\">This step is the most important. It is important to check that, following these calculations, the reconstruction is horizontal. If a curved shape appear, it is a well-known \u201cdome or arc effect\u201d due to the miss-estimations of pixel positions in x, y, and z typical of linear image acquisition.<\/div><div class = \"text-block\">To do this, use the radius of the sphere to rotate the model, by staying pressed with the left click, you can rotate it. There may be some points that are not correct, they will not prevent the continuation of the steps. The main thing is that the model is horizontal.<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj8vbbhyf.png\" \/><\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj8sbbhyf.png\" \/><\/div><div class = \"text-block\">The reconstruction error of the marker positions is also estimated, allowing to estimate areas where new control points have to be added manually to optimize the model. To add control points, select locations on images with right click > Create Marker and right click > Place Marker for the following images to associate a marker to multiple images. It may be necessary to de-align the images, before aligning them with the new control points.<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj8tbbhyf.png\" \/><\/div><\/div>"}},{"id":1054725,"guid":"FB489FA28A9B4106A6960F8B9EA3F8F8","order_id":2,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj8ubbhyf.png\" \/><\/div>"}},{"id":1054726,"guid":"64B1CFA45B774E1CB50E16C657574265","order_id":3,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj8vbbhyf.png\" \/><\/div>"}},{"id":1054727,"guid":"9B7D1989FE6E44F69A4270CCBA3DF72E","order_id":4,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj8sbbhyf.png\" \/><\/div>"}},{"id":1054728,"guid":"0A6107E07BD54621A0D88DF6D3646D92","order_id":5,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj8tbbhyf.png\" \/><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#EA9F6C","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1030740,"guid":"D9EFAF10F53F11EA9888DBC50D398C25","previous_id":1030739,"previous_guid":"C88CD900F53F11EA9888DBC50D398C25","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"A0964E1713744F36B984738DC2830E7B","order_id":1,"type_id":6,"title":"Section","source":{"title":"Creation of the orthoimage"}},{"id":1054724,"guid":"83ED33CD64E44BDB9620D437D72ABAC3","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">The second step is the dense cloud that estimates a reconstruction of the depth of each photo and determines its coordinates with the multiview stereo correspondence and the previous estimate of the image geometry.<\/div><div class = \"text-block\">To calculate the dense cloud, go to Workflow > Build Dense Cloud.<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj8wbbhyf.png\" \/><\/div><\/div>"}},{"id":1054725,"guid":"49DFDFA3009B47AB8B3D86BD89C4E41D","order_id":2,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj8wbbhyf.png\" \/><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#EA9F6C","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1030741,"guid":"9A1E98F0F54011EA9888DBC50D398C25","previous_id":1030740,"previous_guid":"D9EFAF10F53F11EA9888DBC50D398C25","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"5E5C343F1C1C4FD3B81A7BA8AD30C985","order_id":1,"type_id":6,"title":"Section","source":{"title":"Creation of the orthoimage"}},{"id":1054724,"guid":"0FC9D632D6BF4E1CA961455B9E0699AF","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">5) Mesh and orthorectification:<\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#EA9F6C","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1030742,"guid":"294EC950F54111EA9888DBC50D398C25","previous_id":1030741,"previous_guid":"9A1E98F0F54011EA9888DBC50D398C25","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"7E760300C4D54888B857AD7A9D0510AB","order_id":1,"type_id":6,"title":"Section","source":{"title":"Creation of the orthoimage"}},{"id":1054724,"guid":"490399063A9C4802BF552F0E7425E51E","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">The algorithm then uses the points of the dense cloud to generate a closed surface with triangular surfaces, this step is called meshing.<\/div><div class = \"text-block\">It can be made with Workflow > Build Mesh...<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj8ybbhyf.png\" \/><\/div><div class = \"text-block\">Look at the result of the 3D model. In the case of a very dark image it means that the model is upside down, otherwise the model is in the right direction. This is to be taken into account in the next step.<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj8zbbhyf.png\" \/><\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj82bbhyf.png\" \/><\/div><\/div>"}},{"id":1054725,"guid":"FE4F449E70C54D3B852C6F36228FEDFB","order_id":2,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj8ybbhyf.png\" \/><\/div>"}},{"id":1054726,"guid":"0CA3A2169F064503B6205B0C652A727E","order_id":3,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj8zbbhyf.png\" \/><\/div>"}},{"id":1054727,"guid":"0CAB8624EA554832BB71F0551E03253E","order_id":4,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj82bbhyf.png\" \/><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#EA9F6C","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1030743,"guid":"936C2940F54111EA9888DBC50D398C25","previous_id":1030742,"previous_guid":"294EC950F54111EA9888DBC50D398C25","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"7E4AADF52723420588DA8BBB7B34849E","order_id":1,"type_id":6,"title":"Section","source":{"title":"Creation of the orthoimage"}},{"id":1054724,"guid":"0999030AF0CB4A218FC37956D4423091","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Finally, the orthorectified image is estimated from the projection of the colored mesh in a 2D space to correct perspective image and projection distortions.<\/div><div class = \"text-block\">To perform this step, go to Workflow > Build Orthomosaic...<\/div><div class = \"text-block\">If the model is in the right direction then select the default settings, otherwise change Top XY to Bottom XY.<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj83bbhyf.png\" \/><\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj84bbhyf.jpg\" \/><\/div><div class = \"text-block\">Finally it is possible to export the orthophoto with File > Export Orthomosaic > Export JPEG\/TIFF\/png...<\/div><\/div>"}},{"id":1054725,"guid":"FD43F8E7D3FA4977933E0186AE38AF74","order_id":2,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj83bbhyf.png\" \/><\/div>"}},{"id":1054726,"guid":"CC8EEC57BC0C418AA9F65F044EF9903D","order_id":3,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/s3.amazonaws.com\/protocols-files\/public\/20334a051ba8c3edcdfc8008ee8e685c1e9a2b731974dc565b8a74e1f890b3d3\/cj84bbhyf.jpg\" \/><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#EA9F6C","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":1030744,"guid":"E1D21670F54211EA9888DBC50D398C25","previous_id":1030629,"previous_guid":"5C1DF250F51B11EA9888DBC50D398C25","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"ADF793B365FE4F5D8FAF407B9B9F3855","order_id":1,"type_id":6,"title":"Section","source":{"title":"Image acquisition"}},{"id":1054724,"guid":"DB13B10FE0974B5B87366F8248BF7F5B","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">The acquisition of the images must be carried out to have sufficient overlap between the successive images. <\/div><div class = \"text-block\">In our case, we have chosen an overlap of 75% so that each point of the sample is present on 4 images.<\/div><\/div>"}}],"cases":[],"data":null,"html":null,"section":null,"section_color":"#FFED92","section_duration":0,"critical":null,"critical_id":null,"duration":0}],"document":null,"materials":[],"description":"<div class = \"text-blocks\"><div class = \"text-block\">Image acquisition is the first step to save primary color information for environmental samples before disturbing them with other, mainly destructive analyses. The improvement of RGB cameras and image processing algorithms allows to obtain a metrically calibrated image at high resolution called ortho-image. The way to obtain this image requires the processing of several raw images acquired along the sample. We propose a semi-automatic method that uses metrically calibrated targets to create the ortho-image with Agisoft Photoscan or Metashape software.<\/div><\/div>","changed_on":1600007628}