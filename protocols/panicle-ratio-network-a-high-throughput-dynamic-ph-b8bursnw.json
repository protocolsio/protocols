{"access":{"can_view":true,"can_edit":false,"can_remove":false,"can_add":false,"can_publish":false,"can_get_doi":false,"can_share":true,"can_move":true,"can_move_outside":true,"can_transfer":true,"can_download":true,"is_locked":false},"authors":[{"name":"Ziyue Guo","affiliation":"Huazhong Agricultural University","affiliation_url":null,"username":"","link":null,"image":{"source":"","placeholder":"","webp_source":""},"note":"","is_verified_author":true,"is_verified_user":false},{"name":"Chenghai Yang","affiliation":"USDA-Agricultural Research Service","affiliation_url":null,"username":"","link":null,"image":{"source":"","placeholder":"","webp_source":""},"note":"","is_verified_author":true,"is_verified_user":false},{"name":"Wangnen Yang","affiliation":"Huazhong Agricultural University","affiliation_url":null,"username":"","link":null,"image":{"source":"","placeholder":"","webp_source":""},"note":"","is_verified_author":true,"is_verified_user":false},{"name":"Guoxing Chen","affiliation":"Huazhong Agricultural University","affiliation_url":null,"username":"","link":null,"image":{"source":"","placeholder":"","webp_source":""},"note":"","is_verified_author":true,"is_verified_user":false},{"name":"Zhao Jiang","affiliation":"Huazhong Agricultural University","affiliation_url":null,"username":"","link":null,"image":{"source":"","placeholder":"","webp_source":""},"note":"","is_verified_author":true,"is_verified_user":false},{"name":"Botao Wang","affiliation":"Huazhong Agricultural University","affiliation_url":null,"username":"","link":null,"image":{"source":"","placeholder":"","webp_source":""},"note":"","is_verified_author":true,"is_verified_user":false},{"name":"Jian Zhang","affiliation":"Huazhong Agricultural University","affiliation_url":null,"username":"","link":null,"image":{"source":"","placeholder":"","webp_source":""},"note":"","is_verified_author":true,"is_verified_user":false}],"before_start":"{\"blocks\":[{\"key\":\"kv0e\",\"text\":\"To use our trained model, make sure the image resolution is between 0.6 and 2.4 mm.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","book_chapter":null,"can_accept_authorship":false,"can_be_copied":true,"can_claim_authorship":false,"can_remove_fork":false,"can_sign":false,"child_steps":{},"cited_protocols":[],"collection_items":[],"created_on":1651065668,"creator":{"name":"ziyue.guo ","affiliation":"","affiliation_url":null,"username":"n4ple1w1s1v4yle1","link":null,"image":{"source":"/img/avatars/012.png","placeholder":"/img/avatars/012.png","webp_source":""},"badges":[{"id":2,"name":"Author","image":{"source":"/img/badges/bronze.svg","placeholder":"/img/badges/bronze.svg"}}],"affiliations":[]},"description":"{\"blocks\":[{\"key\":\"c27j0\",\"text\":\"In order to increase the convenience and efficiency of rice cultivation and breeding, a PR evaluation model based on deep learning and UAV–RGB images was established in this study by focusing on the ETP and HD, which affect rice yield and reflect rice growth. Based on an image regression method that reduces the effects of cross-overlapping due to an excessive density of targets, PRNet used a combination of DenseNet and SPP to extract the features of growing panicles during the rice heading stage.The training results showed that the model performed well with a data set collected in 2019, and the estimation results obtained using the test data set demonstrated that the model had good robustness.Images containing a whole rice plot can be used as direct inputs for PRNet to obtain PR, and then ETP and HD can be determined with high accuracy according to the PR curve.After testing images with different resolutions in the model, the acceptable resolution range for the model was determined to be between 0.6 mm and 2.4 mm when the RMSE for the estimated results was less than 15%. Thus, data collection schemes were presented to facilitate the use of PRNet.However, different types of cameras have different image quality settings, and the model's estimation accuracy might not be ideal even if the resolution is acceptable.The accuracy of the estimations obtained by the model were higher for rice plots in the center of images captured around noon compared with those at other times or at the edges of images.Based on a high-throughput and efficient UAV–ultra-high-definition imaging platform, PRNet is suitable for nondestructive PR monitoring in more than 2,000 plots within 10 min.Furthermore, this scheme can be extended to other panicle-related crop phenotypic analyses and provide a reference for extracting indicators determined by several traits, thereby accelerating the development of in situ field crop phenotypic information extraction.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","disclaimer":"DISCLAIMER – FOR INFORMATIONAL PURPOSES ONLY; USE AT YOUR OWN RISK\u003cbr\u003e\u003cbr\u003eThe protocol content here is for informational purposes only and does not constitute legal, medical, clinical, or safety advice, or otherwise; content added to \u003ca href=\"http://protocols.io/\"\u003eprotocols.io\u003c/a\u003e is not peer reviewed and may not have undergone a formal approval of any kind. Information presented in this protocol should not substitute for independent professional judgment, advice, diagnosis, or treatment. Any action you take or refrain from taking using or relying upon the information presented here is strictly at your own risk. You agree that neither the Company nor any of the authors, contributors, administrators, or anyone else associated with \u003ca href=\"http://protocols.io/\"\u003eprotocols.io\u003c/a\u003e, can be held responsible for your use of the information contained in or linked to this protocol or any of our Sites/Apps and Services.","document":"","documents":[{"id":0,"type_id":0,"filename":"","key":"","color":"","height":0,"width":0,"is_document":null,"original_file_id":null,"thumb_url":"https://www.protocols.io/img/extensions/tif.png","size":null,"is_private":0,"is_new":0,"ofn":"figure2.tif","url":"https://s3.amazonaws.com/protocols-files/files/hegcbs6m7.tif","bucket_name":null,"s3_webp_url":"","file_id":233666}],"doi":"dx.doi.org/10.17504/protocols.io.bp2l6176rvqe/v1","doi_status":2,"fork_id":null,"fork_info":null,"forks":[],"funders":[],"groups":[{"id":51438,"uri":"hzau_larsc_lab","title":"HZAU_LARSC_Lab","image":{"source":"https://s3.amazonaws.com/protocols-files/files/9969BF2CC62A11EC9FE10A58A9FEAC02-placeholder.png","placeholder":"https://s3.amazonaws.com/protocols-files/files/9969BF2CC62A11EC9FE10A58A9FEAC02-placeholder.png"},"tech_support":{"email":null,"phone":null,"use_email":false,"hide_contact":false,"url":null}}],"guid":"DEBDE3D0C62C11EC9AFE87775147BA7D","guidelines":"{\"blocks\":[{\"key\":\"697pg\",\"text\":\"plese just follow the steps.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","has_references":false,"has_versions":false,"id":61524,"image":{"source":"https://s3.amazonaws.com/protocols-files/files/heggbs6m7.jpg","webp_source":"https://s3.amazonaws.com/protocols-files/files/hegfbs6m7.webp","placeholder":"","webp_placeholder":""},"image_attribution":"","in_trash":false,"is_bookmarked":false,"is_contact_suspended":false,"is_content_confidential":false,"is_content_warning":false,"is_in_transfer":false,"is_owner":true,"is_retracted":false,"is_shared_directly":false,"is_subprotocol":null,"is_unlisted":false,"item_id":913977,"journal":null,"journals":[],"keywords":null,"last_modified":1651110598,"link":"https://doi.org/10.6084/m9.figshare.17169266.v1, https://github.com/Ziyue-Guo/Panicle_Ratio_Network.git","location":null,"manuscript_citation":"","materials":[],"materials_text":"{\"blocks\":[{\"key\":\"62o2n\",\"text\":\"A camera that can take high-resolution images.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","ownership_history":null,"parent_collections":[],"parent_protocols":[],"peer_reviewed":false,"public":true,"public_fork_note":"","published_on":1651110598,"references":[],"related_equipments":[],"retraction_reason":null,"shared_access_id":16,"show_comparison":false,"sign_info":null,"state_version_id":162,"stats":{"is_voted":false,"number_of_views":8,"number_of_steps":6,"number_of_bookmarks":0,"number_of_comments":0,"number_of_bookmarked_comments":0,"number_of_steps_comments":0,"number_of_protocol_comments":0,"number_of_exports":0,"number_of_runs":0,"number_of_votes":0,"number_of_reagents":0,"number_of_equipments":0,"number_of_collections":0,"number_of_forks":{"private":0,"public":0},"number_of_accessible_forks":0},"status":{"id":1,"info":"We use this protocol and it’s working."},"steps":[{"id":1390279,"guid":"E63E0E50C62C11EC9AFE87775147BA7D","previous_id":0,"previous_guid":null,"section":"","section_color":"","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"9sj9l\",\"text\":\"High-resolution images of rice at heading stage were obtained by camera equipment.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":61524,"case_id":0,"critical_ids":"","duration":3888000,"original_id":0,"number":"1","cases":[],"critical":null},{"id":1390282,"guid":"D266C060C62D11EC9AFE87775147BA7D","previous_id":1390279,"previous_guid":"E63E0E50C62C11EC9AFE87775147BA7D","section":"","section_color":"","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"26q1o\",\"text\":\"After image collection, some plots were selected to investigate their panicle number and tillering number.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":61524,"case_id":0,"critical_ids":"","duration":3888000,"original_id":0,"number":"2","cases":[],"critical":null},{"id":1390765,"guid":"53B52650C68A11EC9AFE87775147BA7D","previous_id":1390282,"previous_guid":"D266C060C62D11EC9AFE87775147BA7D","section":"","section_color":"","section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"9gbq2\",\"text\":\"The plot to be observed was cropped from the original image, and the corresponding plot image was annotated according to the ground survey results.The data that support the findings of this study are openly available in [Figshare] at https://doi.org/10.6084/m9.figshare.17169266.v1.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":61524,"case_id":0,"critical_ids":"","duration":1814400,"original_id":0,"number":"3","cases":[],"critical":null},{"id":1390766,"guid":"496CE5B0C68B11EC9AFE87775147BA7D","previous_id":1390765,"previous_guid":"53B52650C68A11EC9AFE87775147BA7D","section":"","section_color":null,"section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"6ek3s\",\"text\":\"A deep CNN (DCNN) for automatically estimating PR was built based on the Keras library with the TensorFlow backend.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":61524,"case_id":0,"critical_ids":"","duration":604800,"original_id":0,"number":"4","cases":[],"critical":null},{"id":1390767,"guid":"E3E2DEA0C68C11EC9AFE87775147BA7D","previous_id":1390766,"previous_guid":"496CE5B0C68B11EC9AFE87775147BA7D","section":"","section_color":null,"section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"bb1p4\",\"text\":\"The data set is divided into training set, validation set and test set.Model parameters are optimized using training sets and validation sets.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}","data":null,"protocol_id":61524,"case_id":0,"critical_ids":"","duration":7200,"original_id":0,"number":"5","cases":[],"critical":null},{"id":1390768,"guid":"699D7D20C68D11EC9AFE87775147BA7D","previous_id":1390767,"previous_guid":"E3E2DEA0C68C11EC9AFE87775147BA7D","section":"","section_color":null,"section_duration":0,"is_substep":false,"step":"{\"blocks\":[{\"key\":\"90hqa\",\"text\":\"Training the heading proportion recognition model.All the code can be viewed at GitHub at https://github.com/Ziyue-Guo/Panicle_Ratio_Network.git.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[{\"key\":0,\"offset\":90,\"length\":54}],\"data\":{}}],\"entityMap\":{\"0\":{\"type\":\"link\",\"mutability\":\"MUTABLE\",\"data\":{\"guid\":\"B2613190C68F11EC85DD0A58A9FEAC02\",\"url\":\"https://github.com/Ziyue-Guo/Panicle_Ratio_Network.git\"}}}}","data":null,"protocol_id":61524,"case_id":0,"critical_ids":"","duration":14400,"original_id":0,"number":"6","cases":[],"critical":null}],"template_id":1,"title":"Panicle Ratio Network: A high-throughput dynamic phenotype recognition model based on ultra-high-definition unmanned aerial vehicle images for rice panicle analysis in fields","title_html":"\u003cp\u003ePanicle Ratio Network: A high-throughput dynamic phenotype recognition model based on ultra-high-definition unmanned aerial vehicle images for rice panicle analysis in fields\u003c/p\u003e","type_id":1,"units":[{"id":1,"type_id":3,"name":"µL","can_manage":0},{"id":2,"type_id":3,"name":"mL","can_manage":0},{"id":3,"type_id":3,"name":"L","can_manage":0},{"id":4,"type_id":3,"name":"µg","can_manage":0},{"id":5,"type_id":3,"name":"mg","can_manage":0},{"id":6,"type_id":3,"name":"g","can_manage":0},{"id":7,"type_id":3,"name":"kg","can_manage":0},{"id":8,"type_id":3,"name":"ng","can_manage":0},{"id":9,"type_id":3,"name":"Hz","can_manage":0},{"id":10,"type_id":24,"name":"°C","can_manage":0},{"id":11,"type_id":24,"name":"°К","can_manage":0},{"id":12,"type_id":24,"name":"°F","can_manage":0},{"id":13,"type_id":25,"name":"Mass Percent","can_manage":0},{"id":14,"type_id":25,"name":"% volume","can_manage":0},{"id":15,"type_id":25,"name":"Mass / % volume","can_manage":0},{"id":16,"type_id":25,"name":"Parts per Million (PPM)","can_manage":0},{"id":17,"type_id":25,"name":"Parts per Billion (PPB)","can_manage":0},{"id":18,"type_id":25,"name":"Parts per Trillion (PPT)","can_manage":0},{"id":19,"type_id":25,"name":"Mole Fraction","can_manage":0},{"id":20,"type_id":25,"name":"Mole Percent","can_manage":0},{"id":21,"type_id":25,"name":"Molarity (M)","can_manage":0},{"id":22,"type_id":25,"name":"Molarity (m)","can_manage":0},{"id":23,"type_id":25,"name":"Genome copies per ml","can_manage":0},{"id":24,"type_id":3,"name":"μV","can_manage":0},{"id":25,"type_id":3,"name":"ms","can_manage":0},{"id":26,"type_id":3,"name":"pg","can_manage":0},{"id":27,"type_id":25,"name":"Molarity dilutions","can_manage":0},{"id":28,"type_id":25,"name":"millimolar (mM)","can_manage":0},{"id":29,"type_id":25,"name":"micromolar (µM)","can_manage":0},{"id":30,"type_id":25,"name":"nanomolar (nM)","can_manage":0},{"id":31,"type_id":25,"name":"picomolar (pM)","can_manage":0},{"id":32,"type_id":24,"name":"Room temperature","can_manage":0},{"id":33,"type_id":30,"name":"rpm","can_manage":0},{"id":34,"type_id":30,"name":"x g","can_manage":0},{"id":165,"type_id":24,"name":"On ice","can_manage":0},{"id":200,"type_id":32,"name":"cm","can_manage":0},{"id":201,"type_id":32,"name":"mm","can_manage":0},{"id":202,"type_id":32,"name":"µm","can_manage":0},{"id":203,"type_id":32,"name":"nm","can_manage":0},{"id":204,"type_id":25,"name":"mg/mL","can_manage":0},{"id":205,"type_id":25,"name":"µg/µL","can_manage":0},{"id":206,"type_id":25,"name":"% (v/v)","can_manage":0},{"id":1324,"type_id":30,"name":"rcf","can_manage":0},{"id":1359,"type_id":35,"name":"Bar","can_manage":0},{"id":1360,"type_id":35,"name":"Pa","can_manage":0}],"uri":"panicle-ratio-network-a-high-throughput-dynamic-ph-b8bursnw","url":"https://www.protocols.io/view/panicle-ratio-network-a-high-throughput-dynamic-ph-b8bursnw","version_class":61524,"version_data":{"id":0,"code":"b8bursnw","version_class":61524,"parent_id":null,"parent_uri":null,"is_same_owner":false,"is_parent_public":false,"has_pending_merge_request":false,"has_approved_merge_request":false,"merge_request":null},"version_id":0,"version_uri":"panicle-ratio-network-a-high-throughput-dynamic-ph-bp2l6176rvqe/v1","versions":[{"id":61524,"title":"Panicle Ratio Network: A high-throughput dynamic phenotype recognition model based on ultra-high-definition unmanned aerial vehicle images for rice panicle analysis in fields","title_html":"\u003cp\u003ePanicle Ratio Network: A high-throughput dynamic phenotype recognition model based on ultra-high-definition unmanned aerial vehicle images for rice panicle analysis in fields\u003c/p\u003e","image":{"source":"https://s3.amazonaws.com/protocols-files/files/heggbs6m7.jpg","webp_source":null,"placeholder":"https://s3.amazonaws.com/protocols-files/files/heggbs6m7.jpg","webp_placeholder":null},"doi":"dx.doi.org/10.17504/protocols.io.bp2l6176rvqe/v1","uri":"panicle-ratio-network-a-high-throughput-dynamic-ph-b8bursnw","published_on":1651110598,"modified_on":1651110598,"version_class":61524,"version_id":0,"version_code":"b8bursnw","version_uri":"panicle-ratio-network-a-high-throughput-dynamic-ph-bp2l6176rvqe/v1","created_on":1651065668,"categories":null,"creator":{"name":"ziyue.guo ","affiliation":null,"affiliation_url":null,"username":"n4ple1w1s1v4yle1","link":null,"image":{"source":"/img/avatars/012.png","placeholder":"/img/avatars/012.png","webp_source":""}},"stats":{"number_of_comments":0,"last_comment_time":0}}],"warning":"{\"blocks\":[{\"key\":\"athfj\",\"text\":\"There is no particularly dangerous operation in this experiment.\",\"type\":\"unstyled\",\"depth\":0,\"inlineStyleRanges\":[],\"entityRanges\":[],\"data\":{}}],\"entityMap\":{}}"}